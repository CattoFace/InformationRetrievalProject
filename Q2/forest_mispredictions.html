<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12</th>
      <td>poli</td>
      <td>Detecting Political Bias Trolls  in Twitter Data   Soon A e Chun1, Richard Holowczak2, Kannan Neten Dharan3, Ruoyu Wang3,  Soumaydeep Basu3 and James Geller3  1Information Systems and Informatics  at CSI , City University of New York, New York, U .S.A.  2Information Systems and Statistics, Baruch College, New York, U .S.A.  3Department of Computer Science, NJIT, Newark, NJ, U .S.A.    Keywords : Troll Detection , Alt-right Tweets, Political Biases , Twitter , Social Network Mining , Election Manipulation.   Abstract:  Ever since Rus sian trolls have been brought to light, their interference in the 2016 US Presidential elections  has been monitored and studied . These Russian trolls employ fake accounts registered on several major social  media si tes to influence public opinion  in other countries . Our work involves discovering patterns in these  tweets and classifying them by training  different machine learning models  such as Support Vector Machines,  Word2vec , Google BERT,  and neural network models, and then applying them to several large Twitter  datasets  to compare  the effectiveness of the  different models. Two classification tasks are utilized  for this  purpose. The first one is used to classify any given tweet as either troll or non -troll tweet. The second model  classifies specific tweets as coming from left trolls or right trolls, based on apparent extreme political  orientation s. On the given data sets , Google BERT provide s the best results, with an accuracy of 89.4% for  the left/right troll detector and 99% for the troll/non -troll detector . Temporal,  geographic , and sentiment   analyses  were  also performed and results were  visualized.    1 INTRODUCTION   The presence of trolls using social media to influence  politics, healthcare and other social issues has  become a widespread phenomenon akin to spam and  phishing. Ever since Russian trolls were brought to  light during the 2016 US Presidential elections, the   influence of trolls has been studied in Computer  Science  and other fields . However, there is no clear  definition of what a troll is. Most authors assume that  it is obvious and their meaning of the word troll can  only be inferred from their treatment of th e subject.  Mojica’s  use of the word “troll” focuses on  determining the intentions of the user  (Mojica, 2016) ,  whether the user is attempting to keep their intention  hidden, how the posts were interpreted by other users,  and what the reactions are to specif ic posts . Kumar et  al. (Kumar, 2014)  use the term "trolling" w hen a user  posts and spreads in formation that is deceptive,  inaccurate, or outright rude. The authors develop ed an  algorithm called TIA, Troll Identification Algorithm,  in order to classify such  users as malicious or benign.  Kumar’s  study is more focused on the integrity of the  network that the trolls are working on. Thus, anyone  who posts information that is incorrect may be a troll,  unlike in (Mojica, 2016), where the intentions of a user are t he focus. In addition, if non -troll users make  negative comments or posts, they are also considered  trolls. The decision  for being classified as a troll is not  only based on the users' own posts, but also on the  responses.   In our work , we focus on a subclass of trolls  defined by their domain, namely “political trolls” that  have nefarious intentions. We  use machine learning   algorithms  to identify Russian troll tweets. More  specifically, we employ known Russian troll tweets   (Fivethirtyeight, Roeder, 201 8) to build  classification  model s that classify any tweet as either being from a  Russian troll or not. An initial review indicated that  not all Russian trolls are of the same kind.  Specifically, we discovered that some of the trolls  indicate a “left” polit ical orientation, while other  trolls appear to be politically at the right end of the  spectrum. Therefore, after building a machine  learning model that distinguishes between troll and  non-troll tweets we buil t another model that separates  left trolls  from right t rolls. Figure 1  shows the  overall  process flow. The box marked as Troll Classifier is  the result of running a machine learning model on  data that was already classified by humans. Similarly,  the Political Bias  Classifier model has been  developed to detect  the political  bias towards “left” or 334 Chun, S., Holowczak, R., Dharan, K., Wang, R., Basu, S. and Geller, J. Detecting Political Bias Trolls in Twitter Data. DOI: 10.5220/0008350303340342 InProceedings of the 15th International Conference on Web Information Systems and Technologies (WEBIST 2019) , pages 334-342 ISBN: 978-989-758-386-5 Copyright c/circlecopyrt2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved “right”  orientation  in the troll dataset.  To analyze  whether trolls have a political bias to ward  one or the  other political affiliation, we use  a two-step analysis .  We first identify a tweet as coming from a troll or not ,  using  the troll classifier and then further predict  whether it expresses a right or left bias.     Figure 1:  Political Bias Troll Detection Framework .  2 DATASETS    Twitter data has been widely used in many text  mining projects. Unlike other social media platforms,  tweets are public and easy to retrieve from Twitter.  Twitter has APIs that help users to retrieve da ta in a  methodological way, e.g., for a specific geographic  region, a specific timeframe, etc. One can fetch data  from a targeted set of users as well.   For building our troll  model and the political bias   detection model, we used a dataset published by  an  online news portal called FiveThirtyEight  (Roeder,  2018 ). This dataset contains  roughly 3 million tweets  that Twitter concluded were associated with the  “Internet Research Agency (IRA).” The IRA is a  company paid by the Russian government to sow  disinf ormation ( Wikipedi a, 2019 ). The data is  completely open source licensed and includes  2,973,371 tweets from 2,848 Twitter handles. It  includes every tweet’s author, text and date; the  author’s follower count and the number of accounts  the author followed; a nd an indication of whether the  tweet was a retweet. Authors are not real names , but  fabricated personas. We call this data table  the  Russian Troll  dataset , where  each tweet is considered   to be from  a troll.   Every tweet in the  data is also labeled with an  “account_type ” that shows whether the  tweet indicates a  left or right political orientation.  Many  tweets are written in the Russian  language . These  tweets have an “account_type ” Russian , which we did  not consider as part of our dataset.   There are over  1.538K tweets identified as “right ” and  approx imately  890K as having a “ left” political bias.    In the first step of  preprocessing , we removed  URLs . We also removed Twitter handles that  appeared to be irrelevant to the classification, and we  removed Non -ASCI I characters from the tweets,   using the ‘Pandas’ package of P ython  (McKinney,  2017;  https://pandas.pydata.org ).  3 TROLL CLASSIFICATION  MODELS   The training  of the troll vs. non -troll and right troll vs.  left troll classifiers was performed  using different  machine learning approaches  to compare the ir  performance s. For all the  machine learning  algorithm s that we are using,  to derive  a classifier,  positive and negative instances are necessary. The  positive instances are constituted by the  Russian Troll  dataset . However, we needed to generate a negative  (i.e. non -troll) data set of the same size. For this we  fetched 3 million random tweets from several Twitter  feed sites ( e.g., http://followthehashtag.com/datasets/   free-twitter -dataset -usa-200000 -free-usa-tweets/ )  and the Tweepy API ( Roesslein, 2019 ) to fetch real  time tweets. We labeled th is dataset as “non-troll, ”  hence, we will call it Non-Troll dataset .   Unfortunately, it was impossible to ascertain that  every on e of these 3 million random tweets is not a  troll tweet, thus, the training data may contain some  errors. Given the very large number of tweets posted  every day (estimated at 500 million), the negative  effect should be limited.     Table 1: Sample  Troll and Non-Troll  Tweets .  Label  Text  1 (troll)  a. Demand paper #VoteTrump #MAGA  https://t.co/YywhqRJ6DR #TrumpForPresident   b. Is Eva Braun opening for Hillary Clinton?  https://t.co/Asmktt8imd   0 (non  troll)  a. I'm at Apple Store, Pheasant Lane in Nashua,  NH https://t.co/E5FCrUFEpL   b. Super excited to continue to play basketball at  KCC next year with‚ https://t.co/QNWtA1bz08   Thus, the troll detection model was built using the  6 million tweets of the Russian Troll dataset  and the  Non-Troll dataset  combined together for training and  testing data.   Twitter Feed   Troll Classifier   Troll    Non-Troll   Political Bias Classifier   Left Troll Tweet    Right Troll Tweet  Detecting Political Bias Trolls in Twitter Data 335 A tweet from  the Russian Troll dataset  was  assigned the  label 1, while a tweet from  the Non -Troll  dataset  was assigned the label 0. Table 1 shows an  example of four tweets taken from the dataset, with  the label and tweet text columns, and Table 2 shows  example s of right and left political bias trolls from the  Russian Troll dataset.    In our experiments, we divided datasets int o  training and test data using an 80:20 breakdown.   Table 2 : Example of Left and Right biased Trolls .  Right  a. You do realize if democrats stop shooting people,  gun violence would drop by 90%   b. US sailor gets 1 year of prison for being reckless  w/ 6 photos of sub Hillary gets away w/ 33k  emails.. https://t.co/jmPjfPCRK4   Left a. 1 dat. 4 shootings. It’s Trump’s Birthday – Tavis  Airforce Base –   b.  1 black president out of 45 white ones is the  exception that proves the rule. The rule is racism.  And then Trump came next.   3.1 Support Vector Machine Classifier   SVM (Support Vector Machines) is a popular  supervised machine learning  technique  (Vapnik,  1995) . The Support Vector Machine conceptually  implements the following idea: input vectors are  (non-linearly ) mapped to a very high -dimensional  feature space. SVM has been proven effective for  many text categorization tasks.   In SVMs, we try to find a hyperplane in an N - dimensional space that can be used to separate the  data points with two different classificati ons.  “Support Vectors” define those points in the data set  that affect the position of the hyperplane. These are  the data points nearest to the hyperplane on both  sides.  Usually, there are several possible hyperplanes  that can be used to classify a datase t into two different  classes. The main objective of the SVM algorithm is  to find a hyperplane with the maximum margin  between the data points. This ensures that when this  model is used to classify new data points, it is likely  to classify them correctly.  It requires input data  represented as multi -dimensional vectors.   Data Preprocessing and Representation : Besides  the steps described in Section 2, w e delete d emoticons  from our dataset, since we are not taking them into  consideration for building the model.  For methods of  using  emoticons in sentiment analysis, see , e.g.,  (Bakliwal, 2012) and our previous work (Ji, 2015).   As the next step, we applied stemming to  the  dataset , using  the Porter Stemmer (Porter, 2006).   To construct one input data model , we use d a  Term Frequency  — Inverse Document Frequency  (tf- idf) vectorizer to convert the raw text data into matrix features. By combining tf and idf, we compute d a tf- idf score for every word in each  document in the  corpus. This score was used to estimate  the  significance of each word for a document , which  helps with classifying tweets.   SVM Classification Model : We built  the SVM  model using the FiveThirtyEight  datase t. The stored  model can be called later for classification of new  data.  We use d the SVM sc ikit-learn implementation  named SVC (Support Vector Classification). It is an  implementation based on libsvm (Chang, 2001 ).    In this text categorization problem,  we mad e use  of a linear SVM classifier with the r egularization  parameter, C = 0.1. The regula rization parameter is  used to control the trade -off between  misclassifications and efficiency. The higher C  is, the  fewer misclassifications are allowed , but training gets  slower. In our case, since our regularization  parameter is very small, misclassifica tions are  allowed, but training is relatively faster. As thi s  dataset is very large, this was  necessary.   We use a Radial Basis Function (RBF) kernel for  our SVM model  as the set of unique words in our data  set presents a high dimensional vector space  (Albon,   2017 ).   3.2 Neural Network Classifier with  One-hot Encoding   Data Representation : There are two popular ways of  representing natural langua ge sentences : vector  embeddings and one -hot matrices. One -hot matrices  contain no linguistic information. They indicate  whether words occur in a document (or a sentence)   but suggest nothing about its frequency , or itsr  relationships to other  words . The cre ation of one-hot  matrices begins with tokenizing the sentence, that is,  breaking it into words. Then we create d a lookup  dictionary of all the unique words /tokens , which need  not have a count or an order. Essentially, every word  is presented by a position /index  in a very long vector.  The vector component at that position is set to 1 if the  word appears. All other components in the vector are  set to 0. For example, in a dictionary that contains  only seven words, the first word would be represented  by [1, 0,  0, 0, 0, 0, 0], the second by [0, 1, 0, 0, 0, 0,  0], etc.  Each vector is of the length of the dictionary  (in our case 3000 words), and vectors are stored as  Python arrays. A whole sentence needs to be  represented by a 2 -dimensional matrix.   Neural Network Classifier : For comparison with  SVM, we first built a sequential classifier, which is a  simple neural network model that consists of a stack  of hidden layers that are executed in a specific order. WEBIST 2019 - 15th International Conference on Web Information Systems and Technologies 336 We used one dense layer and two dropout layers.   Dense neur al network layers are linear neural network  layers that are fully connected. In general, in a dense  layer, every input is connected to every output by a  weight. A dense layer is usually followed by a non - linear activation function. Dropouts are randomly  used to remove data, to prevent overfitting.   Activation functions of a node compute the output  of that node, when given any specific input or set of  inputs. The output of the activation function  is then  used as the input for the next layer . Some of the most   common activation functions  are ReLU (Rectified  Linear Unit), Sigmoid, SoftMax and Logistic  function. In our first input layer, we mad e use of the  ReLU activation function and 512 outputs come out  of that layer. Our second layer, which is a hidden  layer , consisted  of a Sigmoid activation function with  256 outputs. Our output layer , consisted  of SoftMax  activation functions. This configuration was the result  of a number of preliminary experiments and achieved  the best classifier performance.   We mad e use of a categorical crossentropy loss  function. This loss function is also called the SoftMax  loss function. It measures the performance of a  classification model , whose output is a probability  value between 0 and 1.   We use d small  batch sizes of 32 sen tences to train  our model so that we  could  check  its accuracy .  Smaller batches make it faster and easier to train a  model with a large  dataset. W e ran the algorithm for  five epochs while training, where epochs measure the  number of times the machine learni ng program goes  through the entire dataset dur ing training. We  observed that six  epochs led  to overfitting, hence we  reverted to five  epochs.  We implemented  the Neural  Network model using keras ( Chollet, 2015 ) with  Tensorflow ( Tensorflow, 2017 ) backend, which has  its own loss function and optimization function for  computing the accuracy and loss.     After the model was constructed, it was saved in  two parts. One part contains the model’s structure, the  other part consists of the model’s weights. The model  can then be used for predicting categories of tweets  on a new dataset . Results will be shown  in Section 4.   3.3 CNN Neural Network Classifier  with Word2vec Representation   Data Representation : Vector embeddings are spatial  mappings of words or phrases onto a  vector. In a  vector embedding  a word is represented by more than  one bit set to 1. Similar patterns of 1s suggest  semantic relationships between words — for instance,  vector embeddings can be used to generate analogies.  An important vector embedding method  is Word2vec  (Le &amp; Mikolov, 2014).   Word2vec can be constructed and trained to  create word embeddings for entire documents.  Word2vec can group vectors of similar words  together into a vector space. With enough data,  Word2vec models can constrain the meaning  of a  word using past appearances. The output of a  Word2vec model is a vocabulary where each item has  a vector attached to it, which can be used to query for  relationships between words.    For building our classifiers, we use d an existing  Word2vec model, by the name of “Google   Word2Vec ” (Skymind , 2019 ). It is a huge model  created by Google, which comprises a vocabulary of  about 3 million words and phrases. It was trained on  a Google news dataset of roughly 100 billion words.  The length of the vectors is set to 300 features.   Since the Word2vec representa tion of 3 million  words and phrases was unnecessar ily large, we cut it  down to around 20,000 words, by computing the  intersection between  words in our dataset and the  Word2vec model. Our embedding dimension is  equivalent to the length of the vectors, which  is 300.    CNN Classifier : Convolutional Neural Networks   (CNNs)  (LeCun, 1995) are a supervised machine  learning algorithm , which is mainly used for  classification and regression. CNNs usually require  very little preprocessing as compared to other neural  networks. Though CNNs were invented  for analyzing  visual imagery, they have been shown to be effective  in other areas, including  in Natural Language  Processing ( Kim, 2014 ). A CNN consists of input,  output and multiple hidden layers. The intermediate   layers, which are the hidden layers, generally  comprise convolution al layers.   We used three convolutional layers other than the  input and the output layers, and we used ReL U as the  activation function for all of them. The three  sequences have the same number of f ilters, which is  equivalent to the total number of data points in the  training data. The filter sizes for the three  convolutional layers were 3, 4 and 5 respectively. The  activation function in the final output dense layer is  SoftMax, and the number of wor d embeddings is  around 20,000.   We developed CNN model s with both described   data representations, one -hot encoding and  Word2Vec encoding .  We trained the CNN models  over 10 epochs. We ran our model usin g keras with  Tensorflow backend.        Detecting Political Bias Trolls in Twitter Data 337 3.4 State -of-the-Art NLP Model BERT   BERT (Bidirectional Encoding Representations from  Transformers) (Devlin et al.  2019) applies  bidirectional training of “transformer s” to language  modelling. A t ransformer is used for converting a  sequence using an encoder and a decoder into another  sequence. BERT is the first deeply bidirectional  model and relies on  a language learning process  that  is unsupervised. It has been pre -trained using only a  plain Wikipedia text corpus.   In a context -free model, the system generates a  single word embedding representation for each word  in the vocabulary, whereas previous contextual  models generate d a representation of each word that  is based on other words in the sentence. However, this  was done  only in one direction. BERT uses a  bidirecti onal contextual representation that is, it uses  both the previous and next context in a sentence  before or after a word respectively.   We made use of the BERT -base, Multilingual  Cased model with 12 layers; 768 is the size of the  hidden encoder and pooling layers and in all there are  110 Million parameters. A Cased model preserves the  true upper and lower  case (cased words) and the  accent markers.  Thus “bush” (the shrub) is different  from “Bush” (the president).  We train ed our model  for three epochs with a batch size of 32 and sequence  length of 512. The learning rate was  0.00002 . As  before we used  keras with Tensorflow.   The max_posit ion embedding was  set to 512,  which  is the maximum sequence length. That  means  that a specific tweet can have a maximum length of  512 characters. Everything beyond  512 characters is  ignored. The num_attention_heads parameter wa s set  to 12, which is the 12 -head attention mechanism. In  this mechanism, the vector is split into 12  chunks,  each having a dimension  of 512/12 = 42 (42.666…)  and the algorithm  uses these chunks  for each attention  layer in the Transformer encoder. Exhaustive  experiments with these hyperparameters is practically  impossible, but the chosen parameters provid ed the  relatively best results in our experiments.   We ma de use of an Adam optimizer , which is the  default optimizer for BERT. Adam is an alternative to  Stochastic Gradient Descent (SGD), which is used to  update network weights iteratively when training  with data. A learning rate is maintained for each  network weight (parameter) and separately adapted as  learning unfolds. The model was saved for future use  for classification and was also evaluated.        3.5 Political Bias Classifiers   To classify the political orientation of tweets, we  trained the corresponding models described in  Sections 3.1 —3.4, based on the Russian Troll dataset.   The Russian Troll dataset ha s a field labeled  “account_type ” with the political bias or orientation  values of left or right  (among others) .   The right  and left po litical orientation data  distribution in the Russian Troll  dataset used for  training and testing is as follows: Right: 1,538,146;  Left: 890,354.   The SVM,  Fully Connected NN, and  CNN models and the BERT -encoded CNN model   were used  to classify the left and right political bias  in a tweet.     4 RESULTS   4.1 Political Bias Troll Detection  Models   Table  3 compares the accuracy, precision and recall  scores for  the troll detection and political bias  detection models .  It s hows that the neural network  models (fully connect ed NN and CNN  models )  performed  worse than the base SVM model.  On the  other hand, the BERT model outperformed all other  models with an accurac y level of 99% , and with  precision and recall levels of 98% and 99%   respectively .    Table 3:  Comparing the accuracy, precision and re call of   five Machine Learning Models .  Model  Type  Classi fier Type  Accu racy  Precis ion Recall  SVM  Model  Troll Detector  84% 85% 86%  Political Bias  Detector  86% 88% 91%  NN with  One-hot  Encoding  Troll Detector  74% 76% 76%  Political Bias  Detector  84% 88% 90%  CNN with  One-hot  Enco ding Troll Detector  74% 78% 81%  Political Bias  Detector  84% 85% 86%  CNN with  Word2 -vec  Troll Detector  56% - -  Political Bias  Detector  85% - -  BERT  model  Troll Detector  99%  98%  99%   Political Bias  Detector  89%  89%  90%   An important drawback of one -hot encoding is that it  increases the length  of the data vectors. We used only  the 3000 most commonly occurring words in the WEBIST 2019 - 15th International Conference on Web Information Systems and Technologies 338 training corpus, and hence each one -hot vector is of  dimension 3000.   The performance of CNN with the  Word2vec model is significantly lower than that  of  the SVM, NN or CNN with one -hot encoding mode ls,  with an accuracy level of only 56%.    For political bias classification experiments, the  accuracy of SVM, 86%, was slightly  better than NN  or CNN with one -hot encoding and CNN with  Word2Vec, with accuracies  of 84%, 84% and 85% ,  respectively . However, the BERT -based  classification model again outperform ed the others  with an accuracy level of 89%.   4.1.1  Political Bias Troll  Analy sis in Tweets   We collected a  new unique data set of tweets starting  in October of 2016 , just prior to  the US election . An  initial set of 500 Twitter handles belonging to “Alt - Right ,” "Right ,” “Right -Center ,” “Left -Center ,” and  “Left” biased magazines, web sites and personalities  was identified using data collected from the Media   Bias/Fact Check web site  (Media Bias/Fact Check).  The initial set of Twitter handles was thus labeled  with bias es as follows:   Alt-Right Bias: 103 twitter handles   Right Bias: 133 twitter handles   Right Center Bias:  77 twitter handles   Left-Center Bias: 122 twitter handles   Left Bias: 65 twitter handles   The Alt -right bias media sources are often describe d  as moderately to strongly biased toward conservative  causes , through story selection and/or political  affiliation. They often use  strong , “loaded ” words  to  influence an audience by using appeal s to emotion or  stereotypes, publish misleading reports and omit  reporting of information that may damage  conservative causes .  We next identified followers of each of these  Twitter handles (eliminating duplicates) and then  proceeded to downl oad their complete tweet histories ,  thus including tweets from many years back.  Each  tweet was then labeled with the Twitter handle and   political bias.  The results of the data collection  include 1.6 billion tweets from 25 million unique  Twitter handles.   Random sample s of 1 million, 5  million and 20 million tweets were extracted to form  the data set for further analysis.  We call these sample s  Political Bias  dataset s, and we applied our model  to  classify them into trolls vs. non-trolls .   The SVM models were used on the Political Bias   1 million tweet dataset  and the results are in Table 4.   Among 1 million tweets, 730,215 are considered  trolls and among these, the right trolls (546,430 )  outnumber  the 183,785 left trolls.  When  the CNN neura l network classification model with one -hot  matrices representation  was applied to the 5 million  tweets , over 3,586K tweets were classified as trolls.   Among these, the right troll  set consist ed of 2,553K   tweets , outnumbering the left trolls (1,032K tweets ),  as shown in Table 4.   Table 4 : Political Bias trolls using SVM  and CNN with one - hot encoding  and two  classifier models.    Tweet Type  SVM  CNN   Sample dataset  1000000  5000000   Troll Tweets  730215  3586213   Left Troll  Tweets  183785  1032422   Right Troll Tweets  546430  2553791   Thus , 75% and 71% of all troll  tweets  were found to  be politically right tweets , compared to  left tweet s  (25% and 29%) for the respective  models .   We applied the BERT -encoded  CNN model for   classifying the  5 million  tweet  Political Bias dataset  into troll vs. non-troll tweets.  The results show  that  3,598,898 (72%) were trolls and 1,401,102 (28%)  were non -trolls.  The breakdown of P olitical Bias  tweets into  trolls and non -trolls is shown in Table 5 .   Table 5 : Political biases in non-troll tweets and troll tweets   using BERT -CNN Classification Model .   Non-Trolls  Trolls   AltRight  530,990  2,013,935   Right  31,897  64,533   RightCenter  162,061  330,314   Neutral  492,820  766,660   LeftCenter  122,681  270,755   Left 60,653  152,701   Table 6: Average Number of Troll tweets and % of Trolls  by Political Bias of Unique Tweet handles .  Poltical Biases  # of  tweethandles  Avg # of  Troll  tweet s % of Trolls   AltRight  541 1098  76%  Right  29 530 2%  RightCenter  78 789 8%  Neutral  189 393 10%  LeftCenter  43 595 3%  Left 37 180 1%  Grand Total  917 844 100%   We identified 917 unique Twitter handles (users) that  were associated with trolls from the 1 million tweet  machine -labeled dataset, as shown in Table 6, using  BERT classifiers. A much higher average number of  troll tweets (on average 1098 tweets per unique  handle, 76% of all trolls) were associated with the 541 Detecting Political Bias Trolls in Twitter Data 339 unique Twitter handles with an alt -right bias, while  a  total of 80 user accounts considered as left center or  left posted on average 595 (3%) and 180 (1%) troll  tweets, respectively.   4.2 Temporal Analy sis  We performed a temporal progression analysis of left  and right trolls  after identifying trolls using the  5  million Political Bias sample dataset  to understand  how political bias  troll tweets ha ve changed over  time. Figure 2 shows the temporal analysis  from 2004  to 2016.   In 2009, there was a notable peak of trolls,  especially right -biased trolls. This coincides with the  beginning of Barak Obama’s first p residen cy.  4.3 Geospatial Analysis   We performed a geospatial analysis on 5 million   tweets to locate the left and right troll tweets. In the  dataset , only 133,801 tweets  (2.7% ) had geolocation  information and 83,232 geolocated tweets  were  classified as trolls . Table 7 shows the number of left  and right troll tweets based on the geolocatio n data.     Figure 2: Temporal Analysis on Political Bias Trolls: Blue  = Left Trolls. Yellow = Right Trolls.   Figure 3 show the geospatial distribution of approx.  50K right troll tweets.  The distribution of left troll  tweets is omitted due to space constraint s.  Table 7: Breakdown of tweets containing geo location  information  from the 5 Million tweets dataset .  Tweet type (from 5 Million)  Count   Total tweets with geolocation  133801   Total Troll Tweets with geolocation  83232   Right Trolls with geolocation  50154   Left Troll with geolocation  33078   The total ratio of right to left troll tweets is 60:40 i n  Japan, South Korea and Thailand, where the right  troll tweets are more prominent. In the UK, the count of left troll tweets is significantly higher as compared  to the right troll tweets. In the United States, the ratio  of left to right troll tweets is 60:40. We also observe  that the right troll tweets and left troll tweets are  evenly distributed in most of the countries .     Figure 3: Geospatial distribution of Right troll tweets.   4.4 Sentiment Analysis on Political Bias   Dataset of Five Million Tweets   Sentiment analysis was performed for l eft and right  troll tweets  to understand the emotional tone  that  trolls used to influence people’s minds.  The sentiment  analysis model was built using the Sentiment140  dataset (Sentiment140)   Figure 4 illustrates the breakdown of sentiments  of right troll tweets, which have been classified into  five different classes, namely neutral, positive,  extremely positi ve, negative and extremely negative,  based on the data. Figure 5 shows the same  breakdown for left troll tweets. Figure 6 shows a side - by-side comparison.       Figure 4: Sentiments of  right bias trolls.    Figure 5: Sentiments of  left bias trolls.   The sentiment analysis results show  the follow ing:   The ratio of positive, negative and neutral trolls   does not vary much in either left or right troll  tweets.    The number of negative tweets is slightly higher  in right troll tweets by a count of around 7,000  tweets.   The number of positive tweets is slightly lower in  right troll tweets by a count of 13,000 tweets.   WEBIST 2019 - 15th International Conference on Web Information Systems and Technologies 340   Figure 6: Sentiment analysis on right (in red) and left (blue)  troll tweets.   5 CONCLUSIONS AND FUTU RE  WORK   In this paper, we built several machine learning  models to identify  the political bias of trolls . The  classifiers  for troll identification were  developed with   the Russian Troll dataset . The BERT -encoded  classification models  had an accuracy of 89.4% for  left/right troll detector and 99% for troll/non-troll  detector , which is higher than SVM, CNN with  Word2vec and Neural Network with o ne-hot  encoding. Using the troll detection and political bias  detection models, we analyzed t he large scale  Political Bias  datasets  of varying sizes. T here are  more Alt-right accounts/users associated with large  number s of troll tweets  in the number of trolls and  total proportion of trolls  than left biased users . We  also presented geospatial, temporal and sentiment  analys es. Se ntiment analysis on the Political Bias  tweets shows that there are slightly fewer positive  right troll tweets compared to  left troll tweets.   In future work, we plan to develop a large -scale  web-based system  that performs real time  classification of political bias trolls to monitor the  trolls and their political biases and to perform the  geospatial and temporal analys es for identifying  extreme political bias regions and time  intervals .   We  also plan to perform troll contents analyses to  understand th e topics and topic categories of trolls of  different political affiliations . Lastly, we want to  extend our methods to other social networks, such as  Reddit, following  work by Weller and Woo (2019).   ACKNOWLEDGEMENTS   This work is partially supported by  NSF C NS 1747728  and 1624503, and by the National Research  Foundation of Korea Grant NRF -2017S1A3A2066084 .  It is supported by PSC -CUNY Research Awards  (Enhanced): ENHC -48-65. 2017 -2018.   REFERENCES   Mojica, L. G., 2017. A Trolling Hierarchy in Social Media  and a Conditional Random Field for Trolling Detection,  arXiv :1704.02385v1 [cs.CL].   Kumar, S., Spezzano, F., Subrahmanian, V.S., 2014.  Accurately detecting trolls in slashdot zoo via  decluttering. In Proc. of the 2014 International  Conference on Advances in Social Network Analysis  and Mining, ASONAM ’14 , 188 –195, Beijing, China.   Vapnik, V. 1995. Support -Vector Networks, Machine  Learning , 20, 273 -297.  Kim, Y. 2014. Convolutional Neural Networks for  Sentence Classification, Proceedings of the 2014  Conference on  Empirical Methods in Natural Language  Processing (EMNLP), pages 1746 –1751. Also in:  arXiv :1408.5882v2 [cs.CL].   LeCun, Y. 1995. Convolutional Neural Networks for  Images, Speech, and Time Series,  arXiv :1408.5882v2  [cs.CL].   Chang, C. -C., Lin, C. -J., 2011. LI BSVM: A Library for  Support Vector Machines, ACM Transactions on  Intelligent Systems and Technology (TIST) , Volume 2  Issue 3.   Roeder, O., 2018. Why We’re Sharing 3 Million Russian  Troll Tweets https://fivethirtyeight.com/features/why - were -sharing -3-million -russian -troll-tweets/ , Retrieved  June 3, 2019.   Fivethirtyeight, Russian -troll-tweets, https://github.com/   fivethirtyeight/russian -troll-tweets/ Retrieved in Jan  2019.   Wikipedia contributors, 2019. Internet Research Agency. In  Wikipedia, The Free Encyclopedia.  https://   en.wikipedia.org/w/index.php?title=Internet_Research _Agency&amp;oldid=900092717, Retrieved June 3, 2019.   McKinney, W., 2017. Python for Data Analysis, 2nd  Edition -- Data Wrangling with Pandas, NumPy, and  IPython.  O'Reilly Media.   Roesslein, J., 2019. https://tweepy.readthedocs.io/en/latest,  https://github.com/tweepy/tweepy, Retrieved June 3,  2019.    Bakliwal, A., Arora, P., Madhappan, S., Kapre, N., Singh,  M., Varma, V., 2012. Mining Sentiments from Tweets.  3rd Workshop on Computational Approaches to  Subjectivity and Sentiment Analysis , pages 11 –18.  Ji, X., Chun, S., Wei, Z., Geller, J., 2015. Twitter sentiment  classification for measuring public health concerns .  Socia l Network Analysis and Mining. Issue 1/2015 .  Porter, M., 2006. The Porter Stemming Algorithm.  https://tartarus.org/martin/PorterStemmer/, Retrieved  June 3, 2019.   Albon, C, 2017. SVC Parameters When Using RBF Kernel,  https://chrisalbon.com/machine_learning/support_vect Detecting Political Bias Trolls in Twitter Data 341 or_machines/svc_parameters_using_rbf_kernel/,   Retrieved June 3, 2019.   Chollet, F., et al., 2015.  Keras: The Python Deep Learning  library, https://keras.io/,  Retrieved June 3, 2019.   Le, Q., Mikolov, T.,  2014. Distributed Representations of  Sentences and Documents, Proceedings of the 31st  International Conference on Machine Learning ,  Beijing, China, JMLR: W&amp;CP volume 32.   Skymind . A Beginner's Guide to Word2Vec and Neural  Word Embeddings, https://skymind.ai/wiki/word2vec,  Retrieved June 3, 2019.   Tensorflow, 2017. https://www.tensorflow.org/, Retrieved  June 3, 2019.   Devli n, J.,   Chang, M.W., Lee, K., Toutanova, K., 2019.  BERT: Pre -training of Deep Bidirectional  Transformers for Language Und erstanding,  https://arxiv.org/pdf/1810.04805.pdf, Retrieved June 3,  2019.   Weller, H., and Woo, J. 2019. Identifying Russian Trolls on  Reddit with Deep Learning and BERT Word  Embeddings .  http://web.stanford.edu/class/  cs224n/reports/custom/15739845.pdf , Retrieved June  12, 2019.   Sentiment140: dataset with 1.6 million tweets - https://www.kaggle.com/kazanova/sentiment140.   Media Bias/Fact Check, https://mediabiasfactcheck.com/,  Retrieved June 3, 2019 . WEBIST 2019 - 15th International Conference on Web Information Systems and Technologies 342</td>
    </tr>
    <tr>
      <th>35</th>
      <td>poli</td>
      <td>Article Corresponding author: Erica Huls, Department of Communication and Information Sciences, Faculty of Humanities, Tilburg University, PO 90153, 5000 LE Tilburg, the Netherlands.   Email: huls@uvt.nlDiscourse &amp; Society 22(1) 1–18 © The Author(s) 2010 Reprints and permission: sagepub.   co.uk/journalsPermissions.nav DOI: 10.1177/0957926510382836  http://das.sagepub.comPolitical bias in TV interviews Erica Huls and Jasper  Varwijk Tilburg University, the Netherlands Abstract  The study aims to provide empirical data on the alleged political bias of Dutch media. It also  aims to contribute to the development of an instrument for the measurement of partiality in TV interviews. Its main question is: are TV interviewers biased in putting adversarial questions to  politicians with different political backgrounds? The data collection encompasses 12 interviews taken from the late-night talk show Pauw &amp; Witteman during the run-up to the parliamentary  elections of 2006. The analysis focuses on five measures of adversarial questioning that were developed by Clayman et al. (2007): initiative, directness, assertiveness, opposition and accountability,  as well as on a sixth measure that was developed in the context of this study, persistence. The  results show that left-wing politicians are approached less adversarially than right-wing politicians and politicians in the political centre, even when various factors that might offer an alternative explanation are included in the analysis. The conclusion is that interviewers are partial in shaping the way in which politicians can present themselves to the public. Keywords measurement instrument of adversarialness, political bias, question design, questions, TV  interviews Introduction Occasion of the study In the Netherlands, the political bias of media interviewers is a hotly debated issue. It is  not a debate on journalistic norms and values, but on journalistic practice . Just as in the  United Kingdom, the United States and many other countries that value the freedom of the press, Dutch news interviewers are expected to adhere to certain basic standards of professional conduct such as impartiality and objectivity. The debate focuses in particular on journalistic practice on Dutch national radio and television, which are state-subsidized  2  Discourse &amp; Society 22(1) and fulfil a public function. The criticism levelled at media journalists includes their left- wing bias. Journalists are alleged to support left-wing ideals and opinions rather than the right-wing body of thought and to influence future voters in propagating a preference for left-wing political candidates over right-wing ones. The following interview extract is an example of a politician accusing a journalist of being biased. It is taken from the breakfast show Goedemorgen Nederland  (Good Morning Netherlands ), which is broadcast on  weekdays by the broadcast corporation KRO. The interviewer is Sven Kockelmann and the interviewee is the right-wing party leader Geert Wilders. Interviewee:  Once again, we are from the party whose people say what they think. You may  be from the party whose people only say something when it helps. Interviewer:  I do not belong to any party. Interviewee:  Well, that’s not what it looks like. Interviewer: How is that? Interviewee: Well, your questions are quite suggestive. This debate on journalists being biased provided the practical impetus for our study.  Although it is an empirical issue, research on the matter is scarce. We try to fill this gap by empirically investigating the possible political bias of Dutch media interviewers dur - ing the run-up to the parliamentary elections of December 2006. Interaction in TV interviews When we sit in front of the television nowadays to see what is going on in the world, there is a big chance that what is shown will include an interview by a journalist and one or more public figures. The TV interview has grown to prominence during recent decades  (Clayman and Heritage, 2002a). According to Clayman and Heritage (2002a: 28–9), this development is built on a commonality of interests between public figures and journal-ists: ‘Journalists need access to public figures for their livelihood, while public figures need journalists to gain access to what Margaret Thatcher once called “the oxygen of publicity’’’. As a result, there exists an informal and unspoken ‘interview contract’: jour - nalists give public figures access to their platform in exchange for news content that will attract viewers. It is within the framework of this interview contract that the television interview has grown to be one of the most widely used and best-developed formats for political communication worldwide (Elliott and Bull, 1996: 49; Ekström, 2001). Particularly in the run-up period to elections, politicians appear in TV interviews almost  daily. In the context of a growing number of ‘floating voters’ in the Netherlands, esti-mated at 30 percent before the last elections, gaining access to the electorate through TV  interviews can be of decisive importance. Thus, it is no wonder that politicians are eager to exploit this setting to reach and attract voters. Although it is potentially helpful to politicians in gaining political success, taking  part in a TV interview is also a risky endeavour. On more traditional political platforms,  like public speeches or political advertising, politicians have full control over content and process. In the TV interview, however, there is a third party involved, the interview - ers, who take over a lot of the control. In their institutional role as talk managers, inter - Huls and  Varwijk 3 viewers set the topics, ask the questions, determine who speaks, and decide when a  question has been answered sufficiently. Moreover, as mediators between politicians and the viewers at home, interviewers fulfil a democratic function in that they are expected to probe policy issues and to organize the public debate. It is the politicians’ task to present themselves to the viewers while answering difficult questions, posed by interviewers who enter the scene as ‘watchdogs’ (Clayman et al., 2007: 23) of a partici - patory democracy. Various scholars have pointed to a tension in the current journalistic profession  (Clayman and Heritage, 2002a: 150–236; Hutchby, 2006: 127–33). On the one side, neutrality in the sense of ‘neutralism’ 1is considered an important condition for good  journalism: broadly speaking, interviewers have to take a ‘balanced, impartial, or neutral stance’ towards the statements and opinions of the interviewee (Clayman and Heritage, 2002a: 199). On the other side, as critical investigators of political practice and as propo-nents of a participatory society, it is the interviewers’ task to ask penetrating and oppos-ing questions and prevent evasive answers. Thus, in order to discover the ‘real’ facts, journalists have to approach their sources critically and should not be the passive exten-sions of the politicians’ voices. The journalists react to this tension by utilizing question forms that do not express a personal stance, but at the same time contain a critical posi-tion, i.e. by using question formats which realize a complex positioning of the partici-pants in the interview setting, such as the formulation (Heritage, 1985: 101–12) and the ‘You say X, but what about Y?’ pattern (Hutchby, 1992: 675–84). In doing this, they are oriented to ‘neutralism’ by claiming that they apply these forms moderately and to all politicians equally. Recently, Clayman and Heritage have developed a subtle system of categories for  the analysis of the range of question forms used by interviewers of politicians, the Question Analysis System or QAS (Clayman and Heritage, 2002b: 754–71; Clayman   et al., 2007: 30). In total, QAS takes into account ten features of question design. They argue that the different features in general indicate ‘adversarialness’, while they form groups indicating aspects of adversarialness such as ‘initiative’ and ‘assertiveness’ .  They developed this QAS while researching the hypothesized historical trend that jour - nalists interrogate American presidents in an increasingly aggressive way – a trend that was indeed found. This QAS may be particularly useful for the problem we are focusing on. Its application to Dutch interviewers’ questions when approaching politicians with different political backgrounds shows either ‘equal treatment’ or ‘bias’. Apart from this, an application like this provides insight into the quality of QAS in a different context (USA vs. the Netherlands) and a different type of interview (press conferences vs. TV  interviews). A different form of bias, which we also took into account, is the so-called ‘coverage  bias’ (D’Alessio and Allen, 2000): journalists might be biased in the physical amount of coverage that the various ‘sides’ or ‘parties’ in a discussion receive, i.e. they might allow some parties more speaking turns and more speaking time. Our study concerns both ‘coverage bias’ and ‘bias in question design’. We are well aware that we are not investi-gating the complex notion of ‘political bias’ in all conceivable ways. The study is con-fined to a number of relatively encompassing aspects of this notion. The aim of this study can now be summarized as a two-fold one: 4  Discourse &amp; Society 22(1) 1  The study aims to provide a set of empirical data on the alleged political bias of  Dutch TV interviewers and, thus, to contribute to the filling of a gap in a current  social debate. 2 We aim to contribute to the development of a measurement instrument of adver - sarial questioning in TV interviews by elaborating on the existing QAS and  increasing its applicability. Data and method The study is a multiple case study: 12 interviews taken from the late-night talk show  Pauw &amp; Witteman were analysed. In these shows, the interviewers Jeroen Pauw and Paul Witteman discuss ‘the topicality of current affairs, the talk of the town and the delusions of the day’ (Pauw and Witteman, 2007) with guests who play prominent roles in politics, culture and science. The character of the shows is serious – i.e. not satirical and not   belligerent – with a touch of humour, which is apparent from, for example, the witty introductions to the politicians and the other guests at the table, and the use of running jokes. The shows last approximately one hour and are broadcast live on weekdays by the broadcasting association V ARA/NPS on one of the three Dutch state-subsidized national channels. V ARA/NPS is institutionally embedded in NPO, Dutch Public Broadcasting, which regards its independence from political influences as a spearhead in its mission (NPO, 2010). 2 The interview setting is represented in Figure 1. The programme Pauw &amp; Witteman is considered to be one of the backbones of public  broadcasting in the Netherlands (NPS Jaarverslag, 2006). Since its start in September 2006, it has been the talk show on Dutch TV with the highest ratings. It attracts many  Figure 1. The interview setting Huls and  Varwijk 5 viewers at home with a regular market share (i.e. the percentage of the TV watching  population that watches this talk show) of around 20 percent, which increases on some  days to 30 percent. The 12 shows that were analysed had a mean number of viewers of 726,833, which is a mean market share of 18.44 percent, and 4.88 percent of the total TV  watching population. 3  It was – and still is – one of the most important political platforms  in the Netherlands. With one exception, all the interviews studied were broadcast in the ten-week period  preceding the parliamentary elections of December 2006. The format of all the analysed programmes was such that one party leader or MP of a political party active in the elec - toral struggle was interviewed for 10 to 15 minutes, while there were two or three other, non-political, guests sitting around the table. With the aid of the Kieskompas  (2010) – a  sociologically based positioning of the political parties in the Netherlands in a conceptual framework with two dimensions: left vs. right and progressive vs. conservative (see Figure 2) – we decided which two of the 11 political parties were most prototypically left-wing and right-wing, as well as which two were most representative of the political centre. For each of these six parties, an interview with the party leader and an interview with an MP was included in the analysis. The distribution of male and female politicians was kept as equal as possible. Table 1 gives an overview of the interviews that were analysed. The 12 interviews were transcribed and segmented into turns in which a question was  asked. We used a rather broad pragmatic notion of ‘question’ (see Huls, 2009: 158–9). The data collection encompasses 186 minutes of conversation and 700 questions. Figure 2. Positioning of the political parties in the Netherlands on the dimensions  ‘left wing–right wing’ and ‘progressive–conservative’ (based upon Kieskompas, 2010)  6  Discourse &amp; Society 22(1) The partiality of the TV interviewers is analysed by focusing on coverage bias (do the  politicians of the differing orientations receive an equal number of speaking turns and  amount of speaking turns?) and bias in question design (do the politicians of the differing orientations receive the same question forms?). In line with QAS, the following five aspects of question design are investigated: 1 Initiative. Interviewers can choose to be relatively passive in the sense that they allow the politician maximum leeway to construct a response and impose few constraints. Alternatively, they can show initiative by elaborating on their ques-tions and formulating them in such a way that the agenda for response is con-strained. One way to show initiative is to introduce the questions Q with utterances U, as shown in Example 1. Example 1 Introduction to the question (IR = Paul Witteman, IE = left-wing party leader  Jan Marijnissen) IR: U1 →  Jan Marijnissen, you did not take part in the debate ((i.e. a debate organized shortly  before by the commercial network RTL)), because it was RTL’ s choice to organize a  two-way debate.  U2→  Femke Halsema had some very angry words to say about that in ‘De leugen regeert’  ((‘A pack of lies’, a TV programme that exposes ‘lies’ in journalism)).  U3 →  Andre Rouvoet stated this morning in De Volkskrant ((i.e. a national quality news- paper with a high impact)) that he regarded it as ‘cheating the voters’.  Q → Do you agree? Another way to show initiative is to ask more than one question in one (and the same)  turn.T able 1. Overview of the data collection No. Date Politician Function Party Orientation 01 03-11-06 Jan Marijnissen ♂Party leader SP Left wing 02 30-10-06 Agnes Kant ♀Member of Parliament SP Left wing 03 17-11-06 Femke Halsema ♀Party leader GroenLinks Left wing 04 18-01-07 Mariko Peters ♀Member of Parliament GroenLinks Left wing 05 09-11-06 Alexander Pechtold ♂Party leader D66 Centre 06 11-09-06 Lousewies van der Laan ♀Member of Parliament D66 Centre 07 18-10-06 Jan Peter Balkenende ♂Party leader CDA Centre 08 13-09-06Maxime   Verhagen♂Member of Parliament CDA Centre 09 07-09-06 Mark Rutte ♂Party leader VVD Right wing 10 06-11-06 Rita Verdonk ♀Member of Parliament VVD Right wing 11 14-11-06 Marco Pastors ♂Party leader Eén NL Right wing 12 25-10-06 Joost Eerdmans ♂Member of Parliament Eén NL Right wing Huls and  Varwijk 7 2 Directness. Interviewers can choose direct (i.e. blunt, straightforward) forms of  expression, but they can also formulate their questions in a more indirect and careful way. In the latter case, the interviewer reckons with potential face loss of the IE. Indirectly formulated questions are perceived as being more polite. In interviews, indirectness typically takes the form of an expression that precedes and frames the focal question. These expressions either refer to (1) the intention, motivation or ability of the interviewer to ask the question, or (2) the ability or willingness of the interviewee to answer the question. Example 2 Reference to interviewer (IR = Jeroen Pauw, IE = right-wing MP Rita Verdonk) IR: Q → May I ask you to read aloud a short passage? IE:   Yes.  3 Assertiveness. No question is completely neutral. The notion of ‘assertiveness’ refers to the degree to which aspects of question design express expectations concerning the answer. Basically, there are two ways to construct ‘tilted’ ques-tions: (1) by prefacing the question with statements or arguments in favour of one of the answering alternatives, and (2) by formulating the question in the sugges-tive sentence mode. In Example 3, both ways of constructing ‘tilted’ questions co-occur: Example 3 ‘Tilted’ introduction and ‘tilted’ question (IR = Jeroen Pauw, IE = leader of a party in  the political centre Alexander Pechtold) IR: U1 →  With regard to the death penalty, you could say that if Saddam Hussein is  handed over to a tribunal,  U2 →  with most of the parties agreeing to there being a tribunal, because the man should be tried by his own people;  U 3 → if you know that capital punishment is at the top of the list in that culture,   Q →  then it is not so very strange that Saddam Hussein should actually get the  death penalty?  4 Opposition. Opposition concerns the degree to which the interviewer takes a  position opposite to that of the interviewee. Opposition takes place when the question is overtly critical with respect to the interviewee and his or her party. Interviewers can express opposing views (1) in the introduction to the question. Introductions are opposing when they contain rejecting or negatively evaluating remarks concerning utterances and acts of the interviewee. QAS distinguishes two alternatives here: a milder variant (1a), wherein an oppositional introduction is the focus of the subsequent question (see Example 4), and a more adversarial variant (1b), wherein an oppositional introduction is presupposed in the subse-quent question. Moreover, interviewers can express opposing views (2) in the design of the question as a whole. Opposition in the design of the question as a whole occurs when an oppositional or critical posture runs through the question in its entirety. 8  Discourse &amp; Society 22(1) Example 4 Opposing introduction (IR = Jeroen Pauw, IE = PM, and leader of a political party  in the centre Jan Peter Balkenende) IR: U →  Last night we had Amsterdam alderman Aboutaleb with us in the studio, and he got  rather worked up about the fact that it is precisely this cabinet under your leadership  that has paid so little attention to the problems Amsterdam is facing in working on  solutions ((in problem areas with many migrants)). Let’ s take a look at that clip from  last night’ s show.   Q → We’d like to hear your reaction? 5 Accountability. Accountability refers to the degree to which the interviewer asks  the interviewee explicitly to account for his policy. The interviewer does not  accept a political decision without an argument. He challenges the interviewee to justify his political behaviour. The interviewer can formulate his question in a formally ‘neutral’ fashion and simply ask for the reason why the politician behaved the way he did (see Example 5, Q1), or he can be more accusatory by portraying the political decision as doubtful or inexplicable (Example 5, Q2). Example 5 Accountability questions (IR = Paul Witteman, IE = right-wing party leader   Mark Rutte) IR:   Is there anything about this issue ((i.e. the position of the party with respect to Turkey  joining the European Union)) in your party’ s electoral platform? IE:  No there isn’t. IR: Q1 → How can that be?   Q2 →  Hasn’t this been a major issue in your party for a long time? It was part of Bolkestein’ s  agenda for years and years.  We have expanded QAS with a sixth analytical perspective, persistence . Clayman and  Heritage (2002b: 749) claim that QAS can be used to analyse question design in both TV  interviews and press conferences. However, they neglect an important difference in the two  contexts. In contrast to press conferences, where the politician distributes the turns in such a way that an interviewer can ask only one or (rarely) two questions, whereafter the floor goes to the next one, the TV interview allows for a longer, coherent sequence of questions  by the same interviewer. Although this might look like a small difference, its consequences are far-reaching: the interviewer has the opportunity to react to the adequacy of the answers and exploit a range of means in follow-up questions to obtain a more revealing answer (Greatbatch, 1988). When the interviewee fails to produce a coherent answer, the inter - viewer can call him or her to account and still try to obtain a satisfactory answer (Pomerantz, 1984). Answering a question adequately is a norm that, despite a lot of evasive action, remains very much in force in political communication (Clayman, 2001). Our notion of persistence applies to the interviewer’s behaviour in extended sequences  of questions that are topically coherent. It is similar to the notion of ‘pursuit’ (Pomerantz,  Huls and  Varwijk 9 1984; Heritage and Clayman, 2010). The interviewer shows persistence when he does  not simply take the politician’s answer for an answer, but repeats his question, explicitly addresses the politician’s evasive reactions or interrupts the politician. The interviewers are persistent in Example 6, where they are dealing with a comment  by right-wing politician Pieter Winsemius, a fellow party member of interviewee Rita Verdonk, in which he states that, in the next cabinet, he is willing to take over Verdonk’s portfolio as Minister of Immigration and Integration because she failed to solve the prob-lems in the city neighbourhoods. Example 6 Repeating the question, commenting on evasive answering (CEA) and interrupting  IE (IR1 = Paul Witteman, IR2 = Jeroen Pauw, IE = right-wing MP Rita Verdonk) IR1: Q1→  And do you think it is a good idea that? Do you think it is a good idea that he will  finish your job? IE:   Well, look. What I do think is that his report is an inventory he has made and we still have big problems in the neighbourhoods. But, to me, it goes too far, and that was your first comment, that it is all integration pro [blems. I have said there is a complex IR1: Q 2→        [Y es. That is what you have said, but   do you mind if he finishes that job? IE:  Well, look, that is I don’t think that you can put it in this way. We are all dependent on    formation [negotiations.=  IR1:                 [Hmhm   = Let’s wait for these first and then see what [comes out. IR1: Q3→       [Would you be happy to get rid of it? Of    this portfolio? IE:   (&lt;) Uh I have to say that it has been spoken of as a headache portfolio. Well, it is not like that, but I get … As far as the integration part is concerned you get gray hairs from that. [ I mean.=  IR1    [Yeh. IE  = A complete cultural change has to be brought [about. (Under) IR1: Q 4→               [So you don’t mind if you leave it? IE:   Well. I no I am terrifically interested in it. And it also keeps me very busy. So yes of  course leaving it would definitely affect me.   [Sure of course, but the same applies to immigration. IR: Q5→ [Yes. You you you prefer to keep doing it.  IE:   Well, that is not what I am saying. You know, I have just said, it’s all about these formation negotiations. So [yes  IR1: Q 6→             [No. it’s about I [asked what you want. IR2: Q7→          [No, but the issue is what you [want.  IE:            [No.    Nohohohoho no yes and then after that you uh god and you say just with respect to  mister Winsemius. I ‘m getting to know you now, gentlemen. Noho, this is not what is going to happen. IR2:  No. 10  Discourse &amp; Society 22(1) IR1: CEA→ But, we uh simply ask questions and (then I [don’t understand.)=  IE:            [Yes.    = Either you say yes we I know you as interviewers and I would rather not give an  answer. But we don’t know you for this. IE:  No, oh but I keep on giving I do [my utmost to give good answers. IR2: Q8→                   [But fine. Y ou just said I just discussed it with Mister    uh Winsemius, and so in my view you will have said just normally Pieter, before he  said it on Buitenhof. So he probably also said like I do want to do that and I feel I  might well say it on Buitenhof ((i.e. a political TV talk show)). What did you say then? IE:   Well, I mean, he can say that if he wants to. And I can give   my reaction to that, [the (weeks) erm [which I have. IR1:  Q9+10 →                 [And it was? [And what was your reaction then? When the interviewer asks Verdonk whether she sees Winsemius taking her place as  being a good idea (Q1), she doesn’t provide an adequate answer to that question, i.e. she comments on the topic of the question, but does not answer the question in terms of the action that the question requires: a yes/no answer. This leads to the interviewers repeat - ing the question six times (Q2 to Q7), while also interrupting Verdonk in each case. Next, Verdonk evades the question openly, after which the interviewers comment explicitly on her series of inadequate answers (CEA). After an account of the inter - viewee, the interviewers continue repeating the question and interrupting the inter - viewee (Q8 to Q10). By interrupting the interviewee, repeating their question and commenting on eva - sive action, the interviewers demonstrate to the interviewee as well as to the audience that they regard the question as being answered inadequately. They display persistence in obtaining an adequate answer, thereby expressing adversarialness in the questions they ask. Every question of the interviewer in our data collection was judged with respect to  the presence or absence of the specific indicators of the six aspects of question design. This judgement, which was made by Jasper Varwijk, was often based upon formal aspects of the question, and thus could be made with a relatively high degree of reli - ability (Clayman et al., 2007: 31). Problematic cases were discussed by both research - ers, and treated consistently by adding guidelines to the coding manual. A third researcher carried out an independent judgment of five percent of the questions. This judgement was compared with Varwijk’s assessment, and Cohen’s Kappa, a measure that gives insight into the agreement between the judges, was computed (Cohen, 1960). The kappa values of the six aspects of question design were as follows: initia - tive: .91; directness: 1.00; assertiveness: .78; opposition: .71; accountability: 1.00; persistence: .56. 4 Suppose we find a relationship between the political orientation of the interviewee  and the aspects of question design, and that this relationship turns out to confirm the accusations mentioned in the introduction as made by certain right-wing politicians, in particular that right-wing politicians are approached in a more adversarial way than left-wing politicians, then the conclusion that the interviewers show bias would still be pre-mature, because this relationship might be determined by factors other than the political  Huls and  Varwijk 11 orientation. For example, it is easy to imagine that an evasive answer of a politician  might drive the interviewer to more assertiveness and persistence in his next question. If right-wing politicians show this answering behaviour more often than left-wing politi-cians, then the bias found cannot be attributed to the interviewer, but can be said to be their ‘own fault’. On the basis of previous research into interaction (in TV interviews)  and the relationship between media and politics, the factors that might be the most rele-vant as offering alternative explanations for our findings were determined and included in our study. We found 12 of them. A number of these concern the reactions of the inter - viewee in the turn immediately preceding the question: did the interviewee provide an answer or show a form of evasive action? An analysis of evasive action is not an easy endeavour. We based ourselves upon our own research (Huls, 2008, 2009), as well as on research done by others (e.g. Harris, 1991; Clayman, 2001; Kuiper, 2006; Ekström, 2009). We ended up distinguishing 23 forms of evasive action. These were grouped into four factors: (1) answering strategy; (2) politeness strategy; (3) playing with the turn-taking rules; and (4) playing with the discourse role. Five factors are inherently related to the interviewee: their ‘gender’, their role in the  party (party leader or MP?), their political experience, their party’s political position (in power or in opposition) and their party’s position in the polls (support may be stable, increase or decrease). The last three factors are determined by the interviewers. It is possible that one of the  interviewers shows bias, while the other does not. Moreover, the topic of the question (does the question address a topic in national politics or another topic? Does the question address a topic in international politics or another topic?) might determine the adversar - ial behaviour of the interviewers. The codings were entered into SPSS and analysed according to the statistical standard  (Kinnear and Gray, 2001). This means that the two metric variables (i.e. the granted number of speaking turns and the granted amount of speaking time) were analysed by making use of ANOV As and MANOV As. The other variables have a nominal measure-ment level and were analysed by making use of cross tables, chi-square statistics and binary logistic regressions. 5 Results Coverage bias was not found. The politicians of the differing orientations received an equal number of speaking turns (a mean number of 58.2) and also an equal amount of speaking time (a mean of 15.5 minutes). Bias in question design  was found in three of the six aspects studied. There was no  bias in initiative, directness and accountability , but bias was found in assertiveness ,  opposition  and persistence . Figure 3 gives more insight into this bias. One can see that  all three dimensions show the same pattern of political bias (persistence: χ2 (2) = 19,05;  p &lt; .001; opposition: χ2 (2) = 22,95; p &lt; .001; assertiveness: χ2 (2) = 11,12; p &lt; .005).  It is tentatively concluded that the interviewers are more adversarial when they are interviewing right-wing politicians; they are less adversarial when interviewing politi - cians of the political centre and least adversarial when they are interviewing left-wing politicians. 12  Discourse &amp; Society 22(1) However, in the section on Data and method, we argued that a bias, if found, might be  determined by factors other than the political orientation of the interviewee. To check for this possible influence, we first investigated the 12 factors that might offer an alternative explanation with respect to their effect on persistence, opposition and assertiveness; 13 of these 36 effect determinations (12 contextual factors x 3 aspects of question design) were statistically significant. Next, we made context-specific cross tables and studied the precise character of this effect on what really concerns us: the political bias. Figure 4 shows an example of such an effect determination and context-specific anal- ysis. The interviewers are more persistent after a so-called inadequate answer: the figures on the left-hand side are higher than those on the right-hand side, but their bias is appar - ent on both sides. We conclude that this aspect of the answering behaviour of the politi-cian shapes the question design, but does not offer an alternative explanation for the bias that we found.0102030405060 Persistence  Opposition  Asser tiveness  % of questionsLeft wing  Political centre  Right wing   Figure 3. Persistence, opposition and assertiveness in relation to political orientation 01020304050607080 Persistence after an inadequate ans wer of the politician  Persistence after an adequate answ er of the politician  % of questionsLeft wing  Political centre  Right wing   Figure 4. Persistence in relation to adequacy of the answer and political orientation Huls and  Varwijk 13 In this way, we studied what happens to the political bias in the 26 contexts that are  encompassed by the 13 factors that proved to be relevant. Overwhelmingly (16 times), we found the pattern that left-wing politicians are approached in a less adversarial manner than politicians from the political centre, while the approach to right-wing politicians is most adversarial, i.e. the patterns of Figure 4, which are stylized as pattern 1 in Figure 5. Furthermore, we found variation in the position of the politicians in the political cen- tre: they are treated just as adversarially as their right-wing colleagues in six contexts.  This is pattern 2 in Figure 5. In one context, they are treated in a more adversarial manner than the right-wing politicians. See pattern 3 in Figure 5. Moreover, in one context, they are treated less adversarially than both left-wing and right-wing politicians, as visualized in pattern 4. However, the patterns 1 to 4 in Figure 5 are all patterns of bias favouring left-wing over right-wing politicians. An equal treatment as visualized in pattern 5 is found twice: in the persistence of the interviewers when they addressed MPs and in the persistence when the preceding turn of the politician was direct. We conclude that, in nearly all (24 out of 26) contexts investigated, left-wing politicians are approached with significantly less persistence, opposition and assertiveness than right-wing politicians. The study of the factors that might have offered an alternative explanation for the  political bias found did not result in an alternative explanation (for more details, see Varwijk, 2008: 40–8). Some had an effect on the adversarialness of the questions, but not on the bias in the use of these questions. More generally, the conclusion of this study is that interviewers are partial in shaping the way in which politicians can present 01020304050607080 patter n 1 patter n 2 patter n 3 patter n 4 patter n 5% of questions Left wing Political centre Right wing patter n 1: left-wing politicians treated less adv ersarially than politicians from the political centre ,  while r ight-wing politicians are treated most adversarially patter n 2: politicians in the political centre treated just as adversarially as right-wing politicians patter n 3: politicians in the political centre treated more adv ersarially than right-wing politicians patter n 4: politicians in the political centre treated less adv ersarially than right-wing and left-win g  politicians patter n 5: no political bias Figure 5. Patterns in the contextual-specific analyses of the relationship between political  orientation and the adversarialness of the question 14  Discourse &amp; Society 22(1) themselves. Left-wing politicians are approached less adversarially than politicians in  the political centre and right-wing politicians. Discussion The aim of our study was a two-fold one. On the one hand, the study aimed to contribute to the development of a measurement instrument of adversarial questioning in TV inter- views. On the other hand, the aim was to provide a contribution to the discussion on the partiality of the Dutch media. The measurement instrument of adversarial question design QAS proved to be a manageable instrument for the analysis of adversarial question design. It proved possible to apply it in a reliable way (see Data and method, above), while its validity is underpinned in the previous research of the scholars who developed it (Clayman et al., 2007: 27, 32). In this study, we expanded QAS with a sixth aspect of adversarial question design.  The aim of this expansion was to reach a better fit of this instrument, which until now had been applied to press conferences only, with the specific context of the TV interview.  Nearly half of the questions (48.8 percent) showed a form of persistent question design, which proves the relevance of this expansion to the analysis of TV interviews. Moreover,  a post-hoc analysis of the relationships between the various aspects of adversarial ques-tion design showed that persistence has a low correlation with the other aspects (varying from .01 with accountability to .16 with opposition). The analysis of persistence has completed the picture of the interviewer bias, and it represents a different aspect of the overarching notion of ‘adversarialness’. However, the reliability of the coding was not optimal and could be improved (see note 4). Apart from exploring possible expansions, it is also important to reflect on the possi- bility that the instrument might be too extended. The aspect of directness in particular  might not fit into it. More specifically, this aspect distinguished itself from the other aspects of QAS in that one politician received a remarkably different treatment from the other 11: Prime Minister Balkenende was approached significantly more often indirectly. On the one hand, this preferential treatment is in accordance with politeness theory (Brown and Levinson, 1987), which regards indirectness as being related to perceptions of the power difference between speaker and addressee. On the other hand, it is inconsis-tent with QAS, which sees indirectness as an aspect of the construct of ‘adversarialness’. Political bias of the media Our study showed political bias that was not related to, and thus could not be explained by, one of the many contextual factors in the design of the study. When the factors stud-ied cannot clarify the interviewer bias, where does it come from? Were there factors that we neglected? We paid a great deal of attention to the answering behaviour of the interviewee, but  possibly not enough to the truth value and quality of the answers. Suppose left-wing  politicians are right more often than right-wing ones and their answers are qualitatively  Huls and  Varwijk 15 better. If this supposition is true, it is more than reasonable that the interviewers should  show political bias. However, we have not investigated the truth values of the statements and the quality of the answers, because we were afraid to stir up a hornet’s nest. But on second thoughts, this explanation does not have to be dismissed as ‘impossible to inves-tigate’. It is possible to carry out a qualitative and intensive follow-up study of the tran-scripts and analyse so-called ‘minimally contrasting pairs’ (Brown and Gilman, 1989): sequences of utterances on comparable issues with comparable relationships to reality and truth, but differing with respect to the political orientation of the interviewee. Although such an analysis might not explain the bias that we found, it could offer addi-tional insight into the precise way it works. That by itself would be a gain. Finally, we would like to say something about the generalizability of the outcome: the  results of this study show that an important political platform, which is considered to be a backbone of public broadcasting in the Netherlands (see Data and method, above), was not impartial in the run-up to the parliamentary elections of 2006. However, the late-night talk show Pauw &amp; Witteman  was not the only platform where politicians presented them - selves to the public. This study is a case study whose results cannot be generalized to other TV programmes, radio or newspaper interviews, or media in general. In that context, it is  interesting to take a look at the mission of Dutch Public Broadcasting, which states in its first sentence that ‘Dutch Public Broadcasting belongs to everyone and is aimed at every - one, everywhere and always’ (Mission and Strategy, no date). According to University of Amsterdam researcher Scholten (in Wind, 2007), the idea is that ‘the differing broadcast associations may be biased, but it is a task for them together to present sufficient multifor - mity’. From this perspective, our finding that Pauw and Witteman are left-wing is note - worthy, but there is no cause for concern if it is counterbalanced by right-wing platforms. However, insight is lacking here. What is needed now is more research into different inter - viewers, programmes, broadcasting systems, stations and organizations, and other forms of media. Only then will it be possible to make generalizing statements about the political bias of Dutch media and continue the current debate on a more empirical note. Acknowledgements The following persons and platforms contributed to this study. Miriam Lauers was the  second judge in the analysis of the reliability of the coding. Carel van Wijk authorized the statistical analyses. Allard Welmers provided viewer ratings. Malcolm Wren informed us about the legal and normative framework of political TV interviews in the UK. He  also helped with the translation of the fragments. The study was presented and discussed in the Ross Priory Group for Research on Broadcast Talk. Marc Swerts and Paul Drew gave comments on an earlier version of this article, as did two anonymous reviewers of the VIOT conference and a reviewer of Discourse &amp; Society. We are grateful to the  people involved for their contributions. Notes 1. ‘Neutralism’ is distinguished from ‘neutrality’ in the professional literature (Clayman and  Heritage, 2002a). The questions in media interviews cannot meet the norm of ‘neutrality’ in an  absolute sense: the selection of topics and contexts is not neutral, questions unavoidably con-tain presuppositions that are problematic for the interviewee to a lesser or higher degree, and questions are formulated in such a way that they create a specific expectancy of the answer. 16  Discourse &amp; Society 22(1) 2. NPO as well as the embedded V ARA/NPS work within the legal framework of the Dutch  Mediawet (i.e. Media Law), which defines it as the task of public broadcasting to offer a multiform range of programmes and to present a picture of society and its social, cultural and  religious views in a balanced way (Mediawet, 2010: article 13). We did not find any indication  that the normative framework of TV programmes in the Netherlands gets more relaxed as one  moves into late-night shows, nor did we find stricter rules and regulations during the run-up  to an election. 3. These figures were provided by ‘KLO Informatie en Advies’. In addition, 5.8 percent of the viewers of the Pauw &amp; Witteman show is younger than 30 years old, 26.9 percent is aged  between 30 and 50, 52.8 percent is between 50 and 70 years old, and 14.5 percent is 70 or older. With respect to the political orientation of the viewers (i.e. their voting behaviour in the preceding parliamentary elections of 2003): 12.9 percent voted for the left-wing SP, 27.5  percent voted PvdA (the position of this party in the Dutch political landscape is clarified in  Figure 2), 16.2 percent voted for the party in the political centre CDA, 7.6 voted for right-wing VVD, and the remaining category of 35.8 percent includes the voters for the other parties, the viewers without the right to vote, and the viewers whose political orientation is unknown. 4. The reliability of the coding of persistence with a value of .56 is not optimal. The kappa val-ues of the underlying indicators ‘repeating the question’, ‘commenting on evasive action of the politician’ and ‘interruption’ were .47, .47 and .66 respectively. These reliabilities could   be improved by defining the indicators in a more formal way and providing more specific guidelines. 5. Although the technique used in our analysis of the contextual factors looks different from what others did (Clayman et al., 2007), the difference is superficial: the binary logistic regressions led to the same conclusion that logit would have produced. Transcription conventions (after Montgomery, 2007) (&lt;) pause of a second or less (only partly intelligible) uncertain transcription ((clarification)) clarification, usually contextual information [ beginning of overlapping stretch of speech = introduces latched turn→ indicates line which is the focus of comment or discussion References Brown, P. and Levinson, S. (1987) Politeness: Some Universals in Language Usage. Cambridge:  Cambridge University Press. Brown, R. and Gilman, A. (1989) ‘Politeness Theory and Shakespeare’s Four Major Tragedies’,  Language in Society 18: 159–212. Clayman, S.E. (2001) ‘Answers and Evasions’, Language in Society 30: 403–42. Clayman, S.E. and Heritage, J. (2002a) The News Interview: Journalists and Public Figures on the  Air. Cambridge: Cambridge University Press. Clayman, S.E. and Heritage, J. (2002b) ‘Questioning Presidents: Journalistic Deference  and Adversarialness in the Press Conferences of Eisenhower and Reagan’, Journal of  Communication 52: 749–75. Clayman, S.E., Elliott, M.N., Heritage, J. and McDonald, L.L. (2007) ‘When Does the Watchdog  Bark? Conditions of Aggressive Questioning in Presidential News Conferences’, American  Sociological Review 72: 23–41. Huls and  Varwijk 17 Cohen, J. (1960) ‘A Coefficient of Agreement for Nominal Scales’, Educational and Psychological  Measurement 20: 37–46. D’Alessio, D. and Allen, M. (2000) ‘Media Bias in Presidential Elections: A Meta-Analysis’,  Journal of Communication 50: 133–56. Ekström, M. (2001) ‘Politicians Interviewed on Television News’, Discourse and Society 12(5):  563–84. Ekström, M. (2009) ‘Announced Refusal to Answer: A Study of Norms and Accountability in  Broadcast Political Interviews’, Discourse Studies 11(6): 681–702. Elliott, J. and Bull, P. (1996) ‘A Question of Threat: Face Threats in Questions Posed during  Televised Political Interviews’, Journal of Community and Applied Social Psychology 6: 49–72. Greatbatch, D. (1988) ‘A Turn-taking System for British News Interviews’, Language in Society  12(5): 401–30. Harris, S. (1991) ‘Evasive Action: How Politicians Respond to Questions in Political Interviews’,  in P. Scannell (ed.) Broadcast Talk, pp. 76–99. London: Sage. Heritage, J. (1985) ‘Analyzing News Interviews: Aspects of the Production of Talk for   an Overhearing Audience’, in T.A. van Dijk (ed.) Handbook of Discourse Analysis Vol. 3,  pp. 95–119. New York: Academic Press. Heritage, J. and Clayman, S. (2010) Talk in Action: Interactions, Identities, and Institutions.  Malden, Oxford, Chichester: Wiley-Blackwell. Huls, E. (2008) ‘Haagse Antwoorden: Een Onderzoek naar Genderverschillen in Politieke  Interviews’ [Hague Answers: A Study into Gender Differences in Political Interviews],  Tijdschrift voor Genderstudies, themanummer Gender en Linguïstiek 1: 53–66. Huls, E. (2009) ‘Vraagontwijking: Een Glibberig Fenomeen’ [Evasive Action: A Slippery  Phenomenon], in A. Backus, M. Keijzer, I. Vedder and B. Weltens (eds) Artikelen van de Zesde  Anéla-Conferentie, pp. 153–62. Delft: Eburon. Hutchby, I. (1992) ‘The Pursuit of Controversy: Routine Skepticism in Talk on “Talk Radio”’,  Sociology 26(4): 673–94. Hutchby, I. (2006) Media Talk: Conversation Analysis and the Study of Broadcasting. Maidenhead:  Open University Press. Kieskompas (2010) http://tweedekamer-kieskompas-nl/ (accessed 18 January 2010).Kinnear, P.R. and Gray, C.D. (2001) SPSS for Windows Made Simple, Release 10. Hove:  Psychology Press. Kuiper, Y . (2006) Vraagontwijking: Verschillen tussen Mannelijke Politici, Vrouwelijke Politici  en Niet-Politici [Evasive Action: Differences between Male and Female Politicians and Non-Politicians]. Masters thesis, Tilburg University, Tilburg. Mediawet (2010) http://wetboek.net/Mw/13c.html (accessed 5 May 2010).Missie en Strategie [Mission and Strategy] (no date) http://portal.omroep.nl/ nossites?nav=eayitC sHjCqBfElCcBV (accessed 20 June 2009). Montgomery, M. (2007) The Discourse of Broadcast News: A Linguistic Approach. London and  New York: Routledge. NPO (2010) http://npo.omroep.nl/page/speerpunten/nieuws_en_actualiteit (accessed 5 May 2010). NPS Jaarverslag (2006) www.nps.nl/static/download/npsdoc/NPSJaarverslag2006.pdf (accessed  5 May 2010). Pauw, J. and Witteman, P. (2007) http://omroep.vara.nl/Pauw-Witteman.1363.0.html (accessed 13  November 2007). 18  Discourse &amp; Society 22(1) Pomerantz, A. (1984) ‘Pursuing a Response’, in J. Atkinson and J. Heritage (eds) Structures  of Social Action: Studies in Conversation Analysis, pp. 152–63. Cambridge: Cambridge  University Press. Varwijk, J. (2008) Rechts, Links of Rechtschapen: Een Gespreksanalytische Benadering van  Neutraliteit in Politieke TV Interviews [A Conversation-Analytical Approach of Neutrality in  Political TV Interviews]. Masters thesis, Tilburg University, Tilburg. Wind, M. (2007) ‘Publieke Omroep: Het Blijft Kleven, dat Linkse Imago’ [The National Channel:  It Does Not Get Rid of Its Left-Wing Image], Trouw, 24 November. Available from: www. trouw.nl/krantenarchief/ (accessed 20 June 2009). Erica Huls  is Assistant Professor in the Department of Communication and Information  Sciences, Tilburg University. Her main research topics are power in discourse and polite - ness. She works within the fields of pragmatics and conversation analysis. She has pub - lished a number of books and articles on family interaction, communication in multicultural  settings and gender differences in language use (see, for example, ‘Power in Turkish Migrant Families’, in Discourse &amp; Society 11(3): 345–72). During the last few years, she  has carried out research into question design and evasive action in media interviews.  Jasper Varwijk  recently graduated from Tilburg University, obtaining a Masters degree in  Communication and Information Sciences. For his Masters thesis, he conducted research  on neutrality in TV interviews, which led to several publications. Currently, he is prepar - ing a PhD study on political bias in Dutch journalism and is working as an editor for several magazines focusing on computer technology and new media.  Address : Department  of Communication and Information Sciences, Faculty of Humanities, Tilburg University, PO 90153, 5000 LE Tilburg, the Netherlands.  [email: j.varwijk@me.com]</td>
    </tr>
    <tr>
      <th>93</th>
      <td>news</td>
      <td>doi:10.1111/j.1662-6370.2011.02015.x\n\nThe Fairness of Media Coverage in Question:\nAn Analysis of Referendum Campaigns on\nWelfare State Issues in Switzerland\nLionel Marquis, Hans-Peter Schaub &amp; Marlène Gerber\nUniversity of Lausanne and University of Berne\n\nAbstract: The mass media are assigned an important role in political campaigns on popular votes.\nThis article asks how the press communicates political issues to citizens during referendum campaigns, and whether some minimal criteria for successful public deliberation are met. The press coverage of all 24 ballot votes on welfare state issues from 1995 to 2004 in Switzerland is examined,\ndistinguishing seven criteria to judge how news coverage compares to idealized notions of the media’s role in the democratic process: coverage intensity, time for public deliberation, balance in media\ncoverage, source independence and inclusiveness, substantive coverage, and spatial homogeneity.\nThe results of our quantitative analysis suggest that the press does fulﬁl these normative requirements to a reasonable extent and that fears about biased or deceitful media treatment of ballot\nissues are not well-founded. However, some potential for optimizing the coverage of referendum\ncampaigns by the Swiss press does exist.\n\nKeywords: Referendum campaigns, media fairness, press coverage, welfare state, Switzerland\n\n1. Introduction1\nInstruments of direct democracy are at the heart of the Swiss political system. They are\nwidely used, so much in fact that Switzerland alone accounts for half of all referendums\nheld at the national level all over the world (Kaufmann et al. 2005; DuVivier 2006). Quite\nexpectedly, this unequalled degree of direct democratic practice has triggered research to\nexplore the determinants, conditions, and outcomes of the use of initiatives and referendums, as well as research to ﬁnd out the causes of their success or failure. For example,\nSwiss scholars have directed their attention to the institutional eﬀects of the referendum on\nthe integration of political forces and to its role in shaping the Swiss concordance system\n(e.g., Neidhart 1970; Papadopoulos 1998; Vatter 2002). Another important area of inquiry\nfocused on individual and aggregate citizen behaviour in referendum votes, relating voting\npatterns to the level of elite support or to structural properties of campaign propaganda\n(e.g., Hertig 1982; Trechsel and Sciarini 1998; Bützer and Marquis 2002).\n1\n\nThis research was carried out at the University of Berne in the framework of a project on the ‘‘Political Consequences of Attitudes Toward the Welfare State’’ funded by the Swiss National Science Foundation, whose ﬁnancial\nsupport is gratefully acknowledged (grant #100012–108274). The authors would like to thank Klaus Armingeon\nand Nathalie Giger for their support, as well as Hans Hirter, head of the Anne´e Politique Suisse series, for giving\nus access to its invaluable archive of Swiss press releases. We also thank two anonymous reviewers for their extremely helpful comments on an earlier draft of our manuscript.\n\n 2011 Swiss Political Science Association\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nSwiss Political Science Review 17(2): 128–163\n\n129\n\nIn this study, we follow a complementary approach. Speciﬁcally, we ask how political\nissues are communicated to citizens during referendum campaigns, and whether some minimal criteria for successful public deliberation are met. Our analysis is based on the press\ncoverage of twenty-four ballot votes on welfare issues, spanning more than two legislative\nperiods (1995–2004) of highest importance for the development of the Swiss welfare state.\nAccordingly, our aim is to shed light on the journalistic perception of ballot campaigns.\nHowever, the views of political actors directly involved in partisan campaigns (e.g., parties,\nbusiness associations) are also reﬂected in their agenda-building eﬀorts to capture and manage media attention. It is from the interplay between these two perspectives on the news\nprocess — the journalists’ gatekeeping role and the elites’ agenda-building role — that the\nfocal questions of this study arise. What is the degree of media autonomy? How inclusive\nare journalists’ accounts of the political actors involved in campaigns? How biased are their\nportrayals of issues?\nIn the next section of the paper we present some current ideas about public deliberation\nand provide theoretical insights into the structure and functions of referendum campaigns.\nWe thus set a number of criteria for assessing whether media campaigns may be regarded as\nwise guides to sound decision-making. Section 3 then presents the empirical data collected\nand the methods used for measuring the quality of media campaign coverage. Sections 4 to\n7 oﬀer evidence of how journalists report on welfare state issues. We show that the press\ntreatment of these issues does not fall short of expectations as concerns seven distinct criteria\nof ‘‘fair coverage’’. On this overall basis, we conclude in Section 8 that some fears about\nskewed or deceitful media treatment of ballot issues are not justiﬁed, but also that the\ncommunication and framing of issues does not meet all conceivable normative requirements.\n\n2. Theoretical background: Criteria of fair media coverage\nThis article focuses on the ‘‘supply side’’ of referendum campaigns. Speciﬁcally, we attempt\nto deﬁne a number of dimensions on which to judge the fairness and democratic utility of\nthe coverage of referendum issues in the Swiss media. The importance of articulating ‘‘democratic expectations of media performance’’ has been emphasized in several contributions\n(e.g., Gurevitch and Blumler 1990; McLeod et al. 2002). In particular, the ‘‘social responsibility’’ of the media has attracted much attention, leading scholars to deﬁne a number of\ndesirable qualities of media content –– some of which may be properly regarded as ‘‘ethical’’, but others are more directly related to the functioning of democratic systems (e.g.,\nBunton 1998; Christians and Nordenstreng 2004).\nOur questioning in this article takes place in the interplay of several disciplines — including media ethics and the theory of deliberative democracy. These are broad and currently\nexpanding disciplinary areas rather than formalized theories coupled with established methods and ﬁeldwork, as the example of deliberative theory suggests (see Bächtiger et al. 2010).\nThese theoretical accounts do not provide a clear and agreed-upon indication of what\nmedia fairness should be conceived of, let alone how to measure fairness. However, to the\nextent that the media are an important arena where democratic deliberation may occur, one\nmajor conceptual distinction from deliberative theory is helpful for framing our approach\nto media fairness.\nScholars in the deliberative framework usually advance that democratic decision-making\nand deliberation may be appraised (and purportedly justiﬁed) either from an epistemic or\nfrom a procedural standpoint (see Cohen 1986; Estlund 1997; List and Goodin 2001). The\ndistinction is captured in the question of ‘‘whether we want our political outcomes to be\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nright or whether we want them to be fair’’ (List and Goodin 2001: 277). To be sure, democratic processes oriented toward the search for ‘‘truth’’ or toward the observance of procedures may often bring about similar outcomes. It is nevertheless easy to imagine cases\nwhere ‘‘correctness’’ lacks procedural fairness (e.g., one individual ‘‘rightly’’ chooses for all\nothers) and other cases where procedural rigidity is misplaced from procedure-independent\nstandards (e.g., it violates some notion of the ‘‘common good’’).\nThe ﬁeld of media ethics is concerned with the same kind of questions, asking whether\nand how the ‘‘fairness’’ goal of media coverage can put up with the sometimes dissonant\nideal of the ‘‘correctness’’ of the views being presented — beyond the mere question of\ninformation ‘‘accuracy’’. In this article we adopt a procedural stance and examine how media\ncoverage fulﬁls a number of formal rules regarding the form, provenance, and diﬀusion of\ninformation.2 Even though correctness criteria may appear to involve considerations of a\nmore normative nature, it is however obvious that any set of formal-procedural rules is\nitself not ‘‘given’’. As will become clear, some of the procedural criteria described below\nhave been the subject of considerable speculation and debate. Moreover, ‘‘fairness’’, as the\npivotal concept of procedural approaches, is to be taken here in a generic sense, as it\nextends beyond the notions of fairness developed in careful theoretical analyses of ‘‘democratic proceduralism’’ (Cohen 1989; Estlund 1997).3 This enlarged concept of media fairness\nposits that, whatever the media induce citizens to think and choose, they must do so within\ncertain procedural boundaries.\nIn this article we will focus on seven criteria that appear particularly relevant to evaluating the fairness of the media coverage of referendum campaigns in Switzerland. In this and\nthe following sections we identify these criteria at a fairly abstract level, based on the available literature, and we show how each of them provides an appropriate dimension for\nassessing the achievements of campaign coverage from a normative perspective. Our goal in\nthis contribution is primarily comparative, as we aim at showing how fairness varies across\nissue domains, across media outlets, over time, and across geographical units. Therefore,\nwe deliberately avoid setting precise boundaries between ‘‘fair’’ and ‘‘unfair’’ coverage. On\nthe other hand, the measurement of relevant criteria should be as precise and abstracted\nfrom context as possible, in order to allow for valid and meaningful comparisons. Besides,\nin order to avoid conceptual ambiguities, let us make clear that the term ‘‘fairness’’ is used\nhere to denote the ‘‘positive side’’ on each dimension of media coverage. Thus we do not\nwish to imply, for instance, that a short, two-week campaign coverage is deliberately\n‘‘unfair’’ or intended to fool voters, but only that a longer time period is more desirable\naccording to some formal-procedural normative standard.\nBased on this broad deﬁnition, we now delineate seven speciﬁc criteria for appraising the\nfairness of media campaign coverage.\n2\nBy choosing a procedural rather than epistemic perspective, we do not mean to imply any superiority or higher\ndesirability of the former perspective in dealing with our subject.\n3\nNevertheless, the fact that the elaboration and selection of procedural criteria is no less subjective than that of\nepistemic principles does not mean that the fundamental distinction between the two types of considerations is\nblurred. Generally speaking, our approach to media fairness is blind to information which may be of uttermost\nimportance from an epistemic perspective — the speciﬁc opinions and origins of information purveyed in media\ncoverage. We do not say that journalists are not (or should not be) driven by an orientation toward the common\ngood, as when they downplay opinions that are disruptive and threatening for the democratic order — for example,\nBritish and German journalists have totally ignored extreme right parties in their coverage of election campaigns in\nthe 1980s and 1990s (Bornschier 2010: 174-5). We simply say that this reference to the explicit content and implicit\nintent of media coverage is not relevant for our present purposes.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n130\n\n131\n\n1. Suﬃcient media coverage of issues. We ﬁrst consider the information function of the\nmass media and the public knowledge of political issues that is expected to stem from media\ninformation. Learning eﬀects are extremely important from a normative perspective, since\nthey attest to the capacity of the people to understand politics and to exert inﬂuence on\npolicies, as emphasized by classical democratic theory (e.g., Berelson 1952; Kelley 1960;\nKrouse and Marcus 1984; but see Pateman 1970). As a matter of fact, it has long been\nshown that media exposure generates knowledge about issues and candidates, and enhances\nopinion strength and attitude integration (e.g., Berelson et al. 1954: chap. 11; Delli Carpini\nand Keeter 1996: chap. 5; Jerit et al. 2006). These eﬀects are usually not overwhelming, but\nthey are quite robust across a wide range of contexts. Accordingly, learning eﬀects have\nbeen observed in the Swiss direct democratic context as well (Kriesi 1994; Kriesi 2005: chap.\n4; Marquis 2006). Information holding, in turn, matters for political judgments and voting\ndecisions (Bartels 1996; Sturgis 2003). For example, a lack of knowledge causes citizens to\nbe more conservative on some issues and more liberal on others (Althaus 1998; Gilens\n2001), and it usually prompts reliance on heuristic cues that can lead to serious misﬁts\nbetween the people’s actual choices and their own values and interests (e.g., Kuklinski and\nQuirk 2000). Therefore, the overall intensity of media campaign coverage probably matters\nboth for the public knowledge of issues and for the ﬁnal outcome of the ballots. In fact,\nfew would question that a suﬃcient amount of information is necessary for the proper functioning of democratic institutions. However, as argued below, the content of information\nalso deserves attention, especially as concerns value-laden information (e.g., Hofstetter\net al. 1999).\n2. Suﬃcient time for public deliberation. Time is needed for the public to become\ninformed about the issues and to ponder the pros and cons of a ballot proposal. If all campaign coverage takes place in a last-minute avalanche, then it is unlikely to beneﬁt citizens,\nhowever extensive it may be in terms of sheer volume. Quite logically, the inﬂuence of a\ncampaign usually concentrates on citizens who make up their minds during that campaign,\nthat is, for people whose voting decision was neither clear from the outset nor delayed until\nthe very last campaign days (e.g., Chaﬀee and Choe 1980; Fournier et al. 2004; Marquis\n2006). Were campaigns so short-lived as to be virtually nonexistent for the purpose of\ndeliberation, the collective decision-making process would be essentially reduced to the use\nof last-minute shortcuts (e.g., status quo bias) or of long-standing attitudes and prejudices\n(e.g., a personal bias against ‘‘big government’’). The longer the referendum campaigns, the\nmore likely it is that the same issues will be tackled and thus the same arguments will be\nrepeated. In turn, this cumulative exposure may be expected to facilitate information acquisition by citizens (see Marquis and Bergman 2009). In other words, frequent exposure to\ncampaign information enhances the accessibility of the relevant concepts (e.g., Higgins\n1996; Förster and Liberman 2007) and heightens the likelihood that they will permeate the\ncitizens’ voting considerations.\n3. No outright bias in media coverage. A relatively unbiased media coverage of issues may\nbe stressed as a prerequisite for sound collective deliberation. This ‘‘impartiality’’ or ‘‘balance’’ assumption is more or less explicitly present in the writings of political philosophers\nsuch as Arendt, Elster, and Habermas, but also in concrete experiments designed to mimic\nideal deliberative procedures (e.g., Yankelovich 1991: chap. 12; Luskin et al. 2002). Likewise, the norm of balance is deeply enmeshed in Western (primarily Anglo-American) culture and values (Schudson 2001). It looms large in the self-descriptions and perceived\nprofessional standards of journalists (e.g., Tuchman 1972; Patterson 1998) and in academic\nstudies of media coverage unveiling their structural biases (e.g., Gitlin 1980; Hallin 1984;\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nEntman 2004; Bennett et al. 2007).4 In addition, the development of ‘‘media watchdog journalism’’ monitoring media bias is, in part, reﬂective of the increasingly acute perception of\nthe media bias problem in Western societies (Graber 2006; Hayes 2008). For our present\npurposes, such ‘‘issue neutrality’’ may come in several forms: the media may simultaneously\npresent the arguments of both sides on an issue, or they may successively alternate between\npros and cons (and thus act neutrally on an aggregate basis), or else they may restrict themselves to presenting ‘‘facts’’ and avoid matters of opinion. Meanwhile, the requirement that\nthere be no outright bias in media coverage must not be taken to mean that the media\nshould display no partisan bias, or that they should avoid expressing opinions altogether.\nActually, some bias is inevitable and probably inconsequential, provided that it is not systematic and identical across all media outlets and issues. In addition, some mix of factual\ninformation and opinion statements is probably preferable to either one alone, for voters\nmost certainly need –– and look for –– both types of information to make up their minds.\nAs one study has shown, a voter’s general need for orientation toward media information is\ncodetermined by her interest in acquiring knowledge about facts and about journalistic evaluations (Matthes 2005).\n4. Source independence. Similar to balance, the ‘‘source independence’’ norm implies\nthat the media are assigned responsibility for addressing issues in an autonomous manner.\nIn this case, the normative expectation is that journalists should not depend too heavily\non government, political parties and special interests for getting and framing information\non campaign issues. Actually, there is a widespread belief in Western societies, including\nSwitzerland, that journalists have ‘‘surrendered to complexity’’ and mainly serve as emissaries or ‘‘postmen’’, as Wuerth (1999: 373) put it. According to the ‘‘determination\nhypothesis’’ and similar accounts of media-politics relationships, most news originates\nfrom oﬃcial sources, including government and various branches of the administration,\nand especially from governmental public relations activities. Such source dependency, so\nthe critics say, would lead to the formation of a misinformed and quiescent public (e.g.,\nBaerns 1979; King and Schudson 1995; Shoemaker and Reese 1995; Bentele 2003). For\ninstance, Grossenbacher et al. (2006) found that the press conferences held by two Swiss\ncantonal governments were indeed covered extensively by the local media, and that the\npress releases issued on these occasions were often published in original or only slightly\nabridged form, reproducing the local authorities’ positive self-assessments and issue priority. Likewise, more than half of the news stories in the U.S. press persistently emanate\nfrom oﬃcial sources (e.g., Sigal 1973; Graber 2006). However, some scholars have cast\ndoubt on the generalizability of such ﬁndings. For instance, it was found that the parties’\npress releases rarely ﬁnd their way into the German print media and ⁄ or that they are frequently altered and reframed by journalists (e.g., Donsbach and Wenzel 2002; Fröhlich\nand Rüdiger 2006). To some extent, journalists and their political sources are interdependent, both from a historical perspective (Schönhagen 2008) and in terms of role relationships (Merritt 1995). Journalists themselves are ambivalent about the autonomy issue. On\nthe one hand, they increasingly value public relations sources and practitioners in the\n4\n\nBiased coverage may occur in relatively subtle ways, such as when the photographs of candidates in newspapers\nare more or less favourable, depending on the ﬁt between the candidate’s and the paper’s political leanings (Barrett\nand Barrington 2005). However, no consensus can be found in the literature as to whether media coverage is structurally biased, for instance conservative-leaning vs. liberal-leaning, or pro- vs. anti-establishment. Interestingly, the\npublic perception that the media are biased toward liberal views may not be due to ‘‘real-world’’ media coverage\nbias, but to media self-coverage about biased media content (Watts et al. 1999).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n132\n\n133\n\ncourse of their professional experience (Sallot and Johnson 2006), not least because by\ncreating long-term relationships with insiders they are granted routine access to valuable\nﬁrst-hand information. On the other hand, ‘‘autonomy’’ is seen as an important journalistic norm (e.g., Gurevitch and Blumler 1977; McDevitt 2003), admittedly with some important diﬀerences between national contexts (Patterson 1998; Statham 2006).5 In the present\nstudy, we will assess to what extent journalistic accounts of the campaign issues are elaborated ‘‘independently’’ or based instead on ‘‘self-serving’’ sources of information such as\ngovernment, parties, and referendum committees.\n5. Source inclusiveness. The norm of inclusion calls for the coverage of the whole diversity of viewpoints, arguments, and groups engaged in a referendum campaign. This norm\nthus concerns the question of how broad the variety of sources to which journalists refer\n(and which they make available to the public) should be. From another perspective, it\nasks how open or restricted the access to the media should be for diﬀerent actors to\nvoice their standpoints toward a referendum issue. Several democratic theorists have\nstressed the importance of an unrestricted and equal access for all individuals and societal groups to democratic processes in general (e.g., Dahl 1989: 119–131) and to the processes of public deliberation and will-formation in particular. The inclusiveness of the\nlatter is especially prominent in theories of deliberative democracy. Cohen (1989: 21–23,\n30; see also Dryzek 1990; Habermas 1992) regards inclusiveness and open access as a\ncrucial aspect of an ‘‘ideal deliberative procedure’’.6 However, various empirical studies\nhave raised doubts about whether the media in reality live up to these expectations of\ndemocratic theorists (e.g., Page 1996; Gerhards 1997; Graber 2003). Pfetsch (2004) and\nBerkowitz (2009) argue that the degree of inclusiveness heavily varies depending on factors such as the cultural context, the journalists’ social characteristics, or the issue at\nstake. Speciﬁcally for Swiss referendums, Marquis and Bergman (2009) report a quite\nmarked decrease in the variety of actors involved in advertisement campaigns in the\n1990s. One reason for a low variety of sources might be the increasing commodiﬁcation\nand commercialization of the media, which presses them to restrict themselves to sources\ncompatible with the mainstream (Meier and Jarren 2002). Second, an increasing professionalization in the PR departments of the more established political actors might raise\nthe hurdles for less prominent and ﬁnancially disadvantaged groups to ﬁnd their way\ninto the media (Gurevitch and Blumler 1990). Third, while there do exist strategies for\npolitical ‘‘outsiders’’ to get included in a mediated political discourse, established political\nactors have also developed counter-strategies to hold outsiders and their arguments oﬀ\nthe media attention (Kriesi 2003: 221–225). In the following analysis, we will assess the\nvariety of reported viewpoints by the number of diﬀerent groups of actors which journalists draw on as information sources.\n6. Substantive coverage. For many observers, it is not enough that media information\nbe balanced and independent of special interests — in addition, it has to address the\nsubstance of political issues. In fact, an essential part of campaign news coverage is\n5\n\nFurther, journalists may feel committed to autonomy as a result of their own audiences’ support for the norm\nof impartial coverage (Hargreaves and Thomas 2002) and as a result of their commitment being challenged by\n‘‘popular commentators’’ such as bloggers (Singer 2007). In fact, public trust in the media may be undermined by\nexcessive governmental control (Connolly and Hargreaves Heap 2007).\n6\nThe inclusion of the whole diversity of opinions and societal groups is also a core request of the so-called ‘‘diﬀerence democrats’’, who emphasize that it enhances not only the legitimacy of the opinion-building process, but also\nthe stock of social knowledge and information available to the participants in the public discourse, thus facilitating\nwell-informed and rational decisions (Young 1990: 119; 2000: 81–120; see also Connolly 1991).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nframed in terms of non-substantive features of elections, such as their ‘‘game’’ or\n‘‘horserace’’ aspects, and ignores their underlying issues (e.g., Strömbäck and Dimitrova\n2006). A strong case has been made against the pervasiveness and deleterious inﬂuence\nof horserace information in a variety of election campaigns (e.g., Gollin 1980; Bartels\n1988; Patterson 1994). We therefore only brieﬂy discuss the relevance of the issue for\nthe Swiss direct democratic environment. As pointed out by Rothmayr and Hardmeier\n(2002) and Longchamp (1998), the practice of direct democracy in Switzerland has\ninhibited rather than stimulated the development and use of opinion polls by both the\nmedia and governmental agencies. This is because frequent and ‘‘real’’ voting results\nare widely considered to provide a better account of public opinion than ‘‘unrealistic’’,\n‘‘out-of-context’’ opinion polls. However, Swiss journalists may ﬁnd such polls attractive\nto report, in light of the news media’s preference for the ‘‘horserace’’ aspects of campaigns and for warfare and sports narratives. Moreover, they may ﬁnd it convenient to\ndraw on such ready-to-use information, without paying too much attention to its technical validity and practical relevance (see Hardmeier 1999). As a way to gauge the\nextent of horserace coverage, we will compare the amounts of ‘‘campaign-oriented’’ and\nof ‘‘issue-oriented’’ information provided by the media.\n7. Spatial homogeneity. In a multicultural society such as Switzerland, the protection\nof minorities is usually a pressing issue. In addition, there is widespread concern that\ndirect democratic decisions might heighten the risk of some ‘‘tyranny of the majority’’\n(e.g., Donovan and Bowler 1998; Hajnal et al. 2002). In Switzerland, diﬀerences between\nlinguistic regions, particularly as concerns voting behaviour in referendums, constitute\none of the most salient political cleavages (e.g., Kriesi 1998; Linder et al. 2008). This\ncleavage is also one that is clearly identiﬁable and frequently reported on in the news\nmedia, probably because it is conﬂict-laden and thus has a high news value (Kriesi et al.\n1996; Hardmeier 2000: 388). The Swiss media system is itself highly segmented along linguistic lines (Kriesi et al. 1996; Wuerth 1999; Blum 2003; Tresch 2008), and even the\npublic service media ﬁnd it increasingly diﬃcult to promote national cohesion, as this\ntask is incompatible with economic imperatives (Meier and Schanne 1994: 37–39). In\nfact, concerns about majority rule are not substantiated by empirical evidence in general\nterms, as referendum voting patterns are much more homogeneous than heterogeneous\nacross cantonal and linguistic units (Diskin et al. 2007). In some cases, however, these\nconcerns may be justiﬁed, as suggested by parliamentary votes or referenda results on welfare state issues, showing support for welfare policies to be signiﬁcantly higher in the\nFrench- than in the German-speaking region (e.g., Leuthold et al. 2007). To be sure, it is\nperfectly legitimate for journalists from diﬀerent places and cultural backgrounds to pursue their own agendas, for example as they index their treatment of job issues to real or\nperceived unemployment rates in their own area. Likewise, journalists may choose diﬀerent speciﬁc information ‘‘formats’’ (e.g., heavily biased ‘‘opinion’’ articles or more balanced ‘‘points of view’’ articles) depending on their cultural environment and on how\nparochial the interests at stake are (e.g., Robinson 1995: 360–362). Accordingly, there is\nno reason to expect equal issue coverage all over the country. However, the inﬂuence of\nthe media on voters can diﬀer between the linguistic areas (e.g., Kriesi 1994; Marquis\n2006: 623–628). Hence, heterogeneity of media content may reinforce existing cleavages\nand (re)produce undesirable tensions between linguistic communities. In the cases where\nthe majority group prevails, it may fuel the argument of a ‘‘tyranny of the majority’’. In\nsum, small between-region variations in media coverage are arguably preferable to great\nvariations.\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n134\n\n135\n\n3. Methods and measurements\nThis study bears on the 24 ballot votes dealing with welfare state issues which were held in\nSwitzerland between 1995 and 2004 (see Table A1 in Appendix). Our empirical data consists of press articles collected in twenty-eight daily or weekly newspapers during an eightweek period preceding each ballot. The papers together account for a daily circulation ﬁgure of about two million copies and they are quite representative of the various Swiss\nregions.7 However, they were selected mainly for availability reasons, as they are consulted\non a daily basis by the collaborators of the Anne´e Politique Suisse at the University\nof Berne, Switzerland, and their content is classiﬁed into ﬁne-grained thematic categories.\nIt was thus easy to ﬁnd out all campaign-related articles and to code the relevant\ninformation.\nTwo levels of analysis: articles and issue statements. Overall 4303 articles were found and\ncoded. From these, a one-quarter sample of 1088 articles was randomly selected for additional analysis of the campaign issue statements.8 A maximum of three issue statements per\narticle were coded, with the selection occurring on the basis of internal importance within\neach article. In total, 2859 issues were coded out of our sample, making for an average of\n2.63 issues per article.\nIntensity and length. The number of articles and their size (in centimetres squared, then\nconverted in number of standard newspaper pages) were used to determine the intensity of\ncampaign coverage.9 Based on the date on which an article was published, the number of\ndays remaining before voting day was used to compute a measure of the ‘‘average campaign\nday’’ (mean of days remaining for separate ballots or newspapers).\nSource independence and inclusiveness. Up to ﬁve sources per article were coded to determine who the ‘‘speakers’’ were, i.e., which categories of individuals or groups were primarily involved in determining the content of an article. Multiple sources were considered; for\nexample, when a journalist interviews a political leader, two separate sources are coded.\nSimilarly, up to two sources were coded for each issue statement within an article. We thus\ncontrol for the fact that the original issue arguments delivered by a given source are often\nembedded in the discourse of a diﬀerent ‘‘speaker’’ through positive or negative references.\nFor example, it can be the case that all issue statements contained in an article where\n7\n\nThe 1998 circulation ﬁgures are taken from the WEMF marketing research institute. The two related outlets\n‘‘Blick’’ and ‘‘Sonntags-Blick’’ are considered here as one and the same paper. In contrast, the French-speaking\ntabloid ‘‘Le Matin’’ was not available in the archive of the Anne´e Politique Suisse, although it is one of the major\nSwiss papers. However, a glimpse at the data for ‘‘Blick’’, its counterpart in the German-speaking region, suggests\nthat tabloids play a relatively minor role in the coverage of referendum campaigns. As a matter of fact, the 28 outlets are edited in 16 diﬀerent Swiss cantons (out of a total of 26 cantons). Further, according to survey data, a\nmajority of people in all but three cantons (SO, TG, ZH) are ‘‘heavy’’ or ‘‘medium users’’ of at least one newspaper\namong those considered here (http://www.remp.ch/fr/glossar/index.php [accessed: 15.02.2010]).\n8\nThe selection was performed by simply picking every fourth article in the database, reinitializing the count for\neach ballot issue. Checks were made to ensure that the obtained sample was not diﬀerent from the whole dataset as\nconcerns provenance, format, and article bias. An issue statement is deﬁned here as an argument or set of arguments related to one speciﬁc matter addressed in the campaign about a ballot measure. It may pertain to a policy\ntheme (e.g., environment, energy), a driving value or principle (e.g., solidarity), distinctive qualities of the proposed\nmeasure (e.g., ﬂexibility), or the larger context of the ballots (e.g., rationale for a tactic vote). Issue statements have\nbeen classiﬁed into thirty-three categories (full list available upon request from the authors). For reasons of space\nlimitation, however, we will not dwell on the question of which speciﬁc issues were emphasized in the various referendum campaigns.\n9\nFor various reasons (e.g., missing part), 24 articles could not be coded as to their size and were assigned the median value of all calculated sizes (266 cm2).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\n‘‘journalists’’ are identiﬁed as the speaker category are in fact attributable to other actors to\nwhich journalists refer (e.g., partisan sources, government, and employees’ associations).\nBoth speakers and issue statements’ sources were coded into fourteen mutually exclusive\ncategories: (1) parties, politicians, and other party-related groups or individuals; (2) committees; (3) journalists and press agencies; (4) employers’ organizations; (5) employees’\norganizations; (6) economic associations; (7) national government; (8) local government; (9)\nscience- and education-related groups; (10) health-related groups; (11) disabled people’s\ngroups; (12) women’s and families’ groups; (13) other non-proﬁt organizations; (14) other\nactors. Together, categories (1) and (2) represent what we call ‘‘partisan actors’’.10\nThe importance of journalists (category 3) will be compared with that of the other actor\ncategories (both as ‘‘speakers’’ and as sources of issue statements) to assess the degree of\nthe press’ ‘‘source independence’’. Note, however, that the total for any two groups of\nactors may exceed 100 percent since, by deﬁnition, several actors may be considered as the\n‘‘sources’’ of an article or issue statement.\nFurther, we used the same source categories to build our measure of inclusiveness. It is\nsimply the number of discrete categories from which at least one source of issue statements\nis drawn. In some of the forthcoming analyses, we will satisfy ourselves with this ﬁrst measure (NBCAT). However, in order to control for the fact that some sources may be only\nmarginally involved in agenda-building (and inclusiveness may thus be overestimated), we\nalso assessed the degree of ‘‘equality’’ in the total references to sources of issue statements.\nThis was achieved through the Index of Qualitative Variation (IQV):\n\n\nk\nP\n2\n2\nk N  fi\nIQV ¼\n\ni¼1\n\nN2 ðk  1Þ\n\n;\n\nwhere k is the total number of source categories, N is the total number of (weighted) issue\nstatements, and fi is the frequency of all issue statements attributable to source i (N and f\nmay be computed either as absolute numbers or as proportions). IQV scores can be integrated with NBCAT into a standardized measure of inclusiveness: INC=(NBCAT ⁄ 14) ·\nIQV. Somewhat surprisingly, NBCAT and IQV scores are totally uncorrelated at the level of\nballot measures or of separate media outlets (r &lt; .06). In fact, restriction of range in IQV\nvalues (M = 0.87, SD = 0.04, N = 24 ballot measures) explains why NBCAT has a much\ngreater impact in determining INC scores.11 It also justiﬁes using NBCAT alone, for simpliﬁcation purposes, when IQV scores barely vary in cross-temporal and spatial comparisons.\nSubstantive coverage. The ‘‘format’’ of each article was coded following a three-fold distinction: (1) ‘‘opinion articles’’ (i.e., editorials, interviews, op-eds, free columns, or letters to\nthe editor); (2) ‘‘factual articles’’ (i.e., mere reporting); and (3) ‘‘horserace information’’\n(i.e., voting cues by parties and groups, opinion polls and other predictions, coverage of\ncampaign events). The percentage of articles of the ‘‘horserace’’ type is used to assess the\namount of ‘‘non-substantive’’ information. Among ‘‘substantive articles’’, the percentage of\n10\n\nUnlike in other policy areas such as foreign policy (see Marquis 2006), virtually all committees on welfare state\nissues are backed by parties and politicians.\n11\nAt the level of ballots and papers, INC is strongly associated with NBCAT (r &gt; 0.96) but not with IQV scores\n(r &lt; 0.19). This raises the question whether the aggregation rule (unweighted multiplication of the two measures)\nis appropriate, since both NBcat and IQV are important on theoretical grounds. At the empirical level, however, it\nmakes sense not to give more weight to the variable with lesser variation.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n136\n\n137\n\n‘‘opinion’’ and ‘‘factual’’ articles is used to shed light on the ‘‘orientation’’ and ‘‘information’’ functions of press coverage, respectively.\nBias in coverage. Five broad categories aimed to assess the overall thrust of each article,\nbased on the general slant of its arguments: (1) predominantly pro (i.e., suggesting a ‘yes’\nvote on the ballot question); (2) predominantly con; (3) neutral; (4) mixed, i.e., controversial\nand including both sides; and (5) no argument. Similarly, the bias of each issue statement\nwas coded on the basis of the same categories (excepting the ‘‘no argument’’ category,\nwhich is irrelevant). The categories were collapsed across ballot measures or other relevant\nunits of analysis (newspapers, language areas, etc.) and combined to produce a summary\nindicator of coverage bias:\n\n\n\npro þ neu þ mix\nB¼\n 0:5  2;\npro þ con þ 2  ðneu þ mixÞ\nwhere pro is the number of positive items, con is the number of negative items, neu is the\nnumber of neutral items, and mix is the number of controversial items.12 Unbiased coverage\nis denoted by a B value of 0, while B values of –1 and +1 indicate the highest possible bias\nagainst and in favour of some proposal, respectively.\nHowever, B scores are not well adapted for comparing bias in coverage across several\nballot measures, since the meaning of pros and cons depends on how the ballot question\nwas framed. One strategy is to rely on absolute values (i.e., |B| scores) to get an estimation\nof the overall extent of bias, regardless of direction. Another strategy is to devise a measure\nthat expresses bias in terms of endorsement or opposition of welfare state policies. This\nrequires that ‘‘pro’’ and ‘‘con’’ categories be inverted for ballots in the ‘‘retrenchment’’ category, i.e., measures that seek to reduce welfare beneﬁts or to limit welfare expansion. Thus\nan original B score of +0.2 remains unchanged for expansion measures but its polarity is\ninverted and shifted to –0.2 for retrenchment measures. We call this new measure B*. Computing B* scores also implies that ballot measures can be clearly identiﬁed as ‘‘expansion’’\nor ‘‘retrenchment’’ measures. In other words, only media contents that can be clearly\nassigned to ‘‘pro-welfare’’ and ‘‘anti-welfare’’ positions should be considered. This leads us\nto remove three ‘‘populist’’ proposals (ballots 724, 732, and 781; see Table A1) from the\nanalysis whenever media bias is analyzed by means of B* scores.13 Except in this case, however, and unless indicated otherwise, all indicators used in this study are based on the total\nnumber of ballots (i.e., 24).\n\n12\nWe take into account ‘‘neutral’’ and ‘‘mixed’’ items because failing to do so leads to serious distortions in the\ncases where coverage is mostly neutral but where only a few biased stories would result in meaninglessly high scores\nof coverage bias. Thus, for example, a number of positive items twice larger than that of negative items but equal\nto the number of non-valenced (i.e., neutral and controversial) items yields a B of ‘‘only’’ about 0.14. By the same\ntoken, B scores are expected to be more polarized when measured at the level of issue statements rather than at the\nlevel of articles, because in the former case the number of non-valenced items is considerably lower. Note also that\nB is very strongly correlated (r &gt; 0.98) with alternative measures of media bias, such as that used by Zaller and\nChiu (1996).\n13\nFor our purposes, we deﬁne populist proposals as emanating from right-wing nationalist parties and groups,\nand being opposed by other parties. They consist of ‘‘radical’’, often ‘‘simplistic’’ solutions to welfare problems,\nusually charging ‘‘big business’’, high-proﬁt sectors, or available public wealth. However, as these proposals do not\nalign with the traditional ideological cleavages on welfare issues, opposition to them does not imply an endorsement of the welfare system. Accordingly, these proposals are hardly comparable with other proposals.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nSpatial homogeneity. Indicators for each of the six above criteria of media fairness can\nbe compared between the two main cultural areas in order to assess the homogeneity\nof media coverage. Simple diﬀerences are calculated between values for the majority\n(German-speaking) cultural area and those of minority areas. The only Italian-speaking\npaper in our database (i.e., Corriere del Ticino) is considered together with the Frenchspeaking outlets.14\nValidity checks. Each of the two independent coders read half the selected articles and\nmeasured all particular aspects listed above. Intercoder disagreement was examined from a\nsample of all coded articles and settled through discussion, resulting in more ﬁne-grained\nand univocal coding procedures. The issue statements of all the 1088 selected articles were\nthen coded again. Finally, a sample of 24 articles (one for each proposal) was drawn to\ncheck for coding consistency. Intercoder reliability was found to be satisfactory (Cohen’s\nkappa=0.704).15\nWeighting procedures. Except for analyses bearing solely on the sheer number of articles,\ntwo weighting procedures were applied. First, in keeping with the literature on public attention and response (e.g., Neuman 1990; Price and Zaller 1993), the size of articles was logged\nand used as a weighting factor to account for the notion that marginal returns of an\nincrease in news volume are generally diminishing. That is, for example, the diﬀerence\nbetween a ﬁve-inch-squared, barely visible, short article and a half-page article is probably\nmore consequential than the diﬀerence between a full-page and a double-page article.\nSecond, the ‘‘internal length’’ of issue statements was used to weigh their importance within\nour sample.16\n\n4. An overall view of press performance\nTable 1 gives an overview of six of the seven criteria of media fairness presented in the theoretical and measurement sections — the ‘‘spatial homogeneity’’ dimension shall be analyzed\nseparately below.\n\nIntensity of coverage\nThere is little reason to expect journalists to devote equal attention to all subject matters;\nsome issues are of greater concern to them (and to their readers) and are thus more likely\nto ﬁnd their way onto the media agenda. In fact, there is a good deal of variation in the\n\n14\n\nJournalists and political actors from the two minority cultural areas usually share the same general orientation\ntoward welfare politics (though not in other important policy ﬁelds) and are probably closer to each other than\nthey are to journalists and political actors from the German-speaking majority. More importantly, diﬀerences\nbetween majority and all minority areas are more commented upon and likely to be more consequential for\nnational cohesion than diﬀerences between minorities.\n15\nThis is actually a more than ‘‘fair’’ performance according to the standard interpretation by Landis and Koch\n(1977: 165). 67 issue statements were coded by the two coders simultaneously, i.e., an average of 2.8 issues per article. Three issues were coded by only one coder and were removed from the analysis, thus very slightly overestimating intercoder reliability by obfuscating disagreement over the sheer number of issue statements present in a press\narticle. However, when the three issues are taken into account, the level of disagreement rises by a very small\namount, and j is still 0.67.\n16\nFive rough categories approximating the ‘‘internal length’’ of issue statements were recoded into ﬁve ratios\nreﬂecting their share in the whole article: 0.20, 0.35, 0.50, 0.65, and 0.80.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n138\n\n 2011 Swiss Political Science Association\n\n22.5\n\n45.1\n\n23.8\n\n60.0\n\n64.5\n\n74.9\n\n71\n\n171\n\n100\n\n186\n\n238\n\n275\n\n21.1\n\n82\n\n48.9\n\n19.8\n\n83\n\n156\n\n64.7\n\n258\n\n48.9\n\n61.5\n\n216\n\n156\n\n95.1\n\n317\n\n91.7\n\n64.3\n\n185\n\n312\n\n96.7\n\nSurfaceb\n\n301\n\nNumbera\n\n0.757\n\n0.628\n\n0.732\n\n0.505\n\n0.587\n\n0.389\n\n0.444\n\n0.444\n\n0.729\n\n0.488\n\n0.434\n\n0.762\n\n0.618\n\n0.858\n\n0.666\n\n0.694\n\nInclusivenessc\n\n25.9\n\n26.2\n\n26.4\n\n20.9\n\n25.5\n\n22.0\n\n26.4\n\n26.4\n\n26.7\n\n23.3\n\n18.6\n\n24.5\n\n19.5\n\n23.0\n\n22.7\n\n22.7\n\nAverage\ncampaign\ndayd\n\n)0.315\n)0.013\n)0.122\n)0.208\n\n)0.071\n)0.046\n)0.064\n)0.086\n\n0.168\n\n)0.489\n\n)0.255\n\n0.075\n\n)0.139\n\n)0.098\n\n)0.210\n\n)0.176\n\n)0.151\n\n)0.071\n\n0.089\n\n)0.098\n\n)0.103\n\n)0.050\n\n0.249\n\n87.3\n\n)0.108\n\n)0.074\n\n0.054\n\n78.6\n\n)0.042\n\n)0.006\n\n89.8\n\n89.9\n\n92.1\n\n83.0\n\n89.1\n\n93.7\n\n85.5\n\n85.5\n\n81.5\n\n78.6\n\n78.8\n\n81.0\n\n81.6\n\n)0.142\n\n)0.062\n\n84.3\n\n% Journalists\n(articles)f\n\n0.144\n\nIssue\nbiase\n\n0.075\n\nArticle\nbiase\n\n21.0\n\n22.2\n\n4.6\n\n20.1\n\n12.1\n\n20.1\n\n19.6\n\n19.6\n\n21.8\n\n21.8\n\n3.2\n\n22.3\n\n15.2\n\n13.0\n\n21.7\n\n18.5\n\n% Parties\n(articles)f\n\n25.5\n\n17.2\n\n22.9\n\n31.1\n\n28.2\n\n44.9\n\n31.0\n\n31.0\n\n31.2\n\n17.1\n\n15.0\n\n20.4\n\n35.2\n\n22.8\n\n39.4\n\n28.7\n\n% Journalists\n(issues)f\n\n47.7\n\n57.7\n\n29.6\n\n57.1\n\n36.6\n\n23.0\n\n47.1\n\n47.0\n\n44.6\n\n47.5\n\n34.7\n\n42.8\n\n40.4\n\n39.6\n\n38.8\n\n43.7\n\n% Parties\n(issues)f\n\n42.0\n\n36.6\n\n61.9\n\n52.0\n\n63.8\n\n46.7\n\n49.2\n\n48.6\n\n53.6\n\n45.6\n\n35.5\n\n50.6\n\n50.8\n\n47.5\n\n49.2\n\n48.4\n\n% Reportingg\n\n31.7\n\n32.8\n\n33.2\n\n38.6\n\n27.8\n\n42.2\n\n39.9\n\n40.5\n\n35.4\n\n41.2\n\n33.6\n\n41.4\n\n42.2\n\n38.6\n\n36.8\n\n33.7\n\n% Opiniong\n\n26.3\n\n30.6\n\n4.9\n\n9.3\n\n8.4\n\n11.2\n\n10.9\n\n10.9\n\n11.0\n\n13.2\n\n30.9\n\n8.0\n\n7.0\n\n13.9\n\n14.0\n\n17.9\n\n% Horseraceg\n\n139\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n571 R ⁄ Reform of pension\nsystem (1995)\n572 I ⁄ ‘‘For extending the\npension system’’ (1995)\n602 R ⁄ Labour (weekend ⁄ night work) (1996)\n622 R ⁄ Unemployment\ninsurance (1997)\n643 I ⁄ Retirement age\n(1998)\n654 R ⁄ Labour (night\nwork, maternity) (1998)\n684 R ⁄ Disability\ninsurance (1999)\n685 R ⁄ Maternity\ninsurance (1999)\n721 I ⁄ Retirement age for\nwomen (2000)\n722 I ⁄ ‘‘Flexible\nretirement age’’ (2000)\n724 I ⁄ ‘‘Reduced hospital\ncosts’’ (2000)\n732 I ⁄ ‘‘Cheaper drugs’’\n(2001)\n752 I ⁄ ‘‘Secure pension\nsystem’’ (2001)\n762 I ⁄ Reduction of work\ntime (2002)\n781 I ⁄ ‘‘Gold to pensions’’\n(2002)\n782 CP ⁄ ‘‘Gold to\npensions’’ (2002)\n\nProject (R=referendum,\nI=initiative,\nCP=counterproposal)\n\nTable 1: Indicators of fairness for media coverage of 24 ballot issues\n\nMedia Coverage of Referendum Campaigns\n\n 2011 Swiss Political Science Association\n\n29.0\n\n48.9\n\n40.3\n\n109\n\n170\n\n131\n\n197.0\n(63.5)\n121.5\n(41.2)\n273.0\n(39.0)\n122.5\n(40.5)\n173.8\n(91.0)\n\nNumbera\n\n57.6\n(19.1)\n34.8\n(12.8)\n76.8\n(14.9)\n33.2\n(12.2)\n51.0\n(29.5)\n\nSurfaceb\n\n52.0\n(R=1248.1)\n22.4\n\n45.4\n\n163\n\n179.3\n(R=4303)\n73.5\n\n49.9\n\n152\n\n61.9\n\n21.8\n\n92\n\n234\n\n47.5\n\nSurfaceb\n\n145\n\nNumbera\n\n0.606\n(0.120)\n0.533\n(0.091)\n0.781\n(0.052)\n0.621\n(0.133)\n0.667\n(0.155)\n\nInclusivenessc\n\n0.131\n\n0.623\n\n0.834\n\n0.475\n\n0.683\n\n0.645\n\n0.754\n\n0.629\n\n0.525\n\n0.674\n\nInclusivenessc\n\n25.0\n(2.1)\n22.9\n(3.5)\n25.6\n(1.1)\n23.9\n(0.6)\n22.8\n(2.8)\n\nAverage\ncampaign\ndayd\n\n2.8\n\n24.1\n\n24.6\n\n27.2\n\n27.4\n\n22.9\n\n24.5\n\n26.5\n\n17.6\n\n26.9\n\nAverage\ncampaign\ndayd\n\n0.079\n(0.021)\n0.138\n(0.076)\n0.073\n(0.019)\n0.121\n(0.054)\n0.051\n(0.030)\n\nArticle\nbiash\n0.135\n(0.070)\n0.300\n(0.179)\n0.353\n(0.103)\n0.308\n(0.098)\n0.061\n(0.042)\n\nIssue\nbiash\n\n0.138\n\n0.182h\n\n0.086h\n0.049\n\n0.456\n\n0.252\n\n0.091\n\n0.114\n\n0.026\n\n0.008\n\n)0.046\n0.081\n\n0.406\n\n)0.008\n\n)0.070\n0.067\n\n0.387\n\n0.156\n\nIssue\nbiase\n\n0.156\n\n0.064\n\nArticle\nbiase\n\n86.3\n(4.5)\n88.3\n(4.2)\n87.6\n(6.1)\n80.5\n(1.9)\n86.4\n(4.0)\n\n% Journalists\n(articles)f\n\n5.2\n\n86.4\n\n93.7\n\n93.1\n\n92.0\n\n85.1\n\n82.4\n\n88.7\n\n81.8\n\n96.0\n\n% Journalists\n(articles)f\n\n20.8\n(1.2)\n17.7\n(3.6)\n17.2\n(4.6)\n19.2\n(2.5)\n8.8\n(4.9)\n\n% Parties\n(articles)f\n\n5.2\n\n17.3\n\n12.6\n\n21.0\n\n21.6\n\n14.3\n\n16.7\n\n17.3\n\n21.3\n\n13.1\n\n% Parties\n(articles)f\n\n25.9\n(7.4)\n28.6\n(10.5)\n28.6\n(2.5)\n17.6\n(0.5)\n23.6\n(6.7)\n\n% Journalists\n(issues)f\n\n7.9\n\n25.8\n\n26.1\n\n21.8\n\n13.1\n\n33.8\n\n18.1\n\n26.0\n\n15.5\n\n22.1\n\n% Journalists\n(issues)f\n\n48.2\n(6.6)\n40.4\n(16.1)\n44.5\n(0.1)\n46.8\n(0.7)\n36.3\n(4.6)\n\n% Parties\n(issues)f\n\n9.5\n\n43.5\n\n44.3\n\n42.5\n\n57.8\n\n41.2\n\n46.0\n\n66.7\n\n35.3\n\n32.5\n\n% Parties\n(issues)f\n\n49.3\n(6.2)\n50.9\n(7.5)\n55.5\n(1.9)\n51.4\n(5.8)\n47.2\n(9.5)\n\n%\nReportingg\n\n7.5\n\n50.6\n\n57.5\n\n58.0\n\n58.3\n\n44.1\n\n57.2\n\n48.0\n\n45.1\n\n64.8\n\n% Reportingg\n\n36.1\n(3.6)\n37.3\n(5.8)\n28.8\n(6.6)\n35.2\n(6.0)\n33.0\n(4.2)\n\n% Opiniong\n\n5.3\n\n35.2\n\n22.2\n\n34.3\n\n31.7\n\n26.6\n\n29.1\n\n37.6\n\n41.8\n\n32.0\n\n% Opiniong\n\n14.6\n(7.6)\n11.8\n(2.2)\n15.7\n(4.7)\n13.4\n(0.2)\n19.7\n(10.8)\n\n% Horseraceg\n\n7.7\n\n14.2\n\n20.3\n\n7.7\n\n10.0\n\n29.3\n\n13.6\n\n14.4\n\n13.1\n\n3.2\n\n% Horseraceg\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nLabour regulation (N = 4)\n\nDisability (N = 2)\n\nMaternity (N = 2)\n\nHealth (N = 4)\n\nPensions (N = 10)\n\nMeans for categories of\nproject (standard\ndeviations in parentheses)\n\nStd. dev.\n\n792 R ⁄ Unemployment\nbeneﬁts (2002)\n802 R ⁄ Financing of\nhospital treatments (2003)\n815 I ⁄ ‘‘Health must\nremain aﬀordable’’ (2003)\n816 I ⁄ ‘‘Equal rights for\ndisabled’’ (2003)\n819 I ⁄ ‘‘Apprenticeship\nplaces’’ (2003)\n831 R ⁄ Increase of\npension age for women\n(2004)\n832 R ⁄ Financing\npensions through VAT\n(2004)\n844 R ⁄ Maternity\ninsurance (2004)\nMean (N = 24)\n\nProject (R=referendum,\nI=initiative,\nCP=counterproposal)\n\nTable 1: (Continued)\n\n140\n\n 2011 Swiss Political Science Association\n\n180.5\n(35.5)\n205.2\n(83.5)\n160.0\n(68.6)\n172.8\n(67.3)\n189.4\n(87.7)\n162.1\n(51.1)\n\nNumbera\n\n54.5\n(7.0)\n61.8\n(26.9)\n44.0\n(17.1)\n49.7\n(20.0)\n55.1\n(27.9)\n47.3\n(14.6)\n\nSurfaceb\n0.646\n(0.028)\n0.669\n(0.110)\n0.535\n(0.104)\n0.622\n(0.134)\n0.638\n(0.137)\n0.599\n(0.122)\n\nInclusivenessc\n23.2\n(3.7)\n23.8\n(2.7)\n24.6\n(1.8)\n24.1\n(2.9)\n23.4\n(3.4)\n24.6\n(1.9)\n\nAverage\ncampaign\ndayd\n0.069\n(0.005)\n0.079\n(0.050)\n0.137\n(0.083)\n0.079\n(0.029)\n0.089\n(0.045)\n0.084\n(0.054)\n\nArticle\nbiash\n0.132\n(0.024)\n0.114\n(0.064)\n0.337\n(0.116)\n0.178\n(0.140)\n0.191\n(0.132)\n0.175\n(0.149)\n\nIssue\nbiash\n87.4\n(8.6)\n85.1\n(6.7)\n90.9\n(2.0)\n86.0\n(4.5)\n86.2\n(6.2)\n86.3\n(4.3)\n\n% Journalists\n(articles)f\n14.2\n(1.1)\n17.2\n(3.7)\n18.1\n(4.4)\n17.1\n(5.9)\n16.7\n(5.6)\n17.5\n(4.9)\n\n% Parties\n(articles)f\n28.7\n(6.6)\n23.2\n(7.3)\n30.1\n(11.4)\n25.9\n(6.8)\n22.6\n(6.8)\n28.7\n(8.0)\n\n% Journalists\n(issues)f\n36.4\n(3.9)\n43.6\n(7.8)\n39.1\n(14.3)\n44.4\n(8.7)\n42.1\n(6.7)\n44.5\n(11.7)\n\n% Parties\n(issues)f\n57.8\n(7.0)\n52.6\n(6.8)\n49.0\n(11.2)\n50.2\n(6.7)\n51.4\n(7.8)\n50.7\n(7.2)\n\n%\nReportingg\n\n37.1\n(5.1)\n36.6\n(4.3)\n34.2\n(6.0)\n34.8\n(5.5)\n35.1\n(5.5)\n35.5\n(5.2)\n\n% Opiniong\n\n5.1\n(1.9)\n10.9\n(4.8)\n16.7\n(9.9)\n15.0\n(7.8)\n13.5\n(7.2)\n13.8\n(7.7)\n\n% Horseraceg\n\n141\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNotes: a: Number of articles. b: Surface in standard newspaper pages (one page=1247 cm2). c: Number of actor categories · IQV (see text for calculation details). d: Mean number of days remaining before voting day. e: B scores comprised between -1 (all articles ⁄ issues against project) and\n+1 (all articles ⁄ issues in favour of project); see text for calculation details. f: Sum of categories ‘‘journalists’’ (including press agencies) and ‘‘parties’’ (including referendum ⁄ initiative committees) may exceed 100%, since several actors may be considered as the ‘‘sources’’ of an article. g: Percentage of articles in each category (see text for deﬁnition). h: Means computed from absolute values for each ballot, i.e. |B|. i: Not considered\nhere: counterproposal to the ‘‘gold’’ initiative (ballot #782; see Appendix).\n\nInitiative (N = 12)i\n\nExpansion proposal\n(N = 15)\nReferendum (N = 11)i\n\nRetrenchment proposal\n(N = 6)\nPopulist proposal (N = 3)\n\nUnemployment (N = 2)\n\nMeans for categories of\nproject (standard\ndeviations in parentheses)\n\nTable 1: (Continued)\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nintensity of media coverage of the various ballot issues (SD is about 22 full newspaper\npages for an overall mean of 52 pages). As shown in Table 1, the intensity of press coverage\nvaries between the speciﬁc policy ﬁelds subsumed under the heading ‘‘welfare state issues’’.\nMaternity seems by far the most important category of issues; in contrast, health and disability are of less importance. Further, it seems that retrenchment proposals lead to more\nintense campaigns than expansion or populist proposals. This is understandable, since cutting back beneﬁts may lead to more mobilization by target groups than the promise of\ndeveloping beneﬁts can possibly achieve. As noted above, though, the two proposals to\nintroduce a maternity insurance are a notable exception in this regard as they elicited substantial press coverage, probably due to the fact that the constitutional mandate to implement a maternity leave program dated back to the end of World War II and thus the issue\nwas a recurring one.17 Likewise, referendums are somewhat more covered by the press than\ninitiatives, probably because they bear more frequently on retrenchment programs, but the\ndiﬀerence is modest.\nIn brief, the intensity of press coverage appears to vary between the diﬀerent policy ﬁelds,\narguably as a result of the journalists’ intrinsic interest in them and due to the varying\nmobilization of political and civil society actors. But, to a large extent, campaign intensity\nis probably also exogenously determined by the uncertainty of the result of the ballot. Both\ncampaigners and voters are more likely to get involved in referendums when the margin of\nvictory is perceived to be small (e.g., Downs 1957; Kirchgässner and Schulz 2005). Likewise,\nin our dataset the overall intensity of press coverage is substantially correlated with the\ncloseness of the voting results.18 The closer the (expected) outcome, the more journalists\nreport on issues.\n\nSource inclusiveness\nOne indicator of the fairness of the coverage of a ballot issue is how many diﬀerent\npolitical actors are involved in the deliberation process. Our standardized measure of\ninclusiveness points to a respectable diversity in the sources of issue statements in press\ncoverage (overall mean=0.62). It is highest for maternity issues, and lowest for public\nhealth issues, as well as for issues comprised in the ‘‘populist’’ category. We thus assume\nthat inclusiveness depends on the nature of issues (see Pfetsch 2004: 87–93), as further\nsuggested by the fact that campaign intensity varies between policy ﬁelds, as we have\nseen. Indeed, intensity was shown to depend strongly on inclusiveness, as far as advertisement campaigns are concerned (Marquis and Bergman 2009). Similarly, in press coverage, the correlation between our indicators of intensity and inclusiveness is fairly high\n(Pearson’s r = 0.76). In other words, the more political actors enter the ﬁeld (and journalists’ accounts presumably reﬂect this increasing diversity), the more likely the issue at\nhand is to receive general attention from the press — whether because inclusiveness\ndetermines intensity or because both coverage features are determined by some higherlevel concept such as ‘‘issue importance’’.\n\n17\n\nPrior to the 1999 and 2004 votes, no less than three proposals to create a maternity insurance had already been\nrejected at the polls (Dec. 8, 1974; Dec. 2, 1984; and Dec. 6, 1987).\n18\nThe correlation coeﬃcient is –.54 for the number of articles and –.48 for total surface. Closeness is measured as\nthe absolute diﬀerence between the actual result and a perfectly balanced result: CLOSENESS = | 50 – RESULT |.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n142\n\n143\n\nLength of coverage\nCampaigns in Swiss direct democracy, whether through paid advertisements or in press\nreporting, usually unfold in two phases: there is ﬁrst an accelerating expansion of coverage\nand then a sharp decline in the last days before the vote (e.g., Marquis 2006: 429–438;\nTresch 2008: 147–149). Based on all articles published during all 24 campaigns, a thirdorder polynomial function modelling this typical development accounts for 67 percent of\nthe variance in the total daily surface of articles.19 Hence, at the aggregate level, the twophase pattern ﬁts the data quite well: referendum campaigns on welfare state issues develop\nin a typical way, similar to what has been observed for other types of issues.20 In addition,\nall policy ﬁelds follow roughly the same pattern — the only notable diﬀerence is that campaigns on health matters (including maternity and disability) reach their peak earlier than\nother types of issues.\nThese ﬁndings may dispel concerns that most media information on ballot issues is\nreleased too fast and too late for citizens to use it eﬃciently in their decision making. But\nactually how long is the press coverage of ballot issues? Drawing on our indicator of the\n‘‘average campaign day’’, the ‘‘average information’’ is published some 24 days before the\nvoting date (i.e, it corresponds to the ‘‘mean average day’’ for all 24 ballots). In the same\nperspective, the average median day is 21.6; this means that, in a typical campaign, half of\nthe total (weighted) sum of all information has been released three weeks before voting day,\nand the other half is to be released in the remaining weeks. In addition, there appears to be\nlittle diﬀerence between the various ballot issues — even though ballot issues that draw\nmore intense coverage (pensions, maternity) also tend to be covered for a slightly longer\ntime. To be sure, actual exposure to the ﬂow of information delivered during referendum\ncampaigns may greatly vary from one citizen to another, depending for example on which\nmedia outlet (if any) they use for their information (see below). But our ﬁndings are hardly\ncompatible with the argument that citizens are too time-pressed to make up their minds\nand are not given a chance to learn what the ballot issues are all about.\n\nSource independence\nThe question of media independence and autonomy is important, both from the perspective\nof media practices and ethics and for the purposes of deliberative processes. For example,\nTresch (2008: 142–149) shows that ‘‘agenda-building’’ by political actors through press conferences, party meetings, and other public relations activities, constitutes a substantial part\nof media content in referendum campaigns. Even though such coverage is certainly not\nwithout merit for citizens’ information and orientation, an overly reliance on external\nagenda-building eﬀorts may lead to media instrumentalization beyond that which stems\nfrom patterns of media ownership (see Hallin and Mancini 2004).\n19\nThe following function was ﬁtted to the data: Surface = 0.0015 time3 – 0.1464 time2 + 3.7937 time + 4.3653,\nwith surface measured as a three-day moving average and time measured as the number of days remaining until\nvoting day. The proportion of explained variance rises to 80 percent when Sunday editions are removed. Because\nof their non-continuous time structure, such editions introduce ‘‘noise’’ into the data. However, only ﬁve outlets\nare weekly papers or are published on Sunday, and only 2 percent of articles were published on that weekday.\n20\nAt the level of each single ballot, the characteristic sigmoid shape can be found for all but four campaigns. With\nthe exception of ballots 572, 622, 781, and 782, all functions have positive values for time3 and time, and negative\nvalues for time2. Article size (rather than number) was used, and time was recoded in eight weekly periods to avoid\nhigh ﬂuctuation in daily values. The average R2 for all 24 campaigns is 0.61 (SD=0.23).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nIf we ﬁrst consider journalists and partisan actors (i.e., parties and committees) in their\nrole of ‘‘speakers’’ at the level of articles, it comes as no surprise that journalists outweigh\npartisan actors (86 percent vs. 17 percent, on average). More remarkably, the diﬀerences\nbetween the various ballot proposals are quite limited. Journalists were identiﬁed as ‘‘speakers’’ in 80 to 88 percent of all articles in each of the six policy ﬁelds, while the corresponding interval is 14 to 21 percent for partisan actors — with the notable exception of labour\nmarket policies, where the parties’ share is only 9 percent.21 As for governmental speakers,\nthey appear in less than 10 percent of articles in all policy ﬁelds. (Note that the percentages\nfor the various categories add up to more than 100 percent, since any article can draw on\nseveral types of speakers.)\nAt the level of issue statements, recall that a total of 2859 issues were coded out of our\nsample of 1088 articles. Parties and committees account for about 44 percent of all coded\nissue statements, journalists and press agencies for 26 percent, governmental actors for 17\npercent, employers’ and employees’ organizations for 14 percent, and other types of actors\nfor 20 percent (similar to articles, percentages do not add to 100 percent because several\ncategories of actors can be involved as sources of one issue).22 Overall, then, journalists\nappear much less important as a source of issue statements than as a source of articles\n(i.e., as ‘‘speakers’’), which makes perfect sense. Conversely, even though partisan actors\nare rarely directly involved as speakers (e.g., through interviews or op-eds), they largely\nsucceed in inﬂuencing campaign news by having their issue statements reported in the press\n(Bonfadelli and Blum 2000; Tresch 2008).\n\nBias in media coverage\nThe extent of bias in press coverage can also be investigated at two levels: at the level of\nwhole articles and at the level of issue statements. The analysis draws in both cases on the\nclassiﬁcation of newspapers’ content into partial (pro or con), neutral, and controversial\ncategories. The resulting B scores theoretically vary between –1 (all content is against ballot\nproposal) and +1 (all content is in favour of proposal). B scores are generally higher for\nissues than for articles, because, for one thing, there are far less ‘‘neutral’’ and ‘‘controversial’’ items (about 27 percent) in issue statements than at the level of whole articles (about\n68 percent).\nA striking feature of our results in Table 1 is the relative neutrality with which Swiss\njournalists report on the issues, at least taken collectively — the question of diﬀerences\nbetween media outlets will be addressed below. The mean absolute B value is 0.09 for\narticles and 0.18 for issue statements. In fact, a good deal of this ‘‘directional thrust’’\nin media reporting is concentrated on ballot issues dealing with health matters (public\nhealth, maternity, disability). For example, the initiatives for ‘‘reduced hospital costs’’\n(2000) and ‘‘equal rights for disabled people’’ (2003), as well as the referendum to\noppose paid maternity leaves (2004), stirred up considerable criticism or enthusiasm\nfrom journalists, leading them to take a clear position on these subjects. On closer\n21\n\nIn this domain, parties are secondary to other representative bodies with which they often have strong ties, in\nparticular employers’ and employees’ associations (15 percent).\n22\nThese shares expectedly vary across policy ﬁelds. Journalists are most involved in unemployment, public health,\nand maternity issues (all 29 percent) and least involved with respect to disability (18 percent). Parties and committees are much quoted sources of statements on pensions and disability (48 and 47 percent) and less so on unemployment and labour regulation (36 percent).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n144\n\n145\n\ninspection, it appears that the general type of ballot proposals combines with their subject matter. As a category, the three populist proposals of the years 2000–2002 (including hospital costs) were treated in a far less even-handed manner than retrenchment or\nexpansion proposals, especially as concerns bias in issue statements.23 We may summarize these ﬁndings by saying that journalists, most of the time, report about ballot\nissues in a quite balanced way.\nInterestingly, bias in press coverage is substantially related to several other features examined here (correlations of 0.4 or higher). To begin with, article bias decreases as coverage\nintensity and inclusiveness increase. In other words, imbalance in coverage looms large\nwhen journalists have little to report and rely on fewer sources. At the level of issue statements, a crucial link seems to be with the importance of partisan actors as sources of statements: the more parties and committees are referred to as a basis for issue analysis, the\nlesser the bias.\nUsing B* values we can also determine how media coverage is basically oriented\ntoward welfare state schemes (i.e., the extent to which campaign news systematically\nsupports welfare state expansion ⁄ protection rather than welfare state limitation ⁄\nretrenchment). In so doing, we obtain a mean B* value of 0.01 for articles and 0.06\nfor issues — the press thus displays a very slight pro-welfare bias. This strongly suggests that there is no overall systematic pro-welfare or anti-welfare bias in press coverage. However, diﬀerences exist between the various policy ﬁelds. While neutral with\nrespect to pensions, labour market and unemployment, Swiss media outlets as a whole\nseem committed to more generous social protection programmes in the area of public\nhealth (B*=0.19 for issue statements), including maternity and invalidity (B*=0.35 and\n0.31, respectively).\nIt should also be noted that editorials and interviews are more critical of the welfare state\nthan other format types. B* scores (issue statements) for editorials and interviews are about\n–0.2 and –0.1, respectively, as compared to +0.1 or higher for reports, letters to the editor,\nand campaign news. Journalists opposed to welfare policies, it would seem, rely heavily on\nwriting editorials and selecting anti-welfare interviewees. But this does not suﬃce to countervail the bulk of pro-welfare coverage that stems from ‘‘factual reporting’’ or coverage of\ncampaign events. Besides, the general thrust of media coverage is highly dependent on\nwhich types of actors get their messages across in the various newspapers, since more often\nthan not journalists are balanced in their own issue statements (B* = –0.02). For instance,\nin the many cases where the parties’ issues ﬁnd their way into the media, center-left parties\nare much more likely to voice pro-welfare issues than are right parties (B* = 0.42 vs.\n–0.26). Similarly, the bias brought about by employees’ organizations counterbalances that\nof employers’ organizations (B* = 0.35 vs. –0.29). Overall, referendum committees are relatively neutral toward the welfare system (B* = 0.04), but the organizations representing\nspeciﬁc population groups (retired people, disabled people, youth, women, families) are\noverwhelmingly pro-welfare. Interestingly, the bias exhibited by governmental sources is\nquite diﬀerent depending on the level of government. Institutions and civil servants at the\nnational level (e.g., federal councillors, senior oﬃcials) are clearly less supportive of the\n\n23\n\nThe 2000 and 2001 initiatives (‘‘reduced hospital costs’’ and ‘‘cheaper drugs’’) were fought by all parties, while\nthe 2002 initiative (‘‘gold reserves to retirement pensions’’) was launched by the Swiss People’s Party and backed\nby other smaller populist right parties. Accordingly, the latter was supported by an important minority of 46% of\nthe popular votes, compared to 18% and 31% for the two earlier initiatives.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nwelfare system (or, at least, of welfare state expansion) than are their counterparts at the\ncantonal or local level (B* = –0.15 vs. 0.48).24\n\nSubstantive coverage\nWe focus here on the three main formats of campaign coverage (i.e., ‘‘opinion articles’’,\n‘‘factual reporting’’, and ‘‘horserace information’’) to determine how ‘‘substantive’’ campaign coverage is. Concerns are often expressed that media news that unduly revolves\naround the horserace and ‘‘game’’ aspects of campaigns has a deleterious inﬂuence on public deliberation and citizens’ decision-making. In fact, horserace information was present in\nall campaigns but it is quite weak (14 percent of the overall amount of news, on average)\ncompared to ‘‘opinion articles’’ (35 percent) and ‘‘factual articles’’ (51 percent). Horserace\ncoverage varies between a minimum of 5 percent for unemployment ballot issues and a\nmaximum of 20 percent for labour regulation ballot issues. In comparison, the share of\nopinion articles varies between 29 and 37 percent depending on policy domains, while the\nshare of factual articles varies between 47 and 58 percent. Thus, unlike in other contexts,\nthe horserace is clearly not the leading theme in Swiss referendum campaigns.25\n\n5. A dynamic view of independence, inclusiveness, bias, and substance\nThe picture thus far supports the notion of rather ‘‘fair’’ journalistic practices, as media\ncoverage appears to be relatively balanced, autonomous and substantive. We now examine\nthe hypothesis that journalists are however not immune to the pressure of the political environment and that they become increasingly dependent on external and ⁄ or biased sources of\ninformation over the course of campaigns. In other words, we ask whether the ‘‘fairness’’ of\ncampaign coverage is aﬀected by agenda-building eﬀorts of political actors. We thus investigate the dynamics of campaign coverage, focusing on four aspects examined above: source\nindependence and inclusiveness, bias in coverage and substantive coverage. We believe that\nthe time dimension can add to our understanding of how much journalistic output is autonomous, inclusive, unbiased, and substantive — and possibly also why it deviates from such\nnorms.\nBeginning with source independence, one interesting result is that journalists are the only\nactor category whose importance as a source of issue statements increases throughout the\n24\n\nThis diﬀerence is consistent across all types of issues, excepting maternity, and it may be explained in two ways.\nOn the one hand, the Swiss federal political system is largely based on the ‘‘principle of subsidiarity’’, which posits\nthat the federal state should assume only those tasks which cannot be performed eﬀectively at a more local level.\nHowever, the federal state assumes the greatest responsibility for managing social beneﬁts and ﬁnancing pension\nand health insurances, while local governments may feel less under pressure. In addition, cantons and municipalities have to draw on their own resources to provide social assistance to needy people who fall through the cracks\nof the social safety net and are no longer eligible for national welfare beneﬁts. Accordingly, local authorities are\nless likely to endorse cutbacks in social beneﬁts and are more inclined to support their constituencies’ demands for\nsocial services. On the other hand, the principle of collegiality implies that federal councillors from left parties are\ncompelled to advocate the view of the government as a collective body even when it contradicts the position of\ntheir party or their own opinion. For example, Federal Councillor Ruth Dreifuss, member of the Social Democratic Party and head of the Federal Department of Home Aﬀairs (1994–2002), often had to oppose initiatives\nfrom left groups aiming at expanding or introducing new welfare programmes.\n25\nThis is all the more signiﬁcant as the deﬁnition of horserace information used in this study is rather broad. As a\nmatter of fact, voting cues by parties and major organizations account for the bulk of ‘‘horserace information’’ as\noperationalized here — rather than opinion surveys or descriptions of campaign events.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n146\n\n147\n\n100\n\n10\n\n90\n\n9\n\n80\n\n8\n\n70\n\n7\n\n60\n\n6\n\n50\n\n5\n\n40\n\n4\n\n30\n\n3\n\n20\n\n2\n\n10\n\n1\n\n0\n\nNumber of source categories\n\nPercent of total sources\n\nFigure 1: Source independence and inclusiveness over time.\n\n% journalists (articles)\n% partisan (articles)\n% journalists (issues)\n% partisan (issues)\nNumber of source\ncategories (issues)\n\n0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\nwhole campaign period, even though their share as ‘‘speakers’’ actually declines (see Figure 1). In contrast, parties and committees become a bit less marginal as speakers (gaining\non average some 10 percent of the total share in the last seven weeks). But, most notably,\npartisan actors remain a major source of issue statements for press journalists during the\nwhole campaign period; their share varies between 33 and 61 percent, but without clear\nupward or downward trend over time.26 Just as signiﬁcant, however, is the fact that the\nsheer number of actor categories used as sources of issue statements grows almost linearly\nduring the campaign period — except in the very last weeks — and actually almost doubles\n(from 3 to 6) in the ﬁrst six weeks (see again Figure 1, right-hand axis). To use our terminology, this shows that press coverage becomes more inclusive as time goes by.27 For example, actors that may be regarded as ‘‘outsiders’’ (science and health professionals,\nassociations defending the rights of women ⁄ families ⁄ disabled people, non-proﬁt organizations, and other similar actors) rise from an average number of 0.7 (8th week before vote) to\nan average of 1.5 (4th week) and manage to keep their share of issue statements at just\nunder 20 percent throughout the campaign.\nTaken together, these results suggest that the dynamics of campaign coverage on welfare\nstate issues is hardly compatible with a radical understanding of the ‘‘determination theory’’. Our analysis reveals that journalists maintain their control over the newsgathering\nprocess and that no single source of campaign issue statements holds sway. As Figure 2\nshows, however, this does not mean that journalists downplay the inﬂuence of political\nactors — or even try to do so in a collective sense. In fact, press coverage increasingly takes\nthe form of ‘‘opinion articles’’ over time, while the share of ‘‘factual reporting’’ sharply\ndeclines. In the eight-week period, opinion articles become at least twice more frequent in\nrelative terms (from 22 to 52 percent), while the share of factual articles considerably\ndecreases (from 69 to 26 percent). With two exceptions, all campaigns exhibit this pattern,\n26\nThe same holds, albeit to a smaller extent, for governmental actors, who account for over one quarter of all\nissue statements in the ﬁrst four campaign weeks, but whose importance then declines to less than 15 percent. Yet,\nas compared to their tiny share of 5 percent of articles as ‘‘speakers’’, governmental actors do succeed in getting\ntheir issues on the campaign agenda, especially at the earlier stage.\n27\nFor the sake of simplicity, Figure 1 displays only the number of issue source categories, because IQV values\nhardly vary (min: 0.85, max: 0.90) and thus the variations over time of the composite index INC boil down to variations in the number of source categories.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nFigure 2: Information format over time (substantive vs. non-substantive content).\n100\nPercent of total sources\n\n90\n80\n70\n% reporting\n\n60\n\n% opinion\n\n50\n40\n\n% horserace\n\n30\n20\n10\n0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\nwhereby opinions gain prominence at the expense of the presentation of facts as voting day\ndraws nearer. This may be related to another ﬁnding stressed above, namely that ‘‘speakers’’, i.e. those actors accountable for the content of an article, comprise less journalists and\nmore partisan actors as time goes by. As for horserace news, its salience ﬂuctuates within a\nnarrow 9–16 percent range –– with the understandable exception of the last campaign week,\ngiven the close proximity of the vote and mobilization eﬀorts by parties and other groups.28\nIn sum, there does not seem to be a strong focus or even focalization on the horserace during referendum campaigns in Switzerland. To a large extent, the overall evolution in the format of information is understandable, and some observers may ﬁnd it comforting from a\nnormative perspective. It can be argued that, as a collective actor, journalists ﬁrst proceed\nto present the facts and main arguments (i.e., information function) and then provide citizens with particular opinions to help them take position on the issues (i.e., orientation function).\nLikewise, the ‘‘tone’’ of media coverage changes over time. To begin with, articles become\nmore ‘‘partial’’, i.e., they increasingly take sides for or against the various ballot proposals\n(see Figure 3). The share of partial articles amounts to slightly more than 20 percent in the\nﬁrst three weeks and approaches 50 percent by the last two weeks.29 In contrast, the share\nof partial issue statements — even though much higher than that of articles in overall level\n— slightly decreases over time. To a large extent this stems from the fact that issue statements get more ‘‘controversial’’ (rather than more ‘‘neutral’’) as voting day draws closer,\nand this is probably reﬂective of the growing recognition by journalists of the complexity of\nballot issues. That the press becomes more committed to its opinion-giving and orientation\nfunction in the later stages of campaigns does not entail, however, that it provides an\nincreasingly biased picture of the ballot issues. As shown in Figure 3 (right-hand axis), it is\nstriking how little deviation there is from perfect neutrality (i.e., B*=0) throughout the\neight campaign weeks, based either on articles or on separate issue statements. In fact, 87\npercent of the weekly bias scores for articles are comprised in a range of ± 20 percent\n28\nWe may also add that most newspapers publish a summary list of all parties’ and important organizations’ voting cues in the last week before voting day (which we also included in the horserace category).\n29\nOne natural hypothesis is that journalists themselves become less impartial over time. There is strong evidence\nsupporting this assumption, as the share of partial items among journalists’ articles rises from a low 16 percent\nseven weeks before voting day to a full 44 percent in the last campaign week.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n148\n\n149\n\n100\n\n1.0\n\n90\n\n0.8\n\n80\n\n0.6\n\n70\n\n0.4\n\n60\n\n0.2\n\n50\n\n0.0\n\n40\n\n–0.2\n\n30\n\n–0.4\n\n20\n\n–0.6\n\n10\n\n–0.8\n\n0\n\nArticle/issue bias (B* score)\n\nPercent of total\n\nFigure 3: Bias in media coverage over time.\n\nArticle partiality\n(pro+con/total)\nIssue partiality\n(pro+con/total)\nArticle bias\n(B* score)\nIssue bias\n(B* score)\n\n–1.0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\naround the neutral value.30 In sum, the fact that campaigns become more partisan over time\ndoes not necessarily imply that one side comes to prevail over the other. More often than\nnot media campaign coverage remains remarkably balanced until the end. As we have\nshown above, ballot campaigns usually heat up in the ﬁnal weeks, as agenda-building\neﬀorts by partisan groups intensify. But even then there is very little to suggest that the\npress gives in to external pressure and leaves the ‘‘undecided’’ citizens or ‘‘late deciders’’\nexposed to the unchecked inﬂuence of partisan or special interests.\n\n6. A particularistic view of media fairness\nBased on a number of formal criteria, the press coverage of ballot issues on welfare state\nissues appears relatively ‘‘fair’’. However, such evidence may be somehow illusory if it stems\nfrom the aggregation of contradictory patterns from diﬀerent types of media outlets. For\nexample, a balanced, unbiased portray of ballot issues at the aggregate level may conceal\nmuch greater variation between individual papers, some of which may be slanted toward\nwelfare state expansion while others may be committed to welfare retrenchment. As most\ncitizens read only one newspaper on a regular basis, this would mean that a majority of\npotential voters are exposed to a one-sided communication ﬂow. In addition, if the papers\non one side of the fence (e.g., the ‘‘pro-welfare camp’’) have a larger overall readership than\nthose on the other side, then the societal balance of information would no longer be guaranteed, despite indications to the contrary such as those provided in the preceding sections.\nTo investigate this question, we ask how the coverage of welfare state issues compares\nacross media outlets. Table 2 displays the whole range of indicators used thus far and shows\nhow they vary between the 28 media outlets included in this analysis.\n30\nThe same result is obtained if one takes absolute B scores (and hence all 24 campaigns are considered). However, when issue statements are considered instead of articles, the proportion of biased weekly values (|B|&gt;0.2) rises\nto 52 percent. To some extent this stems from our sampling procedure, because many weekly values are derived\nfrom a limited number of cases — while the whole data is used for articles’ bias. Accordingly, compared to statistics based on exhaustive data, there is a heightened probability that more extreme values of issue bias are produced\nby chance alone. Moreover, these frequent deviations from neutrality are in general temporary and unlikely to last\nfor longer than one week. In fact, the percent of adjacent weeks that exhibit a similar biased value (e.g., B scores\ngreater than 0.2 for both weeks) is only 19 percent.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n115.2\n\n97.6\n83.1\n80.1\n83.7\n77.7\n73.5\n58.4\n70.9\n68.0\n56.9\n42.6\n\n57.4\n35.2\n33.5\n37.7\n24.9\n26.8\n23.0\n\n19.9\n18.5\n\n18.9\n\n14.2\n8.6\n\n6.3\n\n5.7\n6.0\n\n321\n293\n286\n285\n263\n245\n222\n208\n201\n179\n170\n\n166\n165\n122\n104\n97\n90\n89\n\n70\n60\n\n38\n\n33\n21\n\n18\n\n17\n7\n\nSurfaceb\n\n528\n\nNumbera\n\n 2011 Swiss Political Science Association\n0.202\n0.194\n\n0.206\n\n0.143\n0.277\n\n0.222\n\n0.458\n0.752\n\n0.781\n0.750\n0.484\n0.745\n0.696\n0.409\n0.687\n\n0.873\n0.845\n0.865\n0.816\n0.664\n0.874\n0.866\n0.837\n0.783\n0.818\n0.840\n\n0.891\n\n22.8\n32.0\n\n16.3\n\n26.7\n38.7\n\n30.9\n\n27.4\n17.0\n\n26.1\n16.8\n14.6\n22.1\n22.5\n21.9\n20.6\n\n26.0\n27.2\n24.5\n26.0\n26.2\n28.0\n17.3\n26.4\n24.6\n28.7\n18.0\n\n27.3\n\nAverage\ncampaign\ndayd\n\n0.076\n0.000\n\n)0.200\n\n)0.026\n0.054\n0.106\n\n0.664\n0.051\n\n0.435\n\n0.142\n0.003\n\n0.164\n0.448\n)0.106\n0.206\n)0.007\n)0.124\n0.126\n\n0.675\n0.117\n\n0.425\n\n0.066\n)0.108\n\n0.038\n0.145\n)0.094\n0.012\n)0.026\n0.063\n0.046\n\n0.118\n)0.030\n0.153\n0.133\n0.023\n0.111\n)0.014\n0.057\n0.009\n)0.128\n0.040\n\n)0.279\n\n)0.127\n0.044\n)0.018\n0.011\n0.063\n)0.032\n)0.023\n)0.023\n0.006\n0.004\n)0.027\n)0.038\n\nIssue\nbiase\n\nArticle\nbiase\n\n87.3\n100.0\n\n100.0\n\n82.3\n81.2\n\n82.8\n\n84.9\n86.6\n\n91.0\n54.6\n72.3\n92.2\n90.2\n82.9\n91.9\n\n81.4\n93.6\n85.3\n96.4\n83.0\n98.8\n81.2\n91.4\n91.4\n90.0\n75.4\n\n81.0\n\n% Journalists\n(articles)f\n\n19.0\n34.2\n\n6.8\n\n7.6\n9.4\n\n11.2\n\n26.7\n14.6\n\n17.8\n35.6\n33.0\n11.8\n7.9\n24.1\n8.7\n\n20.9\n14.2\n16.7\n8.8\n25.1\n8.5\n25.7\n18.5\n10.8\n25.2\n20.0\n\n14.7\n\n% Parties\n(articles)f\n\n0.0\n77.6\n\n33.3\n\n57.4\n61.4\n\n67.4\n\n28.3\n24.5\n\n15.9\n10.5\n27.7\n25.7\n10.6\n16.8\n22.8\n\n23.1\n23.8\n26.0\n41.4\n18.2\n29.2\n23.8\n22.5\n16.7\n22.7\n34.7\n\n34.6\n\n% Journalists\n(issues)f\n\n91.3\n47.3\n\n66.7\n\n0.0\n24.5\n\n30.2\n\n36.7\n24.0\n\n56.3\n62.7\n43.9\n44.6\n58.8\n53.2\n58.1\n\n45.2\n38.7\n50.0\n25.5\n55.7\n44.7\n43.4\n45.6\n42.3\n47.1\n42.0\n\n35.3\n\n% Parties\n(issues)f\n\n47.6\n65.8\n\n55.9\n\n22.3\n44.1\n\n37.6\n\n48.1\n48.6\n\n55.0\n37.3\n32.1\n67.2\n65.6\n48.4\n59.7\n\n50.9\n53.7\n49.9\n54.0\n47.6\n64.5\n63.6\n57.1\n61.1\n47.3\n46.1\n\n35.9\n\n% Reportingg\n\n12.7\n34.2\n\n24.0\n\n69.7\n52.0\n\n51.6\n\n33.6\n34.1\n\n32.1\n56.5\n42.2\n21.6\n21.1\n46.5\n27.8\n\n34.6\n27.0\n30.8\n26.5\n39.3\n20.2\n30.9\n31.7\n29.3\n35.0\n51.3\n\n46.2\n\n% Opiniong\n\n39.7\n0.0\n\n20.1\n\n8.0\n3.9\n\n10.7\n\n18.3\n17.2\n\n12.9\n6.2\n25.7\n11.1\n13.2\n5.1\n12.5\n\n14.5\n19.3\n19.4\n19.5\n13.1\n15.2\n5.6\n11.2\n9.6\n17.6\n2.6\n\n17.9\n\n% Horseraceg\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNeue Zürcher Zeitung\n(NZZ)\nBasler Zeitung\nLe Temps (March 1998 –)\nSt. Galler Tagblatt\nTages-Anzeiger\nAargauer Zeitung\nLa Liberté\nCorriere del Ticino\nBund\n24 Heures\nNeue Luzerner Zeitung\nNouvelliste et Feuille\nd’Avis du Valais\nBerner Zeitung\nLe Quotidien Jurassien\nSchaﬀhauser Nachrichten\nTribune de Genève\nL’Express\nSolothurner Zeitung\nSüdostschweiz ⁄ Bündner\nZeitung\nBlick ⁄ Sonntags-Blick\nJournal de Genève\n(1995 – Feb. 1998)\nBerner Tagwacht\n(1995 – 1997)\nWochenzeitung\nSchweizerische\nHandelszeitung\nLe Nouveau Quotidien\n(1995 – Feb.1998)\nSonntags-Zeitung\nDie andere Zeitung (DAZ)\n(1995 – 1997)\n\nNewspaper\n\nInclusivenessc\n\nTable 2: Indicators of fairness for all articles published in 28 daily and weekly newspapers\n\n150\n\n 2011 Swiss Political Science Association\n\n236.6\n(184.9)\n126.4\n(95.7)\n172.3\n(74.6)\n19.0\n(10.0)\n\n61.6\n(41.6)\n37.0\n(27.3)\n51.7\n(22.8)\n8.1\n(4.0)\n\nSurfaceb\n0.641\n(0.271)\n0.666\n(0.238)\n0.702\n(0.190)\n0.203\n(0.048)\n\nInclusivenessc\n\n0.138\n\n0.191\n0.749\n\nInclusivenessc\n\n28.0\n(2.1)\n21.4\n(4.7)\n22.9\n(4.6)\n26.0\n(8.4)\n\nAverage\ncampaign\ndayd\n\n5.5\n\n15.7\n24.0\n\nAverage\ncampaign\ndayd\n\n0.018\n(0.083)\n)0.021\n(0.051)\n0.036\n(0.121)\n0.125\n(0.364)\n\nArticle\nbiase\n\n0.062\n\n-0.347\n).001\n\nArticle\nbiase\n\n% Journalists\n(articles)f\n91.2\n(7.1)\n90.8\n(5.2)\n83.5\n(10.6)\n87.7\n(7.5)\n\n)0.007\n(0.153)\n)0.009\n(0.138)\n0.097\n(0.166)\n0.220\n(0.257)\n\n9.5\n\n100.0\n85.5\n\n% Journalists\n(articles)f\n\nIssue\nbiase\n\n0.146\n\n0.089\n.050\n\nIssue\nbiase\n\n19.7\n(9.3)\n14.4\n(6.5)\n19.4\n(8.5)\n9.0\n(6.8)\n\n% Parties\n(articles)f\n\n7.9\n\n0.0\n18.5\n\n% Parties\n(articles)f\n\n41.1\n(19.2)\n25.9\n(3.9)\n24.5\n(13.6)\n38.6\n(24.3)\n\n% Journalists\n(issues)f\n\n7.5\n\n35.7\n23.8\n\n% Journalists\n(issues)f\n\n36.7\n(7.0)\n49.2\n(14.3)\n47.8\n(8.2)\n29.0\n(37.4)\n\n% Parties\n(issues)f\n\n9.9\n\n0.0\n45.4\n\n% Parties\n(issues)f\n\n51.5\n(9.7)\n52.3\n(4.7)\n52.4\n(11.1)\n48.9\n(21.2)\n\n% Reportingg\n\n9.5\n\n81.5\n52.1\n\n% Reportingg\n\n33.5\n(7.1)\n30.4\n(4.1)\n36.4\n(11.5)\n38.2\n(23.6)\n\n% Opiniong\n\n9.5\n\n18.5\n34.2\n\n% Opiniong\n\n15.0\n(7.5)\n17.4\n(2.7)\n11.2\n(5.5)\n12.9\n(15.7)\n\n% Horseraceg\n\n5.6\n\n0.0\n13.7\n\n% Horseraceg\n\n151\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNotes: a: Number of articles. b: Surface in standard newspaper pages (one page=1247 cm2). c: Number of actor categories · IQV (see text for calculation details). d: Mean number of days remaining before voting day. e: B* scores comprised between –1 (all articles ⁄ issues against welfare state\npreservation ⁄ extension) and +1 (all articles ⁄ issues in favour of welfare state preservation ⁄ extension); populist ballots removed; see text for calculation details. f: Sum of categories ‘‘journalists’’ (including press agencies) and ‘‘parties’’ (including referendum ⁄ initiative committees) may exceed\n100%, since several actors may be considered as the ‘‘sources’’ of an article. g: Percentage of articles in each category (see text for deﬁnition). h:\nNewspapers with fewer than 50 articles are excluded; all papers retained (N = 28) for number, surface, and average campaign day. i: National\npapers: Blick, Le Temps, NZZ, Tages-Anzeiger, DAZ. Supraregional papers: Journal de Genève, Neue Luzerner Zeitung, Le Nouveau Quotidien,\nSt. Galler Tagblatt, Südostschweiz. Cantonal papers: Aargauer Zeitung, Basler Zeitung, Bund, Berner Zeitung, Corriere del Ticino, L’Express, La\nLiberté, Nouvelliste, Le Quotidien Jurassien, Schaﬀhauser Nachrichten, Solothurner Zeitung, Tribune de Genève, 24 Heures, Berner Tagwacht.\nWeekly papers: Schweizerische Handelszeitung, Sonntags-Zeitung, Wochenzeitung, Weltwoche.\n\nWeeklyi\n\nCantonali\n\nSupraregionali\n\nNationali\n\nMeans for categories of\nnewspapers (standard\ndeviations in parentheses)\n\nb\n\n3.7\n44.6\n(R=1248.1)\n31.3\n\nSurface\n\nNumbera\n\n5\n153.7\n(R=4303)\n121.1\n\nDie Weltwoche\nMean (N = 21)h\n\nStandard deviation\n\nNumber\n\na\n\nNewspaper\n\nTable 2: (Continued)\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nWe will focus here on the three aspects of independence, bias, and substance. An inspection of individual values and standard deviations shows that there is indeed some variation\nbetween newspapers on these three criteria, but that it is rather limited. According to our\nbias measure B* for articles, the economy-oriented newspapers NZZ and Journal de Gene`ve\nmay qualify as ‘‘anti-welfare’’, as they were, on average, predominantly lopsided against\nwelfare state preservation ⁄ extension. In contrast, the left-wing paper Quotidien Jurassien\nappears as ‘‘pro-welfare’’.31 At the level of issue statements, there is greater variation in B*\nscores, but few papers stand outside a ± 20 percent range around the neutral value (antiwelfare: NZZ; pro-welfare: Quotidien Jurassien and Tribune de Gene`ve). In addition, few\nsingle ballots gave way to skewed information even in any separate outlet. Of all instances\nwith a suﬃcient number of cases, 11 percent were rather pro-welfare and 8 percent were\nrather anti-welfare.32 Weekly (mostly Sunday) papers represent an exception to this overall\nmoderation in dealing with welfare issues, as they appear slanted toward pro-welfare positions (but self-evidently not the right-wing Weltwoche). In sum, the concern that our ﬁnding\nof balanced coverage might be an artifact of aggregation is not substantiated by our data.\nOur ﬁndings concerning the criteria of source independence and substantive coverage tell\na similar story. Signiﬁcant variation between media outlets is scarce, even though some\npeculiarities are worth pointing out. For example, journalists outweigh partisan sources in\nthe Tages-Anzeiger, while in other outlets (e.g., Quotidien Jurassien) these two categories are\nalmost equally present — as speakers or sources of issue statements. In general, journalists\nplay a larger role in national papers than in regional and cantonal papers, which may have\nto do with the resources media organizations must invest to have their journalists closely\ncover ballot campaigns. Finally, the ‘‘format’’ of articles shows little diﬀerence between\nnewspapers. Some of them are more preoccupied with opinion formation than with factual\nreporting (NZZ, Nouvelliste, Quotidien Jurassien, Schaﬀhauser Nachrichten), while the\nopposite holds especially for a couple of French-speaking papers (La Liberte´, Tribune de\nGene`ve, L’Express). With one single exception, horserace information account for less than\n20 percent of campaign coverage in all papers. In any account, then, the overall variation in\nsource independence and information format is limited. The existence of such variation cannot be taken to mean that the press coverage of ballot campaigns in Switzerland is a\nmere collection of disjoint ‘‘speciﬁc campaigns’’ with potentially divergent consequences for\ndiﬀerent segments of the electorate.\n\n7. Spatial patterns of media coverage\nWe now turn to the issue of spatial homogeneity. Provided that the Swiss media system is\nhighly fragmented along linguistic lines, is this segmentation reﬂected in region-speciﬁc\n‘‘styles’’ of media coverage? More speciﬁcally, to what extent are the particular dimensions\nof media coverage that we analyzed thus far similar in the two main Swiss regions? As\n\n31\nIn the following, we will not comment on results for newspapers with a small number of published articles\n(N &lt; 50). Note that the indicators in this section are computed on the basis of all articles published in each newspaper, without distinction of the speciﬁc ballot measures.\n32\n292 campaigns in individual papers were analyzed and B* scores for articles were computed for each of them.\nOnly cases where a newspaper published more than 4 articles on a given campaign were considered. When the same\nprocedure is applied to B* scores for issue statements, the proportion of seemingly ‘‘biased campaigns’’ is much\nhigher, but also less reliable (see above note 30).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n152\n\n153\n\nbecomes clear from Table 3, diﬀerences are in general rather limited, and sizable diﬀerences\nare only found for particular types of ballot issues.\nCampaign intensity as reported in Table 3 is a composite measure derived from the surface of articles, from the circulation ﬁgures of the newspapers, and from the number of people eligible to vote.33 The measure thus points out diﬀerences in the overall potential\nexposure of individual citizens and shows that campaigns are clearly more intense in the\nGerman-speaking region. The diﬀerence is particularly noticeable and systematic with\nrespect to pension and maternity issues. As concerns campaign length, the ‘‘average campaign day’’ indicator suggests that overall diﬀerences are slight. Campaigns may last a bit\nlonger in the German-speaking press, but mainly for measures pertaining to unemployment,\nand in any case not for measures on disability. Further, as would be expected from these\ndiﬀerences in intensity and length, media campaigns are also somewhat more ‘‘inclusive’’ in\nthe German-speaking press, where, on average, two additional actor categories are used as\nsources of issue statements.\nTurning to coverage bias, we again note that diﬀerences between the regions are marginal.\nHowever, as already pointed out above, bias is more conspicuous when measured at the level\nof issue statements rather than at the level of whole articles. Although the overall diﬀerence\nis negligible, this stems from the fact that the small diﬀerences that do exist cancel each other\nout across the various policy ﬁelds. Thus coverage in the German-speaking press was more\nskewed on health and disability measures, while it was less skewed on maternity issues (most\nnotably, French- and Italian-speaking papers had been much more enthusiastically endorsing the 1999 maternity leave project than had their German-speaking counterparts).\nNext, we compared the independence of journalists from external sources of information\nin the two regions. On the whole, the diﬀerences are modest. As speakers, German-speaking\njournalists were less prominent than journalists from other regions on maternity and disability issues, but they were more ‘‘autonomous’’ on unemployment. Diﬀerences were somewhat more pronounced as regards the source of issue statements. Journalists were more\nlikely to be the source of reported issues in the German-speaking press than in the Frenchand Italian-speaking press, especially for unemployment and labour regulation (but not for\nmaternity and disability issues). For example, French-speaking journalists sometimes draw\non scientiﬁc or educational sources (8 percent) for addressing labour and unemployment\nissues, while their German-speaking colleagues never do so (at least in our sample). These\nregional patterns may have at least two diﬀerent causes. On the one hand, turning to external sources may occur because journalists are less sure where they stand (or should stand)\non the issues and ⁄ or because they believe that public opinion on the issues is not crystallized\nyet and need orientating information from political sources. On the other hand, the\nobserved regional gaps may simply be reﬂective of more routinized relationships between\njournalists and political actors in some policy domains.\nThe ‘‘format’’ of information was then considered, with a focus on horserace information. Marginal regional gaps were observed, as the share of horserace items rarely exceeded\n20 percent in any region, but the diﬀerences were rather systematic. In general, information\nin German-speaking papers is more often of the ‘‘horserace’’ type than in French- or\nItalian-speaking papers (an overall 4 percent gap), and this diﬀerence holds for 17 of 24\n33\n\nLe Nouveau Quotidien, DAZ, and Berner Tagwacht are not taken into account in this analysis, due to unavailable circulation ﬁgures, but they represent only about 2 percent of articles and surface. More consequential is the\nfact that the French-speaking tabloid Le Matin, which has the largest circulation in the western region, is not\nincluded in our data. The absence of this paper probably explains part of the diﬀerence between the two regions.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n 2011 Swiss Political Science Association\n\n0.5 (10.5)\n4.0 (9.5)\n\n2.0 (9.5)\n\n3.1 (8.8)\n\n9.3 (15.6)\n2.7 (5.5)\n\n2.0 (9.6)\n1.9 (9.7)\n1.3 (7.8)\n2.5 (10.8)\n\n4.2 (9.2)\n4.7 (10.3)\n2.5 (6.4)\n3.2 (8.3)\n\n2.2 (26.4)\n)4.1 (23.9)\n\n8.9 (27.0)\n\n1.6 (24.8)\n1.2 (25.3)\n0.3 (22.8)\n3.0 (23.8)\n\nAverage\ncampaign\nday\n\n)0.236 (0.297)\n0.178* (0.365)\n\n0.002 (0.120)\n\n)0.036 (0.053)\n)0.035 (0.065)\n0.047 (0.131)\n\n0.013 (0.207)\n0.011 (0.145)\n0.125 (0.420)\n)0.045 (0.071)\n\nIssue\nbias\n(|B| scores)\n\n0.009 (0.091)\n)0.010 (0.075)\n0.037 (0.157)\n0.052 (0.080)\n\nArticle\nbias\n(|B| scores)\n\n)4.0 (86.5)\n)11.3 (78.9)\n\n0.5 (28.7)\n)1.6 (16.0)\n\n10.2 (30.9)\n\n6.1** (28.1)\n5.1 (27.7)\n6.0 (33.0)\n13.1* (28.5)\n\n)0.7 (86.3)\n)1.5 (85.9)\n2.2 (89.1)\n1.3 (86.7)\n6.8 (89.2)\n\nSource\nof issues\n= journalists\n\nSource of\narticles\n= journalists\n\n)4.5 (14.2)\n)1.8 (14.0)\n\n3.9 (7.3)\n\n3.9 (15.7)\n5.7 (16.6)\n5.6 (14.2)\n4.6 (21.0)\n\nImportance of\nhorserace\ninformation\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n**: p&lt;.05; *: p&lt;.10 (two-tailed tests checking for diﬀerences between paired-sample means).\n\nNotes: The ﬁgures show the diﬀerence between the two main linguistic areas (German-speaking vs. French- or Italian-speaking). A positive (negative) diﬀerence means that a given quantity is higher (lower) in the German-speaking area. In parentheses are the reference quantities, i.e., those\nmeasured in the German-speaking area.\nPk Pn\ncirci surfij\nj¼1\na: Intensity = i¼1 voters\n, with circi=circulation of newspaper i, surfij=surface of article j (in pages) in newspaper i, and voters=people eligible to vote (in thousands).\n\nTotal (N=24)\nPensions (N=10)\nHealth (N=4)\nLabour regulation\n(N=4)\nUnemployment\n(N=2)\nMaternity (N=2)\nDisability (N=2)\n\nIntensity a\n\nInclusiveness\n(# of source\ncategories)\n\nTable 3: Interregional diﬀerences with respect to eight indicators of media fairness and six policy ﬁelds\n\n154\n\n155\n\nballot proposals. The largest between-region diﬀerences in the share of horserace articles\nare found for pension and health issues, but there was actually more horserace coverage in\nthe French ⁄ Italian-speaking area on maternity and disability issues.34\n\n8. Conclusion\nThe aim of this study was to assess the fairness of the press coverage of referendums on\nwelfare state issues in Switzerland. We distinguished seven dimensions of media coverage in\norder to determine how it compares to idealized notions of the media’s role in the democratic process. In this concluding section we summarize our analysis of media coverage\nquality and, whenever possible and sensible, we relate our results to those of other studies.\nFirst, as regards the intensity of press coverage in daily newspapers, we found about eight\narticles per proposal and newspaper, amounting to two or three full pages of coverage.\nWith only modest variation across votes (though variation is more pronounced across\nmedia outlets), such coverage might be considered as a ‘‘fair’’ performance.35\nSecond, turning to the question of campaign duration, our results show that the press coverage peaked two to three weeks before the voting day, and that half of the total information had been released some 22 days before the poll. Although comparable studies of\nEuropean referendums are lacking (see Novik 2009: 13) we interpret this average duration\nas ‘‘appropriate’’, since press coverage was relatively gradual and did not surge in the last\ncampaign days.\nThird, we investigated the bias in media coverage. Overall, we ﬁnd a minimal to nonexistent bias at the level of press articles (i.e., the general thrust of news stories) toward prowelfare state orientation. When looking at particular issue statements, the bias appeared\nlarger but still not overwhelming. In fact, bias was largely restricted to matters of public\nhealth in the larger sense (hospital costs, price of drugs, maternity, disability, etc.) and was\nvirtually absent from campaigns on such themes as pensions, labour regulation, and unemployment. The variation in balance among diﬀerent newspaper outlets is rather limited.\nConcerning articles in daily newspapers, only the Journal de Gene`ve and the NZZ adopted\na rather ‘‘anti-welfare’’ position while the Quotidien Jurassien was lopsided toward the\n‘‘pro-welfare’’ camp. However, compared to news balance in other referendum campaigns,\nsuch as Pilon’s (2009) report on the Ontario Provincial Referendum and Hobolt’s (2009:\n186–189) analysis of the ﬁrst Irish referendum on the Nice Treaty, we conclude that the\nreporting on welfare state issues in the Swiss print media generally provides little ammunition to those who suspect or condemn a systematic bias in media coverage.\n\n34\nIt may be that, due to a more skeptical opinion climate toward the latter issues in their region, German-speaking\njournalists had more incentives to engage in opinion formation rather than stick to hard facts and descriptions of\nthe situation. This is especially true for maternity issues, as welfare state support is 30 percent higher on average\namong French- and Italian-speaking voters than among German-speaking voters (our own calculations from the\nmunicipality-level data available in the ‘‘Political Atlas of Switzerland’’, Swiss Federal Statistical Oﬃce).\n35\nThis rather lenient judgment may be qualiﬁed by comparing our results with those of Hobolt (2009: 207)208),\nwho found more intense press coverage for the 2005 French and the Dutch referendum campaigns on the European\nConstitution, even if we restrict the analysis to the country’s two major broadsheet newspapers (NZZ and\nLe Temps, in the Swiss case) as Hobolt did. However, the ﬁgures might not be fully comparable; the vote on the\nEuropean Constitution might have been of greater salience than single welfare state proposals. Moreover, the lower\nfrequency of popular votes in France and the Netherlands as compared to Switzerland may explain a more intense\ncoverage of those (rare) referendums. We should therefore await further research on news reporting in the Swiss\ncontext in order to compare our ﬁndings.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nFourth, the relative independence of journalists from external (particularly partisan)\nsources was examined. Similar to coverage bias, the dimension of media autonomy was\ninvestigated at two levels: articles and issue statements. At the level of articles, it was found\nthat journalists are by far the most important ‘‘speakers’’. Although they can delegate their\nagenda-setting role to other actors by soliciting their opinions through interviews, op-eds,\nor free columns, they rarely do so — at least not until the last three or four campaign\nweeks. Hence, our analysis suggests that the Swiss newspapers’ progressive loss of attachment to parties and other political groups (Meier and Schanne 1994) may have enhanced\ntheir ‘‘autonomy’’ — a concept not to be confused with that of journalistic ‘‘objectivity’’,\nwhich is outside the scope of this study. However, when evaluated at the level of issue\nstatements, the press coverage of referendum campaigns appears in a somewhat diﬀerent\nlight. Without there being anything ‘‘unfair’’ on a priori grounds, media coverage appears\nto largely reﬂect the issue agenda of the major political forces involved in campaigns (i.e.,\npolitical parties and committees, governmental agencies, professional associations, etc.).\nAltogether, these non-media sources account for about three times the number of journalistic issue items.36 In our view, there is no basic contradiction between the ﬁndings from these\ndistinct levels of analysis; taken together, they are reﬂective of both main functions traditionally assigned to news media — an information and an orientation function.\nThe dominance of journalists as sources of articles suggests that press journalists function\nas gatekeepers, selecting who may intervene directly in the news process, rather than as\nmere providers of a ‘‘free forum’’ to which any group or individual is granted equal and\nunlimited access. On the other hand, the press coverage of ballot issues is of course reﬂective — and possibly ‘‘reﬂexive’’ in the Luhmannian sense (Neidhardt 1994) — of what the\nmain political actors have to say. Therefore, media agenda-setting is not exogenous, but largely driven by the agenda of various political elites. As our measure of source inclusiveness\nsuggests, Swiss press journalists tend to rely on a broad array of diﬀerent actor categories,\nand media coverage may thus be said to be ‘‘inclusive’’. However, this substantial diversity\nin news coverage does not allow us to rule out the gatekeeping hypothesis: it is questionable\nwhether all actors who wanted to participate in the campaign debates ﬁnally found their\nway in news reporting.\nNext, our data provided insight into the substance of media coverage. We found that the\noften-criticized ‘‘horserace’’ nature of election coverage is not prevalent in the context of\nSwiss referendum campaigns. For one thing, horserace information accounts for only about\n13 percent of all news items — a tiny proportion compared, for instance, with U.S. presidential campaigns (Strömbäck and Dimitrova 2006), the 1995 Quebec secession referendum\n(see Pilon 2009), or even with more readily comparable campaigns such as the 2000 Danish\nreferendum on the adoption of the Euro (De Vreese and Semetko 2002). In addition,\nalthough the number of ‘‘factual information’’ items exceeds that of ‘‘opinion’’ items, both\nare important categories of press coverage. This again suggests that information and orientation are important functions performed by the media, and that in assuming these functions the media go well beyond predicting which side is likely to win.\nLastly, spatial homogeneity was deﬁned as an additional norm of media coverage. This\nnorm is rooted in the perception that public opinion on welfare state issues frequently\ndiverges across the main linguistic areas. Accordingly, distinctive media coverage threatens\nto reinforce the pre-existing cleavages and to undermine national cohesion by promoting a\n36\n\nAs compared to Tresch’s (2008: 142–149) ﬁndings on media coverage of European politics, state actors play a\nslightly less prominent role in debates on welfare state issues.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n156\n\n157\n\n‘‘tyranny of the majority’’. It was found that regional gaps in the press coverage of campaigns were minimal and largely restricted to three criteria: intensity of coverage, horserace\nreporting and source independence. In the German-speaking region, campaigns were somewhat more intense, more inclined toward horserace information, and journalists were more\noften the source of issues than was the case in the other linguistic areas. This may reﬂect\neither economic or cultural diﬀerences of media organizations between the regions. But\nagain, the hallmark of this analysis is similarity rather than discrepancy. Even when looking\nat speciﬁc welfare policy areas (pensions, health, etc.), press coverage appears — with few\nexceptions — strikingly similar across both regions, in line with the more detailed analysis\nof Swiss European policy by Tresch (2008).\nIn conclusion, the coverage of referendum campaigns on welfare state issues by the Swiss\npress appears reasonably fair when examined from a broad perspective. However, this\nappraisal of ‘‘satisfactory’’ (though certainly not ‘‘optimal’’) media campaign coverage is\nbased on quantitative indicators that may fail to capture many intrinsic qualities of media\ncoverage. Admittedly, the standards used to assess the fairness of media coverage were not\nexcessively high, and the conclusions we draw from our analysis await conﬁrmation from\nindependent datasets and studies, in particular from more qualitative-oriented research\n‘‘putting qualitative ﬂesh on quantitative bones’’ (Tarrow 2004: 176). Accordingly, we call\nfor further testing of the normative framework developed in the present study and for replications of our analysis in other settings. In addition, there is clearly a need of going beyond\nthe mere ‘‘procedural’’ approach to fairness developed here. Although they can be estimated by quantitative indicators, procedure-independent criteria of media fairness may be\nbest deﬁned through qualitative methods.\n\nReferences\nAlthaus, S. (1998). Information Eﬀects in Collective Preferences. American Political Science Review\n92(3): 545–558.\nBächtiger, A., S. Niemeyer, M. Neblo, M. Steenbergen and J. Steiner (2010). Disentangling Diversity\nin Deliberative Democracy: Competing Theories, Their Blind Spots and Complementarities. Journal of Political Philosophy 18(1): 32–63.\nBaerns, B. (1979). Öﬀentlichkeitsarbeit als Determinante journalistischer Informationsleistungen. Publizistik 24(3): 301–316.\nBarrett, A. and L. Barrington (2005). Bias in Newspaper Photograph Selection. Political Research\nQuarterly 58(4): 609–618.\nBartels, L. (1988). Presidential Primaries and the Dynamics of Public Choice. Princeton: Princeton University Press.\n—— (1996). Uninformed Votes: Information Eﬀects in Presidential Elections. American Journal of\nPolitical Science 40(1): 194–230.\nBennett, L., R. Lawrence and S. Livingston (2007). When the Press Fails. Political Power and the News\nMedia from Iraq to Katrina. Chicago: University of Chicago Press.\nBentele, G. (2003). Kommunikatorforschung: Public Relations. In Bentele, G., H.-B. Brosius and O.\nJarren (eds.), Öﬀentliche Kommunikation. Handbuch Kommunikations- und Medienwissenschaft.\nWiesbaden: Westdeutscher Verlag (54–78).\nBerelson, B. (1952). Democratic Theory and Public Opinion. Public Opinion Quarterly 16(3): 313–330.\nBerelson, B., P. Lazarsfeld and W. McPhee (1954). Voting. A Study of Opinion Formation in a Presidential Campaign. Chicago: The University of Chicago Press.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nBerkowitz, D.A. (2009). Reporters and Their Sources. In Wahl-Jorgensen, K. and T. Hanitzsch (eds.),\nThe Handbook of Journalism Studies. New York: Routledge (102–115).\nBlum, R. (2003). Medienstrukturen der Schweiz. In Bentele, G., H.-B. Brosius and O. Jarren (eds.),\nÖﬀentliche Kommunikation. Handbuch Kommunikations- und Medienwissenschaft. Wiesbaden: Westdeutscher Verlag (366–381).\nBonfadelli, H. and R. Blum (2000). Helvetisches Stiefkind: die Rolle der Massenmedien bei der Vermittlung schweizerischer Aussenpolitik. Bern, NFP 42 Synthesis n 28.\nBornschier, S. (2010). Cleavage Politics and the Populist Right: The New Cultural Conﬂict in Western\nEurope. Philadelphia: Temple University Press.\nBützer, M. and L. Marquis (2002). Public Opinion Formation in Swiss Federal Referendums. In\nFarrell, D. and R. Schmitt-Beck (eds.), Do Political Campaigns Matter? Campaign Eﬀects in Elections and Referendums. London and New York: Routledge (163–182).\nBunton, K. (1998). Social Responsibility in Covering Community: A Narrative Case Analysis. Journal\nof Mass Media Ethics 13(4): 232–246.\nChaﬀee, S. and S.Y. Choe (1980). Time of Decision and Media Use During the Ford-Carter\nCampaign. Public Opinion Quarterly 44(1): 53–69.\nChristians, C. and K. Nordenstreng (2004). Social Responsibility Worldwide. Journal of Mass Media\nEthics 19(1): 3–28.\nCohen, J. (1986). An Epistemic Conception of Democracy. Ethics 97(1): 26–38.\n—— (1989). Deliberation and Democratic Legitimacy. In Hamlin, A. and P. Pettit (eds.), The Good\nPolity. Oxford: Blackwell (17–34).\nConnolly, S. and S. Hargreaves Heap (2007). Cross Country Diﬀerences in Trust in Television and\nthe Governance of Public Broadcasters. Kyklos 60(1): 3–14.\nConnolly, W.E. 1991. Identity, Diﬀerence: Democratic Negotiations of Political Paradox. Ithaca:\nCornell University Press.\nDahl, R.A. 1989. Democracy and Its Critics. New Haven [etc.]: Yale University Press.\nDe Vreese, C. and H. Semetko (2002). Public Perception of Polls and Support for Restrictions on the\nPublication of Polls: Denmark’s 2000 Euro Referendum. International Journal of Public Opinion\nResearch 14(4): 367–390.\nDelli Carpini, M. and S. Keeter 1996. What Americans Know about Politics and Why It Matters. New\nHaven and London: Yale University Press.\nDiskin, A., A. Eschet-Schwarz and D. Felsenthal (2007). Homogeneity, Heterogeneity and Direct\nDemocracy: The Case of Swiss Referenda. Canadian Journal of Political Science 40(2): 317–342.\nDonovan, T. and S. Bowler (1998). An Overview of Direct Democracy in the American States. In\nBowler, S., T. Donovan and C. Tolbert (eds.), Citizens as Legislators. Direct Democracy in the\nUnited States. Columbus: Ohio State University Press (1–21).\nDonsbach, W. and A. Wenzel (2002). Aktivität und Passivität von Journalisten gegenüber parlamentarischer Pressearbeit. Publizistik 47(4): 373–387.\nDowns, A. (1957). An Economic Theory of Democracy. New York: Harper Collins.\nDryzek, J.S. (1990). Discursive Democracy: Politics, Policy, and Political Science. New York:\nCambridge University Press.\nDuVivier, K. (2006). The United States as a Democratic Ideal? International Lessons in Referendum\nDemocracy. Temple Law Review 79: 821–876.\nEntman, R. (2004). Projections of Power. Framing News, Public Opinion, and U.S. Foreign Policy.\nChicago: University of Chicago Press.\nEstlund, D. (1997). Beyond Fairness and Deliberation: The Epistemic Dimension of Democratic\nAuthority. In Bohman, J. and W. Rehg (eds.), Deliberative Democracy: Essays on Reason and\nPolitics. Cambridge: MIT Press (173–204).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n158\n\n159\n\nFörster, J. and N. Liberman (2007). Knowledge Activation. In Kruglanski, A. and E.T. Higgins\n(eds.), Social Psychology. Handbook of Basic Principles. New York: Guilford Press (201–231).\nFournier, P., R. Nadeau, A. Blais, E. Gidengil and N. Nevitte (2004). Time-of-Voting Decision and\nSusceptibility to Campaign Eﬀects. Electoral Studies 23(4): 661–681.\nFröhlich, R. and B. Rüdiger (2006). Framing Political Public Relations: Measuring Success of Political Communication Strategies in Germany. Public Relations Review 32: 18–25.\nGerhards, J. (1997). Diskursive versus liberale Öﬀentlichkeit. Eine empirische Auseinandersetzung mit\nJürgen Habermas. Kölner Zeitschrift für Soziologie und Sozialpsychologie 49(1): 1–34.\nGilens, M. (2001). Political Ignorance and Collective Policy Preferences. American Political Science\nReview 95(2): 379–396.\nGitlin, T. (1980). The Whole World is Watching. Mass Media in the Making and Unmaking of the New\nLeft. Berkeley: University of California Press.\nGollin, A. (1980). Exploring the Liaison between Polling and the Press. Public Opinion Quarterly\n44(4): 445–461.\nGraber, D. (2003). The Media and Democracy: Beyond Myths and Stereotypes. Annual Review of\nPolitical Science 6: 139–160.\n—— (2006). Mass Media and American Politics. Washington: CQ Press.\nGrossenbacher, R., T. Forsberg, M. Koch and M. Brändli (2006). Politische Öﬀentlichkeitsarbeit in regionalen Medien. Kilchberg: Publicom AG.\nGurevitch, M. and J. Blumler (1977). Linkages between the Mass Media and Politics: A Model for\nthe Analysis of Political Communications Systems. In Curran, J., M. Gurevitch and J. Woollacott\n(eds.), Mass Communication and Society. London: Edward Arnold (270–290).\nGurevitch, M. and J. Blumler (1990). Political Communication Systems and Democratic Values. In\nLichtenberg, J. (ed.), Democracy and the Mass Media. New York: Cambridge University Press\n(269–289).\nHabermas, J. (1992). Faktizität und Geltung. Beiträge zur Diskurstheorie des Rechts und des demokratischen Rechtsstaats. Frankfurt am Main: Suhrkamp.\nHajnal, Z., E. Gerber and H. Louch (2002). Minorities and Direct Legislation: Evidence from\nCalifornia Ballot Proposition Elections. Journal of Politics 64(1): 154–177.\nHallin, D. (1984). The Media, the War in Vietnam, and Political Support: A Critique of the Thesis of\nan Oppositional Media. Journal of Politics 46(1): 2–24.\nHallin, D. and P. Mancini (2004). Comparing Media Systems. Three Models of Media and Politics.\nNew York: Cambridge University Press.\nHardmeier, S. (1999). Political Poll Reporting in Swiss Print Media: Analysis and Suggestions for\nQuality Improvement. International Journal of Public Opinion Research 11(3): 257–74.\n—— (2000). Meinungsumfragen im Journalismus: Nachrichtenwert, Präzision und Publikum. Medien\nund Kommunikationswissenschaft 48(3): 371–395.\nHargreaves, I. and J. Thomas (2002). New News, Old News. An ITC and BSC Research Publication.\nLondon: ITC.\nHayes, A. (2008). Press Critics Are the Fifth Estate: Media Watchdogs in America. New York:\nPraeger.\nHertig, H.P. (1982). Sind Abstimmungserfolge käuﬂich? — Elemente der Meinungsbildung bei\nEidgenössischen Abstimmungen. Annuaire Suisse de Science Politique 22: 35–57.\nHiggins, E. (1996). Knowledge Activation: Accessibility, Applicability, and Salience. In Higgins, E.\nand A. Kruglanski (eds.), Social Psychology. Handbook of Basic Principles. New York: The\nGuilford Press (133–168).\nHofstetter, C. et al. (1999). Information, Misinformation, and Political Talk Radio. Political Research\nQuarterly 52(2): 353–369.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nHobolt Binzer, S. (2009). Europe in Question: Referendums on European Integration. Oxford: Oxford\nUniversity Press.\nJerit, J., J. Barabas and T. Bolsen (2006). Citizens, Knowledge, and the Information Environment.\nAmerican Journal of Political Science 50(2): 266–282.\nKaufmann, B., G. Kreis and A. Gross (2005). Direkte Demokratie und europäische Integration. Die\nHandlungsspielräume der Schweiz. Basel: Europainstitut.\nKelley, S. (1960). Political Campaigning. Problems in Creating an Informed Electorate. Washington:\nThe Brookings Institution.\nKing, E. and M. Schudson (1995). The Press and the Illusion of Public Opinion: The Strange Case of\nRonald Reagan’s ‘Popularity’. In Glasser, T. and C. Salmon (eds.), Public Opinion and the Communication of Consent. New York: The Guilford Press (132–155).\nKirchgässner, G. and T. Schulz (2005). Was treibt die Stimmbürger an die Urne? Eine empirische\nUntersuchung der Abstimmungsbeteiligung in der Schweiz, 1981–1999. Swiss Political Science\nReview 11(1): 1–56.\nKriesi, H. (1994). Le déﬁ à la démocratie directe posé par les transformations de l’espace public. In\nPapadopoulos, Y. (ed.), Pre´sent et avenir de la de´mocratie directe. Geneva: Georg (31–72).\n—— (1998). The Transformation of Cleavage Politics: The 1997 Stein Rokkan Lecture. European\nJournal of Political Research 33(2): 165–185.\n—— (2003). Strategische politische Kommunikation: Bedingungen und Chancen der Mobilisierung\nöﬀentlicher Meinung im internationalen Vergleich. In Esser, F. and B. Pfetsch (eds.), Politische\nKommunikation im internationalen Vergleich. Grundlagen, Anwendungen, Perspektiven. Wiesbaden:\nWestdeutscher Verlag (208–239).\n—— (2005). Direct Democratic Choice. The Swiss Experience. Lanham: Lexington Books.\nKriesi, H., B. Wernli, P. Sciarini and M. Gianni (1996). Le clivage linguistique. Proble`mes de compre´hension entre les communaute´s linguistiques en Suisse. Berne: Oﬃce fédéral de la statistique.\nKrouse, R. and G. Marcus (1984). Electoral Studies and Democratic Theory Reconsidered. Political\nBehavior 6(1): 23–39.\nKuklinski, J. and P. Quirk (2000). Reconsidering the Rational Public: Cognition, Heuristics, and Mass\nOpinion. In Lupia, A., M. McCubbins and S. Popkin (eds.), Elements of Reason. Cambridge:\nCambridge University Press (153–182).\nLandis, J.R. and G. Koch (1977). The Measurement of Observer Agreement for Categorical Data.\nBiometrics 33(1): 159–174.\nLeuthold, H., M. Hermann and S. Fabrikant (2007). Making the Political Landscape Visible:\nMapping and Analyzing Voting Patterns in an Ideological Space. Environment and Planning B:\nPlanning and Design 34: 785–807.\nLinder, W., R. Zürcher and C. Bolliger (2008). Gespaltene Schweiz – geeinte Schweiz. Gesellschaftliche\nSpaltungen und Konkordanz bei den Volksabstimmungen seit 1874. Baden: Hier und Jetzt.\nList, C. and R.E. Goodin (2001). Epistemic Democracy: Generalizing the Condorcet Jury Theorem.\nJournal of Political Philosophy 9(3): 277–306.\nLongchamp, C. (1998). Demoskopie: Seismograph oder Kompass? Ein Überblick über die Ausbreitung\nund Verwendung der politischen Umfrageforschung in der Schweiz. Referat vor der Erdöl-Vereinigung, 23.03.1998. Online: http://www.gfs.ch/publset.html [accessed: 29.04.2010].\nLuskin, R., J. Fishkin and R. Jowell (2002). Considered Opinions: Deliberative Polling in Britain.\nBritish Journal of Political Science 32(3): 455–487.\nMarquis, L. (2006). La formation de l’opinion publique en de´mocratie directe. Les réfe´rendums sur la\npolitique exte´rieure suisse (1981–1995). Zurich: Seismo.\nMarquis, L. and M. Bergman (2009). Development and Consequences of Referendum Campaigns in\nSwitzerland, 1981–1999. Swiss Political Science Review 15(1): 63–97.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n160\n\n161\n\nMatthes, J. (2005). The Need for Orientation Towards News Media: Revising and Validating a Classic\nConcept. International Journal of Public Opinion Research 18(4): 422–444.\nMcDevitt, M. (2003). In Defense of Autonomy: A Critique of the Public Journalism Critique. Journal\nof Communication 53(1): 155–160.\nMcLeod, D., G. Kosicki and J. McLeod (2002). Resurveying the Boundaries of Political Communications Eﬀects. In Bryant, J. and D. Zillmann (eds.), Media Eﬀects. Advances in Theory and Research.\nMahwah: Lawrence Erlbaum (215–267).\nMeier, W. and M. Schanne (1994). Medien-‘‘Landschaft’’ Schweiz. Zurich: Pro Helvetia.\nMeier, W. and O. Jarren (2002). Ökonomisierung und Kommerzialisierung von Medien und Mediensystem. Bemerkungen zu einer (notwendigen) Debatte. In Haas, H. and O. Jarren (eds.), Mediensysteme im Wandel. Struktur, Organisation und Funktion der Massenmedien. Wien: Braumüller\n(201–216).\nMerritt, D. (1995). Public Journalism and Public Life. Why Telling the News Is Not Enough. Mahwah:\nLawrence Erlbaum.\nNeidhardt, F. (1994). Öﬀentlichkeit, öﬀentliche Meinung, soziale Bewegungen. In Neidhardt, F. (ed.),\nÖﬀentlichkeit, öﬀentliche Meinung, soziale Bewegungen. Kölner Zeitschrift für Soziologie und\nSozialpsychologie, Sonderheft 34 (7–41).\nNeidhart, L. (1970). Plebiszit und pluralitäre Demokratie. Eine Analyse der Funktion des schweizerischen Gesetzesreferendums. Berne: Francke.\nNeuman, W.R. (1990). The Threshold of Public Attention. Public Opinion Quarterly 54(2): 159–176.\nNovik, N. (2009). Do Campaigns Matter? The Contribution of European Union Campaigns to Broad\nPolitical Knowledge. Dissertation. Dublin: Trinity College.\nPage, B.I. (1996). Who Deliberates? Mass Media in Modern Democracy. Chicago: University of Chicago Press.\nPapadopoulos, Y. (1998). De´mocratie directe. Paris: Economica.\nPateman, C. (1970). Participation and Democratic Theory. Cambridge: Cambridge University Press.\nPatterson, T. (1994). Out of Order. New York: Vintage.\n—— (1998). Political Roles of the Journalist. In Graber, D., D. McQuail and P. Norris (eds.), The\nPolitics of News. The News of Politics. Washington D.C.: Congressional Quarterly (17–32).\nPfetsch, B. (2004). Geschlossene Gesellschaft? Akteursensembles und Akteursbewertungen in Pressekommentaren. In Eilders, C., F. Neidhardt and B. Pfetsch (eds.), Die Stimme der Medien: Pressekommentare und politische Öﬀentlichkeit in der Bundesrepublik. Wiesbaden: VS Verlag (74–105).\nPilon, D. (2009). Investigating Media as a Deliberative Space: Newspaper Opinions about Voting Systems in the 2007 Ontario Provincial Referendum. Canadian Political Science Review 3(3): 1–23.\nPrice, V. and J. Zaller (1993). Who Gets the News? Alternative Measures of News Reception and their\nImplications for Research. Public Opinion Quarterly 57(2): 133–164.\nRobinson, G. (1995). Making News and Manufacturing Consent: The Journalistic Narrative and Its\nAudience. In Glasser, T. and C. Salmon (eds.), Public Opinion and the Communication of Consent.\nNew York: The Guilford Press (348–369).\nRothmayr, C. and S. Hardmeier (2002). Government and Polling: Use and Impact of Polls in the\nPolicy-Making Process in Switzerland. International Journal of Public Opinion Research 14(2):\n123–140.\nSallot, L. and E. Johnson (2006). Investigating Relationships between Journalists and Public Relations\nPractitioners: Working Together to Set, Frame and Build the Public Agenda, 1991-2004. Public\nRelations Review 32(2): 151–159.\nSchönhagen, P. (2008). Ko-Evolution von Public Relations und Journalismus: Ein erster Beitrag zu\nihrer systematischen Aufarbeitung. Publizistik 53(1): 9–24.\nSchudson, M. (2001). The Objectivity Norm in American Journalism. Journalism 2(2): 149–170.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nShoemaker, P. and S. Reese (1995). Mediating the Message. Theories of Inﬂuences on Mass Media\nContent. White Plains: Longman.\nSigal, L. (1973). Reporters and Oﬃcials. The Organization and Politics of Newsmaking. Lexington:\nHeath and Company.\nSinger, J. (2007). Contested Autonomy. Professional and Popular Claims on Journalistic Norms. Journalism Studies 8(1): 79–95.\nStatham, P. (2006). Political Journalism and Europeanization: Pressing Europe? European Political\nCommunication Working Paper No. 2006 ⁄ 13.\nStrömbäck, J. and D. Dimitrova (2006). Political and Media Systems Matter: A Comparison of\nElection News Coverage in Sweden and the United States. Harvard International Journal of Press ⁄\nPolitics 11(4): 131–147.\nSturgis, P. (2003). Knowledge and Collective Preferences. A Comparison of Two Approaches to Estimating the Opinions of a Better Informed Public. Sociological Methods and Research 31(4): 453–485.\nTarrow, S. (2004). Bridging the Quantitative-Qualitative Divide. In Brady, H. and D. Collier (eds.),\nRethinking Social Inquiry: Diverse Tools, Shared Standards. Lanham: Rowman &amp; Littleﬁed (171–\n179).\nTrechsel, A. and P. Sciarini (1998). Direct Democracy in Switzerland: Do Elites Matter? European\nJournal of Political Research 33(1): 99–124.\nTresch, A. (2008). Öﬀentlichkeit und Sprachenvielfalt. Medienvermittelte Kommunikation zur Europapolitik in der Deutsch- und Westschweiz. Baden-Baden: Nomos.\nTuchman, G. (1972). Objectivity as Strategic Ritual: An Examination of Newsmen’s Notions of\nObjectivity. American Journal of Sociology 77(4): 660–679.\nVatter, A. (2002). Kantonale Demokratien im Vergleich. Entstehungsgründe, Interaktionen und Wirkungen politischer Institutionen in den Schweizer Kantonen. Opladen: Leske und Budrich.\nWatts, M., D. Domke, D. Shah and D. Fan (1999). Elite Cues and Media Bias in Presidential Campaigns: Explaining Public Perceptions of a Liberal Press. Communication Research 26(2): 144–175.\nWuerth, A. (1999). Mediensystem und politische Kommunikation. In Klöti, U., P. Knoepfel,\nH. Kriesi, W. Linder and Y. Papadopoulos (eds.), Handbuch der Schweizer Politik. Zurich: NZZ\nVerlag (337–384).\nYankelovich, D. (1991). Coming to Public Judgment. Making Democracy Work in a Complex World.\nSyracuse: Syracuse University Press.\nYoung, I.M. (1990). Justice and the Politics of Diﬀerence. Princeton: Princeton University Press.\n—— (2000). Inclusion and Democracy. Oxford: Oxford University Press.\nZaller, J. and D. Chiu (1996). Government’s Little Helper: U.S. Press Coverage of Foreign Policy\nCrises, 1945–1991. Political Communication 13(4): 385–405.\n\nAppendix\nTable A1: List of all ballot measures analyzed in this study\nResult\n(share of yes\nvotes)\n\nBallot title\n571 10th amendment of retirement pension system (25.06.1995)\n572 Initiative on retirement pensions (25.06.1995)\n602 Law on labour: weekend and night work, maternity (01.12.1996)\n622 Financing of unemployment insurance (28.09.1997)\n\n 2011 Swiss Political Science Association\n\n60.7\n27.6\n33.0\n49.2\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n162\n\n163\n\nTable A1: (Continued).\nResult\n(share of yes\nvotes)\n\nBallot title\n643 10th amendment of pension system without increase of retirement age\n(27.09.1998)\n654 Law on labour: night work, maternity (29.11.1998)\n684 Law on disability insurance (13.06.1999)\n685 Law on maternity insurance (13.06.1999)\n721 Initiative against increase of retirement age for women (26.11.2000)\n722 Initiative for ‘‘ﬂexible retirement age from 62 years’’ (26.11.2000)\n724 Initiative for ‘‘reduced hospital costs’’ (26.11.2000)\n732 Initiative for ‘‘cheaper drugs’’ (04.03.2001)\n752 Initiative to ‘‘secure pension system – tax energy instead of labour’’\n(02.12.2001)\n762 Reduction of work time (03.03.2002)\n781 Initiative about gold reserves to retirement pension (22.09.2002)\n782 Counter-proposal about gold reserves to retirement pension (22.09.2002)\n792 Law on unemployment insurance: unemployment beneﬁts (24.11.2002)\n802 Participation of cantons in ﬁnancing of hospital treatments (09.02.2003)\n815 Initiative ‘‘health must remain aﬀordable’’ (18.05.2003)\n816 Initiative ‘‘equal rights for disabled people’’ (18.05.2003)\n819 Initiative for ‘‘suﬃcient apprenticeship places’’ (18.05.2003)\n831 11th amendment of pension system: increase of pension age for women\n(16.05.2004)\n832 Financing of retirement pension through VAT increase (16.05.2004)\n844 Maternity insurance (26.09.2004)\n\n41.5\n63.4\n30.3\n39.0\n39.5\n46.0\n17.9\n30.9\n22.9\n25.4\n46.4\n46.4\n56.1\n77.4\n27.1\n37.7\n31.6\n32.1\n31.4\n55.5\n\nSource: Swiss Federal Chancellery.\n\nLionel Marquis received his PhD from the University of Geneva in 2002. Since 2008 he has been a lecturer and\nresearcher in political science at the University of Lausanne. His research interests comprise Swiss foreign and\nsocial policy, political behaviour and political psychology. Address for correspondence: Lionel Marquis, University\nof Lausanne, Institut d’Etudes Politiques, et Internationales, UNIL-Dorigny, Anthropole, 1015 Lausanne.\nPhone: +41 (0)21 692 31 56; Email: lionel.marquis@unil.ch\nHans-Peter Schaub is a PhD student at the University of Berne. He is working on the Swiss National Science Foundation project ‘‘The quality of democracy in the Swiss cantons’’ and writing his doctoral thesis on democracy’s\nquality in cantons with a popular assembly (Landsgemeinde) as compared to cantons with a ballot box system.\nAddress for correspondence: Hans-Peter Schaub, University of Berne, Institut für Politikwissenschaft, Lerchenweg\n36, 3000 Bern 9. Phone: +41 (0)31 631 48 49; Email: hans-peter.schaub@ipw.unibe.ch\nMarlène Gerber is a PhD student at the University of Berne. She is working on a project funded by the Swiss\nNational Science foundation that examines the potential for deliberation among EU-citizens. She writes her\ndoctoral thesis on deliberative quality in a European-wide deliberative poll on immigration. Address for correspondence: Marlène Gerber, University of Berne, Institut für Politikwissenschaft, Lerchenweg 36, 3000 Bern 9. Phone:\n+41 (0)31 631 83 37; Email: marlene.gerber@ipw.unibe.ch\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n</td>
    </tr>
    <tr>
      <th>4</th>
      <td>poli</td>
      <td>A Question of Balance — 1Running head: A QUESTION OF BALANCE A Question of Balance:Are Google News search results politically biased?By Eric UlkenUSC Annenberg School for CommunicationMay 5, 2005 A Question of Balance — 2 AbstractThis study examines search results from the popular online news portal Google News inan effort to determine whether they are politically biased.  By analyzing the content ofthird-party articles returned in a search on a political candidate (“George W. Bush,” forexample), it is possible to assess the level of bias in the search results.  Articles returnedin searches on the two leading presidential candidates in the weeks before the 2004election were collected, and a random sample of the highest-ranking results was analyzedfor favorability to each candidate.  Results from the same searches on Yahoo News wereused as a benchmark for comparison.  The data show that articles returned in GoogleNews searches are significantly more likely to have a political bias than those returned insearches on Yahoo News, but there is no evidence of an overall conservative bias insearch results on Google News, as has been suggested. A Question of Balance — 3 A Question of Balance: Are Google News search results politically biased?As online news has grown in popularity, a number of sites have sprung up tocatalog the wealth of news content available on the Internet. These so-called news portalsinclude Google News, Yahoo News, Topix.net and MSNBC’s Newsbot.  Through anautomated process known as “spidering” or “crawling,” these aggregators index thecontent of selected news sources and allow users to browse and search recent newsstories, usually linking to the source of the article for the full text.Google News, launched in 2001 but still in the “beta-testing” phase, has becomeone of the Internet’s most popular news portals, drawing about 5.9 million visitors amonth (Gaither, 2005). It indexes the top stories on some 4,500 English-language newssites, updating its index roughly every 15 minutes (Google, 2004).  Google’s innovativemethod of identifying top stories based on how frequently they appear on sites in itsindex – and doing so entirely without human intervention – has made the site a target ofcriticism since its inception.  The efficiency with which Google News is able toautomatically determine relative importance of stories and present a “front page” with topstories in different subject areas has been seen by some as the first ominous sign thatcomputers will eventually make human editors obsolete. At the same time, users haveridiculed flaws in Google News’s algorithms that cause it to occasionally attach a photo A Question of Balance — 4to an unrelated article or elevate a relatively minor story to a prominent spot on its frontpage.Google News front page Yahoo News front page Google does not share the list of sources it crawls, but searches often revealresults from relatively obscure online-only news sites – including some that are bestdescribed as weblogs – leading to questions about Google News’s criteria for inclusionand the notion that there might be some political imbalance in the sites it crawls.  Googlehas taken a lot of criticism recently for the quality of news content in its index.  Earlierthis year, it removed from its index several sites, including the white supremacist journalNational Vanguard, after users complained that hate speech was turning up in searches.Practices at Google News have come under additional scrutiny since March, whenAgence France-Presse filed a lawsuit alleging that Google infringed its copyright bydisplaying AFP material on Google News pages.  The Associated Press has alsoexpressed “concern” about Google’s use of its material without payment (Gaither, 2005).Janice Castro, director of graduate programs at Northwestern University’s MedillSchool of Journalism and one of the founders of the Online News Association, toldCNET News.com the problem with Google News is that it gives users no way of A Question of Balance — 5evaluating the quality of news sources (Olsen, 2005).  “The best is mixed up with thingsthat are far from the best,” Castro said.Web journalism pioneer J.D. Lasica was among the first to suggest a conservativebias in Google News (2004).  “What’s going on?” he wrote in an article for OnlineJournalism Review as the 2004 presidential race was heating up.  “Have Google’s searchresults been hijacked by Fox News?”  Lasica cited several stories from “second-tier”online-only news and commentary sites in a search on the words “John Kerry.”  Theheadlines returned included the following: “John Kerry Said ‘Bring It On,’ Now Whines To Bush To Stop The Ads” “The Imploding John Kerry” “Swift Boat Veterans for Truth Expose John Kerry’s Lies” “John Kerry is Definitely ‘Unfit for Command’”Political bias in news coverage has been the topic of numerous academic studies,most of which have themselves been subjected to charges of bias.  Bias is practicallyimpossible to quantify absolutely, but it can be measured in relative terms.  One of themost widely cited and controversial recent studies attempts to do just that.  Grosecloseand Milyo (2003) assess bias among major news outlets – including The New York Times,USA Today and Fox News’ “Special Report” – by looking at how often they cite certainpolitically active “think tanks” and comparing this with how frequently members ofCongress cite the same sources in floor speeches.  The authors’ assumption is thatconservatively biased news organizations, say, will cite a certain think tank with the samefrequency as a conservative member of Congress.  The study’s conclusion is that themainstream media have an overwhelming liberal bias and the most unbiased news source A Question of Balance — 6is Fox News’ “Special Report.”  This finding was met with as much outrage as praisewhen the study first made the rounds of politically oriented weblogs (Dallas, 2004;Tabarrok, 2004) – proof that bias is always relative to the observer.This study attempts to scientifically test Lasica’s casual observation of bias inarticles linked from Google News.  Unlike the Groseclose/Milyo study, it does not havethe benefit of an independent benchmark for comparison.  Instead, it compares GoogleNews with a more established competitor, Yahoo News, in an attempt to determinerelative bias.  The study looks at balance within stories as an indicator of bias.  Abalanced article will presumably have roughly as many favorable references to the searchterm (i.e., the candidate) as it has unfavorable ones.  Given what Lasica and others havereported about Google News search results, the goal of this study is to prove or disprovequantitatively the assertion that Google News displays a conservative bias.The research question and hypothesis are as follows:RQ1: Are Google News search results politically biased?H1: Results of Google News searches on the two major-party presidentialcandidates will reveal a conservative bias.The research hypothesis is tested by means of a quantitative text analysis ofarticles returned in Google News and Yahoo News search results.MethodThis study analyzes articles returned in searches on the full names of the twomajor-party presidential candidates (“George W. Bush” and “John Kerry”) in the weeks A Question of Balance — 7leading up to the 2004 election in order to determine a bias score for each article and,ultimately, to quantify the overall bias of the search results.Data acquisitionSince the news search engines update their indexes frequently over the course of aday, the results for a particular search term can change from one minute to the next.  Adata acquisition scheme was devised that respects the dynamic nature of the searchresults.  A computer program was written to retrieve the first 10 articles returned byGoogle News and Yahoo News for each search term (“George W. Bush” and “JohnKerry”) at four-hour intervals and save them.Google News search results Yahoo News search results The program was run for the period of Oct. 17-30, 2004, the two weeks precedingthe Nov. 2 presidential election, resulting in a total of 80 “snapshots.”  Each snapshotcontained four sets of search results: “George W. Bush” on Google News, “George W.Bush” on Yahoo News, “John Kerry” on Google News and “John Kerry” on YahooNews.  The program also downloaded the full text of the first 10 articles returned in eachresult list. A Question of Balance — 8Sampling schemeTaking the top 10 articles in each list would yield 3,200 texts.  A moremanageable sample of 100 was selected for analysis.  In order to generate arepresentative sample, a two-stage sampling process was devised that divided the datacollection period into five sequential periods of equal length and then randomly selectedone snapshot from each period.  The stratified selection provided for a sample that wasspread fairly evenly over the two weeks, so that a single news event would be unlikely todominate the sample.  The random selection stage ensured that the final five snapshotsrepresented a variety of dayparts and days of the week.The following snapshots were selected: Monday, Oct. 18, 2004, midnight Thursday, Oct. 21, 2004, 8 a.m. Monday, Oct. 25, 2004, midnight Thursday, Oct. 28, 2004, 4 p.m. Saturday, Oct. 30, 2004, 8 a.m.For each snapshot, the first five articles from each of the four result lists wereselected for analysis, ensuring an equal number of Bush and Kerry results and an equalnumber of Google News and Yahoo News results.  In a couple of cases, the complete textof an article was behind a paid subscription wall.  Where possible, a shortened freeversion was used; otherwise the article was skipped and the next highest-ranked articlewas used instead. A Question of Balance — 9Units of observationThe articles were subdivided by sentence – with a sentence representing a singleunit of observation.  The decision was made to use sentences, rather than propositions, asthe units of observation for two reasons: The texts can be parsed into sentences with minimal work, an importantconsideration given the volume of the data. Propositions – that is, groups of words expressing a distinct idea, whether as aphrase, a sentence or multiple sentences – must be manually identified andparsed by coders.  This introduces the problem of unitizing reliability.Because a number of the texts were extremely long, only the first 25 sentences ofeach article were coded.  It was assumed that an article’s overall bias would be apparentwithin the first 25 sentences.  The results section offers data that support this assumption.Overall, 1,587 sentences were coded.Coding schemeEach sentence could be coded in one of five ways:1. Unfavorable to Kerry2. Favorable to Kerry3. Neutral4. Unfavorable to Bush5. Favorable to BushA coding manual was created to guide coders in the process of evaluating units.(See Appendix A for the full coding manual.)  Because the coding scheme involves A Question of Balance — 10assessing latent meanings of sentences – and the terms “favorable” and “unfavorable” areimprecise – the most important purpose of the coding manual is to define these terms andspecify how to apply them.  The basic coding rules used are as follows: A unit (sentence) can only be coded as favorable or unfavorable if it containsan unambiguous message that, taken independently of other units, is favorableto one candidate or the other. Otherwise it must be coded neutral. If a unit contains both favorable and unfavorable references to the samecandidate, or it contains only favorable or unfavorable references to bothcandidates, it should be coded neutral. If a unit contains one or more favorable references to one candidate and one ormore unfavorable references to the other candidate, only the first reference inthe sentence should be considered in coding. If there is uncertainty about how different people might interpret a unit, itshould be coded neutral.For purposes of assessing favorability, direct quotations and other attributedstatements are treated no differently from statements made by the article’s author, sincethe choice of one particular quote over another can also represent bias.  For example, thesentence, “Democrats accused Bush of misleading the nation about the justification forwar in Iraq,” would be coded as unfavorable to the president.The coding scheme attempts to make the rating process as objective as possible.However, coders’ personal biases could affect how they evaluate elements of the texts.While it is true that such coder subjectivity may skew balance scores of individual A Question of Balance — 11articles in one direction or another, it is still possible to compare average scores forGoogle News and Yahoo News and thus assess bias of one site relative to the other.Coding procedureTwo coders were used in this study.  A primary coder – the author of the study –analyzed all 100 texts.  A second coder – also a graduate student in communication withexperience in content analysis – analyzed 28 of the texts, selected at random, for thepurpose of assessing the validity of the coding scheme and the reliability of the primarycoder.  Articles were assigned to coders in random order using a computer-based codingsystem.  The coders had no knowledge of whether a particular article came via GoogleNews or Yahoo News (or which search term returned it).  Coders were given only theheadline and the name of the source organization for each article.  The coders weretrained and the coding scheme was initially tested using sample texts from articles notincluded in the actual sample.In addition to coding each sentence, coders were asked to assess the overallfavorability of the article in the form of two variables, each with five possible values: Overall favorability to Bush: highly favorable, favorable, neutral, unfavorable,highly unfavorable Overall favorability to Kerry: highly favorable, favorable, neutral,unfavorable, highly unfavorableThese overall favorability scores were intended only for the purpose of validatingthe unit-by-unit coding scheme and ultimately were discarded. A Question of Balance — 12Intercoder reliabilityIntercoder reliability is assessed on two levels: by sentence (the unit ofobservation) and by article (the unit of analysis).At the sentence level, Cohen’s kappa, a measure of agreement between coders onnominative variables, is computed as 0.72 – just above the 70% threshold considered anacceptable level of agreement.  When intercoder reliability is tested at the article level,the agreement between the two coders is closer.  Because the favorability scorescomputed for each article are ratio measurements, the two coders’ scores are fit againsteach other, with the r-square statistic used to express intercoder reliability.  Values of r-square for the Kerry favorability and Bush favorability variables are 0.94 and 0.90,respectively – indicating a relatively high level of agreement between the coders.When computing reliability using such a small number of measurements (only 28articles were coded by both coders), a single outlying value can greatly affect theoutcome. It was necessary to omit one such outlier from consideration in computingagreement on the Kerry favorability score. The offending score was for an article thatcontained only one sentence, which one coder deemed favorable to Kerry and the othercoder recorded as neutral. As a result, the article took a Kerry favorability score of 1 fromone coder and 0 from the other. This greatly affected the reliability calculation, causing r-square to plummet to 0.57.  The article was excluded from the data analysis, which iswhy the data show one article fewer for Yahoo News than for Google News.ResultsUsing the values for each sentence, two scores are calculated for each article, A Question of Balance — 13measuring the degree of the article’s overall favorability to each candidate. Bush andKerry favorability scores for each article are computed using the following formula:favorability score = (sum of favorable units) – (sum of unfavorable units)(total units coded)Favorability scores can thus take values of –1 (completely unfavorable) to 1(completely favorable), with 0 being neutral. For instance, a Kerry favorability score of–0.3 for an article would indicate that, on balance, 30% the content of an article isunfavorable to John Kerry (the actual proportion of unfavorable units might be 35% butoffset by 5% of units coded as favorable to Kerry). Because even the most biased articlescontain a lot of neutral (or irrelevant) content, the scores tend be closer to 0 than to eitherextreme.Two scatterplots – one for Google News and the other for Yahoo News – providea basic summary of the data. They show the two candidates’ favorability scores for eacharticle, plotted against each other. This facilitates comparison of the overall favorabilityof the two portals’ search results.Favorability plots by search engine -1-0.75-0.5-0.2500.250.50.751Kerry favorability-1-0.75-0.5-0.250.25.5.751Bush favorabilityGoogle News-1-0.75-0.5-0.2500.250.50.751Kerry favorability-1-0.75-0.5-0.250.25.5.751Bush favorabilityYahoo News A Question of Balance — 14Each data point represents an article, and its placement on the chart represents itsfavorability to the two candidates: Upper left quadrant: Article is favorable to Kerry and unfavorable to Bush Upper right quadrant: Article is favorable to both Lower right quadrant: Article is favorable to Bush and unfavorable to Kerry Lower left quadrant: Article is unfavorable to bothIn other words, articles in the upper right and lower left are more balanced thanthose in the upper left and lower right. Articles closer to the center are more neutral. Thecircular boundary is a density ellipse drawn around 90% of the data points, which makesit easier to see patterns in the data.  One fact that is not apparent in the scatterplots is thata large number of data points are at the coordinates (0, 0).  This is because many of thearticles – 22% for Google News and 45% for Yahoo News – exhibited no bias at all,either because they discussed both candidates with complete neutrality or because theywere not relevant to either candidate.  A glance at the two plots reveals what can be seenempirically in the search results from the two sites:  Articles returned in the searchesusing Google News are more likely to be biased in favor of one candidate and against theother, while those that turn up in the Yahoo News searches are generally more balanced.In order to illustrate article bias in one dimension, a measurement that takes intoaccount favorability ratings for both candidates is needed.  Two related scores are devisedfor this purpose.  The first, the article balance score, shows the degree to which articlesfavor one candidate over the other.  It is computed using a simple formula:balance score = kerry favorability – bush favorability A Question of Balance — 15An article’s balance score takes a value between –1 and 1, with positive numbersindicating greater favorability to Kerry and negative numbers indicating greaterfavorability to Bush.  Articles with balance scores of 0 are equally favorable (orunfavorable) to both candidates.Article balance scores by search engineBalance score-1-0.500.51 GoogleYahooSearch engineBy taking the average balance scores for articles returned by Google News andYahoo News, each search engine’s overall bias can be determined.  A balance score thatfavors Bush is presumed to show a conservative bias, while one that favors Kerry wouldindicate a liberal bias.  The average balance scores for both Google News and YahooNews are not significantly different from 0, indicating an absence of overall bias in thesearch results for both sites.  Thus, while the data do show bias in many of the articlesreturned by Google News, there is no evidence of an overall conservative (or liberal)slant to the site’s search results, as has been alleged.The second measurement, the article bias score, is simply the absolute value ofthe balance score.  It takes a value between 0 and 1 and represents the proportion of anarticle that is biased, regardless of the direction of bias.  For example, an article in which A Question of Balance — 16half the sentences are coded as favorable to Kerry and the other half as unfavorable toBush would have a bias score of 1, meaning 100% of the article is biased.  In fact, biasscores tend to be closer to 0, though one article returned by Google News had a bias scoreof 0.92.  The mean article bias score for each search engine describes the degree to whichthe average article returned by that search engine is likely to be biased.Article bias scores by search engineBias score00.20.40.60.81 GoogleYahooSearch engineAs seen in the plot above, the articles returned by Google News have a highermean bias score than those returned by Yahoo News (0.23 compared with 0.13, astatistically significant difference).  This means that a search on Google News is likely toturn up articles that are more biased than those returned by its competitor.Besides being coded for favorability, articles were also classified by whether theycame from an independent, online-only source (such as Salon.com) or a website affiliatedwith a traditional news source.  A traditional news source is defined as a wire service,newspaper, magazine, TV station, radio station, broadcast network or cable network.(Content from one of these sources that is syndicated on a news aggregator such asYahoo News is also classified as traditional.)  Of the articles returned by Google News,40% were from non-traditional news sources, while only 24% of the Yahoo News results A Question of Balance — 17came from non-traditional sources.  (See Appendix B for a list of the sources of all thearticles coded.)  Notably, almost all of the bias in Google News’s search results can beattributed to its use of non-traditional sources.  In other words, when articles from non-traditional sources are left out of the calculation, the average bias scores for Google Newsand Yahoo News are virtually identical.Finally, articles that exceeded the 25-sentence length limit for coding tended to bescored as slightly more biased than shorter articles, on average.  A possible explanationfor this is that most of the articles from traditional sources – those less likely to exhibitbias – were shorter than 25 sentences.  If this arbitrary limit were hindering the codingscheme’s ability to ascertain bias in longer texts, one would expect to find a loweraverage bias score for longer articles.DiscussionThe data show that articles returned in Google News searches are more likely tohave a bias toward a particular candidate than those returned in searches on Yahoo News,but there is no evidence of an overall conservative bias in search results on Google News,as has been suggested.  Both Google News and Yahoo News searches returned articlesthat were, on the whole, equally favorable to both George W. Bush and John Kerry.  Thisis what one would expect to see of balanced search results at a time when public opinionis evenly divided between the two candidates.Accordingly, the research hypothesis, H1, is rejected.For both candidates, a slight tendency toward negativism (that is, moreunfavorable content than favorable) can be seen in articles returned by the two news A Question of Balance — 18portals. This can be explained in two ways: By the time the data were collected – in the two weeks before the 2004general election – the race for the presidency had turned increasingly negative. The news media by their nature generally place greater emphasis on negativestories than positive ones.With the abundance of well-respected, credible sources on the Internet, why doesGoogle News return so many articles from biased sources?  An explanation offered byNathan Stoll, Google’s associate product manager for Google News, has to do with thesearch terms themselves (2004):  A search for “John Kerry” will first return entries inwhich the entire search term appears in the headline.  Even though Google Newsexamines the full text of articles when looking for a search term, it puts extra weight onthe headline when it ranks the results.  So, stories with headlines such as “John Kerry liesabout his record” will receive a higher rank than stories with headlines such as “Kerrycampaigns in Ohio” (omitting his first name).  Traditional media – which tend to be lessbiased than many alternative, online-only news sources – generally identify people inheadlines by their last names only.  As a result, articles from these news organizationsmay often be outranked in Google News search results by those from sites that do notfollow this practice.  Given this peculiarity, the use of full names in the searches analyzedhere could be seen as a weakness in the study, but in fact it emulates the behavior of anaverage user.  Unaware of the distinction, a user presumably is more likely to search for afull name than just a last name, resulting in a disproportionate number of results fromnon-traditional news sources.  Searches on Yahoo News do not appear to exhibit thistendency as frequently. A Question of Balance — 19It is important to understand that this study is not an indictment of Google News’spractice of automatically ranking the top stories on its front page and section fronts.While Google News’s ranking methods may be flawed, as some have charged, this studyis concerned only with the site’s search results.  It should also be noted that Google Newsdoes not distinguish between factual and opinion pieces in its search results (Stoll, 2004).Thus, an editorial may appear along with straight-news stories, even though the formerrepresents a particular point of view while the latter are supposed to be reasonablybalanced recitations of fact.  It is not clear that average users can make the distinction,especially given the many online-only sources that often peddle a confusing mixture offact and opinion.  Accordingly, this study makes no attempt to separate news fromeditorial content.The main flaws in the study are with the coding scheme.  Better coder training, amore detailed coding manual and a more precise definition of “favorability” wouldalmost certainly have improved intercoder reliability, which, while not low enough to callinto question the results, is below expectations.  Additionally, using sentences as units ofobservation makes for some ambiguity in the coding process.  If one sentence containsmultiple distinct propositions, or a single proposition stretches across multiple sentences,some of this granularity is lost in the current coding method.If users are looking for current factual information about a political candidate, thisstudy concludes that they are more likely to find it by searching Yahoo News.  If, on theother hand, users want a wide range of alternative viewpoints, then Google News may betheir best bet. A Question of Balance — 20ReferencesDallas, Jim. (2004) “From the Department of ‘Huh?’” Burnt Orange Report [weblog].Retrieved April 12, 2005, fromhttp://www.burntorangereport.com/archives/001234.htmlGaither, Chris. (2005, April 11). “Web Giants Go With Different Angles in Competitionfor News Audience.” Los Angeles Times, p. C-1.Google. (2004). About Google News. Retrieved Dec. 9, 2004, fromhttp://news.google.com/intl/en_us/about_google_news.htmlGroseclose, Tim, and Milyo, Jeff. (2003). A Measure of Media Bias [working paper].Retrieved Dec. 9, 2004, fromhttp://www.stanford.edu/~wacziarg/mediapapers/GrosecloseMilyo.pdfKrippendorff, Klaus. (1980). Content analysis: An Introduction to its Methodology.Beverly Hills, CA: Sage.Lasica, J.D. (2004, Sept. 24). Balancing act: how news portals serve up political stories.Online Journalism Review. Retrieved Dec. 9, 2004, fromhttp://ojr.org/ojr/technology/1095977436.phpLee, Martin A., and Solomon, Norman. (1990). Unreliable Sources: A Guide to DetectingBias in News Media. New York: Carol Publishing.Olsen, Stefanie, and Hansen, Evan. (2005, March 25). “All the news that robots pick.”CNET News.com. Retrieved April 28, 2005, from http://news.com.com/2100-1038_3-5635161.htmlStoll, Nathan. (2004, Nov. 13). [personal communication with Google News associateproduct manager]Tabarrok, Alex. (2004). “Surprise! Fox News Is Fair and Balanced!” MarginalRevolution [weblog]. Retrieved April 12, 2005, fromhttp://www.marginalrevolution.com/marginalrevolution/2003/09/surprise_fox_is.htmlWeber, Robert Philip. (1990). Basic Content Analysis. Newbury Park, CA: Sage. A Question of Balance — 21Appendix A: Coding instructionsProcedureWhen you are assigned an article to code, you will evaluate it in two ways: unit-by-unit and overall. The units of observation are sentences. When you code unit-by-unit,you must consider only the individual unit you are coding. When you code the articleoverall, you can consider aspects of the article, such as the headline, that can't be takeninto account in a unit-by-unit analysis. If there are any technical or proceduralirregularities in the coding, please make a note of it in the comments field.When you have completed the coding process for an article, double-check yourresponse (since you can't go back) and hit the "Submit responses" button. Your responseswill be recorded, and you'll be given the opportunity to continue on to another article.GuidelinesWe are looking for favorable and unfavorable references to John Kerry in theresults of a search on his name, and the same for George W. Bush. You will be codingthe text of articles returned in search queries Yahoo News and Google News.To keep coders from spending an inordinate amount of time on any one story,stories longer than 25 units (sentences) will be truncated. Most stories are shorter thanthis anyway.Here are the basic rules for coding individual units: A Question of Balance — 22 A unit can only be coded as favorable or unfavorable if it contains anunambiguous message that, taken independently of other units, is favorable toone candidate or the other. Otherwise it must be coded neutral. If a unit contains both favorable and unfavorable references to the samecandidate, or it contains only favorable or unfavorable references to bothcandidates, it should be coded neutral. If a unit contains one or more favorable references to one candidate and one ormore unfavorable references to the other candidate, only the first reference inthe sentence should be considered in coding. If there is uncertainty about how different people might interpret a unit, itshould be coded neutral.On the coding form, mark each sentence as favorable to Bush, favorable to Kerry,unfavorable to Bush, unfavorable to Kerry or neutral. Please observe the followingdefinitions when considering what are favorable and unfavorable references.The following may be considered favorable or unfavorable references: Direct references to the candidate (by name or other obvious identifier -- e.g.,"my opponent", "the senator") Quotes from candidates (or their surrogates) about themselves or each other References to actions or statements by the Bush or Kerry campaigns News directly related to candidates' issues or policies where it is clear that thenews is damaging or helpful to a particular candidate The following should be left marked as "netural": A Question of Balance — 23 Mentions of the actions of parties, aides, colleagues, etc., unless they aredirectly related to the campaign General ideological assertions and political observations that are subjectiveand can't be considered positive or negative for either candidate (e.g., "biggovernment is bad" or "social security is broken") Any citation of poll results (since it is difficult to weight poll results fairly) Any mention that cannot be clearly determined to be favorable or unfavorableto a particular candidateWhat constitutes favorable and unfavorable? If a reference cannot be clearly construed as favorable or unfavorable (e.g.,"John Kerry has a rich wife" could be interpreted either way), it should beignored Instances where a favorable adjective is used to describe a neutral orunfavorable action (e.g., "...efficient in his criticism of Bush") do not count asa favorable mention. Same with unfavorable adjectives. Historical references can be coded as favorable or unfavorable only if there isa clear relationship to the candidate and it can be clearly discerned as beingfavorable or unfavorable (e.g., "Truman didn't apologize for war mistakes, soBush shouldn't have to either" could be coded as favorable to Bush) If a candidate's actual or alleged associate or ally is portrayed negatively (orpositively), the ally's relationship to the candidate counts as a singleunfavorable (favorable) reference. (e.g., "Arafat is a murderer. Arafat is a A Question of Balance — 24thug. Arafat is derailing the peace process. Arafat endorses Kerry." Only thelast sentence is coded as unfavorable to Kerry.) A Question of Balance — 25Appendix B: Sources of articles returnedYahoo News returned more articles from traditional media sources (in boldface)than Google News did.  A traditional news source is defined as a wire service,newspaper, magazine, TV station, radio station, broadcast network or cable network,accessed either directly or through a news aggregator.Google NewsVOANewstruthoutChicago MaroonFt. Worth Star-TelegramDaytona Beach News-JournalNME.comUselessKnowledge.comUnconfirmedSources.comThe Jewish PressPRNewswireAxisofLogicThe (Carlisle, Pa.) SentinelSioux Falls Argus Leader quoted on Lucianne.comBiloxi (Miss.) Sun-HeraldDenver Post quoted on Lucianne.comBloombergCBC News (Canada)VOANewsJerusalem PostInternational Herald TribuneNew York PostUselessKnowledge.comXinhuaAP via San Jose Mercury NewsAP via Duluth News TribuneSalon.comBloombergThe AustralianINDOlinkLawrence (Kan.) Journal-WorldCNNAP via canada.comBusiness-Standard.com (India)MichNews.comRushLimbaugh.comTVM (Maldives) via MaldivesInfoPRNewswire via Yahoo NewsMichNews.comwestcoastmusicReadaBet.comThisDay (Nigeria) via AllAfrica.comAP via Canada.comThe Washington DispatchRushLimbaugh.comUselessKnowledge.coms5000.comWashington Times via The Conservative VoiceTVM (Maldives) via MaldivesInfoScranton (Pa.) Times TribuneAP via WHEC-TV (Rochester, N.Y.)(60% traditional media sources)Yahoo NewsChannelNewsAsia.comTheWGALChannel.com (Harrisburg, Pa.)Whitehouse.govTheWGALChannel.com (Harrisburg, Pa.)APPRNewswire via Yahoo NewsPRNewswireWhitehouse.govWhitehouse.govGuardian Unlimited (U.K.)The Southern IllinoisanAP via Daily Herald (Arlington Heights, Ill.)The Smoking GunAFP via Yahoo NewsWhitehouse.govBloombergAFPWCPO.com (Cincinnati)New Zealand HeraldAPAP via Yahoo NewsWPXI.com (Pittsburgh)AP via Duluth News TribuneIndia DailyAFP via Yahoo NewsBloombergINDOlinkKnight RidderBloombergReuters via Australian Broadcasting Corp.AP via Canada.comWhiteHouse.govWorldNetDaily.comWhitehouse.govAP via PhillyBurbs.com (N.J.)PRNewswire via Yahoo NewsKyodo News via Yahoo AsiaAP via WNEP-TV (Scranton, Pa.)AP via Canada.comKYW Newsradio 1060 (Philadelphia)The (Youngstown, Ohio) VindicatorThe Times of IndiaAP via Canada.comIndieWireIndia OnlineAP via WHEC-TV (Rochester, N.Y.)AFP via Khaleej Times (U.A.E.)Editor and Publisher via Yahoo NewsAP via Yahoo News(76% traditional media sources)</td>
    </tr>
    <tr>
      <th>53</th>
      <td>news</td>
      <td>Building User Trust in Recommendations\nvia Fairness and Explanations\nDimitris Sacharidis\n\nE-Commerce Research Unit\nTU Wien\nVienna, Austria\ndimitris@ec.tuwien.ac.at\n\nABSTRACT\nModern Artificial Intelligence (AI) techniques, based on the statistical analysis of big volumes of data, are quickly gaining traction\nacross various domains. Recommender Systems are a class of AI\ntechniques that extract preference patterns from large traces of\nhuman behavior. Recommenders assist people in taking decisions\nthat range from harmless everyday life dilemmas, e.g., what shoes\nto buy, to seemingly innocuous choices but with long-term, hidden\nconsequences, e.g., what news article to read, up to more critical\ndecisions, e.g., which person to hire.\nAs more and more aspects of our everyday lives are influenced\nby automated decisions made by recommender systems, it becomes\nnatural to question whether these systems are trustworthy, particularly given the opaqueness and complexity of their internal\nworkings. These questions are timely posed in the broader context\nof concerns regarding the societal and ethical implications of applying AI techniques, which have also brought about new regulations,\nlike the EU’s “Right to Explanation” [2].\nIn this talk, we discuss techniques for increasing the user’s trust\nin the decisions of a recommender system, focusing on fairness aspects and explanation approaches. On the one hand, fairness means\nthat the system exhibits certain desirable ethical traits, such as\nbeing non-discriminatory, diversity-aware, and bias-free. On the\nother hand, explanations provide human-understandable interpretations of the inner working of the system. Both mechanisms can\nbe used in tandem to promote trust in the system. In addition, we\ninvestigate user trust from the standpoint of different stakeholders\nthat potentially have varying levels of technical background and\ndiverse needs.\nThe concept of fairness in AI techniques can be operationalized\nin various forms [3]. As this research field is still in its early stages,\nit lacks clarity and consistency, with each work introducing a new\ndefinition of fairness. This talk attempts to categorize fairness concerns that may lead to low trust in recommender systems. We start\nwith the observation that fairness means a lack of discrimination\nwhen allocating some sensitive resource. In the context of recommender systems, we distinguish between two resources: accuracy\nand presentation. In the former, as in [8], the concern is about the\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nUMAP ’20 Adjunct, July 14–17, 2020, Genoa, Italy\n© 2020 Copyright held by the owner/author(s).\nACM ISBN 978-1-4503-7950-2/20/07.\nhttps://doi.org/10.1145/3386392.3399995\n\nrelevance of the recommendations, or equivalently about how the\nsystem treats the various stakeholders. In the latter, as in [5], the\nconcern is about the effects of making recommendations, or equivalently about how the system impacts the various stakeholders. In\nrecommender systems, stakeholders are the consumers of recommendations, the providers of the objects of recommendations, and\nthe owners of the system [1].\nExplanations seek to make AI systems more trustworthy. For recommender systems, the most common purposes of an explanation\nare: to show how the system works (transparency); to help users\nmake good decisions (effectiveness); to increase trust in the system;\nto convince users (persuasiveness); to increase users’ perceived satisfaction; to enable users to tell the system it is wrong (scrutability)\n[6]. Modern recommenders are based on model-based collaborative\ntechniques, such as matrix factorization and deep neural networks,\nthat have a large number of parameters not directly interpretable.\nTherefore, it is necessary to employ black box techniques to provide\nplausible interpretations to recommender outputs. One relevant line\nof research is on proxy models that approximate system decisions\nwith a simpler interpretable model, as in [4]. Another direction\nis counterfactual explanations that present examples where the\nopposite decision would be observed [7].\nWe highlight two shortcomings of existing work on recommendation explanations. First, they consider a single stakeholder, the\nconsumer of recommendations, and are not suitable for building\ntrust of multiple stakeholders with different concerns. Second, they\nseek to explain a single recommendation at a time, rather that\nobserving and explaining the long-term behavior of system.\n\nCCS CONCEPTS\n• Information systems → Recommender systems.\n\nKEYWORDS\nRecommender Systems; User Trust; Fairness; Explanations\nACM Reference Format:\nDimitris Sacharidis. 2020. Building User Trust in Recommendations via\nFairness and Explanations. In Adjunct Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization (UMAP ’20 Adjunct), July 14–17, 2020, Genoa, Italy. ACM, New York, NY, USA, 2 pages.\nhttps://doi.org/10.1145/3386392.3399995\n\nBIOGRAPHY\n\nREFERENCES\n\nDimitris Sacharidis is with the\nE-Commerce Research Unit of\nTU Wien, Austria. Prior to that,\nhe was a junior researcher at\n“Athena” Research Center, Greece,\nand a postdoc at the Hong Kong\nUniversity of Science and Technology supported by a Marie\nSkłodowska-Curie individual fellowship. His research interests include topics related to data science, data management, data mining, and recommender systems.\n\n[1] Robin Burke. 2017. Multisided Fairness for Recommendation. CoRR abs/1707.00093\n(2017).\n[2] Bryce Goodman and Seth R. Flaxman. 2017. European Union Regulations on\nAlgorithmic Decision-Making and a "Right to Explanation". AI Magazine 38, 3\n(2017), 50–57.\n[3] Arvind Narayanan. 2018. Translation tutorial: 21 fairness definitions and their\npolitics. In Proc. Conf. Fairness Accountability Transp., New York, USA.\n[4] Marco Túlio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. "Why Should I\nTrust You?": Explaining the Predictions of Any Classifier. In KDD.\n[5] Ashudeep Singh and Thorsten Joachims. 2018. Fairness of Exposure in Rankings.\nIn KDD. ACM, 2219–2228. https://doi.org/10.1145/3219819.3220088\n[6] Nava Tintarev and Judith Masthoff. 2007. A Survey of Explanations in Recommender Systems. In ICDEW.\n[7] Sandra Wachter, Brent D. Mittelstadt, and Chris Russell. 2017. Counterfactual\nExplanations without Opening the Black Box: Automated Decisions and the GDPR.\nCoRR abs/1711.00399 (2017).\n[8] Sirui Yao and Bert Huang. 2017. Beyond Parity: Fairness Objectives for Collaborative Filtering. In NIPS. 2925–2934.\n\n</td>
    </tr>
    <tr>
      <th>13</th>
      <td>poli</td>
      <td>royalsocietypublishing.org/journal/rsif Research Cite this article: Coscia M, Rossi L. 2020 Distortions of political bias in crowdsourcedmisinformation flagging. J. R. Soc. Interface 17: 20200020.http://dx.doi.org/10.1098/rsif.2020.0020 Received: 8 January 2020 Accepted: 13 May 2020 Subject Category: Life Sciences –Mathematics interface Subject Areas: computational biology, biotechnology Keywords: social media, social networks, content policing,flagging, fake news, echo chambers Author for correspondence: Michele Cosciae-mail: mcos@itu.dkDistortions of political bias in crowdsourced misinformation flagging Michele Coscia and Luca Rossi IT University of Copenhagen, Kobenhavn, Denmark MC, 0000-0001-5984-5137; LR, 0000-0002-3629-2039 Many people view news on social media, yet the production of news items online has come under fire because of the common spreading of misinforma- tion. Social media platforms police their content in various ways. Primarily they rely on crowdsourced ‘flags ’: users signal to the platform that a specific news item might be misleading and, if they raise enough of them, the item will be fact-checked. However, real-world data show that the most flagged news sources are also the most popular and —supposedly —reliable ones. In this paper, we show that this phenomenon can be explained by the unrea- sonable assumptions that current content policing strategies make about how the online social media environment is shaped. The most realistic assumptionis that confirmation bias will prevent a user from flagging a news item if they share the same political bias as the news source producing it. We show, via agent-based simulations, that a model reproducing our current understandingof the social media environment will necessarily result in the most neutral and accurate sources receiving most flags. 1. Introduction Social media have a central role to play in the dissemination of news [1]. There is a general concern about the low quality and reliability of information viewed online:researchers have dedicated increasing amounts of attention to the problem of so- called fake news [2 –4]. Given the current ecosystem of news consumption and pro- duction, misinformation should be understood within the complex set of social andtechnical phenomena underlying online news propagation, such as echo chambers [5–10], platform-induced polarization [11,12] and selective exposure [13,14]. Over the years two main approaches have emerged to try to address the problem of fake news by limiting its circulation: a technical approach and an expert-based approach. The technical approach aims at building predictive models able to detect misinformation [15,16]. This is often done using one ormore features associated with the message, such as content (through natural language processing (NLP) approaches [17]), source reliability [18] or network structure [19]. While these approaches have often produced promising results,the limited availability of training data as well as the unavoidable subjectivity involved in labelling a news item as fake [20,21] constitute a major obstacle to wider development. The alternative expert-based approach consists of a fact-checker on the specific topic that investigates and evaluates each claim. While this could be the most accurate way to deal with misinformation, given the amount ofnews that circulates on social media every second, it is hard to imagine how this could scale to the point of being effective. For this reason, the dominant approach, which has recently also been adopted by Facebook, 1is based on a combination of methods that first use computationally detected crowd signals, often constituted by users flagging what they consider fake or misleading infor- mation, and then assigning selected news items to external professional fact-checkers for further investigation [22,23]. Although flagging-based systems remain, to the best of our knowledge, widely used, many authors have ques- tioned their reliability, showing how users can flag news items for reasons © 2020 The Authors. Published by the Royal Society under the terms of the Creative Commons AttributionLicense http:/ /creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the originalauthor and source are credited.  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  other than the ones intended [24,25]. Recently, researchers proposed methods to identify reliable users and improve, in that way, the quality of the crowd signal [20,23]. Regardless of the ongoing efforts, fake news and mislead- ing information still pollute online communications and no immediate solution seems to be available. In 2018, Facebook released, through the Social Science One initiative, theFacebook URL Shares dataset [26], a preview of the larger dataset released recently. 2The dataset contains the web page addresses (URLs) shared by at least 20 unique accountson Facebook between January 2017 and June 2018. Together with the URLs, the dataset also details whether the specific link had been sent to the third-party fact-checkers thatcollaborate with Facebook. We accessed the most shared links in the Italian subset, which revealed some curious patterns and inspired the pre-sent work. We exclusively use this dataset for the motivation and validation of our analysis, leaving the use of the newer full dataset for future work. Table 1 shows the top 10 most reported domains, which are exclusively major national newspapers, news sites and a satirical website. A further analysis of the data reveals, as figure 1 shows,a positive correlation ( y¼ bxafit, with slope α= 0.2, scale β= 1.22 and p&lt; 0.0013) between a source ’sp o p u l a r i t ya n dt h e number of times a domain has been checked by Facebook ’s third-party fact-checkers. We measure the popularity of the source through Alexa ’s (https://www.alexa.com) page views per million users (PVPM). It is worth observing that all the news reported in the top 10 most reported domains have been fact-checked astrue legitimate news (with the obvious exception of the satirical website, which was fact-checked as satire).These observations create the background for the present paper. Our hypothesis is that users are polarized and that polarization is an important driver of the decision of whetherto flag or not a news item: a user will only flag it if it is not perceived truthful enough andif it has a significantly differ- ent bias from that of the user (polarity). Sharing the samebias would act against the user ’s flagging action. Thus, we introduce a model of online news flagging that we call the ‘bipolar ’model, since we assume for simplicity that there are only two poles —roughly corresponding to ‘liberal ’and ‘conservative ’in the US political system. The bipolar model of news-flagging attempts to capture the main ingredients thatwe observe in empirical research on fake news and disinforma- tion—echo chambers, confirmation bias, platform-induced polarization and selective exposure. We show how the proposedmodel provides a reasonable explanation of the patterns that we observe in Facebook data. The current crowdsourced flagging systems seem to assume a simpler flag-generating model. Despite being some- how similar to the bipolar model we propose, in this simple case the model does not account for users ’polarization, thus we will call it the ‘monopolar ’model. In the monopolar model, users do not gravitate around two poles and perceived truthfulness constitutes the only parameter. Users flagnews items only if they perceive an excessive ‘fakeness ’of the news item, depending of their degree of scepticism. We show how the monopolar model relies on unrealistic expectationsand that it is unable to reproduce the observed flag-generating patterns. Lastly, we test the robustness of the bipolar model against various configurations of the underlying network structure and the actors ’behaviour. We show, on the one hand, how the model is always able to explain the observed flaggingphenomenon and, on the other hand, that a complex social network structure is a core element of the system. 2. Methods In this section, we present the main model on which we base the results of this paper. It is possible to understand the bipolar andmonopolar models as a single model with or without users ’ polarization. However, a user ’s polarization has a significant impact on the results, and it seriously affects the social networkunderlying the flagging and propagation processes. For theseTable 1. The top 10 most ﬂagged domains among the Italian links shared on the Facebook URL Shares dataset. domain reported PVPM type 1 repubblica.it 270.00 54.00 national newspaper 2 ilfattoquotidiano.it 85.00 21.00 national newspaper 3 corriere.it 83.00 30.00 national newspaper 4 fanpage.it 49.00 5.00 national news site 5 ansa.it 47.00 12.00 national news site 6 huf ﬁngtonpost.it 40.00 7.20 national news site 7 ilmessaggero.it 34.00 2.00 national newspaper 8 ilsole24ore.com 32.00 4.00 national newspaper 9 lercio.it 29.00 3.00 satire10 tgcom24.mediaset.it 28.00 28.00 national news site110102103 10–210–11 10 102no. flags PVPM Figure 1. The relationship between the web traffic of a website ( x-axis) and the number of flags it received on Facebook ( y-axis). Traffic is expressed in PPVM, which indicates what fraction of all the page views by Alexa toolbar users go to a particular site.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000202  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  reasons, in the paper, we will refer to them as two different models with two different names, which makes the comparisoneasier to grasp. In the following, we start by giving a general overview of the bipolar model (§2.1). In the subsequent sections, we provide themodel details, motivating each choice on the basis of real-worlddata. We conclude by showing the crucial differences betweenthe bipolar and monopolar models (§2.5). We note that our model shares some commonalities with the bounded confidence model [27]. 2.1. Model overview Figure 2 shows a general depiction of the bipolar model. In the bipo-lar model, we have two kinds of agents: news sources and users. News sources are characterized by three values: popularity, polarity and truthfulness. The popularity distributes broadly:there are a few big players with a large following while themajority of sources are followed by only a few users. The polaritydistributes quasi-normally. Most sources are neutral and there areprogressively fewer and fewer sources that are more polarized.Truthfulness is linked to polarity, with more polarized sourcestending to be less truthful. This implies that most news sourcesare truthful, and less trustworthy sources are more and morerare. Each news item has the same polarity and truthfulnessvalues as the news source publishing it. Users only have polarity. The polarity of the users distributes in the same way as that of the news sources. Most users aremoderate and extremists are progressively more rare. Usersfollow news sources, preferentially those of similar polarity(selective exposure). Users embed in a social network, preferen- tially being friends of other users of similar polarity (homophily). A user can see a news item if the item is either published by a source the user is following or reshared by one of their friends. Ineither case, the user can do one of three things: 1. reshare —if the polarity of the item is sufficiently close to their own andthe item is sufficiently truthful; 2. flag —if the polarity of the item is sufficiently different from their own orthe item is not truthful enough; 3. consume —in all other cases, meaning that the item does not propagate and nor is it flagged. We expect the bipolar model to produce mostly flags in the moderate and truthful part of the spectrum. We base this expec-tation on the following reasoning. Since most news sources aremoderate and truthful, the few very popular sources are over- whelmingly more likely to be moderate and truthful. Thus wewill see more moderate and truthful news items, which aremore likely to be reshared. This resharing activity will causethe news items published by the moderate and truthful newssources to be shared to the polarized parts of the network.Here, given that the difference between the polarization of theuser and the polarization of the source plays a role in flaggingeven relatively truthful items, moderate and truthful newsitems are likely to be flagged. Polarized and untruthful items, on the other hand, are unli- kely to be reshared. Because of the polarization homophily thatcharacterizes the network structure, they are unlikely to reachthe more moderate parts of the network. If polarized itemsare not shared, they cannot be flagged. A neutral item is morelikely to be shared, and thus could reach a polarized user, whowould flag it. Thus, most flags will hit moderate and truthfulnews items, rendering the whole flagging mechanism unsuitablefor discovering untruthful items. 2.2. Agents In this section, we detail how we build the main agents in ourmodel: the news sources and the users. As mentioned previously, news sources have a certain popu- larity. The popularity of a news source is the number of usersfollowing it. We generate the source popularity distribution asa power law. This means that the vast majority of news sourceshave a single follower, while the most popular sources have thousands of followers. This is supported by real-world data. Figure 3 ashows the complement cumulative distribution of the number of followersof Facebook pages. These data come from CrowdTangle. 4As we can see, the distribution has a long tail: two out of three Face-book pages have 10 000 followers or fewer. The most popularpages are followed by more than 60 million users. As for the user and source polarities ( p uand pi), we assume that they distribute quasi-normally. We create a normal distributionwith average equal to zero and standard deviation equal to 1.Then we divide it by its maximum absolute value to ensure thatthe distribution fully lies between −1 and 1. In this way we ensure that most users are moderates; more extreme users/sourcesare progressively more rare, at both ends of the spectrum. This is also supported by the literature [28] and by real-world data. Figure 3 bshows the distribution of political leaning in the USA across time [29], collected online. 5These data were collectedsourcespopularity polarity truth userspolarit ypublish reshare degreefrom friend flagfi,u =ti |pi – pu| consumefi,u = 1 –fi,u fi,u + 1 fi,u &lt; r fi,u &gt; f Figure 2. The overview of the bipolar model. From left to right, we show: the characteristics of the agents (source ’s polarities, popularity and truthfulness; and user ’s polarity); the model ’s structures (the bipartite source –user follower network and the unipartite user –user social network); and the agents ’actions (source publishing and users resharing, consuming and flagging news items).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000203  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  by surveying a representative sample of the US electorate via phone and face-to-face interviews. While not perfectly normally distributed, the data show that the majority of Americans either feel they are moderate or do notknow to which side they lean. ‘Moderate ’or‘don’t know ’is always the mode of the distribution, and their combinationis always the plurality option. Finally, sources have a degree of truthfulness t i. Here, we make the assumption that this is correlated with the newssource ’s polarity. The more a source is polarized, the less it is interested in the actual truth. A polarized source wants tobring readers onto their side, and their ideology clouds theirbest judgement of truthfulness. This reasonable assumption isalso supported by the literature [30]. Mathematically , this means that t i=1−|pi|+ϵ, with −0.05≤ ϵ≤0.05 being extracted uniformly at random, ensuring then that ti remains between 0 and 1 by capping it to these values. 2.3. Structures There are two structures in the model: the user –source bipartite network and the user –user social network. 2.3.1. User –source network The user –source network connects users to the news sources they are following. This is the primary channel through which usersare exposed to news items. We fix the degree distribution of the sources to be a power law, as we detailed in the previous section. The degree distribution ofthe user depends on the other rules of the model. There is a certainnumber of users with degree zero in this network. These users donot follow any news source and only react to what is shared bytheir circle of friends. We think this is reasonably realistic. We connect users to sources to maximize polarity homophily. The assumption is that users will follow news organizationssharing their polarity. This assumption is supported by theliterature [31,32]. For each source with a given polarity and popularity, we pick the required number of individuals with polarity values in aninterval around the source polarity. For instance, if a sourcehas popularity of 24 and polarity of 0.5, we will pick the 24users whose polarity is closest to 0.5 and we will connect themto the source. 2.3.2. Social network Users connect to each other in a social network. The social net-work is the channel through which users are exposed to newsitems from sources they are not following.We aim at creating a social network with realistic character- istics. For this reason, we generate it via an Lancichinetti – Fortunato –Radicchi (LFR) benchmark 6[33]. The LFR benchmark ensures that the social network has a community structure, abroad degree distribution, and communities are overlapping,i.e. they can share nodes. All these characteristics are typical ofreal-world social networks. We fix the number of nodes to≈16 000, while the number of communities is variable and not fixed by the LFR ’s parameters. We need an additional feature in the social network: polarity homophily. People are more likely to be friends with like-mindedindividuals. This is supported by studies of politics on socialmedia [34]. We ensure homophily by iterating over all communitiesgenerated by the LFR benchmark and assigning to users grouped inthe same community a portion of the polarity distribution. For instance, if a community includes 12 nodes, we take 12 con- secutive values in the polarity distribution and we assign themto the users. This procedure generates extremely high polarityassortativity. The Pearson correlation of the polarity values at thetwo endpoints of each edge is ≈0.89. 2.4. Actions A news source publishes to all the users following it an item i carrying the source ’s polarity piand truthfulness ti. Every time a user sees an item i, it calculates how acceptable the item is, using the function fi,u. An item is acceptable if it is (i) truthful and (ii) it is not far from the user in the polarity spectrum — experiments [35] show how this is a reasonable mechanics:users tend to trust more sources with a similar polarity to theirown. Mathematically, (i) means that f i,uis directly proportional toti; while (ii) means that fi,uis inversely proportional to the difference between piand pu fi,u¼ti jpi/C0puj: The acceptability function fi,uhas two issues: first, its domain spans from 0 (if ti=0 )t o+ ∞(ifpi=pu). This can be solved by the standard transformation x/(x+ 1), which is always between 0 and 1 if x≥0. Second, for the discussion of our parameters and results, it is more convenient to estimate a degree of ‘unacceptability ’, which is the opposite of the acceptability fi,u. This can be achieved by the standard transformation 1 −x. Putting the two transformations together, the unacceptability fi,uof item ifor user uis fi,u¼1/C0fi,u fi,uþ1:10–410–310–210–11 1 10 102103p (followers ≥ x) followers (×10 k)0100200300400500600700 EL L SL M DK SC C ECcount polarit y(b)(a) Figure 3. (a) The cumulative distribution of source popularity on Facebook in our dataset: the probability ( y-axis) of a page to have a given number of followers or more ( x-axis). ( b) The polarity distribution in the USA from 1994 (light) to 2016 (dark). Biannual observation, except for missing years 2006, 2010 and 2014. EL, extremely liberal; L, liberal; SL, slightly liberal; M, moderate; DK, don ’t know; SC, slightly conservative; C, conservative; EC, extremely conservative.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000204  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  Users have a finite tolerance for how unacceptable a news item can be. If the item exceeds this threshold, meaning fi,u.f, the user will flag the item. On the other hand, if the news item has low to zero unacceptability, meaning fi,u,r, the user will reshare it to their friends. If r/C20fi,u/C20f, the user will neither flag nor reshare the item. The parameters ϕand ρregulate which and how many news items are flagged, and thus we need to tune them to generaterealistic results —as we do in the Results section. 2.5. Monopolar model The monopolar model is the result of removing everything related to polarity from the bipolar model. The sharing and flag-ging criteria are the same as in the bipolar model —testing fi,u against the ρand ϕparameters, with the difference being in how fi,uis calculated. The unacceptability of a news item is now simply the opposite of its truthfulness, i.e. fi,u¼1/C0ti. Moreover, in the monopolar model users connect to random news sources and there is no polarity homophily in thesocial network. The monopolar model attempts to reproduce the assumption of real-world crowdsourced flagging systems: only the least truthfularticles are flagged. However, we argue that it is not a good rep-resentation of reality because truthfulness assessment is not anobjective process: it is a subjective judgement and it includes pre-existing polarization of both sources and users. The bipolar modelcan capture such polarization while the monopolar model cannot. 2.6. Example To understand what happens in the bipolar and monopolarmodels, consider figure 4 as a toy example. Table 2 a,bcalculates fi,ufor all user –source pairs in the bipolar and monopolar models, respectively. Table 3 a,bcounts the number of flags received by each source for different combinations of the ρand ϕparameters in the bipolar and monopolar models, respectively. A few interesting differences between the bipolar and monopolarmodels appear. In the monopolar model, only the direct audience of a source can flag its news items and, if one member of the direct audienceflags, so will all of them. This is because fi,uis equal for all nodes, thus either fi,u.fand the entire audience will flag the item (and no one will reshare it) or fi,u,rand the entire network —not just the audience —will reshare the item, and no one will ever flag it. This is not true for the bipolar model. S1 (figure 4) can be either flagged by its entire audience ( ϕ= 0.14); by part of its audi- ence ( ϕ= 0.3); or by nodes who are not in its audience at all (users U5 and U6 for ϕ= 0.44; or user U7 for ϕ= 0.6). On the other hand, in our examples, S2 is never flagged by its audience (U7). WhenS2 is flagged, it is always because it percolated to a user for which fi,u.f, via a chain of users for which fi,u,r, because fi,uis not constant across users any longer. 3. Results 3.1. Parameter tuning Before looking at the results of the model, we need to identify the range of parameter values that can support robust andU5S2 S1 U3 U1 U7 U2 U4 U6pi = 0.5 ti = 0.55 pu = 0.8 pu = 0.6 pu = 0.4 pu = 0.2 pu = –0.2 pu = –0.45 pu = 0pi = –0.5 ti = 0.45 Figure 4. Two simple structures with sources (squares) and users (circles). Edges connect sources to the users following them and users to their friends. Each s ource has an associated tiand pivalue and each user has an associated puvalue next to their respective nodes. Table 2. The fi,uvalue for each user –source pair from ﬁgure 4 in the ( a) bipolar and ( b) monopolar models. (a) bipolar ’sfi,u (b) monopolar ’sfi,u user S1 S2 user S1 S2 U1 0.35 0.74 U1 0.45 0.55 U2 0.15 0.71 U2 0.45 0.55 U3 0.15 0.66 U3 0.45 0.55 U4 0.35 0.61 U4 0.45 0.55U5 0.48 0.52 U5 0.45 0.55 U6 0.56 0.40 U6 0.45 0.55 U7 0.62 0.10 U7 0.45 0.55 Table 3. The number of ﬂags each source in ﬁgure 4 gets in the ( a) bipolar and ( b) monopolar models, for varying values of ρandϕ. (a) bipolar ( b) monopolar ρϕ S1 S2 ρϕ S1 S2 0.67 0.7 0 2 0.67 0.7 0 0 0.57 0.6 1 1 0.57 0.6 0 0 0.49 0.54 1 1 0.49 0.54 0 1 0.36 0.44 2 0 0.36 0.44 4 10.2 0.3 2 1 0.2 0.3 4 1 0.1 0.6 0 0 0.1 0.6 0 0 0.1 0.5 0 0 0.1 0.5 0 1 0.1 0.14 4 0 0.1 0.14 4 1royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000205  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  realistic results. The most important of the two parameters isϕ, because it determines the number of flags generated in the system. Figure 5 ashows the total number of flags generated per value of ϕ. As expected, the higher the ϕ, the fewer the flags, as the user finds more news items acceptable. The sharp drop means that, for ϕ&gt; 0.6, we do not have a sufficient number of flags to support our observation of the model ’s be- haviour. Thus, hereafter, we will only investigate the behaviour of the model for ϕ≤0.6. ρis linked to ϕ; specifically , its value is capped by ϕ. Aworld with ρ≥ϕis unreasonable, because it would be a scenario where a user feels enough indignation by an item that theywill flag it, but then they will also reshare it to their social network. Thus, we only test scenarios in which ρ&lt;ϕ. Another important question is what combination of ϕand ρvalues generates flags that can reproduce the observed relation between source popularity and the number of flagswe see in figure 1. To do so, we perform a grid search, testing many combinations of ϕ–ρvalues. Our quality criterion is the absolute difference in the slope of the power fit betweenpopularity and the number of flags. The lower the difference, the better the model is able to approximate reality. Figure 5 bshows such a relationship. We can see that there is an area of high performance at all levels of ϕ. 3.2. Bipolar model Figure 6 shows the distribution of the polarity of the flagged news items, for different values of ϕand setting ρ= 0.08, an interval including the widest spectrum of goodness of fit asshown in figure 5 b. We run the model 50 times and take the average of the results, to smooth out random fluctuations. We can see that our hypothesis is supported: in a polarized environment the vast majorityofflagged news items are neutral. This happens for ϕ≤0.3, which, as we saw in figure 5 b,i st h e most realistic scenario. For ϕ≥0.4, our hypothesis would not be supported, but, as we can see in figure 5 b, this is the area in red, where the model is a bad fit for the observations anyway —since here we are looking at ρ= 0.08 results. Figure 7 shows the distribution of truthfulness of the flagged items. These distributions show that, by flagging following their individual polarization, users in the bipolarmodel end up flagging the most truthful item they can —if ϕis high enough, items with t i∼1 cannot be flagged almost regardless of the polarity difference.The two observations put together mean that, in the bipolar model, the vast majority of flags come from extremists who are exposed to popular neutral and truthful news. The extremists do not follow the neutral and truthful news sources, but getin contact with neutral and truthful viewpoints because of their social network. The bipolar model results —in accordance with the obser- vation from figure 1 —suggest that more popular items are s h a r e dm o r ea n dt h u sf l a g g e dm o r e .O n ec o u l db et e m p t e dt o identify and remove fake news items by taking the ones receivingmore than their fair shares of flags given their popularity. How- ever, such a simple system would not work in reality. Figure 1 is based on data coming after Facebook ’s machine learning pre- processor, the aim of which is to minimize false positives. 7 Thus, even after controlling for a number of factors —source popularity, reputation, etc. —most reported flags still end up attached to high-popularity, high-reputability sources. 3.3. Monopolar model In the monopolar model, we remove all aspects related topolarity, thus we cannot show the polarity distribution of the flags. Moreover, as we have shown in §2.6, the effect ofρand ϕis marginal. Thus we only show in figure 8 the truth- fulness distribution of the flags, for only ϕ= 0.1 and ρ= 0.08, noting that all other parameter combinations result in apractically identical distribution. The monopolar results show the flag truthfulness distribution as the ideal result. The distribution shows a dispro-portionate number of flags going to low truthfulness news items, as they should —the drop for the lowest truthfulness value is due to the fact that there are few items at that lowlevel of truthfulness, and that they are not reshared. Is this ideal result realistic? If we use the same criterion as we used for the bipolar model to evaluate the quality of themonopolar model, the answer is no. The absolute slope difference in the popularity –flag regression between obser- vation and the monopolar model is ≈0.798 for all ϕ–ρ combinations. This is a significantly worse performance than the worst-performing versions of the bipolar model — figure 5 bshows that no bipolar version goes beyond a slope difference of 0.5. Thus we can conclude that the monopolar model is not a realistic representation of reality, even if we would expect it tocorrectly flag the untruthful news items. The bipolar model is a better approximation, and results in flagging truthful news items. 0.1 0.2 0.3 0.4 0.5 0.6 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45r 00.050.100.150.200.250.300.350.400.450.50 abs slo pe difference 02.0 × 1054.0 × 1056.0 × 1058.0 × 1051.0 × 1061.2 × 1061.4 × 1061.6 × 1061.8 × 1062.0 × 106 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9no. flags ff(b) (a) Figure 5. (a) The number of flags ( y-axis) in the bipolar model for different values of ϕ(x-axis). ( b) The slope difference (colour; red = high, green = low) between the real world and the bipolar fit between the source popularity and the number of flags received, per combination of ϕandρvalues ( x–yaxis).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000206  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  3.4. Robustness Our bipolar model makes a number of simplifying assumptions that we need to test. First, we are showing results for a model in which all news sources have the same degree of activity ,meaning that each source will publish exactly one news item. This is not realistic: data from Facebook pages show that there is a huge degree of activity heterogeneity (figure 9 a). There is a mild positive correlation between the popular- ity of a page and its degree of activity (log-log Pearson correlation of ≈0.12; figure 9 b). For this reason, we use the real-world distribution of page popularity and we lock it in with its real-world activity level. This is the weighted bipolar model, in which each synthetic news source is the model ’s equivalent of a real page, with its popularity and activity. A second simplifying assumption of the bipolar model is that the reshareability and flaggability parameters ρand ϕarethe same for every individual in the social network. However, people might have different trigger levels. Thus we create thevariable bipolar model, where each user has its own ρ uand ϕu. These values are distributed normally, with their average /C22r¼0:08 (and standard deviation 0.01) and /C22fdepending on which average value of ϕwe are interested in studying (with the standard deviation set to one-eighth of /C22f). Figure 10 shows the result of the weighted and variable variants against the original bipolar model. In figure 10 a, we report the dispersion (standard deviation) of the polariz- ation values of the flags. A low dispersion means that flagscluster in the neutral portion of the polarity spectrum, mean- ing that most flags signal neutral news items. In figure 10 b, we report the average truthfulness of flagged items. We can see that taking into account the pages ’activities increases the dispersion by a negligible amount and only020406080100120140no. flags polarity010203040506070no. flags polarity 0510152025 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0no. flags polarity012345678no. flags polarity 00.20.40.60.81.01.21.4 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0–1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0–1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0no. flags polarity00.010.020.030.040.050.060.070.080.090.10no. flags polarity(e)( f)(b) (a) (c) (d) Figure 6. Flag count per polarity of items at different flaggability thresholds ϕfor the bipolar model. Reshareability parameter ρ= 0.08. Average of 50 runs. (a)ϕ= 0.1, ( b)ϕ= 0.2, ( c)ϕ= 0.3, ( d)ϕ= 0.4, ( e)ϕ= 0.5 and ( f)ϕ= 0.6.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000207  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  for high values of ϕ. This happens because there could be some extremely active fringe pages spamming fake content, which increases the likelihood of extreme flags. There is no difference in the average truthfulness of flagged items. Having variable ϕandρvalues, instead, actually decreases dispersion, making the problem worse —although only for larger values of ϕ. In this configuration, a very tolerant society with high (average) ϕwould end up flagging mostly neutral reporting —as witnessed by the higher average truthfulness of the reported items. This is because lower-than-average ρu users will be even less likely to reshare the most extreme news items. So far we have kept the reshareability parameter constant atρ= 0.08. If we change ρ(figure 11) the dispersion of a flag ’s polarity (figure 11 a) and its average truthfulness value (figure 11 b) do not significantly change. The changes are050100150200250 00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0 00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0 0.00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0no. flags truthfulness020406080100120140no. flags truthfulness 05101520253035404550no. flags truthfulness0246810121416no. flags truthfulness 00.51.01.52.02.53.0no. flags truthfulness00.020.040.060.080.100.120.140.160.180.20no. flags truthfulness(e)( f)(b) (a) (c) (d) Figure 7. Flag count per truthfulness of items at different flaggability thresholds ϕfor the bipolar model. Reshareability parameter ρ= 0.08. Average of 50 runs. (a)ϕ= 0.1, ( b)ϕ= 0.2, ( c)ϕ= 0.3, ( d)ϕ= 0.4, ( e)ϕ= 0.5 and ( f)ϕ= 0.6. 00.51.01.52.02.53.03.54.0 00.10.20.30.40.50.60.70.80.91.0no. flags truthfulness Figure 8. Flag count per truthfulness of items for the monopolar model for ϕ= 0.6. Average of 50 runs.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000208  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  10–410–310–210–11 1 10 102103p (shares ≥x) shares01234567 00.5 1.0 1.5 2.0 2.5 3.0 3.5log (followers) log (shares) 110102 no. sources(b) (a) Figure 9. (a) The cumulative distribution of source activity in Facebook in our dataset: the probability ( y-axis) of a news source sharing a given number of items or more ( x-axis). ( b) The relationship between activity ( x-axis) and popularity ( y-axis) in our Facebook dataset. 00.10.20.30.40.50.6s(pi)bipolar weighted variable 00.10.20.30.40.50.60.70.80.9 0.1 0.2 0.3 0.4 0.5 0.6m(ti) f0.1 0.2 0.3 0.4 0.5 0.6 fbipolar weighted variable(b) (a) Figure 10. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items in the bipolar model and its weighted and variable variants.s(pi) 0.1 0.2 0.3 0.4 0.5 0.6m(ti) f0.1 0.2 0.3 0.4 0.5 0.6 f(b) (a) 00.10.20.30.40.50.6 r = 0.03 r = 0.04 r = 0.05 r = 0.06 r = 0.07 r = 0.08 00.10.20.30.40.50.60.70.80.9 r = 0.03 r = 0.04 r = 0.05 r = 0.06 r = 0.07 r = 0.08 Figure 11. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items for different values of reshareability ρ.s(pi) m(ti) 0.1 0.2 0.3 0.4 0.5 0.6 f0.1 0.2 0.3 0.4 0.5 0.6 f(b) (a) 00.10.20.30.40.50.60.7 bipolar no-homophily no-community 00.10.20.30.40.50.60.70.80.91.0 bipolar no-homophily no-community Figure 12. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items in the bipolar and alternative models.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000209  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  due to the fact that ρsimply affects the number of flags: a higher ρmeans that users are more likely to share news items. More shares imply more news items percolating through the social network and thus more flags. The bipolar model contains many elements besides the ρ and ϕparameters. For instance, it imposes that the social net- work has several communities and that social relationshipsare driven by homophily. These two elements are based on existing literature, yet we should test their impact on the model. First, keeping everything else constant, the no-homophily variant allows users to connect to friends ignoring their polarity value. In other words, polarity is randomly distribu- ted in the network. Second, keeping everything else constant,the no-community variant uses an Erdo ̋s–Rényi random graph as the social network instead of an LFR benchmark. The Erdo ̋s–Rényi graph extracts connections between nodes uniformly at random and thus it has, by definition, no com- munity structure. Figure 12 shows the impact on flag polarity dispersion (figure 12 a) and average truthfulness (figure 12 b). The no-homophily variant of the bipolar model has a significantly higher dispersion in the flag polarity distribution, and lowertruthfulness average, and the difference is stable (though stronger for values of ρabove 0.3). This means that polarity homophily is playing a key role in ensuring that flags are pre-dominantly assigned to neutral news items: if we remove it, the accuracy in spotting fake news increases. In contrast, removing the community structure from the net- work will result in a slightly smaller dispersion of flag ’s polarity and higher average flag truthfulness. The lack of communities might cause truthful items to spread more easily, and thus beflagged, increasing the average flag truthfulness. 4. Discussion In this paper, we show how the assumption of traditionalcrowdsourced content policing systems is unreasonable. Expecting users to flag content carries the problematic assump- tion that a user will genuinely attempt to estimate the veracityof a news item to the best of their capacity. Even if that was a reasonable expectation to have, a user ’s estimation of veracity will be made within their individual view of the world andvariable polarization. This will result in assessments that will give an easier pass to biased content if they share such bias. This hypothesis is supported by our bipolar agent-basedmodel. The model shows that even contexts that are extremely tolerant towards different opinions, represented by our flagg- ability parameter ϕ, would still mostly flag neutral content, and produce results that fit well with observed real-world data. Moreover, by testing the robustness of our model, we show how our results hold both for the amount of heterogen-eity of source activity and for individual differences in both tolerance and propagation attitudes. Removing polarization from the model, and thus testing what we defined as the monopolar model, attempts to repro- duce the assumptions that would make a classical content policy system work. The monopolar model, while seeminglybased on reasonable assumptions, is not largely supported by established literature in the area of online behaviour and social interaction, differently from the bipolar model.Moreover, it is not able to deliver on its promises in terms of ability to represent real-world data.Our paper has a number of weaknesses and possible future directions. First, our main results are based on a simu- lated agent-based model. The results hold as long as the assumptions and the dynamics of the models are an accurateapproximation of reality. We provided evidence to motivate the bipolar model ’s assumptions, but there could still be fac- tors unaccounted for, such as the role of originality [36] or ofspreaders ’effort [37] in making content go viral. Second, many aspects of the model were fixed and should be investi- gated. For instance, there is a strong polarity homophilybetween users and news sources, and in user –user connec- tions in the social network. We should investigate whether such strong homophily is really supported in real-world scen-arios. Third, the model has an essentially static structure. The users will never start/stop following news sources, nor befriend/unfriend fellow users. Such actions are commonin real-world social systems and should be taken into account. Fourth the model only assumes news stories worth interacting with. This is clearly different from the realitywhere, in a context of overabundant information, most stories are barely read and collect few reshares or flags. Including those news stories in the model could certainly affect theoverall visibility of other items. Finally, the model does not take into account reward and cost functions for both users and news sources. What are the repercussions for a newssource of having its content flagged? Should news sources attempt to become mainstream and gather following? Such reward/cost mechanisms are likely to greatly influence ouroutcomes. We plan to address the last two points in future expansions of our model. Ethics. No individual-level data have been accessed in the develop- ment of this paper. The paper ’s experiments rely on synthetic simulations. Motivating data provided by the Social Science Research Council fulfil the ethical criteria required by Social Science One. Data accessibility. The archive containing the data and code necessary for the replication of our results can be found at http://www.michelec-oscia.com/wp-content/uploads/2020/03/20200304_ffff.zip Authors ’contributions. L.R. collected the data. M.C. performed the exper- iments. M.C. and L.R. jointly designed the study, analysed the data, prepared the figures, and wrote and approved the manuscript. Competing interests. We declare we have no competing interest. Funding. No funding has been received for this article. Acknowledgements. This study was supported in part by a dataset from the Social Science Research Council within the Social Data Initiative. CrowdTangle data access has been provided by Facebook in collabor- ation with Social Science One. The authors also thank Fabio Gigliettoand the LaRiCA, University of Urbino Carlo Bo, for data access, and Clara Vandeweerdt for insightful comments. Endnotes 1https://www.facebook.com/facebookmedia/blog/working-to- stop-misinformation-and-false-news (April 2017, date of access 3 March 2020). 2https://socialscience.one/blog/unprecedented-facebook-urls-data- set-now-available-research-through-social-science-one (February 2020, date of access 3 March 2020). 3From a least-squares fit in a log-log space. Alternative hypotheses such as linear relationship or exponential relationship are discarded, with p-values approximately 0.98 and 0.34, respectively. 4https://www.crowdtangle.com/ 5https://electionstudies.org/resources/anes-guide/top-tables/?id= 29 (date of access 11 November 2019). 6https://sites.google.com/site/andrealancichinetti/files 7https://about.fb.com/news/2018/06/increasing-our-efforts-to- fight-false-news/ (date of access 7 January 2020).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 2020002010  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  References 1. Newman N, Fletcher R, Kalogeropoulos A, Nielsen R. 2019 Reuters institute digital news report 2019 , vol. 2019. Oxford, UK: Reuters Institute for the Study of Journalism. 2. Allcott H, Gentzkow M. 2017 Social media and fake news in the 2016 election. J. Econ. Perspect. 31, 211 –36. (doi:10.1257/jep.31.2.211) 3. Lazer DMJ et al. 2018 The science of fake news. Science 359, 1094 –1096. (doi:10.1126/science. aao2998) 4. Vosoughi S, Roy D, Aral S. 2018 The spread of true and false news online. Science 359, 1146 –1151. (doi:10.1126/science.aap9559) 5. Adamic LA, Glance N. 2005 The political blogosphere and the 2004 US election: divided they blog. In Proc. of the 3rd Int. Workshop on Link Discovery, Chicago, IL, 21 –24 August 2005 , pp. 36 –43. New York, NY: ACM. 6. Garrett RK. 2009 Echo chambers online? Politically motivated selective exposure among internet news users. J. Comput.-Mediated Commun. 14, 265 –285. (doi:10.1111/j.1083-6101.2009.01440.x) 7. Nikolov D, Oliveira DFM, Flammini A, Menczer F. 2015 Measuring online social bubbles. PeerJ Comput. Sci. 1, e38. (doi:10.7717/peerj-cs.38) 8. Quattrociocchi W, Scala A, Sunstein CR. 2016 Echo chambers on Facebook. See https://papers.ssrn.com/ sol3/papers.cfm?abstract_id=2795110. 9. Flaxman S, Goel S, Rao JM. 2016 Filter bubbles, echo chambers, and online news consumption. Public Opin. Q. 80, 298 –320. (doi:10.1093/poq/ nfw006) 10. Dubois E, Blank G. 2018 The echo chamber is overstated: the moderating effect of politicalinterest and diverse media. Inf. Commun. Soc. 21, 729 –745. (doi:10.1080/1369118X.2018.1428656) 11. Del Vicario M, Vivaldo G, Bessi A, Zollo F, Scala A, Caldarelli G, Quattrociocchi W. 2016 Echo chambers: emotional contagion and group polarization on Facebook. Sci. Rep. 6, 37825. (doi:10.1038/ srep37825) 12. Garimella K, De Francisci Morales G, Gionis A, Mathioudakis M. 2018 Political discourse on socialmedia: echo chambers, gatekeepers, and the price of bipartisanship. In Proc. of the 2018 World Wide Web Conference, Lyon, France, 23 –27 April 2018 , pp. 913 –922. Geneva, Switzerland: International World Wide Web Conferences Steering Committee. 13. An J, Quercia D, Crowcroft J. 2013 Fragmented social media: a look into selective exposure to political news. In Proc. of the 22nd Int. Conf. on World Wide Web, Rio de Janeiro, Brazil, 13 –17 May 2013 , pp. 51 –52. New York, NY: ACM.14. Bakshy E, Messing S, Adamic LA. 2015 Exposure to ideologically diverse news and opinion on Facebook. Science 348, 1130 –1132. (doi:10.1126/science. aaa1160) 15. Conroy NJ, Rubin VL, Chen Y. 2015 Automatic deception detection: methods for finding fake news. Proc. Assoc. Inf. Sci. Technol. 52,1–4. (doi:10.1002/ pra2.2015.145052010082) 16. Shu K, Sliva A, Wang S, Tang J, Liu H. 2017 Fake news detection on social media: a data miningperspective. ACM SIGKDD Explor. Newsl. 19,2 2 –36. (doi:10.1145/3137597.3137600) 17. Wei W, Wan X. 2017 Learning to identify ambiguous and misleading news headlines. In Proc. of the 26th Int. Joint Conf. on Artificial Intelligence, Melbourne, Australia, 19 –25 August 2017 , pp. 4172 –4178. Palo Alto, CA: AAAI Press. 18. Li Y, Li Q, Gao J, Su L, Zhao B, Fan W, Han J. 2015 On the discovery of evolving truth. In Proc. of the 21th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, Sydney, Australia, 10 –13 August 2015 , pp. 675 –684. New York, NY: ACM. 19. Wu L, Liu H. 2018 Tracing fake-news footprints: characterizing social media messages by how they propagate. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, CA, 5 –9 February 2018 , pp. 637 –645. New York, NY: ACM. 20. Tschiatschek S, Singla A, Gomez Rodriguez M, Merchant A, Krause A. 2018 Fake news detection in social networks via crowd signals. In Companion Proc. of the Web Conf. 2018, Lyon, France, 23 –27 April 2018 , pp. 517 –524. Geneva, Switzerland: International World Wide Web Conferences Steering Committee. 21. Giglietto F, Iannelli L, Valeriani A, Rossi L. 2019 ‘Fake news ’is the invention of a liar: how false information circulates within the hybrid news system. Curr. Sociol. 67, 625 –642. 22. Myslinski LJ. 2013 Social media fact checking method and system, 4 June 2013. US Patent 8,458,046. 23. Kim J, Tabibian B, Oh A, Schölkopf B, Gomez- Rodriguez M. 2018 Leveraging the crowd to detect and reduce the spread of fake news and misinformation. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, 5 –9 February 2018 , pp. 324 –332. New York, NY: ACM. 24. Crawford K, Gillespie T. 2016 What is a flag for? Social media reporting tools and the vocabulary of complaint. New Media Soc. 18, 410 –428. (doi:10. 1177/1461444814543163) 25. Gillespie T. 2018 Custodians of the Internet: platforms, content moderation, and the hidden decisions that shape social media . New Haven, CT: Yale University Press.26. Messing S, State B, Nayak C, King G, Persily N. 2018 Facebook URL Shares. See https://doi.org/10.7910/ DVN/EIAACS. 27. Mathias J-D, Huet S, Deffuant G. 2016 Bounded confidence model with fixed uncertainties and extremists: the opinions can keep fluctuating indefinitely. J. Artif. Soc. Soc. Simul. 19, 6. (doi:10. 18564/jasss.2967) 28. Giglietto F, Iannelli L, Rossi L, Valeriani A, Righetti N, Carabini F, Marino G, Usai S, Zurovac E. 2018Mapping italian news media political coverage in the lead-up to 2018 general election. See https:// papers.ssrn.com/sol3/papers.cfm?abstract_id=3179930. 29. American National Election Studies. 2008 The ANES guide to public opinion and electoral behavior. Seehttps://electionstudies.org/resources/anes-guide/ top-tables/?id=29. 30. Lewandowsky S, Ecker UKH, Cook J. 2017 Beyond misinformation: understanding and coping with the ‘post-truth ’era. J. Appl. Res. Memory Cogn. 6, 353 –369. (doi:10.1016/j.jarmac.2017.07.008) 31. Iyengar S, Hahn KS, Krosnick JA, Walker J. 2008 Selective exposure to campaign communication: the role of anticipated agreement and issue publicmembership. J. Politics 70, 186 –200. (doi:10.1017/ S0022381607080139) 32. Stroud NJ. 2008 Media use and political predispositions: revisiting the concept of selective exposure. Pol. Behav. 30, 341 –366. (doi:10.1007/ s11109-007-9050-9) 33. Lancichinetti A, Fortunato S, Radicchi F. 2008 Benchmark graphs for testing community detection algorithms. Phys. Rev. E 78, 046110. (doi:10.1103/ PhysRevE.78.046110) 34. Conover MD, Ratkiewicz J, Francisco M, Gonçalves B, Menczer F, Flammini A. 2011 Political polarizationon twitter. In Proc. 5th Int. AAAI Conf. on Weblogs and Social Media, Barcelona, Spain, 17 –21 July 2011. Palo Alto: AAAI Press. 35. Swire B, Berinsky AJ, Lewandowsky S, Ecker UKH. 2017 Processing political misinformation: comprehending the Trump phenomenon. R. Soc. open sci. 4, 160802. (doi:10.1098/rsos.160802) 36. Coscia M. 2017 Popularity spikes hurt future chances for viral propagation of protomemes. Commun. ACM 61,7 0 –77. (doi:10.1145/3158227) 37. Pennacchioli D, Rossetti G, Pappalardo L, Pedreschi D, Giannotti F, Coscia M. 2013 The threedimensions of social prominence. In Proc. Int. Conf. on Social Informatics, Kyoto, Japan, 25 –27 November 2013 , pp. 319 – 332. New York, NY: Springer.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 2020002011  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022</td>
    </tr>
    <tr>
      <th>57</th>
      <td>news</td>
      <td>Running head: ORGANIZATIONAL BAD NEWS TRAINING\n\n1\n\nDisplaying Fairness While Delivering Bad News: Testing the Effectiveness of Organizational\nBad News Training in the Layoff Context\nStatus: Currently in press at Journal of Applied Psychology\nManuela Richter\nCornelius J. König\nChristopher Koppermann\nMichael Schilling\nUniversität des Saarlandes, Germany\n\nAuthor Note\nManuela Richter, Department of Psychology, Universität des Saarlandes,\nSaarbrücken, Germany; Cornelius J. König, Department of Psychology, Universität des\nSaarlandes, Saarbrücken, Germany; Christopher Koppermann, Department of Psychology,\nUniversität des Saarlandes, Saarbrücken, Germany; Michael Schilling, Department of\nPsychology, Universität des Saarlandes, Saarbrücken, Germany.\nWe thank William McKinley for his helpful feedback on an early version of this\npaper. We also thank Scott Tonidandel for his helpful advice and support on applying relative\nweight analysis to MANOVA using the statistical package R.\nCorrespondence concerning this article should be addressed to Manuela Richter,\nUniversität des Saarlandes, Arbeits- &amp; Organisationspsychologie, Campus A1 3, 66123\nSaarbrücken, Germany. E-mail: m_richter@mx.uni-saarland.de.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n2\n\nAbstract\nAlthough giving bad news at work is a stressful experience, managers are often\nunderprepared for this challenging task. As a solution, we introduce organizational bad news\ntraining that integrates (a) principles of delivering bad news from the context of health care\n(i.e., bad news delivery component), and (b) principles of organizational justice theory (i.e.,\nfairness component). We argue that both the formal and fair delivery of bad news at work can\nbe enhanced with the help of training to mitigate distress both for the messenger and the\nrecipient. We tested the effectiveness of training for the delivery of a layoff as a typical bad\nnews event at work. In two studies, we compared the performance of a training group\n(receiving both components of training) with that of a control group (Study 1, Study 2) and a\nbasics group (receiving the bad news delivery component only; Study 2) during a simulated\ndismissal notification meeting. In general, the results supported our hypotheses: Training\nimproved the formal delivery of bad news and predicted indicators of procedural fairness\nduring the conversation in both studies. In Study 2, we also considered layoff victims’\nnegativity after the layoff and found that training significantly reduced negative responses.\nThis relationship was fully mediated by layoff victims’ fairness perceptions. Despite\npreparation, however, giving bad news remained a challenging task in both studies. In\nsummary, we recommend that organizations provide managers with organizational bad news\ntraining in order to promote professional and fair bad news conversations at work.\nKeywords: delivering bad news, training, organizational justice, procedural fairness,\nlayoff\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n3\n\nDisplaying Fairness While Delivering Bad News: Testing the Effectiveness of Organizational\nBad News Training in the Layoff Context\n“So although I wish I were here with better news, the fact is that you and I are sitting\nhere today because this will be your last week of employment at this company.”\n(George Clooney alias Ryan Bingham in the motion picture Up in the Air by Dubiecki,\nClifford, Reitman, and Reitman, 2009)\nGiving bad news to an employee is as much a regular task for managers as it is a\ndifficult one (Bies, 2013). Managers have to communicate not only organizational\ndownsizing and layoffs (Clair &amp; Dufresne, 2004), but also negative performance feedback\n(Ilgen &amp; Davis, 2000), pay cuts (Greenberg, 1990), negative hiring (Lavelle, Folger, &amp;\nManegold, 2014) or promotion decisions (Lemons &amp; Jones, 2001), or disciplinary warnings\n(Cole &amp; Latham, 1997). What all these conversations have in common is the stress they\narouse in managers and employees alike: Employees feel threatened by bad news because it\nimpairs their self-esteem and creates uncertainty about their future (e.g., Baumeister,\nBratslavsky, Finkenauer, &amp; Vohs, 2001), and managers feel uncomfortable with their\nresponsibility for giving this news and thus doing harm to the employee (e.g., Molinsky &amp;\nMargolis, 2005). Furthermore, self-presentation concerns, feelings of guilt, or an anticipation\nof negative employee reactions can contribute to managers’ reluctance to give bad news\n(Rosen &amp; Tesser, 1970). Unfortunately, managers’ concerns often become reality, especially\nif bad news is given in an unfair and insensitive way. Organizational justice research has\nwidely demonstrated that employees respond adversely to unfair treatment while learning\nabout bad news, be it job applicants receiving rejection (Gilliland, 1994), employees\nexperiencing negative performance appraisal (Holbrook, 1999), or employees being given\nnotice of a layoff (Konovsky &amp; Folger, 1991).\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n4\n\nNevertheless, it has barely been explored how managers should be prepared for the\nchallenge of giving bad news in a fair way. The present research therefore addresses whether\ntraining can be developed that is useful for improving managers’ performance in a bad news\nconversation with an employee and, as a result, for reducing the negative impact of the\ndelivery or receipt, respectively, of bad news for managers as the messengers and employees\nas the recipients. For this purpose, we developed organizational bad news training, building\nupon principles of delivering bad health news from the context of health care (Baile et al.,\n2000; Rosenbaum, Ferguson, &amp; Lobas, 2004) and integrating principles of organizational\njustice theory (Colquitt, 2001; Leventhal, 1980). We then conducted first empirical tests of\nthe effectiveness of organizational bad news training while applying it to a bad news event\nthat is both prototypical and one of the most challenging a manager might face in working\nlife—delivering layoff news to an employee.\nIntroducing Organizational Bad News Training\nThe Bad News Delivery Component of Training\nEncountering bad news is an undesired and unpleasant event for recipients and\nmessengers alike. In particular, messengers exhibit an aversion to giving bad news that\nhinders them from carrying out the task properly, a phenomenon referred to as the MUM\neffect (“keeping mum about undesirable messages”; Rosen &amp; Tesser, 1970, p. 254). Research\nhas shown that messengers’ concerns about giving bad news are manifold, and include\nfeelings of guilt towards those suffering from bad news (Tesser &amp; Rosen, 1972), fears of\nnegative evaluations and self-presentation concerns of being associated with bad news (Bond\n&amp; Anderson, 1987), and anticipation of negative reactions of the recipients (Rosen &amp; Tesser,\n1970). In line with these findings, giving bad news to an employee can create considerable\nstress in managers, whether it pertains to the communication of negative hiring decisions or\nto the delivery of layoff news (e.g., Folger &amp; Skarlicki, 1998; Lavelle et al., 2014). In some\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n5\n\ncases, for instance if managers do not support the decisions they have to convey (e.g.,\nconducting a layoff due to downsizing rather than performance deficits), doing harm to an\nemployee may also contradict a manager’s role expectation of being a “good” supervisor who\naspires to promote and support his or her employees (Kets de Vries &amp; Balazs, 1997). This\nsituation may also create uncertainty about which behaviors are appropriate to implement this\ntask (Kahn, Wolfe, Quinn, &amp; Snoek, 1964). Such uncertainties about the role, together with a\nlack of critical knowledge and mastery experience in giving bad news, may relate to\nmanagers’ self-efficacy concerns regarding their ability to deal with the challenging task\nsuccessfully (Bandura, 1997), and this may in turn affect their performance (Stajkovic &amp;\nLuthans, 1998).\nTo reduce managers’ stress and to increase their performance in giving bad news,\norganizational bad news training needs to clarify the manager’s role as a leader whose task is\nsometimes to give bad news to an employee in order to achieve a “greater good or purpose”\n(Molinsky &amp; Margolis, 2005, p. 245). Furthermore, it is deemed necessary that training\nconveys knowledge about the appropriate behaviors for performing this task, thus providing\nmanagers with a sense of predictability and personal control of the situation. In practice,\nbehaviors crucial for giving bad news have usually been examined in health care\nprofessionals (Rosenbaum et al., 2004). Nevertheless, physicians and managers may have\nsimilar goals, for instance to facilitate recipients’ acceptance of a negative outcome and to\npreserve their positive attitudes, and they also seem to be exposed to similar challenges:\nAlthough the nature of physicians’ jobs—working with people with physical or mental\nillnesses—implies a constant exposure to giving bad health news, they often report stress and\nconcerns as well as a lack of confidence and competence in delivering a diagnosis (e.g.,\nCohen et al., 2003; Orgel, McCarter, &amp; Jacobs, 2010). Training in delivering bad health news\nhas been found to improve medical students’ and residents’ performance and confidence in\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n6\n\ndelivering a diagnosis during role-playing scenarios with peers or actors (e.g., Baer et al.,\n2008; Baile et al., 1999; Bonnaud-Antignac, Campion, Pottier, &amp; Supiot, 2010; Rosenbaum\net al., 2004). Such training usually conveys knowledge about the systematic structuring of a\nbad news conversation with a patient. A prominent example is the SPIKES protocol, which\ndescribes step-by-step strategic guidelines for delivering bad health news (Baile et al., 2000;\nBuckman, 1992). In particular, physicians should arrange the setting before the bad news\nconversation (setting up), assess the patient’s awareness of the problem (perception), inquire\nabout the patient’s desire for information disclosure (invitation), deliver bad health news\n(knowledge), address the emotions expressed (empathy), and arrange follow-up steps (e.g.\ntreatment plan) and summarize the discussion (strategy and summary).\nGiven the positive effects of such training in the context of health care, organizational\nbad news training should include a bad news delivery component that clarifies the manager’s\nrole and provides knowledge about the formal delivery of bad news to an employee, using a\nsimilar step-by-step protocol: First, managers should arrange the setting; second, they should\ndeliver the bad news immediately at the beginning of the meeting; third, they should provide\na detailed explanation for the bad news; fourth, they should deal with the emotions expressed\nby the employee; fifth, they should provide information about follow-up measures to promote\nplanning for the future; and, sixth, they should summarize the discussion.\nThe Fairness Component of Training\nAs much as giving bad news is a challenging task for managers, implementing an\nunfavorable outcome with interpersonal sensitivity and fairness is all the more demanding\n(Folger &amp; Skarlicki, 1998; Molinsky &amp; Margolis, 2005). Nevertheless, organizational justice\nresearch has widely demonstrated the beneficial effects of fairness at work on the\nestablishment of positive work outputs and relationships (for an overview, see Colquitt,\nConlon, Wesson, Porter, &amp; Ng, 2001). In particular, if employees have to deal with negative\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n7\n\nwork events, procedural fairness seems to be crucial for their favorable reactions to the\norganization and its agents (e.g., Cohen-Charash &amp; Spector, 2001; Colquitt et al., 2001).\nProcedural fairness refers to the processes and procedures used to make or implement\ndecisions (e.g., Leventhal, 1980). Research has shown, for example, that fair performance\nappraisal procedures were associated with employees’ motivation to improve their\nperformance (Elicker, Levy, &amp; Hall, 2006), whereas unfair procedures in promotion\ndecisions reduced employees’ commitment to their employer (Lemons &amp; Jones, 2001).\nSimilarly, in the context of reorganization, surviving employees reported more commitment\nand fewer turnover intentions if the reorganization process had been fair (Kernan &amp; Hanges,\n2002). Laid-off employees, on the other hand, were less angry (Barclay, Skarlicki, &amp; Pugh,\n2005) and less likely to complain and to take legal action against the employer (Konovsky &amp;\nFolger, 1991; Wanberg, Bunce, &amp; Gavin, 1999) if the layoff procedure had been fair.\nGiven the benefits of procedural fairness, organizational bad news training should\ninclude a fairness component that provides managers with knowledge about procedural\nfairness and its enactment in order to improve the perceived fairness of a bad news\nconversation and, as a consequence, to reduce employees’ negativity towards their supervisor\nand their employer afterwards. Specifically, procedural fairness can be increased by\nimplementing the principles postulated by Leventhal (1980): Procedures are fair if they are\nused consistently across persons and time (consistency) and without any bias or self-interest\n(bias suppression), if they are based on accurate information (accuracy), represent the needs\nof all parties involved (representativeness), and follow moral and ethical standards\n(ethicality). To implement the consistency principle while giving bad news, managers should\ncommunicate the news in an unambiguous and coherent manner throughout the conversation,\nand they should demonstrate bias suppression by appealing to the facts instead of attributing\nthe bad news to the employee’s personality. To promote representativeness, managers should\n\nORGANIZATIONAL BAD NEWS TRAINING\noffer two-way communication and give employees the opportunity to voice their views;\naccuracy should be fostered by providing adequate and reasonable explanations of the bad\nnews; and the principle of ethicality should be met by treating employees with politeness,\ndignity, and respect, for instance by mentioning their positive attributes and contributions (as\nsuggested by Wood and Karau (2009)). Previous research has already shown that leaders can\nbe trained to be fairer in their interactions with their employees (for an overview, see\nSkarlicki &amp; Latham, 2005). Fairness training (vs. no training) increased not only\nsubordinates’ perceptions of their leaders’ procedural fairness (Cole &amp; Latham, 1997;\nSkarlicki &amp; Latham, 1996, 1997), but also employees’ organizational citizenship behavior\n(Skarlicki &amp; Latham, 1996, 1997).\nTaken together, organizational bad news training needs to include (a) a bad news\ndelivery component to improve managers’ formal delivery of bad news and (b) a fairness\ncomponent to improve their display of fairness during this procedure. Whereas the former\nshould influence managers’ outcomes (e.g., reduce stress), the latter should influence\nemployee outcomes (e.g., reduce negativity towards employer).\nApplying Organizational Bad News Training to the Layoff Context\nA layoff can be considered as both a typical and one of the most challenging bad news\nevents at work. Therefore, it was deemed an appropriate field of application for testing the\neffectiveness of organizational bad news training on messengers’ performance in a bad news\nconversation. For many years, organizational downsizing has been discussed as a prevalent\nphenomenon in both the psychology and management literature, although it has often been\nrelated to negative outcomes for both organizations and humans (e.g., Datta, Guthrie, Basuil,\n&amp; Pandey, 2010; McKee-Ryan, Song, Wanberg, &amp; Kinicki, 2005; van Dierendonck &amp;\nJacobs, 2012). Layoffs impair not only the physiological and psychological well-being of the\nemployees who lose their jobs, the layoff victims (McKee-Ryan et al., 2005; Paul &amp; Moser,\n\n8\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n9\n\n2009), and the employees remaining at the company, the layoff survivors (Grunberg, Moore,\n&amp; Greenberg, 2001; van Dierendonck &amp; Jacobs, 2012), but also the well-being of the\nmanagers who have to communicate the dismissal messages, the layoff agents (Grunberg,\nMoore, &amp; Greenberg, 2006; Kets de Vries &amp; Balazs, 1997; Parker &amp; McKinley, 2008).\nSpecifically, having to conduct layoffs is a stressful task for managers because they\nhave to harm their employees by communicating a job loss for economic or strategic reasons\nthat are beyond an employee’s individual control and usually independent of performance\ndeficits (Folger &amp; Skarlicki, 1998; Molinsky &amp; Margolis, 2005). As indicated by interviews\nwith layoff agents conducted by Kets de Vries and Balazs (1997), undertaking the role of a\nlayoff agent can violate a manager’s role perception as a supportive leader, arouse feelings of\nrole ambiguity, and impair confidence in one’s ability to conduct this task. Furthermore,\nmanagers may also feel conflicted between the company’s business objectives and\nemployees’ well-being, i.e. the opposing expectations of the two parties. Accordingly, being\na layoff agent has been related to managers distancing themselves from the laid-off\nemployees (Clair &amp; Dufresne, 2004; Folger &amp; Skarlicki, 1998) in order to avoid feelings of\nemotional discomfort and confrontation with negative employee reactions. Unfortunately,\nmanagers’ concerns often hinder them from giving the bad news of a layoff in a fair and\nsensitive way (Folger &amp; Skarlicki, 1998). Research has shown that employees and their\nrepresentatives often consider it necessary to take legal steps against the employer following\nunfair layoff procedures (Konovsky &amp; Folger, 1991; Wanberg et al., 1999). Such\norganizational justice deficits in conducting layoffs are also reflected in German labor court\nstatistics (Destatis, 2015): Since 2010, about 400,000 labor court proceedings have been\ncompleted every year, around 50 percent of which were brought against the employer for\nlayoff reasons. In 2014, for instance, 201,354 of 392,061 (51 %) completed proceedings were\nsubmitted for layoff reasons.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n10\n\nTo summarize, the first component of organizational bad news training (i.e., the bad\nnews delivery component) should provide the layoff agent with knowledge about the formal\ndelivery of layoff news by using the step-by-step protocol described previously. These\nsystematic guidelines should improve their performance during a dismissal notification\nmeeting. Furthermore, information about their role and about ways to manage critical\nemployee reactions should give layoff agents an idea about what might happen during the bad\nnews conversation. This should provide them with a sense of personal control, which should\nin turn mitigate their feelings of stress and emotional discomfort in giving bad news (Tetrick\n&amp; LaRocco, 1987). The second component of organizational bad news training (i.e., the\nfairness component) should teach layoff agents ways in which to enact procedural fairness\nprinciples (Leventhal, 1980) while delivering layoff news. This should improve the perceived\nfairness of the notification procedure and, as a result, mitigate negative employee reactions,\ngiven the findings that procedural fairness has a positive impact on laid-off employees’\nemotional reactions (e.g., anger; Barclay et al., 2005) and attitudes (e.g., desire to complain or\nto take legal action; Konovsky &amp; Folger, 1991; Wanberg et al., 1999).\nStudy 1 was designed to test the overall effectiveness of organizational bad news\ntraining. For this purpose, a training group was provided with complete organizational bad\nnews training, which included both the bad news delivery and the fairness components, and\ncompared with a no-training control group. Following this, Study 2 was designed to identify\nthe specific impact of the two components. For this purpose, three experimental groups were\nneeded: (a) a training group that was provided with both the bad news delivery and the\nfairness components of organizational bad news training, (b) a basics group that was provided\nwith the bad news delivery component only, and (c) a control group that was provided with\nneither of the components. Given the expected effect of the training components, the formal\ndelivery of layoff news should improve, and feelings of emotional discomfort should\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n11\n\ndecrease for the training group and the basics group compared to the control group. However,\nthe enactment of procedural fairness should improve only for the training group, and layoff\nvictims’ negative reactions should also decrease only for the training group as compared to\nboth the basics group and the control group. Finally, given that practical rehearsal is an\nimportant means to create proficiency and confidence in being able to perform a task\nsuccessfully (Bandura, 1997), layoff agents’ confidence in their ability to deliver layoff news\nshould improve for the training group if only the training group is given the opportunity to\nexercise the task as compared to the basics group and the control group. Based on the above\ndiscussion, we therefore make the following hypotheses:\nH1: Layoff agents’ formal delivery of layoff news improves for (a) a training group and\n(b) a basics group, as compared to a control group.\nH2: Layoff agents’ feelings of emotional discomfort in delivering layoff news decrease\nfor (a) a training group and (b) a basics group, as compared to a control group.\nH3: Layoff agents’ confidence in their ability to deliver layoff news improves for a\ntraining group as compared to (a) a control group and (b) a basics group.\nH4: Layoff agents’ procedural fairness in delivering layoff news improves for a training\ngroup as compared to (a) a control group and (b) a basics group.\nH5: (a) Layoff victims dismissed by a training group report less negativity towards the\nemployer than those dismissed by a basics group and a control group, and (b) this effect\nis mediated by layoff victims’ perceptions of procedural fairness.\nStudy 1\nIn Study 1, we compared the performance of a training group with a no-training control\ngroup in a simulated bad news conversation (i.e., dismissal notification meeting) in order to\ntest H1a, H2a, H3a, and H4a. We chose a laboratory setting to evaluate the effectiveness of\ntraining for three reasons. First, it allowed us to randomly assign participants to the training\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n12\n\nconditions. It would hardly be possible, and would also be ethically problematic, to withhold\ntraining from a sample of managers conducting operational layoffs. Second, laboratory\nsettings and role-playing exercises allow trainees to practice new skills without risking harm\ndue to improper treatment (Skarlicki &amp; Latham, 2005), which is also the reason why health\ncare researchers typically simulate doctor-patient interviews using actors or student peers as\nrole-players (e.g., Baer et al., 2008; Bonnaud-Antignac et al., 2010). Third, as organizational\nbad news training has not yet been studied, we decided to begin this research in a laboratory\nsetting to gain an impression about its effectiveness and applicability.\nMethod\nParticipants and design. The sample consisted of 51 participants (30 females, 21\nmales) with a mean age of 27.18 years (SD = 6.33). Forty-three were students on a Bachelor,\nMaster, or PhD course at a German university (72 % studied psychology), and eight were\nprofessionals from start-up companies located at the campus. Thirty-eight participants (74 %)\nworked at least part-time, and a considerable number of respondents had some kind of layoff\nexperience: Eight (16 %) reported that they had been laid off in the past, 25 (49 %) had\nwitnessed at least one layoff in a close relationship (e.g., family member or close friend), and\n28 (55 %) had witnessed at least one layoff in a more distant relationship.\nAll participants had to formally register for a training session and were randomly\nchosen for the training group or the control group, respectively. Training was announced as a\nworkshop to practice conduct in critical leader-member interactions. Participants in the\ntraining group received training in a traditional classroom setting and performed a dismissal\nnotification meeting in an individual role-play session about five days later. Participants in\nthe control group performed the dismissal meeting without training.\nTraining intervention. Classroom training consisted of a half-day workshop and\ncomprised five learning modules (for details, see Table 1). In Module 1, trainees were\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n13\n\nprovided with information about their role as a layoff agent and the challenges of giving bad\nnews. In Module 2, trainees were taught how to enact procedural fairness principles while\ndelivering layoff news (Leventhal, 1980). For example, they learned how to provide adequate\nand reasonable explanations for the layoff reasons in order to fulfill the accuracy principle. In\nModule 3, we explained the step-by-step protocol of giving bad news at work (e.g., delivering\nthe bad news immediately). Module 4 described emotional reactions that might be expressed\nby employees in response to bad news (i.e., shock, anger, negotiation) and how to deal with\nthem. In Module 5, trainees were asked to take the perspective of either the manager or the\nemployee in a dismissal meeting and to act according to these roles in two peer role-plays.\nTesting scenario.1 All participants were assigned to the role of the leading manager of\nthe customer support division of a mobile telephone provider. They were informed that due to\nchanging market conditions, the company had reported declines in sales and that top\nmanagement had decided upon strategic restructuring and headcount reduction. Participants\nthen were asked to conduct a dismissal meeting with Mrs. (or Mr.) Brauer, a 29-year-old\nemployee who had been employed at the company for five years. A small conference table\nhad been prepared and participants were given some time to plan the conversation. They were\nalso advised to conduct the meeting professionally because they would receive feedback\nafterwards.\nMrs. (or Mr.) Brauer was represented by one of five role-players, henceforth referred to\nas the layoff victim. We chose both male and female victims to account for any differential\nreactions of participants towards men or women losing their jobs. In a preliminary training\nsession, layoff victims had been informed about their role and trained to play a shocked and\nstunned employee. To realize semi-standardized interviews, they had been taught a protocol\nof predetermined statements which had to be made in each dismissal meeting (i.e., “You\ncan’t be serious!”, “What did I do wrong?”, “Why me?”, “But we have just taken out a loan. I\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n14\n\nthought we had a good relationship!”, “What shall I do now?”, “I can’t manage this!”, “This\nis too much for me!”, “What will this do to me?”, “And if I kill myself?”).2\nDuring the conversation, an observer monitored the participants’ performance. The\nobserver was hidden in the background, invisible to the participants and thus unable to\nunwittingly influence or coach their performance through nonverbal communications (e.g.,\nfacial expressions). Both the observer and the layoff victims were blind to the participants’\ntraining condition; the participants themselves were also unaware of the existence of different\ntraining conditions. Immediately after the dismissal meeting, the dependent variables were\nmeasured. Finally, participants received feedback about their performance, were debriefed\nabout their experiences during the simulation and the purpose of the study, and offered a\nfollow-up talk if necessary. The whole procedure lasted for approximately 30 minutes.\nMeasures.3 All dependent measures were collected after the dismissal meeting. Unless\notherwise specified, all scales used 5-point Likert scales ranging from 1 = “strongly disagree”\nto 5 =”strongly agree”.\nData from self-reports. Participants’ feelings of emotional discomfort were measured\nin terms of negative affect using a subscale of the Positive and Negative Affect Schedule\n(PANAS; Watson, Clark, &amp; Tellegen, 1988). Negative affect was assessed on ten adjectives\n(e.g., “distressed”), using a 5-point scale (1 = “not at all” to 5 = “extremely”). Participants’\nconfidence in their ability to deliver layoff news was assessed with six items developed for\nthe purpose of this study (e.g., “I felt capable of conducting the dismissal meeting”).\nData from the layoff observer. The observer indicated participants’ formal delivery of\nbad news on twelve items; on dichotomous scales (1 = “yes, 2 = “no”), six items measured\nthe elements of the dismissal meeting referring to the step-by-step protocol of giving bad\nnews (e.g., “Delivered the layoff message within the first five sentences”); on 5-point Likert\nscales, six items assessed the flexibility in applying this protocol (e.g., “Responded to the\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n15\n\nemployee’s behavior flexibly). Additionally, the observer evaluated participants’ enactment\nof procedural fairness (Leventhal, 1980). A multi-item measure was developed for the\npurpose of this study: Consistency was measured with three items (e.g., “Remained\nbinding”), bias suppression (“Based the conversation on occupational grounds only”),\nethicality (e.g., “Behaved in a polite and respectful manner”) and representativeness (e.g.,\n“Facilitated the employee to express his/her views and feelings”) with four items each, and\naccuracy (e.g., “Tailored the explanations to the employee’s specific needs”) with six items.\nResults and Discussion\nMeans, standard deviations and correlations among the variables are displayed in Table\n2. We used independent samples t-tests to test H1a, H2a, and H3a (see Table 3 for results).4\nIn terms of layoff agents’ formal delivery of bad news, we analyzed the observer’s perception\nof participants’ compliance with the elements of the step-by-step protocol of giving bad news\nand their flexibility in applying this protocol. As predicted, analyses revealed significant\neffects of training condition on elements and flexibility, indicating that the training group\ncomplied better with the elements of the step-by-step protocol and was also more flexible in\napplying the protocol than the control group. H1a was therefore supported. However, training\ndid not reduce participants’ negative affect and also did not improve their confidence in their\nability to deliver layoff news (all p’s &gt; .05); H2a and H3a were therefore not supported.\nDue to theoretical and methodological relationships among the procedural fairness\nvariables, we used multivariate analyses of variance (MANOVA) to test H4a. MANOVA\nresults for the observer data revealed a significant multivariate effect of training condition on\nthe combined procedural fairness principles, Wilks’ Λ = .48, F(5,45) = 9.81, p &lt; .01, η2 = .52,\nindicating that the two groups differed significantly in terms of their enactment of the\nprocedural fairness principles. Follow-up independent samples t-tests revealed significant\neffects of training condition on each procedural fairness principle (see Table 3 for results).\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n16\n\nFrom the observer’s perspective, training improved layoff agents’ enactment of fairness\nduring the dismissal meeting procedure: Trainees delivered the layoff more consistently\n(consistency) and impartially (bias suppression) than non-trainees. The training group also\noutperformed the control group in providing adequate explanations (accuracy), allowing\nlayoff victims to voice their views and feelings (representativeness), and treating them with\nrespect (ethicality), thus fully supporting H4a. However, multiple t-tests as follow-up tests to\na MANOVA suffer from the methodological limitation of ignoring correlations among\ndependent variables, unlike relative weight analysis applied to MANOVA (Tonidandel &amp;\nLeBreton, 2013). Relative weight analysis allowed us to determine the relative contribution\nof each fairness variable to the overall multivariate effect of training (again see Table 3),\ntaking these correlations into account. The highest relative weights were found for\nconsistency and bias suppression, with 21 % and 14 % of variance accounted for by training\ncondition, respectively. Thus, layoff agents’ enactment of consistency and impartiality seem\nto be the most important factors in determining the perceived procedural fairness of a layoff.\nIn summary, although training was not effective in reducing participants’ self-reported\nnegative affect or in increasing their confidence, Study 1 demonstrated the overall\neffectiveness of organizational bad news training on participants’ performance from an\nobserver’s perspective: Training improved not only layoff agents’ formal delivery of bad\nnews, but also their enactment of procedural fairness principles (Leventhal, 1980) while\ndelivering layoff news from an observer’s viewpoint. Nevertheless, it remained unclear\nwhich underlying mechanism produced the positive effects of training, i.e. whether it was the\nbad news delivery aspect or the fairness aspect of organizational bad news training. More\nspecifically, did training work because of participants’ increase in knowledge about the\nformal delivery of bad news at work or because of their enactment of procedural fairness\nwhile communicating the bad news? Study 2 was designed to address this question.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n17\n\nStudy 2\nIn Study 2, we extended our design to three training conditions, comparing a training\ngroup with a basics group and a control group. Similar to Study 1, the training group received\nboth the bad news delivery and the fairness components of organizational bad news training.\nThe basics group, by contrast, was only provided with the bad news delivery component, and\nnot with the fairness component. Together with a no-training control group, we were now\nable to identify the effectiveness of the two components of organizational bad news training.\nWe again used a layoff as an appropriate bad news event in order to test H1 to H4.\nFurthermore, to test H5, we also addressed layoff victims’ negativity in terms of their anger,\ntheir intent to complain, and their intent to take legal action against their employer.\nMethod\nParticipants and design. The sample consisted of 75 young adults (46 females, 29\nmales) with a mean age of 23.49 years (SD = 4.38). All of them were students on a Bachelor,\nMaster or PhD course at a German university from different subject areas (e.g., 55 %\npsychology, 17 % economics and law, 7 % education, 5 % computer science); forty (53 %)\nworked at least part-time. Fifteen respondents (20 %) reported that they had been laid off in\nthe past, 35 (47 %) had witnessed at least one layoff in a close relationship (e.g., family\nmember or close friend) and 45 (60 %) in a more remote relationship (e.g., distant\nacquaintances), and five (7 %) had laid off someone else in the past.\nParticipants were assigned to either a training group (n = 25), a basics group (n = 25),\nor a control group (n = 25). All of them had to perform a dismissal meeting in a face-to-face\nrole-play; for the training group and the basics group, the role-play took place about four days\nafter the intervention.\nTraining intervention. Participants in the training group were provided with both the\nbad news delivery and the fairness components of organizational bad news training. Training\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n18\n\ncomprised the same five modules as provided in Study 1 (see Table 1), but this time we used\nweb-based training to meet current organizational requirements of flexible learning on\ndemand (DeRouin, Fritzsche, &amp; Salas, 2005). To increase trainees’ motivation, we integrated\na mixture of text, graphics, audio and video clips as well as learning games. For example,\ntextual materials provided information about the step-by-step protocol of giving bad news at\nwork and video clips illustrated the enactment of procedural fairness principles. We also\nincluded real-time video conferencing with one of our trainers to realize the rehearsal\nexercise. Trainees spent an average of three hours on the e-learning.\nBasics intervention. Participants in the basics group were only provided with the bad\nnews delivery component of organizational bad news training. Similar to those in the training\ngroup, participants were informed about their role as a layoff agent, the step-by-step protocol\nof giving bad news, and the management of critical employee reactions (Modules 1, 3, and\n4). However, they were not taught about procedural fairness and its enactment (Module 2),\nand they also did not undergo rehearsal (Module 5). The basics group received textual\nmaterials and graphics only. Participants spent an average of half an hour on the materials.\nTesting scenario. The testing procedure corresponded exactly with that of Study 1. All\nparticipants were assigned to the role of a manager and asked to conduct a dismissal meeting\nwith an employee named Mrs. Brauer, played by two female role-players. We only used\nfemales because Study 1 found no gender effects on any of the dependent measures. Layoff\nvictims had again been trained to act in a shocked manner using the same script as in Study 1.\nIdentical to Study 1, both the observer and the layoff victims were blind to the participants’\ntraining condition; the participants themselves were also unaware of the existence of different\ntraining conditions. Dependent measures were collected immediately after the dismissal\nmeeting, except feelings of emotional discomfort, which were measured before (i.e., negative\naffect scale) and after the meeting (i.e., distress scale). Finally, participants received feedback\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n19\n\nabout their performance, were debriefed about their feelings and experiences during the\nsimulation as well as the study objectives, and offered a follow-up talk if necessary.\nMeasures. Three different sources of variance were used: data from self-reports, from\nthe observer, and from the layoff victim. Unless otherwise specified, all measures and scales\nwere identical to Study 1. All new scales used 5-point Likert scales ranging from 1 =\n“strongly disagree” to 5 = “strongly agree”.\nData from self-reports. Participants’ feelings of emotional discomfort prior to the\ndismissal meeting were measured in terms of negative affect using the negative PANAS\nsubscale reported in Study 1. To measure feelings of discomfort after the dismissal meeting,\nwe developed a distress scale measuring participants’ reluctance to give bad news with six\nitems (e.g., “I didn’t like giving layoff news to the employee”) based on Cox, Marler,\nSimmering, and Totten (2011). Additionally, participants’ confidence in their ability to\ndeliver layoff news was assessed with the same six items used in Study 1.\nData from the layoff observer. The observer rated participants’ formal delivery of\nlayoff news on the elements and the flexibility scales used in Study 1. The observer also\nevaluated participants’ enactment of procedural fairness on the scales used in Study 1.\nHowever, we reformulated some items of our multi-item measure to increase correspondence\nwith existing scales (Colquitt, 2001). For instance, the ethicality item of Study 1 “Behaved in\na polite and respectful manner” was split up into “Treated the employee in a polite manner”\nand “Treated the employee with respect” (cf. Colquitt, 2001).\nData from the layoff victims. The layoff victims evaluated participants’ performance\naccording to the enactment of procedural fairness principles using the same scales as those\nfor the observer. Inter-rater (victim-observer) reliability of the scale scores was r = .56 for\nconsistency, r = .64 for bias suppression, r = .84 for accuracy, r = .84 for representativeness,\nand r = .82 for ethicality (all p’s &lt; .01). However, we computed separate scores for the\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n20\n\nobserver and victim data due to their passive or active role during the dismissal meeting,\nrespectively, and the consequently different emotional quality of their ratings. Additionally,\nwe measured the layoff victims’ negativity towards the former employer: Anger was\nmeasured with four items (i.e., “I feel outrage towards the company”), complain with four\nitems (i.e., “I would complain to friends about this employer”), and legal action with five\nitems (i.e., “I would consider taking legal action”) taken from Wood and Karau (2009).\nResults and Discussion\nMeans, standard deviations, and correlations among the variables are shown in Table 4.\nWe used planned contrast analyses to test our hypotheses (reported in Table 5). Following the\nprocess recommended by Furr and Rosenthal (2003), we translated the predicted group\nmeans into contrast weights (Contrast A to Contrast E for the five hypotheses) and then\ncomputed significance tests and effect sizes (i.e., rcontrast). Given the following contrasts\n(a1 a2 a3), please note that the first index (a1) always displays the value for the control group,\nthe second (a2) the value for the basics group, and the third (a3) the value for the training\ngroup.\nWe first tested H1, that participants’ formal delivery of layoff news during the\ndismissal meeting should be higher in the training group and the basics group than in the\ncontrol group. We used Contrast A (-2 1 1) to compare the control group with the other two\ngroups. In support of H1, we found significant effects for elements and flexibility. From an\nobserver’s perspective, the training group and the basics group complied better with the\nelements of the step-by-step protocol of giving bad news and were also more flexible in\napplying the protocol than the control group. Nevertheless, additional analyses showed that\nthe training group was still more flexible than the basics group, t(72) = 2.87, p &lt; .01, rc = .32.\nH2 stated that participants’ feelings of emotional discomfort should be lower in the\ntraining group and basics group than in the control group. We used Contrast B (2 -1 -1) to\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n21\n\ncompare the control group with the other two groups and did not find significant effects\neither for participants’ negative affect measured before the dismissal meeting or for their\ndistress measured after the dismissal meeting, thus not supporting H2. However, an\nadditional contrast analysis showed that the training group reported less negative affect\nbefore the dismissal meeting than the basics group and the control group, t(72) = 2.04, p &lt;\n.05, rcontrast = .23. Nevertheless, all participants felt equally distressed afterwards.\nRegarding H3, Contrast C (-1 -1 2) tested the assumption that participants’ confidence\nshould be higher in the training group than in the other two groups. However, we found no\nsignificant effect, thus failing to confirm H3.\nWe then tested H4, that participants’ procedural fairness during the dismissal meeting\nshould be higher in the training group compared to the basics group and the control group.\nWe used multivariate contrast analyses to test for group differences for the combined\nprocedural fairness principles, followed by univariate contrast analyses for the separate\neffects. Contrast D (-1 -1 2) compared the training group with the other two groups and was\nsignificant for both the observer data, Wilks’ Λ = .28, F(5,68) = 35.64, p &lt; .01, η2 = .72, and\nthe layoff victim data, Wilks’ Λ = .62, F(5,68) = 8.47, p &lt; .01, η2 = .38. Subsequent\nunivariate contrasts were significant for each fairness principle, indicating that the training\ngroup showed more consistency, impartiality, accuracy, representativeness, and ethicality\nduring the dismissal meeting than the other two groups. Thus, H4 was fully supported. To\ndetermine the relative importance of each fairness variable for the overall fairness effect, we\nagain applied relative weight analysis (Tonidandel &amp; LeBreton, 2013), comparing the results\nof the training with the other two groups. For the observer data, the highest relative weights\nwere found for bias suppression (33 %) and consistency (15 %). For the layoff victim data,\nwe also found the highest relative weights for bias suppression (14 %) and consistency (14\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n22\n\n%). Similar to Study 1, enactment of impartiality and consistency were the most important\nfactors in determining the overall procedural fairness of a layoff.\nRegarding H5a, we analyzed whether layoff victims report less negativity towards the\nemployer if dismissed by the training group as compared to the basics group and the control\ngroup. We used multivariate and follow-up univariate contrast analyses to test for group\ndifferences for the three negativity measures (i.e., anger, complain, legal action). Multivariate\nContrast E (1 1 -2) compared the training group with the other two groups and was found to\nbe significant, Wilks’ Λ = .81, F(3,70) = 5.55, p &lt; .01, η2 = .19, with follow-up univariate\ncontrasts showing significance for all negativity measures: In support of H5a, layoff victims\nwere less angry and less willing to complain or to take the employer to court when their\nlayoff agent had been trained. We used a bias-corrected bootstrapping approach with 5,000\nbootstrap samples (Preacher &amp; Hayes, 2004) to test whether the relationships between\ntraining condition and negativity were mediated by layoff victims’ perceptions of procedural\nfairness. Table 6 displays the results of the mediation analyses: The indirect effects of\ntraining condition on all negativity measures via procedural fairness were significant (for\nanger, indirect effect = -1.04, SE = .20, 95% CI [-1.44, -0.65]; for complain, indirect effect =\n-0.86; SE = .18, 95% CI [-1.22, -0.51]; for legal action, indirect effect = -1.07, SE = .22, 95%\nCI [-1.54, -0.64]). Sobel tests confirmed these findings, and H5b was thus supported.\nIn summary, providing messengers with the bad news delivery component of\norganizational bad news training improved the formal delivery of layoff news in a dismissal\nmeeting for both the training group and the basics group as compared to the control group.\nHowever, only the fairness component of training was effective in improving the procedural\nfairness of a dismissal meeting, given the finding that the training group outperformed the\nother two groups with regard to the enactment of procedural fairness from both the observer’s\nand the layoff victims’ perspective. Thus, providing messengers with some kind of checklist,\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n23\n\nas often used in practice, seems to be insufficient to reach the best performance. Given the\nsignificant mediation effect, the impression of a fair layoff procedure was also responsible for\nlayoff victims’ lowered negative responses to their employer, thus highlighting that it is\nparticularly the fairness mechanism that drives the positive effects of training (Barclay et al.,\n2005; Konovsky &amp; Folger, 1991). Furthermore, although training was again not successful in\nimproving messengers’ confidence or in reducing their distress after the bad news\nconversation, it turned out to be useful for reducing negative affect beforehand.\nGeneral Discussion\nGiving bad news to an employee is a difficult, but common management task\n(Molinsky &amp; Margolis, 2005). Organizational bad news training was suggested to improve\nmessengers’ performance in giving bad news, to increase impressions of fairness during a bad\nnews conversation, and thus to have a positive impact on both the messengers’ (e.g., feelings\nof emotional discomfort) and the recipients’ outcomes (e.g., negative responses towards the\nemployer). Across two studies, we applied organizational bad news training to the layoff\ncontext and found evidence that training had positive effects particularly on layoff agents’\nformal and fair performance in giving bad news and on layoff victims’ responses afterwards.\nGiven these findings, our first test of the effectiveness of organizational bad news\ntraining seems to have been successful, thus clearly extending previous research. We\nsuccessfully integrated principles of delivering bad news from the context of health care\n(Baile et al., 2000; Rosenbaum et al., 2004) and principles of organizational justice theory\n(Colquitt, 2001; Leventhal, 1980) and applied it to both a typical and one of the most\nchallenging bad news events at work—delivering layoff news to an employee. By integrating\na basics group in Study 2, which received only one component of organizational bad news\ntraining, it was furthermore possible to demonstrate that the two main components of training\nfulfilled specific purposes. Whereas the bad news delivery component provided knowledge\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n24\n\nabout the delivery of bad news and particularly improved messengers’ formal performance in\na bad news conversation, it was especially the fairness component of training which\nfacilitated the display of fair behavior and thus reduced negative reactions of the recipients.\nPrevious research (Konovsky &amp; Folger, 1991; Wanberg et al., 1999) has already shown that a\nlack of fairness can be associated with managers disregarding employees’ needs and can\ntherefore elicit negative employee reactions. In line with this, our mediation analyses\nconfirmed that it was indeed recipients’ perceived fairness that reduced their negative\nresponses to the bad news. Thus, emphasizing fairness elements while giving bad news seems\nto be an encouraging way to mitigate employees’ harmful behaviors such as complaining\nabout the employer and, thus, to maintain favorable organizational outcomes.\nHowever, positive effects of organizational bad news training on messengers’\nsubjective outcomes were less evident. Although we were able to reduce layoff agents’\nnegative affect before the bad news conversation with the help of training, the\nimplementation of the layoff remained difficult for all participants: Training affected neither\ntheir confidence in their ability to deliver layoff news nor their feelings of emotional\ndiscomfort after the dismissal meeting in either study. The simulated environment and\nlimitations concerning training intensity and practical experiences may have contributed to\nthe lack of effects on these subjective outcomes. When conducting real layoffs, managers will\nmost likely experience higher emotional drain and may therefore benefit more directly from\ntraining. Nevertheless, it also seems reasonable that although training can be useful for\nincreasing knowledge and skills in conducting a bad news conversation fairly, the situation\nitself may remain aversive, particularly with regard to layoffs. Despite training, it may still be\ndifficult to express a layoff decision transparently, to bear an employee’s emotional reactions,\nand to show appreciation for an employee’s work which is no longer required. Thus, giving\nbad news will likely never be an enjoyable task.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n25\n\nA particular strength of our studies is that we used observer and layoff victim data to\ndetermine whether training was successful rather than relying solely on self-reports, thus\navoiding common method variance. We also developed multi-item scales for Leventhal’s\n(1980) procedural fairness principles, allowing us to address both the structural and social\naspects of procedural fairness independently, instead of computing a generic procedural\nfairness score. Moreover, we used two different training modalities to test the effectiveness of\norganizational bad news training. Although web- or computer-based training is usually\napplied to teach technical skills (DeRouin et al., 2005), our results suggest that even\ninterpersonal behaviors such as the enactment of fairness can improve if participants are\nprovided with interactive elements, face-to-face role-play exercises, and feedback.\nThe main limitation of both studies is the use of a laboratory setting. Young adults\n(many of them employed and reporting past experiences with observing layoffs) were\nassigned to training, basics or control conditions, subsequently performing a manager’s task\nof delivering layoff news without having experience in a managerial role. Although we would\nwelcome a replication in the field, the intention of observing true layoffs would appear to be\nfairly unrealistic, and we doubt that any organization would support this research due to the\nsensitivity of company data. There is also an ethical problem of not offering training to a\ncontrol group of managers who have to lay off employees, especially since both of our\nstudies suggest that positive effects of such training can be expected for both managers and\nemployees. The use of a less delicate subject, for instance applying organizational bad news\ntraining to the task of giving negative performance feedback (Holbrook, 1999; Ilgen &amp; Davis,\n2000), might allow field tests of training effectiveness. In the critical context of layoffs,\nhowever, using an experimental design and simulations to illustrate a dismissal meeting\nallowed us to determine causal effects of training on messengers’ performance. Although true\nlayoff agents may have to deal with more diverse and more intense emotional reactions in\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n26\n\npractice, standardized tasks provide comparable testing situations, and performance in these\ntasks can be a good indicator of participants’ actual performance. Furthermore, attending or\nrecording real dismissal meetings would have been impossible due to privacy policies as well\nas ethical and moral responsibilities towards those laid off, especially if the layoff agents are\nin the process of learning and are still inexperienced. This is likely the reason why physicians\noften test the effectiveness of student or resident training for the disclosure of bad health\nnews using peer role-plays or standardized role-plays with simulated patients or actors (e.g.\nBaer et al., 2008; Bonnaud-Antignac et al., 2010). Nevertheless, subject matter experts\nevaluated our training concept as fairly applicable to practice and the dismissal meetings as\nfairly realistic, thus resolving some concerns about the artificiality of our research.5\nFuture research should test the effectiveness of organizational bad news training for\nless delicate leader-member communications. For instance, considering managers’\nperformance in giving negative performance feedback to an employee in order to evaluate\nHR measures might provide a rationale to test the effectiveness of training and thus allow for\nfield studies. Such evidence from less critical contexts might convince organizations and\nmanagers to take part in future field studies focusing on layoffs. Future research should also\ntest the usefulness of training in terms of dealing with more diverse employee reactions (e.g.,\nanger, negotiation) as well as the effectiveness of more intensive training. More practical\nexercises could be provided in order to increase messengers’ mastery experience and selfefficacy expectations (Bandura, 1997), and a clearer discussion of the concerns in giving bad\nnews (Rosen &amp; Tesser, 1970) could be integrated in order to reduce messengers’ feelings of\nstress and emotional discomfort. Furthermore, it could be interesting to test the impact of\nadditional interventions. For example, providing supervision by an experienced manager or\nconsultant as a mentor before (e.g., for preparation) and after (e.g., for debriefing) a bad news\nconversation may be useful for sharing and qualifying experiences and thus for reducing\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n27\n\nfeelings of stress. We also do not know anything about the persistence of training effects, for\nexample whether participants are able to recall knowledge about the formal delivery of bad\nnews and procedural fairness principles if necessary.\nIn practical terms, our studies can be used to encourage organizations to implement\norganizational bad news training in human resource development, not only for the purpose of\npreparing managers for conducting layoffs, but also for improving critical leader-member\ninteractions in general. Since managers have to give bad news to their employees regularly\n(e.g., performance reviews, working overtime), preserving positive relationships between the\nemployees on the one hand and the managers or the organization, respectively, on the other\nshould be a common goal. Organizational bad news training should therefore be provided to\nmanagers not only right before a bad news event, but rather continuously as a part of their\nleadership development. Since our studies showed that training can be used to make the\ndelivery of bad news both more structured and fairer, and also that negative responses of the\nrecipients may be reduced, it is likely that organizations will benefit from implementing\norganizational bad news training as well: If an employer is perceived as being fair, employees\nmight react with fewer harmful behaviors, thus improving or maintaining positive\norganizational outcomes (Cohen-Charash &amp; Spector, 2001; Colquitt et al., 2001).\nIn conclusion, much work has been done on describing the negative consequences of\nunfairness or the positive consequences of fairness when implementing unfavorable outcomes\nat work (Gilliland, 1994; Holbrook, 1999; Konovsky &amp; Folger, 1991). Given the\ncommonness of bad news conversations between supervisors and their employees, however,\nmuch work remains to be done on preparing managers for this challenging task in order to\navoid these negative consequences. Organizational bad news training that focuses on both\ndelivery and fairness issues in giving bad news seems to be a promising way to minimize\nharm for all involved.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n28\n\nReferences\nAndrzejewski, L., &amp; Refisch, H. (2015). Trennungs-Kultur und Mitarbeiterbindung:\nKündigungen, Aufhebungen, Versetzungen fair und effizient gestalten [Separation\nculture and employees’ commitment: Managing layoffs, terminations, and transfers\nwith fairness and efficiency] (4th ed.). Cologne, Germany: Luchterhand.\nBaer, A. N., Freer, J. P., Milling, D. A., Potter, W. R., Ruchlin, H., &amp; Zinnerstrom, K. H.\n(2008). Breaking bad news: Use of cancer survivors in role-playing exercises. Journal\nof Palliative Medicine, 11, 885–892. doi:10.1089/jpm.2007.0253\nBaile, W. F., Buckman, R., Lenzi, R., Glober, G., Beale, E. A., &amp; Kudelka, A. P. (2000).\nSPIKES—A six-step protocol for delivering bad news: Application to the patient with\ncancer. Oncologist, 5, 302–311. doi:10.1634/theoncologist.5-4-302\nBaile, W. F., Kudelka, A. P., Beale, E. A., Glober, G. A., Myers, E. G., Greisinger, A. J., …\nLenzi, R. (1999). Communication skills training in oncology. Cancer, 86, 887–897.\ndoi:10.1002/(SICI)1097-0142(19990901)86:5&lt;887::AID-CNCR27&gt;3.0.CO;2-X\nBandura, A. (1997). Self-efficacy: The exercise of control. New York, NY: Worth Publishers.\nBarclay, L. J., Skarlicki, D. P., &amp; Pugh, S. D. (2005). Exploring the role of emotions in\ninjustice perceptions and retaliation. Journal of Applied Psychology, 90, 629–643.\ndoi:10.1037/0021-9010.90.4.629\nBaumeister, R. F., Bratslavsky, E., Finkenauer, C., &amp; Vohs, K. D. (2001). Bad is stronger\nthan good. Review of General Psychology, 5, 323–370. doi:10.1037/1089-2680.5.4.323\nBies, R. J. (2013). The delivery of bad news in organizations: A framework for analysis.\nJournal of Management, 39, 136–162. doi:10.1177/0149206312461053\nBond, C. F., &amp; Anderson, E. L. (1987). The reluctance to transmit bad news: Private\ndiscomfort or public display? Journal of Experimental Social Psychology, 23, 176–187.\ndoi:16/0022-1031(87)90030-8\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n29\n\nBonnaud-Antignac, A., Campion, L., Pottier, P., &amp; Supiot, S. (2010). Videotaped simulated\ninterviews to improve medical students’ skills in disclosing a diagnosis of cancer.\nPsycho-Oncology, 19, 975–981. doi:10.1002/pon.1649\nBuckman, R. (1992). How to break bad news: A guide for health care professionals.\nBaltimore, MD: Johns Hopkins University Press.\nClair, J. A., &amp; Dufresne, R. L. (2004). Playing the grim reaper: How employees experience\ncarrying out a downsizing. Human Relations, 57, 1597–1625.\ndoi:10.1177/0018726704049991\nCohen-Charash, Y., &amp; Spector, P. E. (2001). The role of justice in organizations: A metaanalysis. Organizational Behavior and Human Decision Processes, 86, 278–321.\ndoi:10.1006/obhd.2001.2958\nCohen, L., Baile, W. F., Henninger, E., Agarwal, S. K., Kudelka, A. P., Lenzi, R., …\nMarshall, G. D. (2003). Physiological and psychological effects of delivering medical\nnews using a simulated physician-patient scenario. Journal of Behavioral Medicine, 26,\n459–471. doi:10.1023/A:1025724118504\nCole, N. D., &amp; Latham, G. P. (1997). Effects of training in procedural justice on perceptions\nof disciplinary fairness by unionized employees and disciplinary subject matter experts.\nJournal of Applied Psychology, 82, 699–705. doi:10.1037/0021-9010.82.5.699\nColquitt, J. A. (2001). On the dimensionality of organizational justice: A construct validation\nof a measure. Journal of Applied Psychology, 86, 386–400. doi:10.1037/00219010.86.3.386\nColquitt, J. A., Conlon, D. E., Wesson, M. J., Porter, C. O. L. H., &amp; Ng, K. Y. (2001). Justice\nat the millennium: A meta-analytic review of 25 years of organizational justice\nresearch. Journal of Applied Psychology, 86, 425–445. doi:10.1037/00219010.86.3.425\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n30\n\nCox, S. S., Marler, L. E., Simmering, M. J., &amp; Totten, J. W. (2011). Giving feedback:\nDevelopment of scales for the mum effect, discomfort giving feedback, and feedback\nmedium preference. Performance Improvement Quarterly, 23, 49–69.\ndoi:10.1002/piq.20094\nDatta, D. K., Guthrie, J. P., Basuil, D., &amp; Pandey, A. (2010). Causes and effects of employee\ndownsizing: A review and synthesis. Journal of Management, 36, 281–348.\ndoi:10.1177/0149206309346735\nDeRouin, R. E., Fritzsche, B. A., &amp; Salas, E. (2005). E-learning in organizations. Journal of\nManagement, 31, 920–940. doi:10.1177/0149206305279815\nDestatis [Federal Statistical Office]. (2015). Rechtspflege - Arbeitsgerichte 2014 [Judicature\n– Labor courts 2014]. Wiesbaden, Germany: Statistisches Bundesamt. Retrieved from\nhttps://www.destatis.de/DE/Publikationen/Thematisch/Rechtspflege/GerichtePersonal/\nArbeitsgerichte2100280147004.pdf?__blob=publicationFile\nDubiecki, D., Clifford, J., Reitman, I., (Producers) &amp; Reitman, J. (Producer and Director)\n(2009). Up in the Air [Motion Picture]. United States: Paramount Pictures.\nElicker, J. D., Levy, P. E., &amp; Hall, R. J. (2006). The role of leader-member exchange in the\nperformance appraisal process. Journal of Management, 32, 531–551.\ndoi:10.1177/0149206306286622\nFolger, R., &amp; Skarlicki, D. P. (1998). When tough times make tough bosses: Managerial\ndistancing as a function of layoff blame. Academy of Management Journal, 41, 79–87.\ndoi:10.2307/256899\nFurr, R. M., &amp; Rosenthal, R. (2003). Evaluating theories efficiently: The nuts and bolts of\ncontrast analysis. Understanding Statistics, 2, 33–67.\ndoi:10.1207/S15328031US0201_03\nGilliland, S. W. (1994). Effects of procedural and distributive justice on reactions to a\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n31\n\nselection system. Journal of Applied Psychology, 79, 691–701. doi:10.1037/00219010.79.5.691\nGreenberg, J. (1990). Employee theft as a reaction to underpayment inequity: The hidden cost\nof pay cuts. Journal of Applied Psychology, 75, 561–568. doi:10.1037/00219010.75.5.561\nGrunberg, L., Moore, S. Y., &amp; Greenberg, E. S. (2001). Differences in psychological and\nphysical health among layoff survivors: The effect of layoff contact. Journal of\nOccupational Health Psychology, 6, 15–25. doi:10.1037/1076-8998.6.1.15\nGrunberg, L., Moore, S. Y., &amp; Greenberg, E. S. (2006). Managers’ reactions to implementing\nlayoffs: Relationship to health problems and withdrawal behaviors. Human Resource\nManagement, 45, 159–178. doi:10.1002/hrm.20102\nHolbrook, R. L. J. (1999). Managing reactions to performance appraisal: The influence of\nmultiple justice mechanisms. Social Justice Research, 12, 205–220.\ndoi:10.1023/A:1022196301372\nIlgen, D. R., &amp; Davis, C. A. (2000). Bearing bad news: Reactions to negative performance\nfeedback. Applied Psychology, 49, 550–565. doi:10.1111/1464-0597.00031\nKahn, R. L., Wolfe, D. M., Quinn, R. P., &amp; Snoek, J. D. (1964). Organizational stress:\nStudies in role conflict and ambiguity. New York, NY: Wiley.\nKernan, M. C., &amp; Hanges, P. J. (2002). Survivor reactions to reorganization: Antecedents and\nconsequences of procedural, interpersonal, and informational justice. Journal of\nApplied Psychology, 87, 916–928. doi:10.1037/0021-9010.87.5.916\nKets de Vries, M. F. R., &amp; Balazs, K. (1997). The downside of downsizing. Human\nRelations, 50, 11–50. doi:10.1177/001872679705000102\nKonovsky, M. A., &amp; Folger, R. (1991). The effects of procedures, social accounts, and\nbenefits level on victims’ layoff reactions. Journal of Applied Social Psychology, 21,\n\nORGANIZATIONAL BAD NEWS TRAINING\n630–650. doi:10.1111/j.1559-1816.1991.tb00540.x\nLavelle, J. J., Folger, R., &amp; Manegold, J. G. (2014). Delivering bad news: How procedural\nunfairness affects messengers’ distancing and refusals. Journal of Business Ethics, 1–\n13. doi:10.1007/s10551-014-2500-5\nLemons, M. A., &amp; Jones, C. A. (2001). Procedural justice in promotion decisions: using\nperceptions of fairness to build employee commitment. Journal of Managerial\nPsychology, 16, 268–281. doi:10.1108/02683940110391517\nLeventhal, G. S. (1980). What should be done with equity theory? New approaches to the\nstudy of fairness in social relationships. In K. J. Gergen, M. S. Greenberg, &amp; R. H.\nWillis (Eds.), Social exchange: Advances in theory and research (pp. 27–55). New\nYork, NY: Plenum.\nMcKee-Ryan, F., Song, Z., Wanberg, C. R., &amp; Kinicki, A. J. (2005). Psychological and\nphysical well-being during unemployment: A meta-analytic study. Journal of Applied\nPsychology, 90, 53–76. doi:10.1037/0021-9010.90.1.53\nMolinsky, A., &amp; Margolis, J. (2005). Necessary evils and interpersonal sensitivity in\norganizations. Academy of Management Review, 30, 245–268. doi:10.2307/20159118\nOrgel, E., McCarter, R., &amp; Jacobs, S. (2010). A failing medical educational model: A selfassessment by physicians at all levels of training of ability and comfort to deliver bad\nnews. Journal of Palliative Medicine, 13, 677–683. doi:10.1089/jpm.2009.0338\nParker, T., &amp; McKinley, W. (2008). Layoff agency: A theoretical framework. Journal of\nLeadership &amp; Organizational Studies, 15, 46–58. doi:10.1177/1548051808318001\nPaul, K. I., &amp; Moser, K. (2009). Unemployment impairs mental health: Meta-analyses.\nJournal of Vocational Behavior, 74, 264–282. doi:10.1016/j.jvb.2009.01.001\nPreacher, K. J., &amp; Hayes, A. F. (2004). SPSS and SAS procedures for estimating indirect\neffects in simple mediation models. Behavior Research Methods, Instruments, &amp;\n\n32\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n33\n\nComputers, 36, 717–731. doi:10.3758/BF03206553\nRichter, M., &amp; König, C. J. (2013). Professionelles Trennungsmanagement: Wie\nFührungskräfte geschult werden [Professional redundancy management: How managers\nare trained]. Wirtschaftspsychologie Aktuell, 20(1), 15–18.\nRosenbaum, M. E., Ferguson, K. J., &amp; Lobas, J. G. (2004). Teaching medical students and\nresidents skills for delivering bad news: A review of strategies. Academic Medicine, 79,\n107–117. doi:10.1097/00001888-200402000-00002\nRosen, S., &amp; Tesser, A. (1970). On reluctance to communicate undesirable information: The\nMUM effect. Sociometry, 33, 253–263. doi:10.2307/2786156\nSkarlicki, D. P., &amp; Latham, G. P. (1996). Increasing citizenship behavior within a labor\nunion: A test of organizational justice theory. Journal of Applied Psychology, 81, 161–\n169. doi:10.1037/0021-9010.81.2.161\nSkarlicki, D. P., &amp; Latham, G. P. (1997). Leadership training in organizational justice to\nincrease citizenship behavior within a labor union: A replication. Personnel\nPsychology, 50, 617–633. doi:10.1111/j.1744-6570.1997.tb00707.x\nSkarlicki, D. P., &amp; Latham, G. P. (2005). How can training be used to foster organizational\njustice? In J. Greenberg &amp; J. A. Colquitt (Eds.), Handbook of organizational justice\n(pp. 499–522). Mahwah, NJ: Erlbaum.\nSronce, R., &amp; McKinley, W. (2006). Perceptions of organizational downsizing. Journal of\nLeadership &amp; Organizational Studies, 12, 89–108. doi:10.1177/107179190601200406\nStajkovic, A. D., &amp; Luthans, F. (1998). Self-efficacy and work-related performance: A metaanalysis. Psychological Bulletin, 124, 240–261. doi:10.1037/0033-2909.124.2.240\nTesser, A., &amp; Rosen, S. (1972). Similarity of objective fate as a determinant of the reluctance\nto transmit unpleasant information: The MUM effect. Journal of Personality and Social\nPsychology, 23, 46–53. doi:37/h0032881\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n34\n\nTetrick, L. E., &amp; LaRocco, J. M. (1987). Understanding, prediction, and control as\nmoderators of the relationships between perceived stress, satisfaction, and\npsychological well-being. Journal of Applied Psychology, 72, 538–543.\ndoi:10.1037/0021-9010.72.4.538\nTonidandel, S., &amp; LeBreton, J. M. (2013). Beyond step-down analysis: A new test for\ndecomposing the importance of dependent variables in MANOVA. Journal of Applied\nPsychology, 98, 469–477. doi:10.1037/a0032001\nTrobst, K. K., Collins, R. L., &amp; Embree, J. M. (1994). The role of emotion in social support\nprovision: Gender, empathy and expressions of distress. Journal of Social and Personal\nRelationships, 11, 45–62. doi:10.1177/0265407594111003\nvan Dierendonck, D., &amp; Jacobs, G. (2012). Survivors and victims, a meta-analytical review of\nfairness and organizational commitment after downsizing. British Journal of\nManagement, 23, 96–109. doi:10.1111/j.1467-8551.2010.00724.x\nWanberg, C. R., Bunce, L. W., &amp; Gavin, M. B. (1999). Perceived fairness of layoffs among\nindividuals who have been laid off: A longitudinal study. Personnel Psychology, 52,\n59–84. doi:10.1111/j.1744-6570.1999.tb01813.x\nWatson, D., Clark, L. A., &amp; Tellegen, A. (1988). Development and validation of brief\nmeasures of positive and negative affect: The PANAS scales. Journal of Personality\nand Social Psychology, 54, 1063–1070. doi:10.1037//0022-3514.54.6.1063\nWood, M. S., &amp; Karau, S. J. (2009). Preserving employee dignity during the termination\ninterview: An empirical examination. Journal of Business Ethics, 86, 519–534.\ndoi:10.1007/s10551-008-9862-5\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n35\n\nFootnotes\n1\n\nThe scenario used in Studies 1 and 2 is available online as supplemental materials\n\n(Supplement A).\n2\n\nLayoff victims’ statements were inspired from practical reports of managers and\n\nconsultants (Andrzejewski &amp; Refisch, 2015; Richter &amp; König, 2013). Although the reaction\n“And if I kill myself?” might seem very challenging to the reader, Andrzejewski and Refisch\ncaution managers to take suicidal intentions seriously, and this problem is also addressed in\nthe movie Up in the Air (Dubiecki et al., 2009) cited at the beginning of the article.\n3\n\nMore detailed information about the items developed for Studies 1 and 2 is available\n\nonline as supplemental materials (Supplement B). Unfortunately, we had to exclude the\nlayoff victims’ ratings of procedural fairness in Study 1 because of poor scale quality. As a\nconsequence, we reduced the number of role-players in Study 2 to improve rating quality.\n4\n\nIn Study 1, we also computed all analyses adding participants’ past layoff experiences\n\nand gender as covariates because experiences with layoffs might have shaped their attitudes\ntowards downsizing and therefore their performance in the dismissal meeting (Sronce &amp;\nMcKinley, 2006) and because women might have been more empathic and supportive than\nmen towards the layoff victim (Trobst, Collins, &amp; Embree, 1994). We also included layoff\nvictims’ gender as a covariate because participants might have responded differentially\ntowards a man or a woman losing his/her job. We did not find any significant changes in our\nresults considering the covariates, except for participants’ confidence which turned\nsignificant (p = .04). In Study 2, considering covariates did not change the results at all.\n5\n\nFurther information about the quality checks with subject matter experts is available\n\nonline as supplemental materials (Supplement C).\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n36\n\nTable 1\nTraining Modules for Studies 1 and 2\nNo.\n\nModule\n\nMethod\n\nDescription\n\nCondition\n\nStudy 1\nRole of a layoff agent Information about layoffs, the role and responsibilities of a leader Lecture\nand a layoff agent\n\nStudy 2\nLecture\n\n2\n\nFairness and\ncommunication\n\nImportance and enactment of procedural fairness principles:\n Consistency (e.g., be coherent, be unambiguous)\n Bias suppression (e.g., be objective, be impartial)\n Accuracy (e.g., provide reasonable explanations)\n Representativeness (e.g., allow voice, active listening)\n Ethicality (e.g., mention contributions, be polite)\n\nLecture\nDiscussion\n\nLecture\nVideo aids\n\nTraining\n\n3\n\nFormal delivery\nof bad news\n\nStep-by-step protocol of giving bad news:\n1. Arranging the setting (e.g., private room)\n2. Delivering the bad news immediately\n3. Explaining the reasons for the decision in detail\n4. Managing the employee’s emotions\n5. Future planning / follow-up measures (e.g., job coaching)\n6. Summary / finishing the meeting\n\nLecture\nDiscussion\n\nLecture\nVideo aids\n\nTraining\nBasics\n\n4\n\nEmployee reactions\n\nCoping with employee reactions (i.e., shock, anger, negotiation)\n\nLecture\nDiscussion\n\nLecture\nTraining\nWritten exercise Basics\n\n5\n\nRehearsal\n\nPracticing a dismissal meeting in a role-playing exercise\nBehavioral feedback from a trainer\n\nLive role-play\nFeedback\n\nVirtual role-play Training\nFeedback\n\n1\n\nTraining\nBasics\n\nNote. In Study 2, discussion elements from classroom training in Study 1 were replaced with visual materials (e.g., clips and videos) or written exercises (e.g., quiz). The basics\ngroup received only written information about the modules and no discussion or visual aids as compared to the training group. The rehearsal during the training intervention was\ndifferent from the simulated dismissal meeting during the testing sessions. The testing happened live in both studies.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n37\n\nTable 2\nMeans, Standard Deviations, and Zero-Order Correlations (Study 1)\nVariable\n\nM\n\nSD\n\n1\n\n.51\n\n.50\n\n––\n\n2. Negative affect\n\n2.34\n\n0.64\n\n–.09 (.84)\n\n3. Confidence\n\n3.19\n\n0.71\n\n.27 –.36** (.85)\n\n4. Elements\n\n4.53\n\n1.29 .62** –.13\n\n.31*\n\n––\n\n5. Flexibility\n\n3.56\n\n0.66 .64** –.26\n\n.20\n\n.83** (.74)\n\n6. Consistency\n\n3.77\n\n0.78 .68** –.31*\n\n.18\n\n.60** .73** (.82)\n\n7. Bias suppression\n\n3.75\n\n0.83 .64** –.20\n\n.04\n\n.64** .74** .77** (.81)\n\n8. Accuracy\n\n3.58\n\n0.65 .60** –.04\n\n.20\n\n.78** .75** .72** .72** (.77)\n\n9. Representativeness\n\n3.48\n\n0.73 .48** –.08\n\n.21\n\n.55** .58** .47** .46** .57** (.74)\n\n1. Condition\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\nLayoff agent self-reports\n\nLayoff observer ratings\n\n10. Ethicality\n3.82 0.83 .47** –.29* .08 .52** .58** .63** .63** .68** .52** (.79)\nNote. N = 51. Condition: 0 = control group, 1 = training group. Elements = whether participants complied with\nthe elements of the step-by-step protocol of giving bad news; Flexibility = whether participants used the protocol\nin a flexible way. Cronbach’s alpha coefficients are displayed in parentheses where applicable.\n* p &lt; .05. ** p &lt; .01.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n38\n\nTable 3\nResults of t-Tests and Relative Weights (Study 1)\nCondition\nTraining\nControl\n(n = 26)\n(n = 25)\n\nt-Test\nRelative\nweight\n\nConfidence\ninterval\nLower Upper\n95% CI 95% CI\n\nM\n\nSD\n\nM\n\nSD\n\nt(49)\n\nd\n\nNegative affect\n\n2.40\n\n0.69\n\n2.28\n\n0.59\n\n–0.66\n\n–0.19\n\nConfidencea\n\n3.00\n\n0.70\n\n3.39\n\n0.69\n\n1.98\n\n0.56\n\nElements\n\n3.72\n\n1.17\n\n5.31\n\n0.84\n\n5.58**\n\n1.56\n\nFlexibility\n\n3.13\n\n0.61\n\n3.97\n\n0.39\n\n5.85**\n\n1.64\n\nConsistency\n\n3.24\n\n0.70\n\n4.28\n\n0.42\n\n6.46**\n\n1.80\n\n.205\n\n.079\n\n.359\n\nBias suppression\n\n3.21\n\n0.84\n\n4.26\n\n0.38\n\n5.81**\n\n1.61\n\n.138\n\n.032\n\n.298\n\nAccuracy\n\n3.18\n\n0.56\n\n3.95\n\n0.50\n\n5.22**\n\n1.45\n\n.088\n\n.014\n\n.209\n\nRepresentativeness\n\n3.13\n\n0.68\n\n3.82\n\n0.61\n\n3.79**\n\n1.07\n\n.070\n\n.002\n\n.189\n\nLayoff agent self-reports\n\nLayoff observer ratings\nFormal delivery\n\nProcedural fairness\n\nEthicality\n3.43 0.90\n4.20 0.56\n3.71** 1.03\n.021\n&lt; .001\n.121\nNote. Elements = whether participants complied with the elements of the step-by-step protocol of giving bad\nnews; Flexibility = whether participants used the protocol in a flexible way. Relative weight analysis was only\ncomputed for the procedural fairness variables. Raw weights and 95% confidence interval around the raw\nweights are displayed.\na\nOne participant did not provide confidence information, resulting in df = 48 for this variable.\n* p &lt; .05. ** p &lt; .01.\n\nORGANIZATIONAL BAD NEWS TRAINING\n\n39\n\nTable 4\nMeans, Standard Deviations, and Zero-Order Correlations (Study 2)\nVariable\nM\nSD\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n1. Condition\n1.00 0.82 ––\nLayoff agent self-reports\n2. Negative affect\n2.29 0.58 –.26* (.79)\n3. Distress\n3.78 0.86 .02 .56** (.87)\n4. Confidence\n3.28 0.74 .05 –.42** –.51** (.85)\nLayoff observer ratings\n5. Elements\n4.77 1.21 .68** –.12 –.14 .10\n––\n6. Flexibility\n3.57 0.62 .63** –.16 –.09 .24* .76** (.73)\n7. Consistency\n3.84 0.72 .73** –.23* –.01 .16 .54** .63** (.89)\n8. Bias suppression\n3.51 0.70 .76** –.19 –.00 .13 .52** .68** .85** (.83)\n9. Accuracy\n3.00 0.76 .57** –.10 .11\n.16 .51** .77** .62** .69** (.93)\n10. Representativeness\n3.28 1.04 .52** –.10 .15\n.11 .43** .62** .55** .64** .79** (.94)\n11. Ethicality\n3.54 0.87 .43** –.03 .21\n.06 .30** .53** .49** .62** .79** .85** (.94)\nLayoff victim ratings\n12. Consistency\n3.94 0.48 .49** –.01 .16\n.14 .41** .62** .56** .63** .70** .57** .64** (.82)\n13. Bias suppression\n3.65 0.61 .50** –.13 .15\n.11 .41** .53** .57** .64** .64** .64** .63** .58** (.70)\n14. Accuracy\n3.16 0.79 .34** –.05 .17\n.16 .32** .60** .47** .49** .84** .73** .78** .65** .72** (.93)\n15. Representativeness\n3.38 1.00 .31** .03\n.18\n.06 .29* .48** .46** .51** .64** .84** .77** .52** .68** .72** (.94)\n16. Ethicality\n3.77 0.82 .25* .05 .23* .06 .25* .41** .34** .42** .68** .78** .82** .54** .67** .81** .81** (.93)\n17. Anger\n3.06 0.99 –.33** –.06 –.26* .05 –.34** –.50** –.45** –.50** –.65** –.69** –.71** –.57** –.78** –.78** –.80** –.84** (.96)\n18. Complain\n3.07 0.82 –.34** –.01 –.24* .01 –.32** –.49** –.48** –.51** –.65** –.74** –.71** –.55** –.78** –.80** –.82** –.84** .94** (.92)\n19. Legal action\n2.95 1.11 –.32** –.00 –.25* .05 –.28* –.39** –.39** –.43** –.57** –.66** –.65** –.51** –.78** –.73** –.75** –.78** .92** .89** (.97)\nNote. N = 75. Condition: 0 = control group, 1 = basics group, 2 = training group. Elements = whether participants complied with the elements of the step-by-step protocol of\ngiving bad news; Flexibility = whether participants used the protocol in a flexible way. All measures were collected after the bad news conversation, except negative affect,\nwhich was measured beforehand. Cronbach’s alpha coefficients are displayed in parentheses where applicable.\n* p &lt; .05. ** p &lt; .01.\n\nTESTING BAD NEWS TRAINING\n\n40\n\nTable 5\nResults of Contrast Analyses and Relative Weights (Study 2)\nControl\n(n = 25)\nM\nSD\n\nCondition\nBasics\n(n = 25)\nM\nSD\n\nTraining\n(n = 25)\nM\nSD\n\nCritical\ncontrast\nt(72)\nrcontrast\n\nConfidence interval (CI)\nfor relative weights\nLower 95% CI Upper 95% CI\n\nRelative weight\nLayoff agent self-reports\nNegative affect\n2.43\n0.58\n2.38\n0.45\n2.06\n0.65\n1.52\n.18\nDistress\n3.79\n0.83\n3.71\n0.77\n3.84\n1.01\n0.08\n.01\nConfidence\n3.31\n0.86\n3.13\n0.69\n3.39\n0.65\n0.97\n.11\nLayoff observer ratings\nFormal delivery of bad news\nElements\n3.56\n1.00\n5.20\n0.76\n5.56\n0.77\n8.72**\n.72\nFlexibility\n3.08\n0.54\n3.62\n0.44\n4.02\n0.47\n6.22**\n.59\nProcedural fairness\nConsistency\n3.30\n0.61\n3.65\n0.43\n4.58\n0.34\n9.51**\n.75\n.148\n.064\n.234\nBias suppression\n3.03\n0.45\n3.17\n0.39\n4.33\n0.33\n12.79**\n.83\n.329\n.209\n.446\nAccuracy\n2.65\n0.59\n2.64\n0.48\n3.70\n0.66\n7.38**\n.66\n.065\n.011\n.142\nRepresentativeness\n2.92\n0.76\n2.68\n0.91\n4.24\n0.67\n7.51**\n.66\n.100\n.048\n.178\nEthicality\n3.39\n0.62\n2.91\n0.75\n4.31\n0.57\n7.21**\n.65\n.079\n.029\n.146\nLayoff victim ratings\nProcedural fairness\nConsistency\n3.73\n0.40\n3.80\n0.34\n4.30\n0.47\n5.35**\n.53\n.137\n.034\n.245\nBias suppression\n3.39\n0.52\n3.44\n0.56\n4.13\n0.47\n5.64**\n.55\n.143\n.029\n.289\nAccuracy\n3.02\n0.64\n2.78\n0.67\n3.67\n0.77\n4.54**\n.47\n.035\n&lt; .001\n.124\nRepresentativeness\n3.27\n0.84\n2.85\n1.00\n4.03\n0.81\n4.46**\n.47\n.057\n.002\n.162\nEthicality\n3.73\n0.66\n3.34\n0.85\n4.24\n0.71\n3.87**\n.41\n.011\n&lt; .001\n.063\nNegativity\nAnger\n3.32\n0.95\n3.35\n0.97\n2.52\n0.84\n3.61**\n.39\n.024\n&lt; .001\n.131\nComplain\n3.26\n0.78\n3.37\n0.83\n2.57\n0.64\n4.04**\n.43\n.107\n.019\n.248\nLegal action\n3.19\n1.16\n3.32\n1.02\n2.32\n0.88\n3.73**\n.40\n.060\n.001\n.195\nNote. rcontrast = effect size for contrast analyses. Critical contrasts are relevant for hypothesis testing: Contrast A (-2 1 1) for the formal delivery variables, Contrast B (2 -1 -1) for\nnegative affect and distress, Contrast C (-1 -1 2) for confidence, Contrast D (-1 -1 2) for the procedural fairness variables, and Contrast E (1 1 -2) for the negativity variables.\nRelative weight analyses were only computed for the procedural fairness and negativity variables comparing the training group with the other two groups. Raw weights and 95%\nconfidence intervals around the raw weights are displayed.\n* p &lt; .05. ** p &lt; .01.\n\nTESTING BAD NEWS TRAINING\n\n41\n\nTable 6\nResults of Mediation Analyses with Procedural Fairness as a Mediator and the Negativity Scales as Dependent Variables (Study 2)\nAnger\nPredictors\n\nB\n\nSE\n\n–0.82\n\n0.22\n\nF\n\nTotal R2\n\n13.23**\n\n.15\n\nt(72)\n\nModel 1\nCondition\n\nComplain\n\n–3.64**\n\n–0.75\n136.83**\n\nModel 2\n\nB\n\nSE\n0.18\n\nLegal action\nF\n\nTotal R2\n\n16.45**\n\n.18\n\nt(72)\n–4.06**\n\n.79\n\nB\n–0.94\n\n146.23**\n\nSE\n0.25\n\n.80\n\n–1.41\n\n0.09 –14.85**\n\n–1.16\n\n0.08 –15.01**\n\n–1.44\n\n0.13 –11.16**\n\nCondition\n\n0.23\n\n0.13\n\n0.11\n\n0.11\n\n0.13\n\n0.18\n\n1.04\n\nTotal R2\n\n14.10**\n\n.16\n\n81.27**\n\n.69\n\n–3.75**\n\nProcedural fairness\n\n1.72\n\nF\n\nt(72)\n\n0.71\n\nTest of the indirect effect\n\nTest of the indirect effect\n\nTest of the indirect effect\n\n–1.04 (0.21)\n\n–0.86 (0.17)\n\n–1.07 (0.22)\n\n–5.03**\n\n–5.03**\n\n–4.81**\n\n–1.04 (0.20)\n\n–0.86 (0.18)\n\n–1.07 (0.22)\n\nSobel test\nEffect (SE)\nZ\nBootstrap\nEffect (SE)\n\n95% CI\n[–1.44, –0.65]\n[–1.22, –0.51]\n[–1.54, –0.64]\nNote. N = 75. Condition: 0 = no-training groups (control, basics), 1 = training group. Procedural fairness = overall fairness score averaged over all procedural fairness items (as\nindicated by the layoff victims). Model 1 = Total effect, df = 1,73. Model 2 = Direct effect, controlling for mediator, df = 2,72. Indirect effect: If bootstrapped 95% confidence\nintervals (CI) do not include zero, indirect effects are significant.\n* p &lt; .05. ** p &lt; .01.\n\nORGANIZARTIONAL BAD NEWS TRAINING\n\n42\n\nSupplemental Materials\nSupplement A\nTesting Scenario for Studies 1 and 2\nGeneral instructions\nIn the following, you will have to perform a dismissal meeting from the perspective of a\nleader. Please read the following scenario and think about how to proceed during the meeting\nand which information might be important. You have about ten minutes of preparation time.\nPlease closely emphasize with your role as a leader and try to act as in a real situation.\nPlease note: An unprofessional dismissal meeting might have negative consequences for the\norganization, the laid-off employees and also for you as a leader. Please take care that you\nperform the dismissal meeting professionally.\nSituation\nYou are the leading manager of the customer support division of a mobile telephone provider.\nYour team members are well-versed in doing their job, and you enjoy being the leader of this\ndivision.\nDue to increasing demands for smart phones and changing market conditions, your company\nhas fallen behind. In 2011, your company reported declines in sales and stock prices. Thus,\ntop management has recently decided to initiate a strategic restructuring including a\nheadcount reduction of 20%. You have been nominated to assume the “responsible and\nimportant task” of implementing the downsizing in your division in a timely manner.\nDismissal meetings have to be conducted with five of your employees within in one month,\nand it is the first time you have to dismiss several employees at once.\nLayoffs are based on the poor order situation and the required strategic restructuring, which\nwill result in an automation of leads and outsourcing to external call centers. Accordingly, the\ncustomer support division is especially affected by layoffs. Both the works council and the\nHuman Resource department have developed social selection criteria to minimize negative\nconsequences of the planned layoffs. The selection criteria are job tenure (&lt; 10 years), age (&lt;\n45 years) and maintenance obligations towards spouse or children.\nInstruction for the role-played dismissal meeting\nYour first dismissal meeting is about to happen. Mrs. (or Mr.) Brauer is waiting outside your\nroom. She (He) is a loyal employee whom you hired in your early days as a manager at the\ncustomer support division. Mrs. (or Mr.) Brauer is responsible for troubleshooting services.\nShe (He) is valued for her (his) kindness and competence by your team as well as your\ncustomers. Mrs. (or Mr.) Brauer is 29 years old and has a young family with eight-year-old\ntwins. Her (His) spouse is also employed. In the past year, they have taken out a loan to build\na house. You have always had a good relationship to Mrs. (or Mr.) Brauer. Unfortunately, her\n(his) work will be transferred to local franchising companies. Alternative job opportunities in\nyour company have been checked, but are currently not available. Mrs. (or Mr.) Brauer has a\n\nORGANIZARTIONAL BAD NEWS TRAINING\n\n43\n\nshorter job tenure than her (his) colleagues, so the selection criteria pointed towards her (him)\nquite easily. Now, it is your turn to ask Mrs. (or Mr.) Brauer to come in so that you can\ndeliver the dismissal notice.\nIn compensation, you may offer Mrs. (or Mr.) Brauer half a month’s salary for each year of\nemployment. Termination of appointment is fixed eight weeks as from now. Additionally,\nyou may offer Mrs. (or Mr.) Brauer in-house applicant coaching to find a new job. Please\nfind further information about legal issues or family counseling services in the portfolio\nenclosed. Please use these materials during the dismissal meeting.\n\nORGANIZARTIONAL BAD NEWS TRAINING\nSupplement B\nMeasures Developed for Studies 1 and 2\n(* indicates items which were added or changed for Study 2)\n1. “Formal delivery of bad news” scales used in Studies 1 and 2\n(a) “Elements” of the bad news conversation\n1.\n2.\n3.\n4.\n5.\n6.\n\nDelivered the layoff message within the first five sentences.\nExplained the reasons for the layoff.\nWas responsive to the employee’s reactions.\nInformed about the next steps.\nProvided a follow-up appointment and brought the meeting to an end.\nComplied with the correct order of the elements.\n\n(b) “Flexibility” during the bad news conversation\n1. Prepared a common basis for the conversation.\n2. Introduced the particular steps proactively.\n3. Delineated the particular steps clearly.\n4. Dwelled on particular steps excessively. [reverse-coded]\n5. *Addressed particular steps insufficiently. [reverse-coded]\n6. Responded to the employee’s behavior flexibly.\n7. Was distracted by the employee’s objection. [reverse-coded]\n2. “Procedural fairness” scales used in Studies 1 and 2\n(a) Consistency\n1. Communicated consistently.\n2. Communicated ambiguously. [reverse coded]\n3. Remained binding.\n4. *Remained consequent and without contradictions.\n(b) Bias suppression\n1.\n2.\n3.\n4.\n\nAppeared to be impartial towards the employee.\nBased the conversation on occupational grounds only.\nArgued from the personal point of view only.\nRemained objectively and calm.\n\n(c) Accuracy\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\nAppeared to be impartial towards the employee.\nWas candid in communicating with the employee.\nEnsured that the employee realized the layoff.\nExposed the layoff decision in a clear and intelligible manner.\nTailored the explanations to the employee’s specific needs.\nUsed accurate information without hiding something.\nExplained the layoff thoroughly and reasonably.\n*Explained the layoff thoroughly.\n*Explained the layoff reasonably.\n\n44\n\nORGANIZARTIONAL BAD NEWS TRAINING\n\n45\n\n(d) Representativeness\n1.\n2.\n3.\n4.\n\nFacilitated the employee to express his/her views and feelings.\nReacted adequately to the employee’s questions, concerns and resistance.\nAllowed the employee to finish speaking.\nListened carefully.\n\n(e) Ethicality\n1.\n2.\n3.\n\nPaid tribute to the employee’s work done.\nMade improper remarks and comments. [reverse coded]\nBehaved in a polite and respectful manner.\n*Treated the employee in a polite manner.\n*Treated the employee with respect.\n4. Performed the dismissal meeting properly.\n*Treated the employee with dignity.\n*Upheld ethical and moral standards during the dismissal meeting.\n3. “Confidence” scale used in Studies 1 and 2\n1.\n2.\n3.\n4.\n5.\n6.\n\nI had difficulties in carrying out the dismissal meeting properly. [reverse-coded]\nI felt capable of conducting the dismissal meeting.\nI was able to address all issues well.\nI felt unable to cope with the task. [reverse-coded]\nI would do the dismissal meeting in the same way again.\nAll in all, I am satisfied with my performance during the dismissal meeting.\n\n4. “Distress” scale used in Study 2\n1.\n2.\n3.\n4.\n5.\n6.\n\nI didn’t like giving layoff news to the employee\nIt was not easy to give the dismissal notice\nI felt guilty after having given the dismissal notice\nIt was hard for me to tell the employee that she was dismissed\nI felt uncomfortable when dismissing the employee\nI was afraid about how the employee would react to the dismissal notice.\n\nORGANIZARTIONAL BAD NEWS TRAINING\n\n46\n\nSupplement C\nQuality Checks for Study 2\nObjectives of the Quality Checks\nGiven the limitation of our research to a laboratory setting, there might be concerns\nabout the realism of the conversations and the applicability of our concept of organizational\nbad news training to practice. As a solution, we surveyed subject matter experts with personal\nexperiences in conducting layoffs and received evidence for the applicability and realism of\nboth training and the dismissal meetings.\nSample and Method of the Quality Checks\nWe asked seven subject matter experts (three management consultants, two members of\nHR, and two managers) to review a sample of dismissal meeting conversations with regard to\nrealism. All 75 dismissal meetings tested in Study 2 had been audio recorded. Furthermore,\nthree management consultants evaluated our concept of organizational bad news training with\nregard to applicability and usefulness. The mean age of the experts was 47 years (SD = 7\nyears) with an average job tenure of 21 years (SD = 9 years); four of them were female.\nExperts were not informed about the training modalities or the purpose of our studies, and all\nof them had much experience in conducting layoffs.\nRegarding realism of the dismissal meetings, experts were presented with three\nrecordings, one from each the control group, the basics group, and the training group. We\nchose examples that were closest to the average performance scores of their reference groups\nand asked experts to indicate the perceived realism on seven items (e.g., “The way the\ndismissal meeting was conducted was realistic”, “I believe that a ‘real’ manager would say\nsomething similar in a dismissal meeting”), using five-point scales ranging from 1 =\n“strongly disagree” to 5 = “strongly agree.” We also asked them to verbally describe their\nsubjective impression after having listened to the recordings, to indicate the best and the\n\nORGANIZARTIONAL BAD NEWS TRAINING\n\n47\n\ncommonest of the three examples, and to estimate how often (1 = “never” to 5 = “very\noften”) managers are prepared for dismissal meetings presenting five different formats (i.e.,\n“No preparation”, “Examining the employee’s personnel records”, “Consultation with\nsupervisor or HR”, “Training on legal aspects”, and “Training on more psychological\naspects”).\nRegarding applicability to practice, three experts gained access to the web-based\ntraining materials and were asked to evaluate training on five items (e.g., “This training\nconcept may be applicable to practice in a similar fashion”, “In general, I think training is\nsuitable for use in practice”), using five-point scales ranging from 1 = “strongly disagree” to\n5 = “strongly agree.” They were also asked to indicate how important (1 = “not important at\nall” to 5 = “very important”) they consider the five training modules and how often (1 =\n“never” to 5 = “very often”) similar contents are part of practical dismissal training.\nResults of the Quality Checks\nRegarding subject matter experts’ ratings of the realism of the dismissal meetings, all\nexamples were rated as fairly realistic (M = 3.73, SD = 0.37 for the control group; M = 3.82,\nSD = 0.41 for the basics group; M = 4.08, SD = 0.22 for the training group). Although six of\nthe seven experts indicated that the training group performed best, four of the seven experts\ndesignated the example of the basics group and two the example of the control group to be\ncommonest in practice.\nAn expert described her impression about the control group as follows: “Both the\nsupervisor and the employee are unable to cope with the situation, and this fits practice very\nwell.” An expert’s impression about the basics group was: “Very forceful, very technical,\nlittle emotional responsiveness. Unfortunately, this makes it very practical.” An expert’s\nimpression of the training group was: “The manager allows for a dialog, but remains\nconsistent and strong. […] seems to be the least distressed of the three examples.”\n\nORGANIZARTIONAL BAD NEWS TRAINING\n\n48\n\nFurthermore, experts indicated that managers most often prepare dismissal meetings in\nterms of “Consultation with supervisor or HR” (M = 4.00, SD = 0.82). The other ratings were\n“Examining the employee’s personnel records” (M = 3.86, SD = 0.38), “Using a checklist”\n(M = 3.57, SD = 0.98), “Training on legal aspects” (M = 3.00, SD = 0.58), “Training on more\npsychological aspects” (M = 2.43, SD = 0.53), and “No preparation” (M = 2.14, SD = 0.69).\nRegarding experts’ ratings of the applicability to practice, training was evaluated as\nfairly useful and applicable (M = 3.80, SD = 0.60). All modules were rated as important to\nvery important (all M’s &gt; 4). In particular, both the step-by-step guidelines of giving bad\nnews and supervisors’ fairness were perceived as very important (M = 5.00) by all experts;\nhowever, whereas some kind of structure for the formal delivery of bad news is often\nprovided to managers in practical dismissal training (M = 4.67, SD = 0.58), fairness issues are\nonly sometimes addressed (M = 2.67, SD = 0.58).\nDiscussion of the Quality Checks\nIn summary, subject matter experts perceived training as fairly useful for practical\npurposes and the dismissal meetings as fairly realistic, thus lowering concerns about\nartificiality and generalizability. They also indicated that training in delivering layoff news is\nrare in practice and that managers are most often prepared in terms of consultations with their\nsupervisors or members of the human resource department. Furthermore, if training is\nprovided to managers, it usually includes information about the formal delivery of layoff\nnews, whereas fairness issues are only rarely addressed. Given the finding that experts also\nindicated the “unfair” conversations (i.e., the control group and the basics group) to be\ncommonest, there seem to be demands for fairness training in practice.\n\n</td>
    </tr>
    <tr>
      <th>75</th>
      <td>news</td>
      <td>Google’s Top Stories and the Fairness Doctrine: Unbalanced Amplification of\nFar-Right News Sources\nEni Mustafaraj\neni.mustafaraj@wellesley.edu\nDepartment of Computer Science\nWellesley College, Wellesley, MA\n\nAbstract\nGoogle’s Top stories is a component of Google Search\nthat frequently surfaces current news when a user performs a search. Our one-year long audit of Google’s\nsearch results for the candidates of the 2020 US Presidential Elections indicated that the composition of the\nTop stories panel shows an unbalanced amplification of\nfar-right news publishers.\n\nIntroduction\nIn their book “Network Propaganda” (Benkler, Faris, and\nRoberts 2018), the authors consider a set of actors and technological drivers that have been identified as causing the\npresent state of information disorder, among others, “fake\nnews” entrepreneurs, political clickbait fabricators; Russian hackers, bots, and sockpuppets; the Facebook Newsfeed algorithm and online echochambers; Cambridge Analytica; and white supremacists and alt-right trolls. Ultimately, they settle on the right-wing media ecosystem as\n“the primary culprit in sowing confusion and distrust in the\nbroader American media ecosystem.” Their analysis is based\non three sources of data: the open web, Facebook news sharing, and Twitter news sharing. Although the book doesn’t\naddress the question of how people access news on the Web,\nit appears to suggest the primacy of social media in this respect. In the aftermath of the 2016 US Election, Facebook\nmade changes to its news feed algorithm that reduced the\namount of referral traffic to other websites. Thus, since 2017,\nsearch engines have directed more traffic to news websites\nthan social media.1\nAs the amount of search engine referrals to news sources\nincreases, it is worth investigating what news is shown by\nsearch engines. Since 2016, Google, the most used search\nengine, has modified its search results page (SERP) interface\nto show Top stories, a panel of up to 10 headlines accompanied by images, near the top of the SERP. When the search\nterm concerns events or people in the news, Top stories is\nthe first element of the page shown on mobile and desktop\ndevices. Given that thousands of stories from thousands of\nCopyright c 2020, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n1\nhttps://www.businessinsider.com/search-engines-more-trafficpublishers-social-media-2017-2018-2\n\nnews sources are written daily, by selecting only a few of\nthem at a time, Google’s Top stories is engaging in what is\nknown as “algorithmic news curation” (Diakopoulos 2019).\nIf algorithms are curating news, what choices are they\nmaking, especially with respect to news sources with problematic credibility? Concretely, are the right-wing publications identified in (Benkler, Faris, and Roberts 2018) as the\ncause of our current information disorder (pre- and post2016 US Election) being promoted by Google Top stories?\nDoes that apply to left-wing publications?\n\nFigure 1: Google’s Top stories panel for Joe Biden on Oct 2,\n2019. All three stories are from news sources considered as\n“right-wing” or “far-right” (partisan audience bias &gt; 0.5).\nThis line of research, which falls under the umbrella of algorithm auditing (Sandvig et al. 2014), is important for two\nreasons: 1) more people use search engines than social media on a daily basis. If they are being exposed to news in this\nway, we need to understand how algorithms are curating the\nnews; 2) there is evidence that as many as half of all search\nqueries don’t lead to clicks,2 because a user’s information\nneed is fulfilled by the SERP content. Thus, the news headlines that a user sees in Top stories might be all they remember about a news event. Taken together, these headlines can\nframe issues in a partisan way and help with media agenda\nsetting. To exemplify, Google’s Top news panel on Figure 1\n2\nhttps://searchengineland.com/49-of-all-google-searches-areno-click-study-finds-318426\n\nshows an occasion in which all three headlines are from farright news sources, and critical of candidate Joe Biden.\n\nData\nWe have been auditing Google’s Top stories for the coverage\nof the 2020 US Presidential Elections since December 2018\n(Kawakami, Umarova, and Mustafaraj 2020). Although we\nhave data for 30 candidates, we focus here only on the top\nfive Democratic candidates and the incumbent president,\nDonald Trump. Our auditing system has captured the list\n(and ordering) of ten top stories multiple times a day. Approximately, we collected 80,000 news articles from 2,168\nnews sources. We then use the Partisan Audience Bias scores\ndataset (Robertson et al. 2018) to assign a partisanship score\nto news sources. The scores are between -1 (far left) to +1\n(far right). For example, Breitbart News has a score of 0.74\nand LGTBQ Nation a score of -0.77. To simplify our analysis, sources with scores (-1, -0.5) are labeled as “far left”,\nthose in (-0.5, 0.0) as “center left”, those in (0.0, +0.5) as\n“center right”, and those in (+0.5, +1) as “far right”. These\nnumbers reflect the partisanship of their audience and might\nnot be an objective measure of the news sources bias.\n\nResults\nFor each of the four categories above, we calculated the proportion of occurrences of news articles from corresponding\nnews outlets. The results are summarized in Table 1. What is\nimportant to notice here is the dominance of the “center left”\nsources (which is known as mainstream media) especially\nfor Donald Trump, as well as the disproportionate amount\nof far-right media coverage, especially for the front-runner\nDemocratic candidate, Joe Biden.\nCandidate\nDonald Trump\nJoe Biden\nBernie Sanders\nElizabeth Warren\nAmy Klobuchar\nPete Buttigieg\n\nFL\n8.7%\n9.0%\n15.2%\n11.5%\n8.8%\n10.7%\n\nCL\n64.9%\n51.9%\n50.4%\n53.5%\n57.2%\n52.9%\n\nCR\n17.6%\n16.1%\n18.0%\n19.3%\n17.2%\n21.1%\n\nFR\n8.3%\n22.1%\n14.3%\n14.6%\n12.7%\n11.6%\n\nTable 1: The proportion of Top stories’ news articles for four\ngroups of partisan audience bias: FL - Far Left, CL - Center\nLeft, CR - Center Right, FR - Far Right.\nThis unbalanced coverage of Joe Biden is captured better\nin Figure 2, which shows the stark contrast between all four\ngroups of media. There was a reason for this: Joe Biden was\nseen as the candidate who was most likely to beat President\nTrump in the election. Thus, news outlets who support the\npresident focused on aggressively covering Biden’s candidacy. Meanwhile, far-left sources focused more on Bernie\nSanders, given his political ageenda.\n\nDiscussion\nIs Google’s Top stories algorithm reflecting user’s demand\nfor news; the uneven supply from the news publishers; or\ntrying to impose the so-called “fairness doctrine” (Simmons\n\nFigure 2: Distribution of articles volume by various news\noutlets in the partisan audience bias spectrum for Joe Biden’s\nGoogle searches. Notice the disproportionate far-right coverage by 28 news sources.\n1978), which was a policy implemented in the United States\nfrom 1949-1987, demanding from broadcasters the coverage\nof opposing views. Since overall there are fewer far-right\nnews sources compared to the rest of the field, they are disproportionately represented in Top stories. Should that be\nconsidered fair? Given the findings from (Benkler, Faris, and\nRoberts 2018) on the role that the Breitbart-led right-wing\nnews ecosystem played in the 2016 US election, setting the\nnews agenda, by focusing on immigration fears and alleged\nClinton’s corruption, our results indicate a possible scenario\nrepetition. Thus, we invite discussion on the principles that\nshould underlie algorithmic news curation.\n\nAcknowledgments\nI am grateful to my students Emma Lurie, Khonzoda\nUmarova, and Anna Kawakami for their contributions to this\nproject and the Wellesley Cred Lab members for their continuous support. This project was partially funded by the National Science Foundation, through grant IIS 1751087.\n\nReferences\nBenkler, Y.; Faris, R.; and Roberts, H. 2018. Network propaganda: Manipulation, disinformation, and radicalization\nin American politics. Oxford University Press.\nDiakopoulos, N. 2019. Automating the news: How algorithms are rewriting the media. Harvard University Press.\nKawakami, A.; Umarova, K.; and Mustafaraj, E. 2020. The\nmedia coverage of the 2020 us presidential election candidates through the lens of google’s top stories. Proceedings of\nthe International AAAI Conference on Web and Social Media 14(1):868–877.\nRobertson, R. E.; Jiang, S.; Joseph, K.; Friedland, L.; Lazer,\nD.; and Wilson, C. 2018. Auditing partisan audience bias\nwithin google search.\nSandvig, C.; Hamilton, K.; Karahalios, K.; and Langbort, C.\n2014. Auditing algorithms: Research methods for detecting\ndiscrimination on internet platforms.\nSimmons, S. J. 1978. The fairness doctrine and the media.\nUniv of California Press.\n\n</td>
    </tr>
    <tr>
      <th>97</th>
      <td>news</td>
      <td>Two-Sided Fairness in Non-Personalised Recommendations\nAadi Swadipto Mondal* , Rakesh Bal∗ , Sayan Sinha∗ , Gourab K Patro\n\narXiv:2011.05287v1 [cs.AI] 10 Nov 2020\n\nIndian Institute of Technology Kharagpur, India - 721302.\n{aadismondal, rakesh.bal, sayan.sinha, patrogourab}@iitkgp.ac.in\n\nDataset The dataset used for this research is a publicly\navailable news dataset that includes news articles (in Norwegian) in connection with anonymised users (Gulla et al.\n2017). From this dataset, we use the 865 articles with publicly available news contents and the news consumption history (how much time a user spends reading different articles)\nof 63260 anonymised users.\n\nNon-personalised Recommendation Let U and A be the\nset of users and articles (items) respectively. Most of the\nrecommender systems rely on some form of scoring for\nuser-item pairs (e.g., ratings). Here we derive such scores\nfrom the “Active Time” of a user on an article (the total\namount of time in seconds the user spends on the article).\nWe derive the score for user u ∈ U and article a ∈ A\nActT ime(u, a)\n· Na . Here\npair as: Score(u, a) = P\n′\n′\nu ∈U ActT ime(u , a)\nActT ime(u, a) is the total active time of the user u on article a and Na is the number of users who have viewed the\narticle at least once. Next, we linearly scale all the scores of\neach user separately to floating-point numbers in the range\n(1 to 10), in order to ensure similar scales for fast and slow\nreaders. This choice of scores is purely dataset-specific and\ncan be replaced with other suitable score metric as per the\nrequirement. Here, a higher score signifies more affinity of\na user towards the article. However, there are many userarticle pairs for which a score does not exist, owing to the\nfact that the user might not have viewed that particular article. We find these missing values using Non-Negative Matrix Factorisation (NMF) (Koren, Bell, and Volinsky 2009).\nNon-negative Matrix Factorisation (NMF): We obtain a\nsparse matrix V from the normalised scaled scores obtained\nearlier. The rows of V represent the users, and the columns\nrepresent the articles. We then perform NMF on V and obtain V̂ which provides us with the predicted scores for the\nmissing values in V . V ∗ denotes the final score matrix,\nwhich comprises the original scores from V , as well as the\npredicted scores from V̂ (for the missing entries in V ). NMF\nwas set on training with hyperparameters α = 0.0002, and\nβ = 0.02. Convergence was assumed when ∆cost &lt; 0.001\n(around 2, 500 epochs).\nThe Recommendation: As we talk about non-personalised\nrecommendation, the goal is to find κ-sized recommendation\nwhich would be liked by most of the users. For this purpose,\nit is wiser to use V ∗ as it—being a complete score matrix—\ncan provide insights on all the user-article pairs. Next, we\ndiscuss two kinds of fairness desirable in such recommendations and also the obstacles in achieving them.\n\n* The first three authors have contributed equally.\nCopyright © 2021, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n\nUser Fairness As the recommendation is global, it should\nfairly represent the interests of the users on the platform.\nThus, we can re-purpose and use multi-winner voting rules\n\nAbstract\nRecommender systems are one of the most widely used services on several online platforms to suggest potential items\nto the end-users. These services often use different machine\nlearning techniques for which fairness is a concerning factor, especially when the downstream services have the ability to cause social ramifications. Thus, focusing on the nonpersonalised (global) recommendations in news media platforms (e.g., top-k trending topics on Twitter, top-k news on a\nnews platform, etc.), we discuss on two specific fairness concerns together (traditionally studied separately)—user fairness (Chakraborty et al. 2019) and organisational fairness\n(Burke et al. 2020). While user fairness captures the idea of\nrepresenting the choices of all the individual users in the\ncase of global recommendations, organisational fairness tries\nto ensure politically/ideologically balanced recommendation\nsets. This makes user fairness a user-side requirement and\norganisational fairness a platform-side requirement. For user\nfairness, we test with methods from social choice theory, i.e.,\nvarious voting rules known to better represent user choices in\ntheir results. Even in our application of voting rules to the recommendation setup, we observe high user satisfaction scores\n(table 2). Now for organisational fairness, we propose a bias\nmetric (eq-1) which measures the aggregate ideological bias\nof a recommended set of items (articles). Analysing the results obtained from voting rule-based recommendation, we\nfind that while the well-known voting rules are better from\nthe user side, they show high bias values and clearly not suitable for organisational requirements of the platforms. Thus,\nthere is a need to build an encompassing mechanism by cohesively bridging ideas of user fairness and organisational fairness. In this abstract paper, we intend to frame the elementary\nideas along with the clear motivation behind the requirement\nof such a mechanism.\n\nTwo-Sided Fairness\n\nTable 1: Some of the seed words having high PMI values\nLeft-biased\nRight-biased\n\nmotstandernes, djevlene, motstander, problem, motstand, scorer, møte, sjef, kontret, balanse, maktet, rød, igjen\nbakgrunnen, grunn, etablerte, opprettelsen, døpt, alternativ, offensivt, defensiv, renter, tilværelsen, høyre, erna, siv\n\nin our setup as voting rules are known to fairly represent voters’ choices while choosing winners. To map our setup to an\nelection we do the following; election E = (C, V), where\ncandidate set C = A = (a1 , ..., am ) is the set of articles,\nvoter set V = U = (u1 , ..., un ) is the set of users, and we\nconsider scores V ∗ as the corresponding votes. The winners\nof the election are denoted by the set W = (w1 , ..., wκ )\nwhich is a subset of C and are elected using various voting rules. In this work, we experimented with six famous\nvoting rules, namely SNTV, STV, k-Borda, Bloc voting,\nChamberlin Courant and Monroe (Elkind et al. 2017). Next,\nwe find the average satisfaction of all users for the results\nobtained from each election method like: Satisf action =\n1 P\nW∩T op-κu\n. Here T op-κu is the top κ articles for\nκ\nU u∈U\nuser u as per the scores in V ∗ . The satisfaction score for\neach election method has been presented in Table 2 column\n2. A high satisfaction score would ensure that the recommendation results (election winners) hence obtained follow\nthe general principle of user fairness. In all our experiments,\nthe value of κ has been taken as 10.\nOrganisational Fairness For organisational fairness\n(Burke et al. 2020), the set of recommended articles needs\nto be balanced in terms of political/ideological bias. Before\nfinding political bias of the articles in our dataset, first,\nwe analyse articles from politically-biased media houses –\nnamely, Klassekampen (left) and Aftenposten (right) (Nor\n2020), as well as articles talking about eminent people\ninvolved in politics pertaining to either of these ideologies.\nUsing co-occurrence analysis of words in the articles of\nbiased media houses, we shortlist some of the words with\nthe highest Pointwise Mutual Information (PMI) scores.\nSome of the words having high PMI values—which we later\nuse as seed words—have been mentioned in Table 1. We\nconsider that their presence in an article indicates a higher\nlikelihood of it being politically biased. Thus, we designate\nthe articles in our dataset as either left-biased or right-biased\nbased on whether they contain the majority of seed words\nfrom the left category or right category. Next, we find the\nreference bias (ρ) of the user population on the platform as\nthe ratio of total time spent on the left-biased articles to that\non the right-biased articles1 . Finally, we design a bias metric\n2\nwhich measures how far are the global recommendations\nfrom reference ρ.\nBias =\n\n−lef tCount + ρ ∗ rightCount\nlef tCount + ρ ∗ rightCount\n\n(1)\n\nHere lef tCount and rightCount are the number of occurrences of left and right biased seed words in a set of articles.\nHence, Bias &lt; 0 indicates left-bias and Bias &gt; 0 indicates right-bias. Closer the value of Bias to zero, better is\n1\n\nIn our experiments, ρ was found to be 1.423.\nMore sophisticated methods for bias analysis can also be used\nwith the availability of relevant annotated resources in Norwegian.\nHowever this is not under the purview of this abstract.\n2\n\nthe method in terms of satisfying organisation fairness. The\nrange of Bias is [-1, 1]. We calculated the bias values of the\nglobal recommendations obtained earlier using voting rules.\nThe results have been shown in Table 2 column 3.\nTable 2: User Satisfaction and Organisational Bias\nElection Method\nSNTV\nk-Borda\nBloc\nSTV\nCC\nMonroe\n\nSatisfaction\n\nBias\n\n0.878\n0.800\n0.856\n0.894\n0.883\n0.825\n\n-0.115\n0.033\n-0.240\n-0.117\n-0.169\n-0.103\n\nDiscussion For better user fairness, we repurposed wellknown voting rules from fair voting theory, and implemented the same in our recommendation setup. Our evaluation shows that they achieve good user satisfaction scores\n(column 2 of table 2). However, they show high bias values (column 3 of table 2). This is happening as the voting\nrules do not consider the article content while choosing the\nglobal recommendations. On the other hand, organisational\nfairness—relating to balance in the content distribution—\nrequires the bias to be close to zero. Therefore, there is a\nneed for designing a mechanism which simultaneously cares\nfor user fairness and organisational fairness while designing non-personalised recommendations. All of our resources\ncan be found at https://github.com/americast/electoral.\nAcknowledgement We would like to thank Prof Niloy\nGanguly (CSE, IIT Kharagpur) and Rishabh Joshi (LTI,\nCMU) for their continued support throughout the development of this work. Gourab K Patro is supported by a fellowship from Tata Consultancy Services.\n\nReferences\n2020. Norwegian Newspapers: Where to Read News in Norway.\nhttps://www.lifeinnorway.net/norwegian-newspapers/.\nBurke, R.; Voida, A.; Mattei, N.; and Sonboli, N. 2020. Algorithmic Fairness, Institutional Logics, and Social Choice. In Harvard\nCRCS Workshop: AI for Social Good.\nChakraborty, A.; Patro, G. K.; Ganguly, N.; Gummadi, K. P.; and\nLoiseau, P. 2019. Equality of voice: Towards fair representation\nin crowdsourced top-k recommendations. In Proceedings of the\nConference on Fairness, Accountability, and Transparency, 129–\n138.\nElkind, E.; Faliszewski, P.; Skowron, P.; and Slinko, A. 2017. Properties of multiwinner voting rules. Social Choice and Welfare\n48(3): 599–632.\nGulla, J. A.; Zhang, L.; Liu, P.; Özgöbek, Ö.; and Su, X. 2017. The\nAdressa dataset for news recommendation. In Proceedings of the\ninternational conference on web intelligence, 1042–1048.\nKoren, Y.; Bell, R.; and Volinsky, C. 2009. Matrix factorization\ntechniques for recommender systems. Computer 42(8): 30–37.\n\n</td>
    </tr>
    <tr>
      <th>79</th>
      <td>news</td>
      <td>MEDIA BIAS, POLITICAL POLARIZATION,\nAND THE MERITS OF FAIRNESS◦\nRYAN Y. FANG♦\nAbstract. In this paper, we study the economic and social consequences of biased\nnews coverage in the public media and evaluate the merits of content regulations\ndesigned to curtail such bias. We present a general model of the market for news and\nshow that rational Bayesian consumers might prefer biased news to more balanced\nnews, even when the latter is significantly more informative. Consequently, media\noutlets motivated only by higher profits might produce news with significant bias in\nequilibrium. Our model is able to fit documented empirical relationships between\nmedia bias and consumer ideology. It also provides an explanation for the historical\nvariations of the average degree of bias in the U.S. news market based on changes\nin the cost of news to the consumers and the intensity of competition. Our policy\nanalysis shows that content regulations can never lead to Pareto superior outcomes\nbut can lead to Pareto dominated ones. Thus, they are poorly justified on the ground\nof protecting consumer welfare. However, we also find that media bias can lead to\npolitical polarization. While content regulations might help to mitigate such polarization, their effectiveness depends critically on market conditions.\nJEL Classification: D03; D83; L12; L13; L51; L52\nKey Words: Media Bias, Political Polarization, Content Regulation, Confirmation\nBias, Bayesian Rationality, Endogenous Information Acquisition\n\nDate: February 15, 2014.\n◦\nThis research was conducted under the direction of my advisers Roger Myerson, Philip Reny, and\nHugo Sonnenschein and have benefited immensely from their insightful suggestions. I am also grateful\nfor the valuable comments provided by Jesse Shapiro, Richard Van Weelden, and seminar participants\nat Brown University, the Pennsylvania State University, and the University of Chicago. All remaining\nerrors are, of course, my own.\n♦\nDepartment of Economics, University of Chicago. Email: ryfang@uchicago.edu.\n1\n\n1. Introduction\n“Where the press is free and every man able to read, all is safe.” - Thomas\nJefferson (to Colonel Charles Yancey 1816)\nIt is widely believed that a free, fair, and honest news media is one of the essential\npillars of a modern democracy. Because of its importance, scholars, politicians, and\nvarious watchdog groups have closely monitored the state of the media and have never\nbeen shy to voice their criticism.\nThus, allegations of failure by the media to meet public expectations and, in particular, allegations of bias in its coverage of political news have been plentiful in public\ndiscourse. However, in the past two decades, such allegations appeared to be growing more prevalent and impassioned in the United States. Numerous best-sellers have\nbeen written to warn the public of the pervasiveness and severity of media bias.1 Research scholars have identified and measured media bias in the U.S. news market (e.g.,\nGroseclose and Milyo (2005) and Gentzkow and Shapiro (2010)) and its impact on the\nviews of the general public and the outcomes of political processes (e.g., Gentzkow\nand Shapiro (2004), DellaVigna and Kaplan (2007), and Chiang and Knight (2011)).2\nRecent surveys by the Pew Research Center for the People and the Press (2011) show\nthat consumers’ perception of media bias has deteriorated drastically since the mid\n1980s (see Figure 1.1).\nScholars, pundits, and politicians have expressed concerns over the apparent surge\nof media bias in the U.S. news market. It is the belief shared by many that media bias\nis the deliberate attempt by media outlets to misinform the public in pursuit of their\nown agendas. Moreover, biased news is less informative and thus inferior in value to\nconsumers. Thus, in order to protect consumer welfare, the government must intervene\nand impose fairness standards in the industry to curtail media bias.\nContent regulations that restrict the degree of bias in news coverage are popular tools\nfor such purposes. In the United Kingdom, the Office of Communications’s Broadcasting Codes require news to be reported with “due impartiality”.3 In the United States,\nthe Federal Communications Commission (FCC) enforced the Fairness Doctrine, which\nrequired TV and radio stations to present contrasting viewpoints on controversial issues of public interest. The FCC dissolved the doctrine during the deregulation sweep\n1\n\nFor example, Coulter (2003) and Goldberg (2002) claim that there is a significant liberal bias in\nthe American public media, while Alterman (2003) and Brock, Rabin-Havt, and Media Matters for\nAmerica (2012) claim that the bias is to the right.\n2\nNote that, while many studies find significant bias in the news media, Puglisi and Snyder (2012) find\nthe press to be largely balanced.\n3\nSection\nFive\nof\nthe\nOfcom\nBroadcasting\nCodes,\navailable\nat:\nhttp://stakeholders.ofcom.org.uk/broadcasting/broadcast-codes/broadcast-code/?a=0.\n2\n\nFigure 1.1. Percentage of Respondents Expressing Concerns for Media Bias\n\nof the Reagan Administration. But attempts to reintroduce the Fairness Doctrine and\neven to codify it have not stopped since.4\nIn this paper, we present a general model of the market for news and apply it to examining the economic and social consequences of media bias and evaluating the merits\nof these regulations on news content. Motivated by our goal to understand the impact\nof content regulations such as the Fairness Doctrine as well as the empirical measures\nof media bias in the literature, we define such bias in this paper as the unbalanced\npresentation of information (views, evidence, etc.) in favor of (i.e., inherently biased\nto) different sides of a controversial issue. The media outlets in our model can spend\na limited amount of resources on acquiring information regarding the unknown state\nof the world and can allocate these resources to collecting information with different\nbiases. They can produce balanced news reports by allocating resources evenly across\nthe collection of information favoring each side. Otherwise, their news reports will be\nbiased. Thus, media bias can be created in the process of collecting and synthesizing\n4\n\nSee Limburg (2013) for a brief account of the introduction and abolition of the Fairness Doctrine and\nsuggestions for further reading.\n3\n\ninformation. The media outlets can also garble the information they have collected\nbefore reporting them to the consumers. However, we show that if the media outlets’\ngoal is to maximize profits, garbling is suboptimal and is not part of their equilibrium\nstrategies.\nOur findings cast serious doubt on the common justification for content regulations\nthat hinges on protecting consumers from misinformation. Although there is evidence\nsuggesting that consumers exposed to unbalanced news sources appear to be relatively\npoorly informed (e.g., Gentzkow and Shapiro (2004)), this does not necessarily imply\nthat consumer welfare is lower. Our results show that rational Bayesian consumers who\nconsume news only to help themselves make informed individual decisions may strictly\nprefer biased news to more balanced news, even if the latter provides significantly\nmore information. The reason is that, while more information always improves the\naccuracy of the consumers’ beliefs and can never hurt a rational Bayesian consumer\nmaking non-strategic decisions (Blackwell (1951)), its value depends on the nature of\nthe consumers’ decision problem and the nature of other information the consumers\nhave.5\nIn particular, acquiring information with opposite biases can be inefficient. Contrasting viewpoints or conflicting evidence prevents rational consumers from becoming\ncertain of the underlying state and making resolute decisions that bring higher expected\nutilities. Thus, when information are costly to gather and there is tradeoff between\ninformation with different biases, learning only one-sided information can be more efficient to the consumers. This may be the case even when there is significant decreasing\nreturn to scale associated with producing information biased to one side, and allocating\nall resources to collecting one-sided information results in less information gathered in\ntotal.\nWe show that media outlets may choose to produce news with significant bias in\nequilibrium even when they are only motivated by higher profits. Moreover, content\nregulations not only cannot lead to Pareto improvements from market outcomes, they\ncan in fact result in Pareto dominated outcomes. Thus, these regulations are poorly\njustified on the ground of protecting consumer welfare. On the other hand, we also\nfind that media bias can lead to political polarization, which is behaviorally defined by\nconsumers taking more extreme actions in opposite directions. We show that content\n5\n\nNote that, in this paper, a news report providing “more information” is one that presents a larger\nnumber of facts (pieces of evidence) and does not necessarily dominate a news report providing less\ninformation according to the Blackwell order, which already takes into account of the nature of the\ndecision problem. In fact, pairs of news reports often cannot be ordered by the Blackwell order, which,\nof course, is not complete.\n4\n\nregulations can help mitigate such polarization under some market conditions, but can\nalso exacerbate polarization under other circumstances.\nA fast growing literature on media economics has produced many insightful explanations for the perceived biases in the news media.6 Baron (2006), Besley and Prat\n(2006), Duggan and Martinelli (2011), and Anderson and McLaren (2012) show that\nmedia bias may originate from the supply side, when media outlets or their employees\nhave incentives to deliberately distort the consumers’ beliefs with biased news. On\nthe other hand, other papers have modeled media bias as originating from the demand\nside. The consumers may demand bias in their news because they appreciate the entertainment value in such news (e.g. Mullainathan and Shleifer (2005), Bernhardt, Krasa,\nand Polborn (2008)) or find such news more useful in helping them determining their\noptimal course of action (e.g. Chan and Suen (2008), Oliveros and Vardy (2012), and\nSobbrio (2013)). Gentzkow and Shapiro (2006) and Stone (2011) show that media bias\ncan arise if media outlets have the incentive to mislead consumers unsure of the media\noutlets’ capabilities into believing that they are of the superior type or if consumers\nand reporters misinterpret their information (i.e., they are affected by confirmation\nbiases in the spirit of Rabin and Schrag (1999)).\nIn this paper, our consumers only care about making optimal individual choices and\nconsume news only to assist their decision making as in Chan and Suen (2008) and\nOliveros and Vardy (2012). The media outlets in our model only aim to maximize\nprofits as in Mullainathan and Shleifer (2005) and Sobbrio (2013). This is not to say\nthat we do not think that the entertainment value in news and the media outlets’\nincentives to influence their consumers are not important aspects of the problem. But\nwe believe that, to better understand these other aspects, it is important to learn how\nfar a more basic model can take us to understand the phenomenon of media bias.\nIn contrast to the fruitful research on the cause of media bias and its impact on\ndemocratic processes, little has been done to develop a theoretical understanding of\nthe industrial organization of the market for news, which is essential for the evaluation\nof media industry regulations. Earlier models that study the commercial aspects of\nmedia bias (e.g., Mullainathan and Shleifer (2005), Anderson and McLaren (2012),\nand Sobbrio (2013)) are too restrictive to match the rich body of empirical evidence\naccumulated by recent studies (e.g. Hamilton (2006), Gentzkow, Glaeser, and Goldin\n(2006), Gentzkow and Shapiro (2010), and Gentzkow, Shapiro, and Sinkinson (2012)).\nFor example, consumers are generally restricted to consuming only one news report, and\nmost of the models have difficulties analyzing oligopolistic competition involving more\n6\n\nSee Prat and Stromberg (2011) for a survey of the literature on the political economy of public media.\n5\n\nthan two media outlets. Consequently, these models cannot match known consumption\npatterns, according to which consumers often consume multiple number of news reports\nwith distinct biases, and media outlets attract consumers from distinct ideological\ngroups (the Pew Research Center for the People and the Press (2012) and Mitchell,\nJurkowitz, Enda, and Olmstead (2013)).\nIn this paper, media outlets have more freedom in deciding the amount of information\nto report and the manner in which they report, while consumers are able to consume\nmultiple news reports. At the same time, our model remains tractable and is able to\naccommodate any finite number of media outlets. The generality of our model leads to\nnew predictions. In addition to matching the above mentioned consumption patterns,\nthe flexibility to handle large number of competitors allows us to examine the joint\neffect of the cost incurred by consumers from consuming news and the intensity of\ncompetition on the average degree of bias in the news supplied in equilibrium. We\nare thus able to explain the historical variations of the degree of media bias in the US\nmarket based on the changes in those factors.\nLast, this paper presents a new model of rational demand for biased information.\nAs in Calvert (1985) and Suen (2004), the preference for biased information by our\nconsumers is attributable to the non-concavity in the value of information (Radner\nand Stiglitz (1984)). However, the ways bias is conceptualized differ across these models, which lead to different behavioral predictions.7 The type of preference for biased\ninformation in our model is an example of the concept generally termed “confirmation\nbias” in the Psychology literature (See Klayman (1995) and Nickerson (1998)), which\nhas been introduced to the economics literature by Rabin and Schrag (1999).\nThe rest of the paper is organized as follows: the next section introduces the formal\nmodel. In Section 3, we characterize the optimal news report from an individual\nconsumer’s perspective and show that it often is biased. Section 4 studies the industrial\norganization of the market for news and analyzes the relationship between average\nequilibrium media bias and other market conditions. Towards the end of the section,\nwe lay out the empirical implications of our model and evaluate the effect of imposing\ncontent regulations on consumers’ well-being. In Section 5, we show that media bias can\nlead to political polarization. We demonstrate that content regulations can mitigate\nsuch polarization and discuss their limits. Section 6 concludes with a discussion on\npossible extensions. All proofs are relegated to the appendix.\n\n7\n\nFor example, in Chan and Suen (2008), which shares the same basic model as Suen (2004), the\nconsumers are never willing to pay for more than one news reports.\n6\n\n2. The Model\nConsider a market for news with a continuum of consumers and a finite number\nof producers. The producers will be referred to as media outlets. The mass of the\nconsumers is normalized to unity and N ∈ N denotes the number of media outlets.\nThe consumers each, independently, face a choice under uncertainty and the media\noutlets provide information that can potentially assist the consumers in making better\ndecisions.\n2.1. The Consumers’ Decision. Let i denote a typical consumer who faces a choice\nbetween three actions: the left action, denoted by l, the right action, denoted by r,\nand abstention, denoted by a. As summarized in Table 2.1, i’s utilities associated with\nactions l and r depend on the unknown state of the world, which can be either left,\ndenoted by L, or right, denoted by R, while her utility associated with action a is\ncertain and is normalized to 0. The parameters αi , βi , δi , γi are positive real numbers.\nδi\ni\n&lt; δi +γ\n, so that action a is not dominated.\nWe assume that αiα+β\ni\ni\nTable 2.1. Consumer i0 s Decision Problem\nL\nR\nl αi −βi\nr −δi γi\na 0\n0\nConsumer i is assumed to be a subjective expected utility (SEU) maximizer. Let\nher subjective prior belief over the possible states, {L, R}, be given by the vector\n(1 − πi , πi ), that is, she believes that state R obtains with probability πi .8 Let upi (d)\ndenote her expected utility when her belief over {L, R} is given by the vector of probabilities (1 − p, p) and she decides to take action d ∈ {l, r, a}. Define dbi (p) as her\noptimal decision given her belief p, i.e., dbi (p) ≡ arg maxd∈{l,r,a} upi (d). Ex ante, her\noptimal decision depends on her utility function and prior belief as follows:\n\ni\n\n{l},\nπi ∈ [0, αiα+β\n)\n\ni\n\n\n\n{l, a}, πi = αi\n\n\n\nαi +βi\n\nαi\nδi\nb\ndi (πi ) =\n{a},\nπi ∈ αi +βi , δi +γi .\n\n\n\nδi\n\n\n{a, r}, πi = δi +γ\n\ni\n\n\n\nδi\n{r},\nπi ∈ ( δi +γi , 1]\n8Note that the consumers are not forced to have heterogeneous priors. The subjective prior beliefs of\n\nall of the consumers may very well agree.\n7\n\nIn the rest of the paper, members of dbi (πi ) are referred to as consumer i’s “default\nactions”.\nDifferent consumers can have different utility functions and beliefs, hence the dependence of (αi , βi , δi , γi , πi ) on i. Consequently, they might have different default\nactions.\nFor example, imagine that two candidates are vying for a political office. The consumers at a positive utility cost can either vote for the left candidate (action l) or vote\nfor the right candidate (action r). Otherwise, she can choose to abstain (a). One of\nthe two candidates has higher valence than the other. The better candidate could be\nthe left one (state L) or the right one (state R). Consumer i always wants to vote for\nthe candidate with the higher valence.\nAlternatively, imagine that there is contention over the optimal strategy to prevent\na hostile foreign country from developing nuclear weapons. All consumers agree that\nif the foreign country’s nuclear program is still in its early stage (state L), sanctions\nare the most appropriate policy. However, if the nuclear program has passed a certain\npoint (state R), preemptive military actions are necessary. Consumer i can, again at\na cost, choose to advocate for either choice (actions l or r) or she can refrain from\nchoosing sides at all (action a).\nIn either case, if i is sufficiently certain that the true state is L (R), or, more precisely,\nδi\ni\nif πi &lt; αiα+β\n(respectively, if πi &gt; δi +γ\n), her optimal choice is l (r). Otherwise, she is\ni\ni\nbetter off choosing a, which is both less costly and less risky than the other choices.\nNote that how certain consumer i needs to be to choose l or r depends on her utility\nfunction. Two consumers with the same belief might choose different actions because\nof their different preferences. For example, given the same belief about the candidates’\nvalence, one consumer might choose to vote for the left candidate and the other for\nthe right candidate because they each find their chosen candidates’ personal traits\nmore likable. Alternatively, given the same belief about the success of the foreign\ncountry’s nuclear program, one consumer might support sanctions while the other\nsupports military action, because the former disapproves of the use of violence in\ngeneral and the latter is more lax about it.\nFor expositional convenience, the consumers with default action l, i.e. all i with\ndbi (πi ) = {l}, are referred to as “liberals”, and those with default actions r and a are\nreferred to as “conservatives” and “moderates”, respectively.9\n2.2. The News Reports.\n9Those consumers who are indifferent between two actions can be categorized into either group.\n\nIn\nthe following analysis, they will generally form a subset of measure zero. Consequently, their behavior\ndoes not affect our analysis.\n8\n\n2.2.1. Investigations and Signals. To produce a news report, the media outlets need\nto investigate into various matters pertaining to the unknown state. Conceptually, we\ncan think of this as the media outlets asking a number of questions, each with an “yes”\nor “no” answer, on behalf of their readers / viewers. Formally, these investigations can\nbe modeled as binary signals that send a message of “left” or “right” in each state.\nWe recognize that investigations conducted by media outlets to ascertain the truth\nof an uncertain issue can in fact favor one side or the other. For example, when\ninvestigating the valence of a political candidate, the media outlets can elicit opinions\nfrom a supporter of the candidate or a member of the same political party. These people\nare more likely to endorse the candidate, and might even endorse him or her knowing\nthat he or she in fact has lower valence. Thus, opinions elicited from supporters or\nparty members are inherently biased towards their favored candidate.\nTo capture this idea, we assume that there are two types of binary signals the media\noutlets can acquire: signals that are biased to the left (in short, “left signal s”) and\nsignals that are biased to the right (“right signals”). As illustrated in Table 2.2, when\nthe true state is L, a left signal always identifies the state, correctly, as left. On the\nother hand, if the true state is R, a left signal only correctly identifies the state as right\nwith probability σL ∈ (0, 1) and, with the remaining probability, the signal makes a\nmistake (or “lies”) and identify the state as left. A right signal is defined symmetrically,\nand is characterized by some σR ∈ (0, 1) (see Table 2.3).\nGiven her prior belief (1 − πi , πi ), consumer i expects a left signal to report “left”\nwith a probability strictly higher than 1 − πi , and, upon receiving a “left” report from\nthe signal, the consumer updates her belief to (1 − π 0 , π 0 ), where π 0 &lt; π. The opposite\nis true for a right signal. This is the sense in which the signals are biased: ex ante,\na left (right) signal is more likely to cause the consumer to have a stronger belief in\nstate L (respectively, R).10 In the previous example, the opinion from a supporter of\nthe left candidate amounts to a left signal, while the opinion from a supporter of the\nright candidate is a right signal.\nTable 2.2. A Left Signal\n“lef t”\n“right”\n\nL\nR\n1 1 − σL\n0\nσL\n\n10In precise terms, “more likely” here means “with higher probability than actuarially fair according\n\nto the consumer’s prior belief”.\n9\n\nTable 2.3. A Right Signal\nL\nR\n“lef t”\nσR\n0\n“right” 1 − σR 1\nHowever, bias does not have to result from misrepresentation of facts. It can equally\nbe due to the uneven type I and type II errors associated with the particular investigation. For example, when investigating the foreign nuclear program, the media outlets\ncan attempt to find out whether or not the foreign country has developed the capacity\nto enrich uranium, which must occur before the milestone of development, or they can\nattempt to find out if that country has already conducted nuclear tests, which occurs\nafter the critical stage. The former amounts to a right signal, since it will fail to recognize that the milestone has not been reached, if the foreign country has acquired\nthe capacity to enrich uranium. The latter, on the other hand, is equivalent to a left\nsignal.\nRealistically, even a left (right) signal may not be perfectly accurate in identifying\nthe left (right) state. There may very well be small chances that the signals can err in\ntheir favored states. Such small chances are ignored here in order to gain tractability.\nHowever, one needs not to be too concerned by this simplification. As it will become\nclearer below, the consumers’ expected utilities are continuous in the conditional probabilities characterizing our signals. Thus, so long as the probability that left and right\nsignals misidentify their favored states is small, the predictions of consumers’ behavior\nin our model remain good approximations.\n2.2.2. News Reports and News Consumption Bundles. Each media outlet can produce\none news report, which is based on the findings of the various investigations conducted.\nTracking all the possible combinations of findings from those investigations and compute the probabilities they each obtain is potentially a very tedious task. However,\nnote that a collection of left signals can be identified with a single (composite) left\nsignal.\nFor example, consider a collection of two left signals characterized by conditional\nprobabilities σL and σL0 , respectively. In state L, both signals are going to identify the\nstate as L. In state R, there are four distinct possible outcomes in which zero, one,\nor two of the signals identifies the state correctly as R. However, if any of the two\nleft signals identifies the state as R, we can conclude that the state must indeed be R.\nThus, for all intents and purposes, we can simply identify the two left signals with a\nsingle left signal characterized by conditional probability σL00 , which is the probability\n10\n\nthat any of the two original left signals correctly identifies the state in R. Note that\nσL00 &gt; max{σL , σL0 } as long as the two original signals are not perfectly correlated.\nSimilarly, any collection of left (right) signals can be identified with a single (composite)\nleft (right) signal.\nOn the other hand, a collection of signals of both types can be identified to a composite signal that sends a message mL (respectively, mR ) when any of the right (left)\nsignals reports “left” (“right”), and sends a message mN when all of the left signals\nreport “left” and all of the right signals report “right”. Thus, a news report that reports\ntruthfully the findings from all the investigations conducted can be identified as a composite signal characterized by a pair of conditional probabilities (σL , σR ) ∈ [0, 1]2 , where\nσL (respectively, σR ) is the probability that any left (right) signal correctly identifies\nthe state as R (L) (see Table 2.4).\nIf such a news report sends a message mL (mR ), consumer i knows that the true state\nmust be L (R). Thus, mL (mR ) can be interpreted as “conclusive evidence” presented\nby the media outlet in support of state L (R). By contrast, message mN represents\n“inconclusive evidence” presented by the media outlet. There may be two types of\ninconclusive evidence: if either σL or σR equals to zero, the evidence is “one-sided ”,\nwhile, if both σL and σR are positive, the evidence is “conflicting”.\nTable 2.4. A News Report\nsL\nsN\nsR\n\nL\nR\nσR\n0\n1 − σR 1 − σL\n0\nσL\n\nNote that the media outlet is assumed to be reporting its findings truthfully here.\nIf, instead, the media outlet chooses to garble its signals, its news report is no longer\nequivalent to the composite signal presented in Table 2.4. However, as we shall see\nin our analysis below, we do not expect this to happen in equilibrium if the media\noutlets maximize their profits. This is because that, in equilibrium, where consumers\nhave rational expectations of the media outlets’ strategies, garbling its signals can only\nreduce a media outlet’s profit and is therefore dominated by truthful reporting.\nFinally, as alluded to earlier, the consumers in our model have the freedom to consume news reports produced by multiple media outlets. For any set of media outlets\nJ ⊆ {1, 2, . . . , N }, a “news consumption bundle” consisting of the news reports produced (faithfully) by members of J is equivalent to the collection of all the left signals\nand all the right signals acquired by those media outlets and can be identified again with\n\na (richer) composite signal characterized by conditional probabilities σLJ , σRJ ∈ [0, 1]2 ,\n11\n\n\nwhere σLJ , σRJ depend on the conditional probabilities characterizing each of the media outlet’s reports, which, in turn, depend on the amount of resources devoted by the\nmedia outlets to acquire their signals.\n2.2.3. News Production Technology. Each media outlet is endowed with q units of\nresources that can be spent on conducting investigations (i.e., acquiring signals). q\nis normalized so that it falls in (0, 1). A media outlet can allocate these resources\nbetween acquiring left signals and right signals. Specifically, media outlet j chooses a\n\n“reporting strategy”, characterized by a pair of non-negative real numbers qLj , qRj such\nthat qLj + qRj ≤ q, where qLj (respectively, qRj ) is the amount of resources allocated to\nacquiring left (right) signals.11\nSpending qLj and qRj on acquiring left and right signals gives media outlet j a compos\n\n\nite signal characterized by σLj , σRj = σ qLj , σ qRj . The function σ : [0, 1] → [0, 1]\nspecifies the news production technology available to the media outlet. We assume\nthat σ is strictly increasing and that σ (0) = 0. The strict monotonicity of σ reflects\nthe idea that, as a media outlet spends more resources on collecting information, its\ninformation becomes better.12\nFor any subset of media outlets J, a news consumption bundle consisting reports\n\nfrom these outlets is characterized by σLJ , σRJ , where σbJ , b = L, R, should depend on\nthe statistical interdependence between all of the b-biased\nsignals contained in all of\n \nj\nJ\nthe news reports. We assume that σb = τJ σb j∈J , where τJ : [0, 1]|J| → [0, 1] is\n  \n\nQ\ndefined by τJ σbj j∈J ≡ 1 − j∈J 1 − σbj . That is, the composite signals generated\nby the news reports are, in effect, statistically independent conditional on the state.13\nIn what follows, we refer to (q, 0) and (0, q) as “extreme reporting strategies” and\nany other feasible (qL , qR ) as an “interior reporting strategy”. We shall from time to\n11The fact that media outlets only choose the allocation of resources to acquiring signals reflects our\n\nrestriction of attention to the undominated truthful reporting strategies.\n12For example, if the media outlet acquires more left signals, the probability that at least one of these\nsignals will correctly identify the state R increases as long as those signals are not perfectly correlated.\nNo additional restrictions on σ (e.g., on its curvature) is imposed. While it is reasonable to expect\nthat σL and σR should be concave in the number of signals the media outlet acquires, they need not\nto be concave in the amount of resources the media outlet spends. There may very well be significant\nscale economies in acquiring signals of the same type and the resulting σ may be linear or even convex.\n13This assumption is in fact more restrictive than what is needed for our results and is made for\nexpositional brevity only. However, we do need τJ to be strictly monotone and concave. As discussed\nearlier, the curvature of σ is not restricted. In particular, it can be convex. Thus, the fact that τJ is\nstrictly concave reflects the assumption that by pooling their resources, two media outlets can produce\na single news report that is more accurate than the news consumption bundle containing news reports\nproduced independently by these outlets. This could be due to repetitions in investigations conducted\nby the outlets.\n12\n\n\n\n\ntime abuse notation and write σ (qj ) for σ qLj , σ qRj\nand τ σ (qj ) , σ qk for\n\n\n\n\nτ σ qLj , σ qLk , τ σ qRj , σ qRk\n.\n\n2.2.4. Defining Bias. A media outlet is considered “biased to the left (right)” if it allocates more resources to acquiring left (right) signals. Formally, a news report (qL , qR )\nR\nis biased to the left (right) if ρ ≡ qLq+q\n&lt; 12 (&gt; 12 ), where | ρ − 12 | measures the degree\nR\nof bias in the report.\nThus, media bias is created in the process of acquiring and synthesizing information.\nBy choosing different experts or institutions to consult, questions to ask, or matters\nto investigate, the media outlets can make their reports favor one state over the other.\nIn our previous example, a media outlet that only elicits opinions from a candidate’s\nsupporters is considered to be biased towards that candidate. On the other hand,\na media outlet that elicits opinions from supporters of both candidates is considered\nbalanced.\nOur definition of media bias is tailored to representing the kind of bias policies like\nthe Fairness Doctrine are intended to curtail. Moreover, it corresponds directly to the\nmeasures of media bias in the empirical literature adopted by scholars like Groseclose\nand Milyo (2005), who measure the bias of a media outlet by the relative frequencies\nthe latter quotes “liberal think tanks” versus “conservative ones”, and Gentzkow and\nShapiro (2010), who measure bias by the relative frequencies media outlets use phrases\nthat are more commonly used by Democrats versus those used by Republicans.14\nSimilarly, a news consumption bundle is said to be “biased to the left” or “biased to\nR\n&lt; 12 or ω &gt; 12 respectively. | ω − 21 | measures the degree of\nthe right” if ω ≡ σLσ+σ\nR\nbias in the news consumption bundle.\n\n2.3. The Value of Information to Consumers. The consumers are assumed to\nhave rational expectations about the media outlets’ reporting strategies and update\ntheir beliefs according to Bayes’ rule. Given consumer i’s prior belief, πi , and her\nnews consumption, σ ≡ (σL , σR ), we can calculate i’s posterior belief upon receiving\nmessages mL , mR , and mN , respectively, as well as her prior belief for the likelihood\n\n14The correspondence to the Gentzkow and Shapiro (2010) measure might appear less obvious at first.\n\nHowever, if we recognize that phrases used by politicians are likely related to the issues they raise,\nthe questions they ask, and the arguments they make, all of which are presumably in favor of their\nown causes; then more frequent usage of the same phrases as a politician may well indicate that the\nmedia outlet takes the same stance as that politician on the underlying issues.\n13\n\nof receiving them. Abusing notation a little, these can be written as:\np (mL ) = (1 − πi ) σR\np (mR ) = πi σL\np (mN ) = 1 − πi σL − (1 − πi ) σR\np (R | mL ) = 0\np (R | mR ) = 1\np (R | mN ) =\n\nπi [1 − σL ]\n.\n1 − πi σL − (1 − πi ) σR\n\nNote that the bias in consumer i’s news consumption bundle determines how the report\naffects her posterior belief. After receiving conclusive evidence mL (mR ), the consumer\nknows that the state is L (R). However, her posterior belief, and hence optimal choice,\nupon receiving inconclusive evidence mN depends on ω. For any πi ∈ (0, 1), holding\nσL + σR constant, p (R | sN ) is strictly increasing in ω, and p (R | sN ) &lt; πi (&gt; πi ) if\nand only if ω &lt; 12 (&gt; 12 ).\nDefine u∗i (p) ≡ max{upi (l) , upi (r) , upi (a)}. Thus, u∗i (p) is the maximum expected\nutility consumer i can achieve without additional information given her belief (1 − p, p).\nConsumer i’s “default utility” is u∗i (πi ). Having access to a bundle of news reports allows\nthe consumer to make her decision contingent on the message she receives. Thus, with\nconsumption bundle (σL , σR ), the maximum expected utility consumer i can achieve,\nex ante, becomes:\nUi∗ (σL , σR , πi )\n≡ p (mR ) u∗i (p (R | mR )) + p (mL ) u∗i (p (R | mL )) + p (mN ) u∗i (p (R | mN ))\n= πi σL γi + (1 − πi ) σR αi + [1 − πi σL − (1 − πi ) σR ] u∗i (p (R | sN )) .\n\n(2.1)\n\nThe difference between Ui∗ (σL , σR , πi ) and u∗i (πi ) is the net gain in expected utility\nbrought by the news consumption bundle σ and, hence, is how much the news consumption bundle is valued to the consumer.\n\n14\n\nSince [1 − πi σL − (1 − πi ) σR ] is non-negative for all (σL , σR ) ∈ [0, 1]2 , we can rewrite\n(2.1) as:\nUi∗ (σL , σR , πi ) = max{πi σL γi + (1 − πi ) σR αi\n+πi (1 − σL ) αi + (1 − πi ) (1 − σR ) (−βi ) ,\nπi σL γi + (1 − πi ) σR αi\n+πi (1 − σL ) (−δi ) + (1 − πi ) (1 − σR ) γi ,\nπi σL γi + (1 − πi ) σR αi }.\nThe expressions in the brackets are the consumer’s expected utility if she commits\nto choosing l, r, and a, respectively, after receiving inconclusive evidence. Viewed as\nfunctions of (σL , σR ) or functions of πi , all of these expressions are linear. Thus, Ui∗ is\nthe maximum of linear functions and is therefore convex in (σL , σR ) and in πi .\n3. Utility Maximizing News Reports\nWe are interested in the consumers’ welfare in various market outcomes with or\nwithout government intervention. This comes down to understanding the consumers’\npreference over news consumption bundles. In this section, we ask the following question: fixing a media outlet’s resources and production technology, what is the most\nvaluable news report it can produce for an individual consumer, given the consumer’s\npreference and prior belief? Formally, let (α, β, δ, γ) be any member of R4++ that satα\nδ\n&lt; δ+γ\n, we want to solve, for each q ∈ (0, 1) and each π ∈ (0, 1), the following\nisfy α+β\nproblem:\nmax(qL ,qR ) U ∗ (σ (qL ) , σ (qR ) , π)\ns.t.\n\n(3.1)\n\nqL , qR ≥ 0\nqL + qR ≤ q,\n\nwhere the dependence of U ∗ on the utility vector (α, β, δ, γ) is suppressed in the notation.\nα\nAs it turns out, if the consumer is a liberal or a conservative, i.e., if π &lt; α+β\nor\nδ\nπ &gt; δ+γ\n, the solution to this problem is remarkably simple.\nProposition 1. The unique solution to problem (3.1) is q∗ = (q, 0), if the consumer\nis a liberal, and is q∗ = (0, q), if she is a conservative.\nThus, a liberal prefers her news report to be extremely biased towards the left, while\na conservative prefers her news report to be extremely biased to the right. These consumers’ preference for biased news is rational and consistent with SEU maximization.\n15\n\nNote that, when σ is concave, acquiring more left (right) signals or producing such\nsignals with higher accuracy may lead to larger reductions in the number or accuracy\nof of right (left) signals that can be produced. That is, the extremely biased news\nreport may be significantly less informative than a more balanced one. Nevertheless,\nthe partisan consumers always prefer the former.\nTo understand the intuition behind Proposition 1, let us explore some properties of\nthe function U ∗ . The following lemma establishes that U ∗ is monotone in (σL , σR ).\nLemma 1. For any π ∈ (0, 1) and any σL , σL0 , σR , σR0 ∈ [0, 1], such that σL &lt; σL0 and\nσR &lt; σR0 :\na) U ∗ (σL , σR , π) ≤ U ∗ (σL0 , σR , π) and U ∗ (σL , σR , π) ≤ U ∗ (σL , σR0 , π);\nb) U ∗ (σL , σR , π) &lt; U ∗ (σL0 , σR0 , π) ≤ U ∗ (1, σR0 , π) = U ∗ (σL0 , 1, π).\nA short algebraic proof of Lemma 1 is given in the appendix. However, note that,\nfor b = L, R, reducing σb can be viewed as randomly misreporting the realization of\nb-biased signals. Thus, Lemma 1 a) is essentially a special case of Blackwell’s (1951)\nwell-known theorem on comparing experiments. It re-iterates the well-known fact that,\nto an individual facing a non-strategic decision problem, more information is never a\nbad thing.\nLemma 1 b) implies that the marginal utility value of resources spent on collecting\none of the two types of information must always be strictly positive. Thus, it is\nnever optimal for the consumers if a media outlet underutilizes its resources, hence\nthe solution to (3.1), (qL∗ , qR∗ ), must satisfy qL∗ + qR∗ = q.\nThe next lemma identifies the conditions in which additional information of a particular kind is not valuable. If the consumer’s news consumption bundle is σ, let\npσπ (L | mN ) denote her posterior belief after she is presented with inconclusive evidence. Recall that db(p) is the consumer’s optimal choice(s) of action when her belief\nis given by p.\nLemma 2. For any π ∈ (0, 1) andany σL , σL0 , σR , σR0 ∈ [0, 1]:\n\n\n(σ0 ,σR )\n(σ ,σ )\na) If db pπ L R (L | mN ) = db pπ L\n(L | mN ) = {r}, then U ∗ (σL , σR , π) =\nU ∗ (σ 0 L , σ R , π); and,\n\n\n\n\n(σL ,σR0 )\n(σL ,σR )\nb\nb\nb) If d pπ\n(L | mN ) = d pπ\n(L | mN ) = {l}, then U ∗ (σL , σR , π) =\nU ∗ (σ L , σ 0 R , π).\nLemma 2 says that if, upon receiving inconclusive evidence (mN ), the consumer’s\noptimal choice is l (r), then additional information (signals) biased to the right (left)\nadds no value to her unless it can persuade her to change action.\n16\n\nBecause the consumer is a Bayesian, a news report that directly sends her a message\nfrom the set {mL , mR , mN } is equivalent to two reports that inform her, in turn, about\nwhich message she can rule out. For example, telling the consumer mL is equivalent to\nfirst telling her not mR and then not mN . However, if her choice after receiving mN is\nl, then, after receiving the report “not mR ”, the consumer can just go ahead and choose\nl. This is simply Savage’s (1972) “Sure-thing Principle”, which our SEU maximizing\nconsumer respects. Consequently, the second report is useless to her. Moreover, even\nif the second report is made more informative (i.e., σR increases), it still does not help\nthe consumer as long as it is not informative enough to persuade her to change her\nchoice after receiving mN .\n(σ ,σ )\nRecall that pπ L R (L | mN ) ≤ π, if and only if σL ≥ σR . Therefore, for a liberal,\nthere exists ε &gt; 0, such that any news report (σL , σR + ε) with σL ≥ σR is as valuable to\nher as the extremely biased news report (σL , 0). The opposite is true for a conservative.\nOn the other hand, Lemma 1 and the strict monotonicity of σ imply that\nU ∗ (σ (qL ) , σ (qR ) , π) ≤ U ∗ (σ (q) , σ (q) , π)\nfor all interior reporting strategies (qL , qR ). Proposition 1 follows immediately.\nWe can also visualize Proposition 1 in Figure 3.1, which depicts the consumers’\nindifference curves. The set of feasible reporting strategies is the area bounded by\nthe black dotted curve that represents the production possibility frontier (PPF) of the\nmedia outlet. The PPF is determined by σ and q and can be concave, linear or convex,\nif σ is concave, linear or convex respectively.\nLemma 1 implies that there can be no “thick” indifference curves and that indifference curves lying to the North-East represent higher values to the consumer. Lemma\n2 implies that, when the difference between σL and σR is sufficiently large, the indifference curves are either horizontal (σL &lt; σR ) or vertical (σL &gt; σR ). Moreover, the\nvertical part of a liberal’s indifference curves must cross the 45-degree line. So does\nthe horizontal part of a conservative’s indifference curves. Therefore, a liberal’s utility\nmust be maximized at the corner (σ (q) , 0), while a conservative’s utility is maximized\nat (0, σ (q)).\nHowever, note that Proposition 1 relies on our implicit assumption that the media\noutlet is equally efficient in acquiring information biased to the left and right, which\nimplies that the PPF is symmetrical about the 45-degree line. If, instead, we assume\nthat the media outlet is more efficient in acquiring information biased to the left,\nthen the PPF looks like the grey dotted curve in Figure 3.1. In that case, while a\nconservative still prefers an extremely biased news report, her utility maximizing news\nreport may very well be (q, 0).\n17\n\nFigure 3.1. Indifference Curves of Liberals and Conservatives\n\nThe argument for Proposition 1 given above does not apply to the moderates. Unlike\nthe case with liberals and conservatives, the horizontal and vertical parts of a moderate’s indifference curves do not cross the 45-degree line (See Figure 3.2). Therefore,\na moderate consumer’s utility may very well be maximized by an interior reporting\nstrategy. However, the next proposition shows that, if σ is convex, the solution to (3.1)\nis still at a corner. Thus, when increasing the accuracy of the left (right) signals does\nnot cost strictly more in terms of the accuracy of the right (left) signals, a moderate\nalso prefers her news report to be extremely biased.\nProposition 2. If σ : [0, 1] → [0, 1] is convex, the solution to problem (3.1) is either\n(q, 0) or (0, q) for all consumers.\nProposition 2 follows from the fact that U ∗ is convex in (σL , σR ) and that σ is strictly\nincreasing. If σ is also convex, U ∗ is convex in (qL , qR ) and the solution to (3.1) must\nbe an extreme point of the set of feasible reporting strategies. Lemma 1 rules out the\nextreme point (0, 0). Proposition 2 can also be visualized in Figure 3.2.\n3.1. Discussion.\n18\n\nFigure 3.2. Indifference Curves of Moderates\n\n3.1.1. Contrasting Viewpoints. The conventional wisdom professes that, to make an\ninformed decision, one should consider arguments both for and against any particular\ncourse of action; and that truth will emerge from competition in the marketplace of\nideas. Such beliefs are behind industry regulations that obligate media outlets to\npresent diversified viewpoints on controversial affairs of public interest. However, our\nanalysis above suggests that the conventional wisdom may have been misapplied in\nthis case.\nWhile learning additional information that might challenge one’s current belief can\nnever hurt if such information is readily available, this is not necessarily true when\nsuch information can only be acquired at a cost and one has to trade off information\nfrom different sources. In order to present contrasting viewpoints, a media outlet has\nto acquire both information biased to the left and to the right. However, Lemma 2\nidentifies circumstances under which acquiring information biased in a particular direction adds no value to the consumer. By contrast, Lemma 1 guarantees that resources\ncan be better spent on acquiring information biased in the other direction. This is\ntrue regardless of the efficiency with which the media outlet can acquire information.\n19\n\nThus, the consumer prefers her evidence to be more one-sided, even if that evidence is\nless accurate in identifying the true state. Regulations restricting the degree of bias in\nnews reporting can therefore hurt the consumers.\nHowever, this is not to say that such regulations cannot be justified at all. As we\nshow in Section 5, content regulations like the Fairness Doctrine may serve the society\nas a whole by preventing political polarization and correcting distortions created by\nmisalignment between individual and societal interests.\n3.1.2. More Choices Available to Consumers. We can extend the model to include any\nfinite number of choices by the consumers. In this case, Proposition 2 goes through\nwithout any modification. That is, so long as σ is convex, the utility maximizing news\nreport for a consumer is always extremely biased, regardless of how many actions she\ncan choose from.\nIn the general model, the consumers can still be divided into groups according to\ntheir default actions. In particular, we can identify the “most liberal consumers”, whose\ndefault action is the “most liberal action”, that is, db(0). Similarly, the “most conservative consumers” are those with default action db(1). Lemma 2 and Proposition 1 still\nhold in the general model for the most liberal action and the most liberal consumers\nas well as the most conservative ones.\n\n4. The Industrial Organization of the Market for News\nIn this section, we analyze the industrial organization of the market for news and\nexamine how equilibrium demand and supply respond to changes in market conditions.\nWe then relate our results to empirical observations made by other researchers.\n4.1. The Consumers. Recall that there is a continuum of consumers with unit mass.\nEach consumer is described by a five-dimensional vector, (α, β, δ, γ, π) that specifies\nher utility function and prior belief. In the rest of the paper, we consider the aggregate\ndemand by these consumers for news reports offered by an array of media outlets. In\norder to keep track of the demand of all the consumers, we restrict attention to the\ncase in which all of the consumers share the same utility function as summarized in\nTable 4.1. Here, c ∈ (0, 1) represents the cost associated with taking action l or r. For\nexpositional brevity, we shall identify a consumer with her prior belief.\nThe consumers may still differ in their prior beliefs and, hence, default optimal\n), a conservative has prior belief in\nactions. A liberal now has prior belief in [0, 1−c\n2\n\n1+c\n1+c\n( 2 , 1], and a moderate’s prior belief falls in the interval 1−c\n,\n. Let the distribution\n2\n2\n20\n\nTable 4.1. Consumers’ Utility Function\nL\nR\nl 1 − c −1 − c\nr −1 − c 1 − c\na\n0\n0\nof the consumers’ prior beliefs be summarized by the distribution function F , which\nhas a continuous density f and support [0, 1].15\n4.2. The Producers. The producers in the market for news are N ∈ N profitmaximizing media outlets. The media outlets’ profits, denoted Πj , for j = 1, 2, . . . N ,\nare assumed to be an increasing affine function of the measure of consumers they\nattract. Thus, maximizing expected profits is the same as maximizing expected readership / viewership. This assumption is common in the literature and is appropriate\nwhen the majority of the media outlets’ profits come from advertising.\nRealistically, a media outlet’s advertising income should also depend on the demographic characteristics of its readers / viewers. In particular, advertisers might pay\ndifferent rates for consumers who only consume news from one media outlet from\nthose who consume news from multiple sources (Gentzkow, Shapiro, and Sinkinson (2012), Ambrus, Calvano, and Reisinger (2013)). As we show below, this\ncan be easily accommodated in our model by adjusting the weight on the measures of\ndifferent groups of consumers.\n4.3. The Market Demand for News. Recall that, the value of news consumption\nbundle σ ≡ (σL , σR ) to the consumer is the difference between U ∗ (σL , σR , π) and u∗ (π).\nWe denote this value by V (σL , σR , π). Define π∗ (σL , σR ) implicitly by pσπ∗ (R | sN ) =\n1−c\nand π ∗ (σL , σR ) by pσπ∗ (R | sN ) = 1+c\n.16 U ∗ (σL , σR , π) and u∗ (π) are given by:\n2\n2\n\n\nπ ∈ [0, π∗ (σL , σR )]\n\n1 − 2π − c + 2σL π\nU ∗ (σL , σR , π) =\n[σL π + σR (1 − π)] (1 − c) π ∈ (π∗ (σL , σR ) , π ∗ (σL , σR )) ,\n\n\n\n2π − 1 − c + 2σR (1 − π) π ∈ [π ∗ (σL , σR ) , 1]\n15Some readers may be concerned by the assumed combination of homogeneous utility functions and\n\nheterogeneous priors. However, as demonstrated by the analysis so far, the behavior characteristics\nof the consumers and, in particular, their preferences for biased news reports, are not driven by\nany restrictions on their utilities or beliefs. Moreover, this is also only a choice of representation:\nthe consumers described above behave identically as a set of consumers with a common prior and\nheterogeneous utility functions. Detailed discussion is given in Appendix 7.3.\n16Thus, fixing a news consumption bundle σ, π (σ , σ ) is the prior belief of a consumer who is\n∗\nL\nR\nindifferent between actions l and a after learning inconclusive evidence sN . Similarly, consumer\nπ ∗ (σL , σR ) is indifferent between actions a and r after learning sN .\n21\n\nand\nu∗ (π) =\n\n\n 1−c \n\n1\n−\n2π\n−\nc\nπ\n∈\n0, 2\n\n\n\n1−c 1+c\n, 2\n2\n 1+c \nπ ∈ 2 ,1\n\nπ∈\n\n0\n\n\n\n\n2π − 1 − c\n\n\n\n.\n\nRecall that, π∗ &lt; 1−c\nand π ∗ &lt; 1+c\n, if σL &lt; σR , while the opposite is true, if σL &gt; σR .\n2\n2\nThe consumers can acquire any number of news reports offered in the market at\na constant cost (in terms of money, time, effort and other resources) of κ &gt; 0 per\n\n≡ κ, where\nnews report.17 To avoid triviality, κ needs to satisfy κ &lt; V σ (q) , 0, 1−c\n2\n\n\n1+c\n1−c\nV σ (q) , 0, 2 = V 0, σ (q) , 2 is the highest possible value of a single news report\nto any consumer.\nThe consumers each choose a set of news reports that maximizes their expected\nutilities. We assume that when a consumer is indifferent between consuming a news\nreport or not, she always chooses to consume it.18 Moreover, when a consumer is\nindifferent between a number of news consumption bundles, she randomly chooses one\nof them and all news consumption bundles are chosen with equal probabilities.\nTo illustrate how market demand is determined, suppose there are two media outlets\noperating in the market, namely, media outlets j and k. They each offer a news report,\n\n\ncharacterized by qj = qLj , qRj and qk = qLk , qRk respectively. A consumer with\n \nprior belief π values these reports at V (σ (qj ) , π) and V σ qk , π , and values the\n \nbundle of these two reports at V τ σ (qj ) , σ qk , π . Without loss of generality, let\n \nV (σ (qj ) , π) ≥ V σ qk , π . Thus the consumer will consume qj , if V (σ (qj ) , π) ≥\n \nκ. She will choose to consume both qj and qk if V τ σ (qj ) , σ qk , π ≥ 2κ and\n \nV τ σ (qj ) , σ qk , π − V (σ (qj ) , π) ≥ κ.\n4.4. Model Specialization. We have defined all of the necessary components of our\nformal model. However, this setup is quite general. While all of the qualitative results\nin the following sections are stated and proved within this general setting, sharper\ncharacterizations can be given if the model is further specialized. Thus, in addition\nto the general model, we consider a specialized model with the following additional\nassumptions.\n2c\nAssumption 1. c, q, and σ satisfy: σ (q) &gt; 1+c\n.\n17The assumption of a constant marginal consumption cost is made for convenience only.\n\nLetting\nthe marginal consumption cost depend on the number of news reports received does not qualitatively\nchange our results.\n18This implies that the sum of the media outlets’ readership / viewership is upper semi-continuous in\ntheir reporting strategies.\n22\n\nAssumption 1 ensures that any moderate consumer can potentially be persuaded to\ntake a partisan action even when the evidence is not conclusive.\nAssumption 2. σ (x) ≡ x\nThe following analyses focus on market forces that drive media bias, and not on the\nmedia outlets’ considerations for production efficiency. Therefore, in the specialized\nmodel, σ is assumed to be linear. Since σ (0) = 0, letting the slope of σ be unity, i.e.,\nσ (x) ≡ x, is without loss of generality.\nAssumption 3. F is given by the truncated normal distribution with mean µ ∈\n 1−c 1+c \n, 2 and variance σ 2 , i.e.,\n2\n\n\n(x−µ)2\n1\n1\n−\n\n2σ 2\n√\nf (x) =  ´\ne\n(y−µ)2\n1\n−\nσ 2π\n√1 e\n2σ 2 dy\n0 σ 2π\n\nfor all x ∈ [0, 1] and is equal to 0 otherwise.19\nWhile most of the results stated in the following sections only require the distribution\nF to be uni-modal, some of them do depend on its shape. Instead of imposing a number\nof conditions on F , we simply assume that it takes the form of a truncated normal\ndistribution.\n4.5. Monopoly. When there is only one media outlet in the market, the consumers\ncan consume at most one news report. Therefore, given the monopolist j’s reporting\nstrategy qj , consumer π chooses to consume j’s news report if and only if V (σ (qj ) , π) ≥\nκ. Thus, j faces the following problem:\nˆ\n\nj\nj\nmax\nΠj qL , qR ; κ\n= max\nf dπ\n(4.1)\nj j\nj j\nj\nqL\n,qR\nqL\n,qR {π∈[0,1]|V (σ (qL\n),σ(qRj ),π)≥κ}\ns.t. qLj , qRj ≥ 0\nqLj + qRj ≤ q.\n\n\nLemma 1 implies that, for any κ &gt; 0 and any qeLj , qeRj &gt;&gt; qLj , qRj , {π ∈ [0, 1] |\n\n\nV qLj , qRj , π ≥ κ} ( {π ∈ [0, 1] | V qeLj , qeRj , π ≥ κ}. Since F has full support on\n[0, 1], this implies that j can strictly increase its profit by increasing both qLj and qRj .\n\nTherefore, any solution to (4.1), qj∗ ≡ qLj∗ , qRj∗ , must satisfy: qLj∗ + qRj∗ = q.\nThe same holds for a duopolist, a triopolist, or, in general, any producer in the\nmarket. Since f is supported on [0, 1], there are always marginal consumers that\nare indifferent between distinct news reports or indifferent between consuming a news\n19π in this expression is the familiar mathematical constant.\n\n23\n\nreport or not. Therefore, it is always suboptimal for a profit maximizing media outlet\nto underutilize its resources.20 Moreover, a media outlet has no incentive to garble its\nsignals, that is, mis-reporting the findings from its investigation. Blackwell’s (1951)\ntheorem implies that any garbling by the media outlet can only reduce the value of its\nnews report to all of the consumers and, consequently, leads to lower profits.\nj\nqL\nFixing qLj + qRj , changing the bias ρj = qj +q\nj , makes a news report more valuable to\nL\nR\nsome consumers and less valuable to others. Thus, in general, the monopolist’s choice\nof bias in its report involves a tradeoff between one group of consumers and another.\nHowever, there are exceptions, as illustrated by the next lemma.\nLemma 3. There exists κ∗ ∈ (0, κ) such that, if κ ∈ (κ∗ , κ), then the monopolist’s\nproblem (4.1) has only extreme solutions (i.e., either (q, 0) or (0, q)).\nThat is, when the news consumption costs borne by the consumers are sufficiently\nhigh, the only profit maximizing reporting strategies of the monopolist are extremely\nbiased.\nWhen the monopolist increases the bias of its news report in a particular direction,\nthe consumers whose initial position lies opposite to that direction are alienated. However, when the cost of consuming news is high, these consumers would not consume the\nmonopolist’s news report even without the increase in bias. Therefore, the monopolist\nfaces no real tradeoff and is better off choosing an extreme position. However, the next\nobservation shows that, when the cost of consuming news is low, the opposite is true.\n\n\nLemma 4. For any interior qLj , qRj , there exists κ\nb qLj , qRj &gt; 0 such that, if κ ∈\n\n\n0, κ\nb qLj , qRj , Πj qLj , qRj is strictly higher than both Πj (q, 0) and Πj (0, q).\nThus, if the news consumption costs are sufficiently low, the extremely biased reporting strategies are suboptimal, and Problem (4.1) has only interior solutions.\nLemmas 3 and 4 lead to the following Proposition.\nProposition 3. The solution to the monopolist’s problem (4.1) exists for all κ. Moreover, there exist κ∗1 and κ\nb1 in (0, κ), such that, when κ ∈ (κ∗1 , κ), the monopolist’s\nprofit maximizing reporting strategies must be extreme (i.e. (q, 0) or (0, q)), and, when\nκ ∈ (0, κ\nb1 ), the monopolist’s profit maximizing reporting strategies must be interior.\nCompared with a more balanced news report, an extremely biased news report provides strictly higher value to some consumers. On the other hand, Lemma 2 implies\n20Note that τ is a strictly increasing function, so the consumers’ valuation of their second (third, etc)\n\nnews report is also increasing in the resources devoted by the media out.\n24\n\nthat an extremely biased news report provides no value to consumers with strong positions contrary to the direction of its bias, while a more balanced news report provides\npositive value to all consumers. When the consumption costs are high, only high value\nnews reports are consumed. Consequently, the monopolist is better off focusing on a\nsegment of the market and attracting as many consumers in that segment as possible.\nThis is achieved by producing an extremely biased news report. On the other hand,\nwhen the consumption costs are low, a monopolist can capture the whole market by\noffering a more balanced news report.\nWe can further characterize the monopolist’s optimal reporting strategy, by focusing\non the specialized model.\nProposition 4. Under Assumptions 1 to 3, the monopolist’s profit maximizing reporting strategies are biased to the left (right) if and only if µ &lt; 12 (µ &gt; 12 ). Moreover,\nwhen κ &lt; κ\nb1 , the monopolist’s profit maximization strategy is unique and it becomes\nless biased (i.e. | ρj∗ − 21 | decreases) as κ falls.\nIn the specialized model, when consumption costs are low, the monopolist’s problem\nessentially becomes a tradeoff between marginal liberal consumers and conservative\nones. This comes down to comparing the population density of the marginal consumers,\nj∗\nqL\nand hence the dependence of ρ∗ = qj∗ +q\nj∗ on µ.\nL\n\nR\n\n4.6. Duopoly. Now suppose there are two media outlets, j and k. The oligopolistic\ncompetition amongst media outlets is modeled as a strategic game, in which the media outlets independently and simultaneously choose their reporting strategies. The\npayoff to a player is the profits it makes. In the following sections, we study the Nash\nEquilibria of this game.\nThe duopolists each offer a news report. Thus, the consumers can consume up to two\nnews reports at a cost of κ per report. Fixing the reporting strategy of its competitor,\nk, and that of itself, the consumers attracted to media outlet j can be broken down to\ntwo groups. One group of the consumers have a unique optimal consumption bundle\nthat includes j’s news report. The other group of consumers have multiple optimal\nconsumption bundles, and j’s news report is included in some of them. The first group\nof consumers, denoted by Aj ⊆ [0, 1], choose to consume j’s report with probability one.\nOn the other hand, the second group of consumers randomly choose from their optimal\nconsumption bundles, and thus may only choose to consume j’s report with positive\nm\nprobability. Let AjM denote the set of consumers who have M optimal consumption\nbundles, m of which include j’s report.\n25\n\nIn a duopoly, j’s profit can be written as:\nˆ\nˆ\n\n1\nj\nk\nf dπ.\nΠj q ; q , κ =\nf dπ +\n2 Aj12\nAj\nThe duopolists’ game and, more generally, any oligopolists’ game are not continuous,\nthat is, the media outlets’ payoffs are not continuous in their strategies, and pure\nstrategy Nash equilibria do not exist in general. However, as the next proposition\nshows, there always exists at least one Nash equilibrium in mixed strategies. In fact,\nthere exists at least one symmetric equilibrium. Moreover, the mixed strategy equilibria\nhave to satisfy certain properties:\nProposition 5. The duopolists’ game has at least one symmetric Nash equilibrium\n(in mixed strategies) for any κ ∈ (0, κ). Moreover, there exist κ∗2 and κ\nb2 in (0, κ),\n∗\nsuch that, if κ ∈ (κ2 , κ), only (q, 0) and (0, q) can be in the support of any equilibrium\nstrategy, while, if κ ∈ (0, κ\nb2 ), then, in any equilibrium, the probability that some interior\nreporting strategy is chosen must be strictly positive.\nThat is, when the news consumption costs are sufficiently high, only extremely biased news reports are produced with positive probability. However, when the news\nconsumption costs are sufficiently low, more balanced news reports are produced with\npositive probability. Thus, similar to the monopolist’s case, as the costs of consuming news fall, the news reports offered in equilibrium become more balanced, albeit in\na probabilistic sense.21 Note that, when news consumption costs are low, all media\noutlets choose interior reporting strategies with positive probability in the symmetric\nequilibrium.\nThe logic behind Proposition 5 is also similar to the logic behind the monopolist’s\nproblem. Even though the consumers have the freedom to choose two news reports,\nwhen consumption costs are high, doing so is not economical. Thus, an oligopolist’s\nproblem is similar to that of a monopolist when consumption costs are high. Thus, its\noptimal strategy is to focus on a segment of the market.\nOn the other hand, when the consumption costs are low, then it is possible for some\nconsumers to consume two news reports. However, just like before, an extremely biased\nnews report is not valuable to consumers with strong positions opposite to the direction\nof the report’s bias even as a second choice. On the other hand, like in the monopolist’s\ncase, any media outlet can serve the whole market with a more balanced news report.\nConsequently, the media outlets have incentives to reduce biases in their news reports.\nWith the specialized model, we can further characterize the equilibria of this game.\n21Note that, in general, κ\ne\n\ne2 and κ\nb1 6= κ\nb2 .\n1 6= κ\n26\n\nProposition 6. Under Assumptions 1 to 3, there exists κ̌2 ∈ (0, κ∗2 ], such that, when\nµ = 21 and κ ∈ (0, κ̌2 ), the game has a symmetric Pure Strategy Nash Equilibrium\n\n\n(PSNE) at 2q , 2q , 2q , 2q . Moreover, if | µ − 21 | is sufficiently small, then there is a\nPSNE ((x∗ q, (1 − x∗ ) q) , (x∗ q, (1 − x∗ ) q)), where x∗ ∈ [0, 1] and x∗ ≈ 12 .\nThus, in the specialized model with enough symmetry and low consumption costs,\nthe duopolists each choose a (almost) perfectly balanced news report with probability\none in equilibrium.\nNote that, the consumers’ ability to choose any number of news reports is essential\nfor these results. The reason a media outlet offers a less biased news report, when\nnews consumption costs are low, is to attract consumers initially located at the other\nend of the ideological spectrum, who might consume the less biased report as a second\nnews source. For that reason, Propositions 5 and 6 may not hold if the consumers are\nrestricted to consuming only one news report, as illustrated by the next example.\nExample 1. In addition to Assumptions 1 and 3, assume that the consumers are\nrestricted to consuming no more than one news report. Then, for any κ &gt; 0, only\n(q, 0) and (0, q) can be chosen with positive probability in any equilibrium.\n4.7. Multiple Competitors. When there are N &gt; 2 media outlets competing in the\nmarket, results analogous to Propositions 5 and 6 still hold. That is, fixing the number\nof media outlets operating in the market, when news consumption costs are sufficiently\nhigh, we can only expect to see extremely biased news reports in equilibrium. As the\nconsumption costs fall, extreme reporting strategies become less profitable to media\noutlets compared to more balanced ones. Indeed, in some cases, all media outlets end\nup offering perfectly balanced news reports with probability one.\nThe next result shows that, for any level of consumption costs, increase in competition eventually makes the extreme reporting strategies profitable. Thus, the trend\nof decreasing biases brought about by falling consumption costs can be reversed by\nintensifying competition.\ne (κ), such that,\nProposition 7. For each κ ∈ (0, κ), there exists a positive integer N\ne (κ) media outlets and news consumption\nin any equilibrium of the game with N &gt; N\ncost κ, (q, 0) must be chosen with positive probability, and so is (0, q).\nWith low consumption costs, the reason that a media outlet produces a less biased\nnews report in equilibrium is so that it can attract more consumers from the other\nend of the ideological spectrum. However, this becomes difficult when there are more\nmedia outlets producing news with biases that are preferred by those consumers. On\nthe other hand, by reducing the bias in its news report, a media outlet risks losing\n27\n\nconsumers who favor such biases, when there are other media outlets targeting those\nconsumers and are willing to produce news with more bias. Consequently, increasing\nbiases eventually becomes more profitable to the media outlets.\n4.8. Empirical Implications. As argued above, when news consumption costs are\nlow, there must be (symmetric) Nash equilibria in which all media outlets choose interior reporting strategies with positive probability. In particular, we may observe\noutcomes in which news reports are produced with biases across the ideological spectrum. The next example illustrates such a scenario.\nExample 2. Let σ (x) ≡ x and let F be uniform over [0, 1]. Consider a market with\nthree media outlets. Suppose that κ is sufficiently low and the following strategy profile\nis in the support of the equilibrium strategies: ((xq, (1 − x) q) , (yq, (1 − y) q) , ((1 − x) q, xq)),\nwhere 0 &lt; x &lt; y &lt; 1−x. When κ is sufficiently low, all three media outlets can attract\nconsumers from\nall three ideological groups.\nh\ni Specifically, all consumers whose prior beκ\nκ\nlief falls in 2xq , 1 − 2(1−xq)[1−(1−y)q](1−x)q consume the news report (xq, (1 − x) q), all\ni\nh\nκ\nκ\n, 1 − 2(1−xq)(1−y)q\nconsume the news report (yq, (1 − y) q), and all\nconsumers 2(1−xq)yq\ni\nh\nκ\nκ\nconsume the report ((1 − x) q, xq).\nconsumers 2(1−xq)(1−yq)(1−x)q\n, 1 − 2xq\n\n\nκ\nIn this example, the media outlet most biased to the left attracts 1−c\n−\nliberals\n2\n2xq\n\n\nκ\nconservatives. Similarly, the most right-biased media\nand 1−c\n− 2(1−xq)[1−(1−y)q](1−x)q\n2\n\n\n\n\n1−c\n1−c\nκ\nκ\noutlet attracts 2 − 2(1−xq)(1−yq)(1−x)q liberals and 2 − 2xq conservatives. The\n\n\n\n\nκ\n1−c\nκ\nmost balanced news report attracts 1−c\n−\nliberals\nand\n−\n2\n2(1−xq)yq\n2\n2(1−xq)(1−y)q\nconservatives. Thus, the ratio of liberals to conservative consumers decreases as the\nR\nmedia outlet’s bias ρ = qLq+q\nincreases. The average ideological position of a media\nR\noutlet’s consumers is correlated with the bias in its news report. This matches the\nfindings by the Pew Research Center for the People and the Press (2012) in a recent\nsurvey of news consumption patterns (see Figure 4.1).\nMoreover, there are overlaps between the\nouth readership / viewership of the media\ni\nκ\nκ\nlets. The consumers with prior beliefs in 2(1−xq)yq , 1 − 2(1−xq)[1−(1−y)q](1−x)q consume\nboth the most\nleft biased news report and the\nh\ni most balanced news report. The conκ\nκ\nsumers in 2(1−xq)(1−yq)(1−x)q , 1 − 2(1−xq)(1−y)q consume both the balanced report and\nthe most right biased\nreport. The two media outlets with strong\nopposite biases share\nh\ni\nκ\nκ\nthe consumers in 2(1−xq)(1−yq)(1−x)q , 1 − 2(1−xq)[1−(1−y)q](1−x)q . Thus, the media outlets\nwith similar biases share larger overlapping readership / viewership. This pattern of\noverlapping readership / viewership is consistent with the findings by a Nielson survey\n28\n\nFigure 4.1. Pew Research Center Survey on Audience Ideology\n\nconducted on behalf of Pew Research Center (Mitchell, Jurkowitz, Enda, and Olmstead (2013)), which shows a similar pattern of cross viewership between cable news\nprograms in the U.S. market (See Figure 4.2).\nHamilton (2006) documents historical changes of media bias in the U.S. market for\nnews. There was first a trend of decreasing media bias occurred in the late 19th century.\nBefore then, most U.S. newspapers are openly affiliated with political parties. However,\nsince the 1870s, “nonpartisan reporting emerged as a commercial product.” 22 Gentzkow,\nGlaeser, and Goldin (2006) provided a similar account for this change. According to\nthem, in 1870, only 11 percent of all political newspapers claimed to be independent.\n22Hamilton (2006) P. 3\n\n29\n\nFigure 4.2. Nielson Survey on Cross-Viewership\n\nBy 1920, this number had risen to 62 percent. An opposite trend occurred since the\n1990s, when “elements of partisanship reemerged in television.” 23\nBoth of these historical trends can be explained by the present model. As noted\nby Hamilton (2006), the first trend of decreasing media bias corresponded with the\ninvention of rotary printing press. Mass printing and other technological innovation\ndrastically reduced the cost of newspapers to the consumers. Thus, as predicted by\nProposition 5 and 6, the papers had the incentive to reduce bias in their reporting in\norder to capture a larger share of the market.\nWhile news consumption costs did not rise in the 1990s, new technologies such as\ncable and satellite provided consumers with easy access to a wider range of programs.\nThus, as predicted by Proposition 7, increase in competition among media outlets gave\nthem incentives to bias their news reports. The late 1990s saw the establishment of the\nFox News Channel and MSNBC, which over the years have established strong branding\nas conservative and progressive news stations. Moreover, it has been argued that “the\nrise of the conservative Fox News Channel caused CNN to shift to the left. ” 24 Chiang\n23Hamilton (2006) P.3\n24Posner (2005)\n\n30\n\n(2010) provides further evidence that competition induces media outlets to increase\ntheir bias.\n4.9. The Merits of Fairness. Content regulations such as the FCC’s Fairness Doctrine and the Ofcom’s Due Impartiality rules can be modeled in our framework as\nconstraints on the degree of bias with which the media outlets can produce their\n \nnews reports. Formally, such regulations can be represented by a number b ∈ 0, 12\nsuch that all media outlets can only choose reporting strategies (qL , qR ) that satisfy\nL\n| qLq+q\n− 12 |≤ b. Such regulations are said to be binding, if, without these conR\nstraints, the media outlets’ equilibrium strategies assign positive probabilities to reporting strategies that violate these constraints. The next proposition shows that such\nregulations, if binding, will always make some consumers worse off. Moreover, there\nare conditions under which they can make all consumers worse off.\nProposition 8. Content regulations, if binding, can never result in Pareto improvements but can result in Pareto dominated outcomes.\nThus, contrary to widely held beliefs, content regulations like the Fairness Doctrine\nare poorly justified on the ground of protecting consumer welfare. However, as we\nshow in the next section, they may help to mitigate other potentially harmful social\nconsequences of media bias, such as political polarization.\n5. Political Polarization\nThe consumers’ preferences for the biases in their news consumption are not continuous, that is, two consumers with very similar utility functions and prior beliefs may\nprefer their news consumption to contain very different biases. On the other hand,\nhaving received news reports containing different biases, the posterior beliefs of two\nalmost identical consumers may end up being quite far apart. Thus, as we show in\nthe following example, media bias can cause political polarization, which is defined\nbehaviorally as consumers choosing more extreme actions in opposite directions.\nSuppose there are two media outlets operating in the market, and the market conditions are such that in equilibrium, all consumers consume at most one news report\nand the two media outlets offer news reports that are extremely biased in opposite\ndirections, i.e., (q, 0) and (0, q).25 Moreover, suppose that Assumptions 1 and 2 hold.\nThus, all consumers with prior beliefs smaller than 21 strictly prefer the news report\n(q, 0), while the report (0, q) is strictly preferred by consumers with prior beliefs greater\nthan 21 .26\n25By virtue of Proposition 5, such an equilibrium exists when κ is sufficiently high.\n26These assumptions are not essential for this analysis but are made for expositional brevity.\n\n31\n\nConsider two moderates with prior beliefs π 0 and π 00 respectively, where π 0 &lt; 21 &lt; π 00 .\nFurther, let π 0 and π 00 be such that the two moderates each consume one news report.27 The two media outlets are expected to both report message σN with probability 1 − σ (q). In that event, consumers π 0 and π 00 learn the inconclusive evidence\n(σ(q),0)\npresented by their news reports of choice and update their beliefs to pπ0\n(R | sN )\n(0,σ(q))\nand pπ00\n(R | sN ) respectively. By virtue of Assumption 1, both moderates abandon\ntheir default action after seeing the evidence. However, while consumer π 0 chooses\naction l, consumer π 00 goes in the other direction and chooses action r.\nThus, media bias leads to political polarization. Given the choice, both moderate consumers consume a biased news report. However, due to the difference in the\nconsumers’ prior beliefs, the biases in their chosen news reports are in the opposite\ndirections. This difference in their beliefs is not significant enough for the consumers\nto choose different actions without additional information. However, in some event, the\nconsumers learn inconclusive evidence that point to opposite directions. As a result,\nthe two moderates end up choosing opposite partisan actions.\nThe two consumers in this example each represent a positive measure of other moderates whose choices agree with theirs. Thus, in the absence of conclusive evidence,\nthere can be a significant reduction in the population of moderate consumers, while\nthe populations of both partisan groups increase.\nThe extent of political polarization depends on the level of news consumption costs\nand the degree of competition. In the previous example, when κ is high, the news\nreports produced are extremely biased. However, polarization is not severe, since very\nfew consumers consume any news. As κ falls, the news reports remain extremely biased,\nand more moderates choose to consume one of the two news reports. Consequently,\npolarization becomes more severe, that is, in the event that no conclusive evidence is\nfound, more moderates become partisans. However, as κ continues to fall, some moderates find it worthwhile to consume both news reports, which gives them a perfectly\nbalanced news consumption bundle. When presented with inconclusive evidence, these\nconsumers do not change their action, since the evidence in the news reports balance\nout. Thus, polarization is mitigated. It is further mitigated if κ falls even more, as the\nmedia outlets produce more balanced news in response.\nOn the other hand, when news consumption costs are low such that political polarization is not severe to begin with, it can be exacerbated by increase in competition. As\nmore media outlets enter the market, the news reported in equilibrium becomes more\nbiased again. Moreover, the moderates that used to consume two news reports with\n27Such π 0 and π 00 exist for any κ &lt; κ.\n\n32\n\nopposite biases end up consuming news reports biased in the same direction. Thus,\npolarization becomes more severe again. However, with more media outlets acquiring\ninformation, the probability that conclusive evidence is produced increases. So does\nconsumer surplus.\n5.1. Political Polarization and Social Inefficiency. The reason why a consumer\nprefers her news to be biased is because that, in the absence of any conclusive evidence,\nevidence that is more one-sided can make her more certain of what the true state is.\nIndeed, such evidence can be strong enough to convince her to take a more extreme\naction. However, her decision to change action may not be justifiable if all the social\ncosts associated with her action are taken into account. Higher social costs means that\nstronger evidence is needed to justify the consumer’s new action. In other words, the\nconsumer’s choice in light of the evidence presented by her choice of news consumption\nmay be premature from the society’s perspective.\nLet us consider a simple scenario where, in addition to costing c to the consumers,\nthe partisan actions l and r also impose an externality on the society, which makes\nthe social cost of these actions equal to c0 &gt; c. As illustrated in the previous example,\nmedia bias can lead to political polarization. The two moderates in the earlier example\nend up choosing partisan actions after learning inconclusive evidence presented by their\nnews reports.\n0\n&lt;\nConsider consumer π 0 . Suppose that the externalities are significant so that 1−c\n2\n(σ(q),0)\n1−c\n0\npπ 0\n(R | sN ) &lt; 2 . Thus, if consumer π takes into account the costs her action\nimposes on the society, she would not change her action after learning sN . In the\nabsence of any means to ensure that the consumer internalize all the social costs, she\nends up choosing l, and expected social welfare is brought down.\n5.2. Mitigating Political Polarization. Now suppose a content regulation, b, is imposed. For expositional convenience, let b = 0. Then, the only reporting strategies the\n\n\nmedia outlets can choose is 2q , 2q . The inconclusive evidence reported by 2q , 2q is not\nstrong enough to persuade the consumer to change her action, so political polarization\nis mitigated. Moreover, it is easy to verify that, the ex ante expected social welfare\n\nis higher when consumer π 0 chooses news report 2q , 2q instead of (q, 0), as long as\n(σ(q),0)\n1−c0\n&lt; pπ0\n(R | sN ) &lt; 1−c\n. Therefore, the content regulation helps to correct the\n2\n2\ndistortions caused by the externalities.\nHowever, the effectiveness of such regulations in mitigating political polarization depends crucially on market conditions. In fact, there are circumstances under which\ncontent regulations can exacerbate political polarization, rather than mitigate it. Suppose that, in the previous example, the consumption costs are lower so that some\n33\n\nmoderates choose to consume both news reports. However, suppose that the media\noutlets still produce extremely biased news.28 Now suppose that a content regulation,\ncharacterized by 0 &lt; b &lt; 12 , is introduced and is binding in equilibrium.29\nAfter the media outlets reduce their bias to satisfy the regulations, the moderate\nconsumers who were close to being indifferent between consuming one and two news\nreports before the regulation is introduced end up consuming only one news report.\nComparing with their initial consumption bundle, which was completely balanced, the\nnews report they consume now is more biased. Consequently, in addition to reducing\nconsumer surplus, the content regulation can also aggravate polarization, because some\nof those moderates that end up consuming more biased news might end up choosing a\npartisan action in the absence of conclusive evidence.30\n\n6. Conclusion\nWe present a theory of media bias where preference for biased news is consistent\nwith Bayesian rationality. To an individual consumer, consuming biased news may be\na more efficient means to acquire information than consuming more balanced news.\nConsequently, profit maximizing media outlets have the incentive to bias their news\nreports in order to attract more consumers.\nOur model offers theoretical explanations for a number of empirical findings pertaining to consumer and supplier behaviors in the news market uncovered in recent\nstudies. We find that falling costs of consuming news encourages the media outlets to\noffer more balanced news in equilibrium, while the opposite happens when competition\nheightens. The biases in the news reports are correlated with the prior positions of the\nconsumers they attract. The consumer bases of different media outlets may overlap,\nand the overlap is larger if the biases in their news reports are closer.\nMoreover, this new formal framework sheds some light on the social impact of media\nbias and the regulations designed to curtail it. We show that media bias may lead\nto political polarization, which can be socially inefficient when there are externalities.\nContent regulations such as the FCC’s Fairness Doctrine can help to mitigate polarization and correct distortions. However, the severity of political polarization and the\n28In general, without strong efficiency gains, to make the media outlets choose an interior strategy, the\n\nconsumption costs need to be sufficiently low so that balanced reports can potentially attract sizable\npopulations of partisan consumers.\n29Otherwise, it would be unnecessary to introduce this regulation.\n30Because the consumers’ posterior beliefs p(σL ,σR ) (s ) and their valuation of information\nπ\nN\n\nV (σL , σR , π) are both continuous, the set of parameters σ (q) , κ, b that can give rise to such scenarios\nis non-empty.\n34\n\neffectiveness of content regulations both depend critically on market conditions. Under some circumstances, content regulations might exacerbate polarization rather than\nmitigate it.\nOur model can be extended in a number of directions. As discussed in Section 3, an\nimplicit assumption we make is that the media outlets are equally efficient in acquiring\ninformation biased to both directions. If, instead, the media outlets are more efficient\nin producing news reports biased to the left, then even a conservative might prefer left\nbiased news reports to right biased ones.\nMany scholars as well as political commentators have argued that the American\npublic media is biased to the left (e.g., Goldberg (2002), Groseclose and Milyo (2005),\nand Groseclose (2011)). One explanation they give for why a liberal bias exists is that\nthe members of the media elite themselves have liberal views that, in turn, make them\nmore open to liberal arguments. As a consequence, they are more efficient in acquiring\ninformation biased to the left.\nFor example, Groseclose and Milyo (2005) quote the following from Sutter (2001):\nIf the majority of journalists have left-of-center views, liberal news might\ncost less to supply than unbiased news.31\nArguments like these are supported by our model. If the media outlets’ production\ntechnology is sufficiently asymmetrical, both liberals and conservatives prefer news\nreports biased to the left. Consequently, the media outlets produce mostly left biased\nnews in the equilibrium.\nHowever, if the liberal bias results from taking advantage of more efficient production\ntechnology, then such biases are beneficial to all consumers, including the conservatives.\nThe conservatives would be better off if the media outlets could produce right biased\nnews more efficiently. However, when this is not feasible, consuming left biased news\nis optimal for them.\nWe can also let consumers’ well-being depend on each other’s actions (as in an election). Then a consumer’s choice of news consumption imposes an externality on others\nthrough her expected choice of action. Consequently, an individual consumer might\nprefer regulations that affect the variety of news reports other consumers can consume.\nGiven the heterogeneity among the consumers, their preferred policy interventions are\nalso going to differ.\n\n31\n\nSutter (2001) P. 444. Quoted by Groseclose and Milyo (2005) P. 1227\n35\n\nReferences\nAlterman, E. (2003): What Liberal Media? : The Truth about Bias and the News.\nBasic Books, New York, paperback edition edn.\nAmbrus, A., E. Calvano, and M. Reisinger (2013): “Either or Both Competition:\nA "Two-sided" Theory of Advertising with Overlapping Viewerships,” .\nAnderson, S. P., and J. McLaren (2012): “Media Mergers and Media Bias with\nRational Consumers,” Journal of the European Economic Association, 10(4), 831–\n859.\nBaron, D. P. (2006): “Persistent Media Bias,” Journal of Public Economics, pp. 1–36.\nBernhardt, D., S. Krasa, and M. Polborn (2008): “Political Polarization and\nthe Electoral Effects of Media Bias,” Jounal of Public Economics, 92, 1092–1104.\nBesley, T., and A. Prat (2006): “Handcuffs for the Grabbing Hand? Media Capture\nand Government Accountability,” American Economic Review, 96(3), 720–736.\nBlackwell, D. (1951): “Comparison of Experiments,” in Proceedings of the Second\nBerkeley Symposium on Mathematical Statistics and Probability, pp. 93–102. University of California Press.\nBrock, D., A. Rabin-Havt, and Media Matters for America (2012): The\nFox Effect: How Roger Ailes Turned a Network into a Propaganda Machine. Anchor\nBooks.\nCalvert, R. L. (1985): “The Value of Biased Information: A Rational Choice Model\nof Political Advice,” Journal of Politics, 47, 530–55.\nChan, J., and W. Suen (2008): “A Spatial Theory of News Consumption and Electoral Competition,” The Review of Economic Studies, 75, 699–728.\nChiang, C.-F. (2010): “Political Differentiation in Newspaper Markets,” .\nChiang, C.-F., and B. Knight (2011): “Media Bias and Influence: Evidence from\nNewspaper Endorsements,” The Review of Economic Studies, 78, 795–820.\nCoulter, A. (2003): Slander: Liberal Lies about the American Right. Three Rivers\nPress, 1 st edition edn.\nDellaVigna, S., and E. Kaplan (2007): “The Fox News Effect: Media Bias and\nVoting,” Quarterly Journal of Economics, pp. 1187–1234.\nDuggan, J., and C. Martinelli (2011): “A Spatial Theory of Media Slant and\nVoter Choice,” The Review of Economic Studies, 78(2), 640–666.\nGentzkow, M. A., E. L. Glaeser, and C. Goldin (2006): “The Rise of the Fourth\nEstate: How Newspapers Became Informative and Why It Mattered,” in Corruption\nand Reform: Lessons from America’s Economic History, ed. by E. L. Glaeser, and\nC. Goldin. University of Chicago Press.\n36\n\nGentzkow, M. A., and J. M. Shapiro (2004): “Media, Education and AntiAmericanism in the Muslim World,” Journal of Economic Perspectives, 18(3), 117–\n133.\n(2006): “Media Bias and Reputation,” Journal of Political Economy, 114(2),\n280–316.\n(2010): “What Drives Media Slant? Evidence from U.S. Daily Newspapers,”\nEconometrica, pp. 35–71.\nGentzkow, M. A., J. M. Shapiro, and M. Sinkinson (2012): “Competition and\nIdeological Diversity: Historical Evidence from US Newspapers,” .\nGoldberg, B. (2002): Bias: A CBS Insider Exposes How the Media Distort the\nNews. Originally Published by Regnery Publishing, Inc. and Reprinted by Perennial,\nWashington.\nGroseclose, T. (2011): Left Turn: How Liberal Media Bias Distorts the American\nMind. St. Martin’s Press, New York.\nGroseclose, T., and J. Milyo (2005): “A Measure of Media Bias,” Quarterly Journal of Economics, 120(4), 1191–1237.\nHamilton, J. T. (2006): All the News That’s Fit to Sell: How the Market Transforms\nInformation into News. Princeton University Press, Princeton, New Jersey.\nKlayman, J. (1995): “Varieties of Confirmation Bias,” Psychology of Learning and\nMotivation, 32, 385–418.\nLimburg, V. E. (2013): “Fairness Doctrine - U.S. Broadcasting Policy,” .\nMitchell, A., M. Jurkowitz, J. Enda, and K. Olmstead (2013): “How Americans Get TV News at Home,” .\nMullainathan, S., and A. Shleifer (2005): “The Market for News,” American\nEconomic Review, 95(4), 1031–1053.\nNickerson, R. S. (1998): “Confirmation Bias: A Ubiquitous Phenomenon in Many\nGuises,” Review of General Psychology, 2(2), 175–220.\nOliveros, S., and F. Vardy (2012): “Demand for Slant: How Abstention Shapes\nVoters’ Choices of News Media,” .\nPosner, R. A. (2005): “Bad News,” .\nPrat, A., and D. Stromberg (2011): “The Political Economy of Mass Media,” .\nPuglisi, R., and James M. Snyder Jr. (2012): “The Balanced U.S. Press,” .\nRabin, M., and J. L. Schrag (1999): “First Impressions Matter: A Model of Confirmatory Bias,” The Quarterly Journal of Economics, 114(1), 37–82.\nRadner, R., and J. E. Stiglitz (1984): “A Nonconcavity in the Value of Information,” in Bayesian Models of Economic Theory, ed. by M. Boyer, and R. E. Kihlstrom.\nElsevier, Amsterdam.\n37\n\nReny, P. J. (1999): “On the Existence of Pure and Mixed Strategy Nash Equilibria\nin Discontinous Games,” Econometrica, 67(5), 1029–1056.\nSavage, L. J. (1972): The Foundations of Statistics. 1954. Dover Publications, Inc.,\nNew York, second edn.\nSobbrio, F. (2013): “Citizen-Editors’ Endogenous Information Acquisition and News\nAccuracy,” .\nStone, D. F. (2011): “Ideological Media Bias,” Journal of Economic Behavior and\nOrganization, 78, 256–271.\nSuen, W. (2004): “The Self-Perpetuation of Biased Beliefs,” The Economic Journal,\n114, 377–396.\nSutter, D. (2001): “Can the Media Be So Liberal? The Economics of Media Bias,”\nThe Cato Journal, pp. 431–451.\nthe Pew Research Center for the People and the Press (2011): “Press\nWidely Criticized, But Trusted More than Other Information Sources: Views of the\nNews Media: 1985 - 2011,” .\n(2012): “In Changing News Landscape, Even Television is Vulnerable: Trends\nin News Consumption: 1991-2012,” .\n7. Appendix\n7.1. Proofs of Lemmas 1 and 2.\nProof. Let Σ = σL + σR and recall that ω = σΣR and up (d) is the consumers expected\nutility when her belief is given by p and she chooses d ∈ {l, r, a}. It is easy to verify\nthat, when Σ ≤ 1:\nU ∗ (Σ, 0, π) = max{uπ (l) + (γ + β) πΣ, uπ (r) , γπΣ},\n\n(7.1)\n\nU ∗ (0, Σ, π) = max{uπ (l) , uπ (r) + (α + δ) (1 − π) Σ, α (1 − π) Σ},\n\n(7.2)\n\nand,\nU ∗ (σL , σR , π) = max{(1 − ω) [uπ (l) + (γ + β) πΣ] + ωuπ (l) ,\n(1 − ω) uπ (r) + ω [uπ (r) + (α + δ) (1 − π) Σ] ,\n(1 − ω) [γπΣ] + ω [α (1 − π) Σ]}.\n\n(7.3)\n\nWhen Σ &gt; 1, (7.1) and (7.2) no longer hold, but (7.3) still holds so long as (σL , σR ) ∈\n[0, 1]2 .\n38\n\nThe monotonicity of U ∗ stated in Lemma 1 follows from the fact that each of the linear functions supporting U ∗ (σL , σR , π) is non-decreasing in σL = (1 − ω) Σ or σR = ωΣ\nand strictly increasing in Σ. Now if either σL or σR is 1, the news reports are perfectly\ninformative and the consumer can achieve the highest expected utility\npossible. \n\n(σL ,σR )\nb\nLemma 2 follows from the fact that for any (σL , σR ) such that d pπ\n(R | sN ) =\n∗\nπ\nr, U (σL, σR , π) = u (r)+(α\n + δ) πσR , which clearly does not depend on σL . Similarly,\n(σL ,σR )\nb\nwhen d pπ\n(R | sN ) = l, U ∗ (σL , σR , π) = uπ (l) + (γ + β) πσL , which does not\ndepend on σR .\n\n7.2. Proofs of Proposition 2.\nProof. Recall that U ∗ (σL , σR , π) is convex in (σL , σR ). Therefore, given the monotonicity of U ∗ and σ, if σ is convex, then U ∗ (σ (qL ) , σ (qR ) , π) is also convex in (qL , qR ).\nThe set of feasible (qL , qR ) is a polyhedron, thus U ∗ is maximized at an extreme point.\nClearly, (0, 0) cannot be a solution. Therefore, we must have:\nU ∗ (σ (qL ) , σ (qR ) , π) ≤ max{U ∗ (σ (q) , 0, π) , U ∗ (0, σ (q) , π)}.\n\n7.3. Isomorphic Representation. In Section 4, we suggested that our restriction\nof the consumer’s utility function to that defined in Table 4.1 is only a matter of\nrepresentation. The consumers in our simplified model behave identically as a set of\nconsumers with a common prior and heterogeneous utility functions.\nFormally, for any π, π 0 ∈ (0, 1), there exists a vector (α, β, δ, γ) such that, α, β, δ, γ &gt;\nγ\nβ\n0 and δ+γ\n&lt; α+β\n, and, if consumer i’s utility function is that given in Table 4.1 and\nher prior belief is π, and if consumer j’s utility function and prior belief is given by the\nvector (α, β, δ, γ, π 0 ), the following statements hold:\n(1) dbi (π) = dbj (π 0 );\n(2) forany σ ≡ (σL , σR) ∈ [0, 1]2 , Vi (σL , σR ) =Vj (σL , σR ); and,\n(σ ,σ )\n(σ ,σ )\n(3) dbi pπ L R (L | sN ) = dbj p 0 L R (L | sN ) .\nπ\n\nProof. It suffices to show that, we can find (α, β, δ, γ), such that, for any σ ≡ (σL , σR ) ∈\n0\n[0, 1]2 : i) uπi (d) = uπj (d), for d ∈ {l, r, a}; ii) Vi (σL , σR ) = Vj (σL , σR ); and, iii) for all\n(σ ,σ )\n(σ ,σ )\n(σ ,σ )\npπ0 L R (R|sN )\npπ L R (R|sN )\npπ L R (R|sN )\n0\nd, d ∈ {l, r, a}, ui\n(d) ≥ ui\n(d ) if and only if uj\n(d) ≥\n(σL ,σR )\np\n(R|sN )\nuj π0\n(d0 ).\n0\n\n39\n\nBy definition, ii) holds if i) holds and Ui∗ (σL , σR , π) = Uj∗ (σL , σR , π 0 ). (7.1) to (7.3)\nguarantee that both i) and Ui∗ (σL , σR , π) = Uj∗ (σL , σR , π 0 ) hold if:\n\n\n[(1 − π 0 ) α − π 0 β + (γ + β) π 0 Σ] = [1 − 2π − c + 2πΣ]\n\n\n\n\n\n\n[(1 − π 0 ) α − π 0 β] = [1 − 2π − c]\n\n\n\n\n[− (1 − π 0 ) δ + π 0 γ] = [2π − 1 − c]\n\n[− (1 − π 0 ) δ + π 0 γ + (α + δ) (1 − π 0 ) Σ] = [2π − 1 − c + 2 (1 − π) Σ]\n\n\n\n\n\n[γπ 0 Σ] = [(1 − c) πΣ]\n\n\n\n\n[α (1 − π 0 ) Σ] = [(1 − c) (1 − π) Σ]\n.\nThus, there exists (α, β, δ, γ) such that both i) and ii) hold if the system of linear\nequations above has a solution.\n\n1−π\nπ\n1−π\nπ\nIt is easy to verify that (α, β, δ, γ) = (1 − c) 1−π\n0 , (1 + c) π 0 , (1 + c) 1−π 0 , (1 − c) π 0\nis a solution to the system. It is, in fact, the unique solution.\nNote that, when the system of equations hold, we also have:\np\n\n(σL ,σR )\n\np\n\n(σL ,σR )\n\nui π\n\n= uj π0\n\n(σ ,σ )\np L R (R|sN )\n\n(R|sN )\n\n(d) − ui π\n\n(R|sN )\n\n(d) − uj π0\n\n(σ ,σ )\np L R (R|sN )\n\nfor all d, d0 ∈ {l, r, a}. Thus, iii) also holds.\n\n(d0 )\n(d0 )\n\n\n7.4. Proof of Lemma 3.\nProof. For any qL0 ∈ ( 2q , q], we have σ (qL0 ) &gt; σ (q − qL0 ) and hence 1−c\n&lt; π∗ (σ (qL0 ) , σ (q − qL0 )).\n2\nSuppose π∗ (σ (qL0 ) , σ (q − qL0 )) &lt; 1+c\n, then V (σ (qL0 ) , σ (q − qL0 ) , π) is strictly increas2\n\n\n 1+c \n, 1 . That\ning in π over π∗ (σ (qL0 ) , σ (q − qL0 )) , 1+c\nand\nstrictly\ndecreasing\nover\n2\n2\nis to say\n1+c\n} = arg\nmax\nV (σ (qL0 ) , σ (q − qL0 ) , π) .\nπ∈[π∗ (σ(qL ),σ(qR )),1]\n2\n\nNow let κ∗ = maxqL ∈[ q ,q] V σ (qL ) , σ (qR ) , 1+c\n. The maximum is attained given\n2\n2\n\nthe continuity of V in (qL , qR ). By Lemma 1, κ∗ &lt; V σ (q) , σ (q) , 1+c\n= κ. It\n2\nq\n∗\n0\n0\n0\nfollows that, for any κ &gt; κ and qL ∈ ( 2 , q], V (σ (qL ) , σ (q − qL ) , π) &gt; κ implies\nπ ∈ [0, π∗ (σ (qL0 ) , σ (q − qL0 ))], which, in turn, implies that V (σ (qL0 ) , σ (q − qL0 ) , π) is\n.\nstrictly increasing in qL0 . The same clearly holds when π∗ (σ (qL0 ) , σ (q − qL0 )) ≥ 1+c\n2\n∗\nTherefore, when κ ∈ (κ , κ), {(q, 0)} = arg maxqL ∈[ q ,q] Π (qL , qR ).\n2\nA symmetrical argument establishes that {(0, q)} = arg maxqR ∈[ q ,q] Π (qL , qR ). We\n2\nhave thus proved Lemma 3.\n\n{\n\n40\n\n7.5. Proof of Lemma 4 and Proposition 3.\nProof. Lemma 4 follows from the fact that Π (qL , qR ; κ) is continuous in κ over\n\n\n \n\n\n1+c\n1−c\n, V σ (qL ) , σ (qR ) ,\n}\n,\n0, max{V σ (qL ) , σ (qR ) ,\n2\n2\nand hence for any interior (qL , qR ), limκ→0 Π (qL , qR ; κ) = 1 and limκ→0 Π (q, 0; κ) , limκ→0 Π (0, q; κ) &lt;\n1.\nContinuity of Π (qL , qR ; κ) in (qL , qR ) over {(qL , qR ) | qL , qR ≥ 0, qL + qR ≤ q} guarantees that the solution set is non-empty. The rest of Proposition 3 follows from Lemmas\n3 and 4.\n\n7.6. Proof of Proposition 4.\nProof. Under Assumption 2, V (σ (qL ) , σ (qR ) , π) = V (qL , qR , π). Suppose, qL &gt; qR &gt;\n0, we have: 1−c\n&lt; π∗ (qL , qR ) &lt; π∗ (q, 0). Moreover, Assumption 1 implies that\n2\n1\nπ∗ (q, 0) &gt; 2 .\nIt is obvious that for all π ∈ [0, π∗ (qL , qR )], U ∗ (q, 0, π) &gt; U ∗ (qL , qR , π) and hence\nV (q, 0, π) &gt; V (qL , qR , π). Now, for all π ∈ (max{ 21 , π∗ (qL , qR )}, π∗ (q, 0)], we have:\nU ∗ (q, 0, π) = 1 − 2π − c + 2qπ\n≥ πq (1 − c)\n&gt; [σ (qL ) π + σ (qR ) (1 − π)] (1 − c)\n= U ∗ (qL , qR , π) ,\n\n\nand for all π ∈ min{ 12 , π∗ (qL , qR )}, 12 , we have:\nU ∗ (q, 0, π) &gt; U ∗ (q, 0, π∗ (q, 0))\n= π∗ (q, 0) q (1 − c)\nq\n(1 − c)\n&gt;\n2\n≥ [σ (qL ) π + σ (qR ) (1 − π)] (1 − c)\n= U ∗ (qL , qR , π) .\nFinally, if π∗ (q, 0) &lt; π ∗ (qL , qR ), it is obvious that U ∗ (q, 0, π) &gt; U ∗ (qL , qR , π) for all\n[π∗ (q, 0) , π ∗ (qL , qR )].\nTherefore, for all interior q = (qL , qR ) such that qL &gt; qR and all π ∈ [0, π ∗ (qL , qR )],\nwe have V (q, 0, π) &gt; V (qL , qR , π). Similarly, one can show that, for all interior q =\n(qL , qR ) such that qL &lt; qR and all π ∈ [π∗ (qL , qR ) , 1], we have V (0, q, π) &gt; V (qL , qR , π).\nDefine π (σL , σR , κ) ≡ inf{π | V (σL , σR , π) ≥ κ} and π (σL , σR , κ) ≡ sup{π |\nV (σL , σR , π) ≥ κ}.\n41\n\nConsider qL &gt; qR &gt; 0. If κ ≥ V (qL , qR , π ∗ (qL , qR )), then π (qL , qR , κ) ≥ π ∗ (qL , qR ).\nThus, V (q, 0, π) &gt; V (qL , qR , π) implies that Π (q, 0; κ) &gt; Π (qL , qR ; κ). Similarly, if\n0 &lt; qL &lt; qR and κ ≥ V (qL , qR , π∗ (qL , qR )), then Π (0, q; κ) &gt; Π (qL , qR ; κ).\nSuppose there is an interior solution to (4.1), denoted (qL∗ , qR∗ ). Then if qL∗ &gt; qR∗ ,\nit must be that κ &lt; V (qL∗ , qR∗ , π ∗ (qL∗ , qR∗ )) (or, equivalently, qR∗ &gt; 2π∗ qκ∗ ,q∗ ), while\n( L R)\nqL∗ &lt; qR∗ implies κ &lt; V (qL∗ , qR∗ , π∗ (qL∗ , qR∗ )) (or, equivalently, qL∗ &gt; 2π qκ∗ ,q∗ ). In either\n∗( L R)\ncase, the monopolist’s profit is given by:\nˆ π(qL∗ ,qR∗ ,κ)\n∗\n∗\nΠ (qL , qR ; κ) =\nf dπ,\n∗ ,q ∗ ,κ\nπ (qL\nR )\nwhere π (qL∗ , qR∗ , κ) = 2qκ∗ and π (qL∗ , qR∗ , κ) = 2qκ∗ . Hence, the FOC is given by:\nL\nR\n\n\n ∗ 2\nf 1 − 2σ κq∗\n( L)\nqL\n\n\n.\n=\nqR∗\nκ\nf 2σ qj\n( R)\n\n(7.4)\n\nUnder Assumption 3, (7.4) can only be satisfied by one interior reporting strategy\nand qL∗ &gt; qR∗ (respectively, qL∗ &lt; qR∗ ) if and only if µ &lt; 21 (respectively, µ &gt; 12 ). It is\n1\nobvious that Π (q, 0; κ) &gt; Π (0, q; κ)\nFinally, it is easy to verify\n if and only\n if µ &lt; 2 . \nthat when µ &lt; 12 and qL∗ &gt; qR∗ , f\n\n1 − 2σ κq∗\n( L)\n1\n∗\nthe opposite is true when µ &gt; 2 and qL &lt; qR∗ .\n\n/f\n\nκ\nj\n2σ (qR\n)\n\nis increasing in κ, while\n\n\n7.7. Proof of Proposition 5.\nProof. We apply Corollary 5.2 of Reny (1999) to prove the existence of mixed strategy\nNash equilibria for the dupololists’ game. To apply the corollary, we want to show that\nthe mixed extension of the duopolists’ game is both “reciprocally upper semicontinuous”\nand “payoff secure” 32.\nThe sum of the duopolists’ payoffs always equals the total news consumption by all\nthe consumers, and is hence upper semicontinuous in qj and qk for all κ. Proposition\n5.1 of Reny (1999) then ensures that the mixed extension of the duopolists’ game is\nalways “reciprocally upper semicontinuous”.\n\nLet EΠj ϑj , ϑk ; κ denote player j’s expected payoff when j and k play mixed strate\ngies ϑj and ϑk , respectively. Since Πj qj , qk ; κ is only discontinuous at points where\n\nqj = qk , EΠj ϑj , ϑk ; κ can only be discontinuous at points where ϑj and ϑk have mass\npoints at qj and qk , respectively, for some qj = qk . Moreover, for any q = (qL , qR ) and\n\n∆ ∈ R, let q + ∆ denote (qL + ∆, qR − ∆), then Πj qj , qk ; κ is only discontinuous\n32See Reny (1999) for the relevant definitions\n\n42\n\nat (q, q) if Πj (q + ε∆, q; κ) &gt; Πj (q + (−ε∆) , q; κ) for all ε &gt; 0 sufficiently small.\n\nTherefore at those points where EΠj ϑj , ϑk ; κ is discontinuous, player j can “secure”\n\na payoff EΠj ϑj , ϑk ; κ by moving the mass point at qj to qj +ε∆ for some ε arbitrarily\nsmall. Thus the mixed extension of the duopolists’ game is “payoff secure”.\nTherefore the duopolists’ game has at least one Nash equilibrium in mixed strategies.\nMoreover, the duopolist’s game is clearly symmetrical. Therefore, Corollary 5.3 of Reny\n(1999) implies that there exists at least one symmetric Nash equilibrium in mixed\nstrategies of this game. The same argument can be applied to proving the existence of\nsymmetric mixed strategy Nash equilibria for the media outlets’ game with any number\nof players.\n\nRecall from the proof of Lemma 3 that if κ &gt; maxqL ∈[ q ,q] V σ (qL ) , σ (qR ) , 1+c\nand\n2\n2\nif V (σ (q L ) , σ (q − q L ) , π) ≥ κ, then V (σ (q L ) , σ (q − q L ) , π) is either strictly increasing in qL or strictly decreasing in qL . On the other hand, the bundle of news reports con\nsisting one from each media outlet can be valued at most at V τ (σ (q) , σ (q)) , 0, 1−c\n.\n2\n\n1−c\n1\nThus, if κ &gt; 2 V τ (σ (q) , σ (q)) , 0, 2 , no consumer would purchase more than one\n\nnews report. Moreover, V τ (σ (q) , σ (q)) , 0, 1−c\n&lt; 2σ (q) (1 − c) = 2κ.\n2\n∗\nNow let κ2 be defined by:\n\n\n\n\n1−c\n1+c\n1\n∗\nκ2 = max{ max V σ (qL ) , σ (qR ) ,\n, V τ (σ (q) , σ (q)) , 0,\n}.\n2\n2\n2\nqL ∈[ 2q ,q ]\nIt follows that, when κ &gt; κ∗2 , at least one extreme reporting strategy (i.e. (q, 0) or\n(0, q) or both) strictly dominates all interior strategies for either media outlet.\nFinally, let qk = (q, 0). For κ sufficiently small, j’s payoff when choosing strategy\n(q, 0) is:\nˆ\nˆ\n\n1\nk\nf dπ\nf dπ +\nΠj (q, 0) , q ; κ =\n2 Aj12\nAj\n1+c−2κ\nκ\nˆ\nˆ\n2−(1−c)τ (σ(q),σ(q))\n1 2[τ (σ(q),σ(q))−σ(q)]\n=\nf dπ +\nf dπ,\nκ\nκ\n2 2τ (σ(q),σ(q))\n2[τ (σ(q),σ(q))−σ(q)]\nwhile its payoff when choosing strategy (0, q) is:\nˆ\n\nk\nΠj (0, q) , q ; κ =\nf dπ\nAj\n\nˆ 1− κ\n\n2σ(q)\n\n=\n\nf dπ.\nκ+(1−c)[1−σ(q)]\n2[1−σ(q)]\n\n43\n\nNow pick any interior strategy (qL , qR ), j’s payoff when choosing (qL , qR ) is:\nˆ\n\nk\nΠj (qL , qR ) , q ; κ =\nf dπ\nAj\n\nˆ 1−\n=\n\nκ\n2σ (qR )\n\nf dπ.\n\nκ\n2[τ (σ(q),σ (qL ))−σ(q)]\n\nAll of these payoffs are continuous in κ when κ is sufficiently small. Thus, we have\n\n\n\nlimκ→0 Πj (qL , qR ) , qk ; κ = 1 while limκ→0 Πj (q, 0) , qk ; κ , limκ→0 Πj (0, q) , qk ; κ &lt;\n\n1. Therefore, there exists a κ0 &gt; 0 such that Πj (qL , qR ) , qk ; κ is strictly higher than\n\n\nboth Πj (q, 0) , qk ; κ and Πj (0, q) , qk ; κ for all κ &lt; κ0 .\nSimilarly, we can prove that, when qk = (0, q), there exists a κ00 &gt; 0 such that\n\n\n\nΠj (qL , qR ) , qk ; κ is strictly higher than both Πj (q, 0) , qk ; κ and Πj (0, q) , qk ; κ\nfor all κ &lt; κ00 . In fact, the analogous statement can be proved by the same argument\nfor any reporting strategy qk .\nNow let κ\nb2 = min{κ0 , κ00 }. Then, when κ &lt; κ\nb2 , an interior strategy (qL , qR ) strictly\ndominates both (q, 0) and (0, q) for media outlet j when k is restricted to randomizing\nover only {(q, 0) , (0, q)}. Therefore, there cannot be any Nash equilibria where both\nplayers only randomize over {(q, 0) , (0, q)}.\nWe have thus proved Proposition 5.\n\n7.8. Proof of Proposition 6.\n\n\nProof. When both media outlets choose q = 2q , 2q and κ &lt; 1 − 2q q 1−c\n, each receives\n2\na payoff equal to:\nκ\nˆ κ\nˆ\n1 1− q\n1 1− (1− 2q )q\nΠ (q, q; κ) =\nf dπ +\nf dπ.\nκ\n2 κq\n2\nq\n(1− 2 )q\n\nOn the other hand, if media outlet j deviate to some other interior reporting strategy\n(qL , qR ) with qL &gt; qR its payoff is equal to:\nˆ π̃\nΠ ((qL , qR ) , q; κ) =\nf dπ,\nκ\n2qL\n\nwhere π\ne is the prior belief of the most conservative consumer who is willing to choose\nj’s news report as her second choice, which, depending on κ, has to satisfy one of the\nfollowing equations:\n\n\nq q\n 1 V (σ , σ , π\ne\n)\n=\nκ\nif\nV\n(σ\n,\nσ\n,\nπ\ne\n)\n≥\n2V\n,\n,\nπ\ne\nL\nR\nL\nR\n2\n2 2\n,\n\nq q\nV (σL , σR , π\ne) − V , , π\ne = κ Otherwise\n2 2\n\n44\n\n\n\n\nL\nR\nwhere σL = τ 2q , qL and σR = τ 2q , qR . Note that, ∂σ\n= ∂σ\n= 1 − 2q , which\n∂qL\n∂qR\n\nimplies that V (σL , σR , π\ne) is strictly increasing in qL over 12 , π ∗ (σL , σR ) . It follows\nthat, if π\ne &lt; π ∗ (σL , σR ), then it is strictly increasing in qL , and Π ((qL , qR ) , q; κ) &lt;\n\nΠ ((q, 0) , q; κ). When π\ne ≥ π ∗ (σL , σR ), which implies that κ ≤ 2π ∗ (σL , σR ) σR − 2q ,\nwe have π\ne = 1 − 2 σ κ− q = 1 − 2 1−κq q , which is strictly increasing in qR . 2qκL , on the\n( R 2)\n( 2) R\nother hand, is strictly decreasing in qL . Thus any (qL , qR ) with qL + qR &lt; q cannot be\nprofit maximizing for j. Therefore, we can, without loss generality, focus on reporting\nstrategies satisfying qL + qR = q, and can identify j’s strategy with x = qqL . j’s payoff\nthen becomes:\nκ\nˆ 1−\nq\n2(1− 2 )(1−x)q\nΠ (x, q; κ) =\nf dπ.\nκ\n2xq\n\nDifferentiating with respect to x yields:\n!\n\n\nκ\nκ\nκ\nκ\n\n\n−f 1−\nf\nq\nq\n2\n2xq 2qx\n2 1 − 2 (1 − x) q 2 1 − 2 q (1 − x)2\n\n,\n\n(7.5)\n\nwhich, when µ = 12 , is negative for x &gt; 12 . The case when qL &lt; qR is symmetrical\nis positive for x &lt; 12 . Finally, it is easy to verify that, when\nand, when µ = 12 , ∂Π(x,q;κ)\n∂x\n\n\n\nµ = 21 , limx→ 1 Π (x, q; κ) = Π 12 , q; κ . Therefore, at 2q , 2q , 2q , 2q , if a media outlet\n2\nhas a profitable deviation, then its payoff must be maximized by either (q, 0) or (0, q).\nHowever, an argument similar to that applied towards the end of the previous proof\n\n, κ∗2 }, such that for all κ ∈ (0, κ̌2 ),\nshows that we can find a κ̌2 ≤ min{ 1 − 2q q 1−c\n2\n\nΠ x = 21 , q; κ is strictly higher than both Π (0, q; κ) and Π (1, q; κ).\n\n\nTherefore, when µ = 12 and κ ∈ (0, κ̌2 ), 2q , 2q , 2q , 2q is a Nash equilibrium.\nMoreover, it is easy to show that, for all ε &gt; 0, if µ is sufficiently close to 21 , there\n\nexists an x∗ in 12 − ε, 21 + ε , such that limx→x∗ Π (x, x∗ ; κ) = Π (x∗ , x∗ ; κ).\n\nOn the other hand, when κ &lt; 1 − 2q q 1−c\n, Π (x, q; κ) is continuous in (x, q, µ) at\n2\n 1\nq q\n1\n, 2 , 2 , 2 , so is its derivative with respect to x. Therefore, for x∗ and µ sufficiently\n2\nclose to 12 , we can simply replace 12 by x∗ in the above argument, and continuity ensures\nthat all the strict inequalities still hold. Then, (x∗ , x∗ ) is a Nash equilibrium if we also\nhave limx→x∗ Π (x, x∗ ; κ) = Π (x∗ , x∗ ; κ).\nTherefore, for the same κ, if µ is sufficiently close to 21 , the game has a Nash equi\n\n\nlibrium at some ((x∗ q, (1 − x∗ ) q) , (x∗ q, (1 − x∗ ) q)) close to 2q , 2q , 2q , 2q .\n\n7.9. Proof of Proposition 7.\n45\n\nProof. If no media outlet chooses (q, 0) (respectively, (0, q)) with positive probability,\n´1\n´ 1−c\nthen a player can secure a payoff of at least 0 2 f dπ (respectively, 1+c f dπ) by choos2\ning (q, 0) (respectively, (0, q)) with probability one. On the other hand, fixing κ, the\n\nnumber of news report a consumer will consume is bounded above by V 1, 0, 12 /κ.\nThus, when there are N media outlets, the average payoff of a media outlet is bounded\n\nby V 1, 0, 12 / (κN ). Therefore, for N sufficiently large, some player must find it more\nprofitable to play (q, 0) (respectively, (0, q)) than any other interior reporting strategy if none of the other media outlets chooses (q, 0) (respectively, (0, q)) with positive\nprobability.\n\n7.10. Proof of Proposition 8.\nProof. First, by inspecting V , the difference between functions U ∗ and u∗ , we see\nthat for any news consumption bundle (σL , σR ) and any π ∈ [0, 1], we must have\n\n\nV (σL , σR , π) ≤ max{V σL , σR , 1−c\n, V σL , σR , 1+c\n}. That is, either the consumers\n2\n2\n1−c\nwith prior belief given by π = 2 or those with prior π = 1+c\nmust value (σL , σR )\n2\nhigher than any other consumers. It follows that if any news report is consumed at\nor 1+c\n. Since V\nall, it must be consumed by some consumers with prior beliefs 1−c\n2\n2\nis continuous in π, this implies that the news report is also consumed by either some\nliberals or some conservatives.\n \nNow let b ∈ 0, 12 be a set of binding content regulations. Let Σj0 and Σj1 denote the\nsupports of media outlet j’s pre-regulation equilibrium strategy and its post-regulation\nequilibrium strategy, respectively. Then, there must be some media outlet j, for whom\nj\n\nqL\n1\nthe set Σj∗ ≡ { qLj , qRj ∈ Σj0 \ Σj1 || qj +q\nj − 2 |&gt; b} is non-empty. Moreover, either\nL\nR\n\n\nthe set { qLj , qRj ∈ Σj∗ | qLj &lt; qRj } or the set { qLj , qRj ∈ Σj∗ | qLj &lt; qRj } is non-empty.\n\nWithout loss of generality, let { qLj , qRj ∈ Σj∗ | qLj &lt; qRj } be non-empty. Note that,\n\nby definition, the reporting strategies in { qLj , qRj ∈ Σj∗ | qLj &lt; qRj } are played with\npositive probability before the regulations were imposed.\nNow let (qL0 , qR0 ) denote the news report in the set ∪j Σj1 that is most biased to the\nleft. By the above argument, there must be some liberal consumer who are willing\nto consume (qL0 , qR0 ). Moreover, concavity of τ implies that a liberal who is willing to\nconsume (qL0 , qR0 ) in a bundle must be willing to consume it on its own. On the other\nhand, we know that a liberal with prior belief given by π = 0 is not willing to consume\n(qL0 , qR0 ) at any positive κ. Thus, by continuity of V , there exists π 0 ∈ (0, 1) such that\nconsumers with prior belief π 0 are indifferent between consuming (qL0 , qR0 ) on its own\nand not consuming any news. Fixing κ, consumers with prior belief π &lt; π 0 are not\nwilling to consume (qL0 , qR0 ) and are therefore not willing to consume any news with\npositive probability. On the other hand, continuity of V implies that some of these\n46\n\n\nconsumers are willing to consume news reports in { qLj , qRj ∈ Σj∗ | qLj &lt; qRj } at κ.\nThus, these consumers enjoy positive expected surplus in the equilibrium before the\ncontent regulations are imposed and are made strictly worse-off by the introduction of\nsuch regulations. We have thus proved the first half of the proposition.\nConsider a game with two media outlets. Let σ be convex and suppose that, in\nthe equilibrium before content regulations are introduced, one of the two media outlet produces news report (q, 0) with probability one and the other produce (0, q) with\nprobability one. Then Proposition 2 and the concavity of τ implies that the introduction of binding content regulations must make all consumers worse-off. This proves the\nsecond half of the proposition.\n\n\n47\n\n</td>
    </tr>
    <tr>
      <th>89</th>
      <td>news</td>
      <td>THE CREDIBILITY OF NEWSPAPERS,\nTELEVISION NEWS, AND ONLINE NEWS\n\nRasha A. Abdulla, Bruce Garrison,\nMichael Salwen, Paul Driscoll, and Denise Casey\nSchool of Communication\nUniversity of Miami\nP.O. Box 248127\nCoral Gables, FL 33124-2105\nbruce@miami.edu\n\nA paper presented to the Mass Communication and Society Division, Association\nfor Education in Journalism and Mass Communication, annual convention, Miami Beach,\nFla., August 9, 2002.\n\n2\n\nTHE CREDIBILITY OF NEWSPAPERS,\nTELEVISION NEWS, AND ONLINE NEWS\n\nAbstract\nThis exploratory study analyzes the components of credibility of news from\nnewspapers, television, and online sites. A national telephone survey of 536 adults was\nconducted in February 2002. Respondents evaluated the credibility of newspapers,\ntelevision news, and online news using a variation of Gaziano and McGrath’s 12-item\nLikert-type news credibility scale. While there were similarities in how each medium was\nperceived, the study also revealed some fundamental differences. Respondents evaluated\nnewspaper and television news credibility more similarly than they did online news\ncredibility. Respondents judged all three news media most positively in terms of current,\nup-to-date, and timely and most negatively in terms of bias and completeness. However,\nonline users were less negative than newspaper readers and television viewers. Factor\nanalyses yielded somewhat different dimensions. Newspaper credibility was found to\nhave balance, honesty, and currency dimensions. Television news credibility was found\nto have two main components based on fairness and currency. Online news credibility,\nhowever, was built upon trustworthiness, timeliness, and bias factors.\n\nThe authors would like to thank Dean Edward Pfister of the School of\nCommunication at the University of Miami for providing much of the funding for this\nstudy. Additional University of Miami research funding from the Office of the Provost\nalso provided support for this project.\n\n3\n\nTHE CREDIBILITY OF NEWSPAPERS,\nTELEVISION NEWS, AND ONLINE NEWS\n\nThe number of adults using the Internet to find and read news online is\nconsistently on the rise. One national study by the Pew Research Center reported that\nweekly use of online news tripled from 11 million to 36 million people in the United\nStates between 1996 and 1998, which the center called “astonishing” (Pew Research\nCenter, 1998). Other studies have shown similar growth in use of the Internet, the World\nWide Web, and other online information resources (for example, see Jupiter Media\nMetrix, 2001; Nielsen Media Research, 1999).\nOne issue that has emerged because of this growth is the credibility of new\ninformation technologies and new media news delivery systems. Widespread access to\npersonal information, including tracking online purchases, property ownership records,\nand residential telephone numbers, have led to growing public distrust of online sources\nof information. One analysis reported that barely one in three media Web sites posted\ntheir privacy policies for information provided both voluntarily (e.g., personal electronic\nmail addresses or other information taken from user registration forms) and involuntarily\n(e.g., Web browser “cookies” or tracking specific page visits and clicks within a Web\nsite) by users (Pryor &amp; Grabowicz, 2001). Even when they are posted, online statements\nof privacy policy are often lengthy and nearly incomprehensible. They tend to serve more\nas a legal alibi for the Web site owner than an actual information source for site users.\nThe purpose of this study was to investigate the similarities and differences of\nuser perceptions of the credibility of traditional news media delivery systems—\n\n4\n\nnewspapers and television news— and the credibility of Web-based online news.\nSpecifically, this paper investigates news credibility in an attempt to determine the\ncomponents of news credibility across traditional and the new online news media.\nBecause of privacy issues, content accuracy, reliability, and other related\nconcerns, some observers have predicted a troubled future for online news. Johnson and\nKaye (1998) reminded us that one of the basic characteristics of the Internet, its potential\nfree access to everybody to upload information without much scrutiny, might affect the\ncredibility of the medium as a source of information. Flanagin and Metzger (2000) noted\nthat while newspapers, books, and television undergo a process of information\nverification before they reach the public, Internet sites do not always use such measures.\nThe lack of editorial and gatekeeping rules similar to those in the traditional print and\nbroadcast news media is central to the problem. This, of course, is likely to increase the\nimportance of branded online news sites such as CNN.com and perhaps emphasize the\nvalue of the so-called “halo effect” of an existing print or television news organization to\nits online equivalent (such as Time magazine and its Web counterpart, Time Online).\nSchweiger (1998) pointed out that credibility becomes an important heuristic for\ncontent selection at a time of information overload. Credibility may also influence the\njournalistic and commercial success of a medium (Schweiger, 2000). Online news\nindustry observers and newspaper editors have expressed similar concerns over\ncredibility, believability, ethical lapses, newsgathering techniques, and news presentation\n(Lasica, 2001; Arant &amp; Anderson, 2000). These and numerous other professional issues\nare frequent topics of discussion and debate on the pages of the Online Journalism\nReview (http://ojr.usc.edu).\n\n5\n\nCREDIBILITY OF ONLINE NEWS\nStudies conducted in recent years have analyzed the dimensions of computing\ntechnology, the Internet, the Web, and online news credibility. The early public views of\nthe precision and accuracy of computers led to a common perception of their infallibility\nand believability, even the basic credibility of computer-based technologies has been\nstudied (Tseng &amp; Fogg, 1999). A number of scholars have emphasized the importance or\n“crucial” nature of such research (Johnson &amp; Kaye, 1997; Johnson &amp; Kaye, 1998).\nNewhagen (1997) studied the perception of interactivity in mass media and\ncomputer networks. He found that respondents who had e-mailed comments to a network\nnews program rated traditional mass media to be less interactive, less important and of\nlower quality than a national sample. While interactivity ratings did not predict mass\nmedia credibility, respondents who had e-mailed NBC and those who defined\ninteractivity as “cybernetic feedback” (the feedback necessary to the maintenance as a\nself-regulating system) found computer communication to be more credible than those\nwho did not.\nIn their study of computer technology credibility, Tseng and Fogg (1999) found\nthat computer users desire to trust their systems, but that the trust is often undermined\nwhen the system delivers erroneous information. They described four types of computerbased credibility: presumed (based on assumptions), reputed (based on third-party\nreports), surface (based on primitive inspection), and experienced (based on first-hand\nexperience). They further explained that user expertise, user understanding, user need for\ninformation, and evaluation errors influenced this credibility.\n\n6\n\nFlanagin and Metzger (2001) observed that much media credibility research has\nignored online news and that the bulk of research was conducted prior to online news\ndevelopment. There are differences, these scholars have argued, between online news and\nother more-established news media such as television, radio, and newspapers. Online\nnews can be reported at any time. The newspaper, by contrast, is limited to when people\nobtain the hard copy. Thus, the dimension of timeliness must be considered in studying\ncredibility of the Internet as a medium.\nFlanagin and Metzger (2001) concluded that the Internet is a “multidimensional\ntechnology used in a similar manner to other more traditional media” (p. 153). News\ncommunication technologies extend users’ capabilities but eventually are folded into\ntraditional media. They found online conversational uses (such as chat rooms, electronic\nmail, and the telephone) that paralleled traditional media. They also found informationretrieval and information-giving similarities (such as online news and the news media).\nThey concluded that “needs fulfilled by these channels cluster in ways consistent with\npast research, regardless of the technologies employed to meet them” (p. 153).\nIn an earlier study, Flanagin and Metzger (2000) investigated perceptions of\nInternet information credibility in comparison to other media. They concluded that the\nInternet was as credible as television, radio, and magazines, but not newspapers. They\nfound that credibility varied by medium among different types of information sought by\naudiences, such as news and entertainment. Respondents reported that they did not verify\ninformation found on the Internet, but this finding also varied by the type of information\nneeded. The amount of experience using the Internet and how an individual perceived the\ninformation were associated with efforts to verify online information.\n\n7\n\nSchweiger (2000) found newspapers in Germany were rated ahead of the Web\nand television on nine of eleven credibility items. He also found that Web users and nonusers alike rate the credibility of the Web as remarkably similar to television and\nnewspapers. Nadarajan and Ang (1999) found few online newspapers with corrections\npolicies, but that errors were corrected as needed. They concluded that the capabilities of\nthe Web, such as hyperlinks and archiving, were not well used to enhance online news\nand information accuracy. In fact, they said current practices “add to the clutter of\nviewpoints that is symptomatic of this age of information overload” (p. 21). While they\ndo not directly connect this to online news credibility, the implications are clear.\nSundar (1999) determined four basic factors in the perception of online news\nstories: credibility, liking, quality, and representativeness. He explained that credibility in\nthis context was a “global evaluation of the objectivity of the story” (p. 380). Johnson and\nKaye (1997, 2000) found online media to be more believable, fair, accurate, and in-depth\nthan traditional news media. Both online news media and traditional news media were\njudged to be somewhat credible. In an earlier study, Sundar (1996) determined that\nsubjects rated stories with direct quotations from sources to be significantly higher in\ncredibility and quality than those without quotations. The use of direct quotations did not\nappear to affect subject ratings of liking for online news or perceptions of\nrepresentativeness-newsworthiness of the online news.\nKiousis (1999) found news credibility perceptions to be influenced by media use\nand interpersonal discussion of news. He found general skepticism about news, but\npeople rated newspapers as more credible than online news or television. Online news,\nhowever, was rated more credible than television. Like other studies of print and\n\n8\n\nbroadcast news media, Kiousis found credibility rating of a medium associated with its\nuse. He also found links between discussion of news and perceptions of television news,\nbut not for online news or newspapers. He offered evidence of links between media use\nand public perceptions of credibility for newspapers and television news, but not in the\nassessment of online news.\nUsing credibility as their focus, Johnson and Kaye (1998) concluded that online\nnews media and online candidate literature were perceived to be more credible than\ntraditional print and broadcast news media, even though both online news and traditional\nnews media were perceived to be somewhat credible. No differences were found for news\nmagazines and issue-oriented sources.\nFinberg, Stone, and Lynch (2002; see also Online News Association, 2001) found\none main concern about online news credibility was the perceptions of other journalists,\nwho do not hold it in high regard. The national study determined that online news was a\nsupplementary news source for most users. They also observed that the public has\naccepted online news as a credible news option, that many readers did not feel online\nnews credibility was an issue.\n\nMEDIA CREDIBILITY MEASURES\nResearchers have utilized a variety of measurements and statistical procedures in\ntheir quest to understand media credibility. Bivariate and multivariate approaches have\nbeen used, including regression analysis (Mulder, 1980; Mulder, 1981) and factor\nanalysis. While many have used traditional data-collection methods such as telephone\nsurveys and laboratory and field experiments, new technologies such as online surveys\n\n9\n\nand other experiments are beginning to be used as well (Johnson &amp; Kaye, 1998; Sundar,\n1998). Online surveys using electronic mail and the Web, however, have unresolved\nmethodological issues such as low response rates, self-selection bias, and access (Couper,\nTraugott &amp; Lamias, 2001; Schaeffer &amp; Dillman, 1998).\nInfante (1980) used three dimensions to measure source credibility. These were\ntrustworthiness, expertise, and dynamism. Trustworthiness was operationalized as\nhonest-dishonest, trustworthy-untrustworthy, and sincere-insincere. For expertise, he\nused skilled-unskilled, qualified-unqualified, and informed-uninformed. For dynamism,\nhe used bold-timid, active-passive, and aggressive-meek.\nJohnson and Kaye (1998, 2000) employed believability, fairness, accuracy, and\ndepth of information in their study. Sensationalism was one of six dimensions used by\nSundar (1996). He also used accuracy, believability, bias, fairness, and objectivity.\nKiousis (1999) measured online news credibility by asking respondents to assess whether\nonline news is factual, concerned with making profits, invades people’s privacy, is\nconcerned about the community’s well being, and cannot be trusted on a five-point\nLikert-type scale ranging from strongly agree to strongly disagree.\nNumerous researchers have developed media credibility scales. Despite the\ndiversity of scales, the various scale items are highly similar and measure the same\nunderlying dimensions. Rather than searching for a single scale, researchers often create\nad hoc scales to tap into hypothesized “dimensions” of credibility. Sundar (1999)\ndeveloped a credibility scale applicable to both newspapers and online newspapers. He\nfound “striking similarity between the factor structures underlying receivers’ perceptions\nof print and online news” (p. 382). He claimed this similarity made it possible to use the\n\n10\n\nsame scales for different media, which he described as a “boon” to researchers (p. 382).\nFlanagin and Metzger (2000) used single-item measures in studying the credibility of\nInternet information. They operationalized credibility as a multidimensional concept built\nfrom five traditional components found in the literature: believability, accuracy,\ntrustworthiness, bias, and completeness.\nTrustworthiness, fairness, bias, completeness, respect for privacy, representation\nof individual interests, accuracy, concern for community well-being, separation of fact\nand opinion, concern for public interest, factual foundations of information published,\nand qualifications of reporters were used among the credibility measures by Rimmer and\nWeaver (1987). The study’s second set of measures was derived from traditional Roperstyle media use and preference questions.\nMeyer’s (1988) index for newspaper believability was comprised of five\ndimensions. These included fairness, bias, completeness, accuracy, and trustworthiness.\nHe also identified evidence that a newspaper’s credibility and “lovability” may be the\nsame dimensions. Ognianova (1998) utilized nine semantic differential items to measure\nonline news story credibility. They were factual/opinionated, unfair/fair,\naccurate/inaccurate, untrustworthy/trustworthy, balanced/unbalanced, biased/unbiased,\nreliable/unreliable, thorough/not thorough, and informative/not informative.\nWanta and Hu (1994) used believability and affiliation indices to evaluate media\ncredibility. The believability index was built around media manipulation of public\nopinion, getting facts straight, dealing fairly with all sides of an issue, and separation of\nfact from opinion. Affiliation was measured with concern for community well being,\nwatching out for reader interests, and concern for public welfare.\n\n11\n\nGaziano and McGrath (1986) identified twelve dimensions of newspaper and\ntelevision news credibility. They included fairness, bias, completeness, accuracy, respect\nfor privacy, watch for people’s interests, concern for community, separation of fact and\nopinion, trust, concern for public interest, factual, and level of training. Furthermore,\nGaziano’s (1987) analysis of four major credibility studies found twelve\noperationalizations of credibility. These included believability; accuracy, completeness,\nand covering up facts; trustworthiness and reliability; being unbiased, balance of\ncoverage, fairness, objectivity; other characteristics of press performance, such as\ninvasion of privacy, covering up stories; overall evaluations of how well media perform;\nconfidence in media institutions, comparisons of media with other institutions;\nindependence of media from special interests, other organizations, institutions;\npower/influence of media in community or society; relationship of news media to\ngovernment; honesty and ethical standards; and professionalism, training of people in the\nmedia. Gaziano noted that these measures had also been used in studies by Hovland and\nWeiss (1951), Meyer (1988), and others. Gaziano and McGrath observed that media\ncredibility is comprised of “fairness, (un)bias, telling the whole story, accuracy, respect\nfor privacy, watching out after people’s interest, concern for community well-being,\nseparation of fact and opinion, trustworthiness, concern for public interest, factuality, and\nreporter training level” (Rubin, Palmgreen, &amp; Sypher, 1994, p. 234). Rimmer and Weaver\n(1987) reported a Cronbach alpha of 0.90 for the Gaziano and McGrath scale for both\nnewspapers and television. Meyer (1988), however, criticized the Gaziano and McGrath\nscale as lacking face validity and theoretical grounding. He replicated Gaziano and\nMcGrath and developed a five-item news credibility scale. The items – fair, unbiased,\n\n12\n\ntells the whole story, accurate, and can be trusted – yielded a Cronbach alpha of 0.83.\nMeyer argued that his scale had face validity as the concept of believability was reflected\nin each of the five items (Rubin, Palmgreen, &amp; Sypher, 1994, pp. 234-36).\n\nRESEARCH QUESTIONS\nThis study investigates the credibility of news across traditional and online media.\nIt examines the dimensions of news credibility as a threshold to what predicts news\ncredibility. Online news credibility is investigated against use patterns and user\ndemographics using the orientation of the Gaziano and McGrath credibility scale (1986).\nCredibility research comparing the Internet to traditional news sources has not\nbeen conclusive or consistent (Flanagin &amp; Metzger, 2000). Research about print\nnewspapers and online newspapers suggests additional, perhaps new, dimensions may\nexist. For example, print newspapers are regarded as a serious news medium.\nNewspapers, after all, by their very name are committed to “news.” Television news, by\ncontrast, is regarded as less serious because the medium of television is not primarily\nassociated with news and credibility studies have shown television credibility to be more\nbased on individual on-air personalities such as news anchors than the news organization\nor station (Newhagen &amp; Nass, 1987). Television news is often viewed as an addendum to\nthe entertainment medium. Similarly, the Internet and the Web are not solely devoted to\nnews. Thus, the “entertainment” dimension must be considered when print and online\nnewspapers are compared.\nThe following research questions guided this study:\n\n13\n\n1. What are the primary components of newspaper, television news, and online\nnews credibility?\n2. What similarities and differences are found in the credibility dimensions of\nnewspapers, television news, and online news?\n\nMETHODS\nThis study is based upon a national probability sample from the 50 states and\nDistrict of Columbia. Data were collected using a telephone survey of adults age 18 or\nolder, conducted during February 4-7, 2002. A total of 536 interviews were completed.\nThe response rate, excluding businesses, fax machines, numbers not in service, and other\nineligibles, was 41%. Interviewers were communication students trained and supervised\nby the authors. At least two callback attempts were made to complete interviews.\nThe sample was drawn using a stratified design, proportionate to the population of\nthe United States. Population figures were obtained from the 2000 U.S. Census\n(http://blue.census.gov/population/www/cen2000/respop.html). Using proportions equal\nto each state’s population, interviewers were assigned to complete calls to residents\nutilizing a modified random digit dialing model. Residential telephone numbers were\ndrawn from the fall 2001 edition of the national Select Phone telephone software on\ncompact disc and database published by InfoUSA (Select Phone Pro CD database, Ver.\n2.1, winter edition, InfoUSA, Omaha, Neb., 2002). Random residential telephone\nnumbers were generated on a state-by-state basis from the database of over 100 million\ntelephone numbers using a table of random numbers and the random number function\nbuilt into the Select Phone software. Each state roster of chosen numbers was adjusted\n\n14\n\nusing the one-up and one-down last digit method to include unlisted and other numbers\nnot included in the published CD database.\nPrior to asking respondents to evaluate a particular news medium using the scale,\ninterviewers “qualified” responses by establishing use of the medium. Media use was\ndefined as at least one day per week of newspaper readership, at least one day per week\nof television news viewing, and, for online news users, at least one day per week of either\n(a) use of online news on the Web, (b) use of online news through an Internet Service\nProvider (ISP), or (c) use of online news through an Internet search engine portal.\nThe survey instrument included a news credibility scale adapted from Gaziano\nand McGrath (1986; see also Rubin, Palmgreen, and Sypher, 1994). The Likert-type scale\nhad a total of twelve items, focusing on traditional credibility components\n(trustworthiness, currency, bias, fairness, completeness, objectivity, honesty, up-to-date,\nbelievability, balance, accuracy, and timeliness). Respondents rated items on a five-point\nstrongly agree to strongly disagree scale, with neutral as the midpoint. Respondents were\nasked, “I’d like to know what you think about [newspapers, television news, or online\nnews] as a source of news and information. I’m going to mention some descriptive words\n… and, after I read each word, please tell me whether the word describes your feelings.\nGive me your answer in terms of whether you strongly agree, agree, disagree, strongly\ndisagree, or whether you are neutral. Do you think [newspapers, television news, or\nonline news] is …”.\nFor each of the three credibility scales, a summated mean was computed and the\nscales were analyzed for similarities and differences. Scales were factor analyzed to\n\n15\n\ndetermine underlying dimensions of each scale utilizing a 1.0 eigenvalue factoring\ncriterion, the Varimax rotation, and the principal component analysis extraction method.\n\nFINDINGS\nFemales were over-represented and minorities were under-represented, but not so\nseverely as to indicate serious problems in sample representativeness. The sample was\n54% female (n = 291), 9% Hispanic (n =46), and 11% African-American (n = 56). The\nmedian age was 45.0. About four-fifths of the respondents had either a high school\ndegree (n = 170), some college education (n = 131), or a college degree (n = 119). The\nmedian annual family income category was $50,001 to $75,000.\nUse habits varied across news media, but television is the primary source of\ninformation among respondents in this study. Respondents read newspapers a mean of\n3.76 days per week (n= 535, median = 3.0) and watched television news a mean of 5.11\ndays per week (n = 532, median = 7.0). Online news use was measured three ways: (a) in\nterms of days of access of news sites on the Web (n = 312; Mean = 1.65; Median = 0.00);\n(b) days of access of Internet Service Provider (n = 281; Mean = 1.03; Median = 0.00);\nand (c) days of access to a Web portal site (n = 275; Mean = 0.98; Median = 0.00). The\nCronbach alpha reliability coefficient of newspaper credibility scale was 0.81 (n=399).\nThe Cronbach alpha for the television credibility scale was 0.84 (n=447). The alpha for\nthe online news credibility scale was 0.82 (n=145). As shown in Table 1, the type of\nnews preferred varied by news medium used. Newspaper readers and television viewers\nprefer local and national news, while online news users preferred national and\ninternational news and very few used online news sources for local information.\n\n16\n\nInternet users were, by far, most interested in international news. Among online\nnews users, 25 percent chose international news as the type of news they “read most\noften,” as opposed to 8.5 percent of television viewers and 6.1 of newspaper readers. This\nfinding seems to relate to the nature of the Internet as a medium that transcends borders\nand time zones. It also has the potential to be explained by an acculturation process of\nInternet users (who are usually more educated), which makes them more aware of, more\ninterested in, and/or more receptive to, international news. In this regard, the Internet\ncould be serving as an eye-opener to its users, at least in the sense of making them aware\nof a wider range and a more diverse news menu available to them.\nOverall, respondents rated online news highest in credibility. Data in Table 2\nindicate that online users rated online news more positively. The online users scale grand\nmean was 7.01 (SD = 5.14, n = 145), while television users rated television credibility at\n4.85 (SD = 5.85, n = 447), and newspaper users rated newspaper credibility at 4.26 (SD =\n5.44, n = 399). The scores should be understood as reflecting only individuals who were\nself-described users of the media evaluated. This means that television news users who\ndid not use online news did not evaluate online news. Thus, some respondents offered\nperceptions of only one news medium, some offered perceptions of two news media, and\nthe smallest number evaluated all three news media.\nNewspaper readers rated newspapers highest on three variables directly associated\nwith their timeliness (current 1.03, up-to-date 0.97, and timely 0.86) while they rated\nnewspapers lowest in terms of bias (-0.60) and completeness (-0.15). Television viewers\nresponded similarly, rating television news highest for timeliness (current 1.08, up-todate 1.01, and timely 1.00). They also perceived television to be weakest in terms of bias\n\n17\n\n(-0.44) and reporting the whole story (-.019). Online news users see their news source\nsimilarly, but with a more positive perspective. Online news users feel the same about the\nstrengths of online news and its timeliness (current 1.11, up-to-date 1.07, and timely\n1.09), and about the weakness of bias (0.01) and completeness (0.18).\nFactor analysis of the newspaper credibility scale resulted in a three-factor\nsolution emphasizing balance, honesty, and currency of information that accounted for\n56.0% of variance. Factor analysis of the television credibility scale resulted in a twofactor solution emphasizing fairness and currency, which accounted for 53.1% of\nvariance. Factor analysis of the online news credibility scale resulted in a three-factor\nsolution focused upon trustworthiness, currency, and bias that accounted for 60.0% of\nvariance.\nTable 3 displays the newspaper credibility factor analysis. The three factor\nsolution reveals distinct dimensions to credibility focusing on balance, honesty, and\ncurrency. The balance factor is anchored by balance (.767) and report the whole story\n(.732). Objectivity, fairness, accuracy, and bias also load on the factor. Honesty is the\nsecond component, made up of dishonest (.812), believable, and trustworthy. Currency,\nthe third factor, is built around up-to-date (.781), current (.765), and timely (.749).\nAs shown in Table 4, the television news credibility factor analysis emphasizes\nfairness and currency. The dominant factor centers on fairness (.819). Other strongloading scale items are balance (.738), trustworthy (.719), accurate (.701), and objective\n(.701). The remaining items in the factor were report the whole story, believable, biased,\nand dishonest. The second factor is similar to the currency factor in newspapers, but the\nstrongest-loaded item was current (.808), but also had up-to-date (.798) and timely (.769)\n\n18\n\nalso strongly loaded. This certainly relates to literature about television news credibility\nthat suggests credibility is more individually than institutionally oriented Newhagen and\nNass (1987).\nThe online news credibility factor analysis in Table 5 has three primary\ndimensions: trustworthiness, timeliness, and bias. Trustworthy is the highest loaded item\nfor the seven-item factor one (.783), but believable (.750) and accurate (.727) were also\nstrong. Other items for this factor included report the whole story, balanced, fair, and\ndishonest. Factor two, currency, is similar to the factors found for newspapers and\ntelevision news. For each of the three factor solutions, currency was composed of the\nsame items. Timely (.898) is the dominant item, but current (.867) and up-to-date (.772)\nalso load well. The bias factor in this scale, not apparent in the newspaper or television\nnews factor solutions, points to an interesting difference in this solution when compared\nto the other two. Biased (.846) and objective (.592) form this two-item factor, but suggest\nimportant perceived differences by users of online news compared to newspapers and\ntelevision news.\n\nDISCUSSION\nMedia credibility is a complex concept. Researchers have used a wide range of\napproaches to evaluate it and to understand its components. The addition of online news\nto the list of sources of information available to the public has led to concerns about its\ncredibility as well as its perception by the public as a news source in relation to\nestablished and more traditional news sources. As access and availability of online news\ngrows, the concern for quality of information found online will also increase. News\n\n19\n\nconsumers concerned about sources of information and its trustworthiness, believability,\ncurrency, and other characteristics will demand and seek sources of news that are reliable\nand credible.\nEven when individual credibility dimensions by news medium are standardized, it\nis apparent that researchers who wish to compare across media will still need some form\nof compromise in selecting their dimensions for analysis.\nThis study has revealed differences in how Americans perceived the credibility of\nnewspapers, television news, and online news in early 2002. In the post-September 11\nworld, it is highly likely that news consumers are quite interested in news that is not just\nup to standards prior to the September 11 terrorist attacks, but perhaps seek news that\nexceeds them. While this study does not assess this, it may be a factor in respondents’\nassessments of the credibility of newspapers, television news, and online news.\nThe dimension of currency, timeliness, and up-to-date remain important in the\ncredibility of all three news media studied. For newspapers, the dominant aspect of\ncurrency is that it is perceived to be up-to-date. Television news is thought to be current,\nbut also up-to-date and timely. Online news is seen to be timely, but also current and upto-date. These subtle differences suggest further research to determine their importance.\nNewspaper credibility is seen to be based in balance, honesty, and currency. But\nnewspapers, to offer credibility, must be perceived to be balanced in story telling,\ncomplete in providing information, objective and fair, accurate, and unbiased. They must\nalso be honest in their presentation of news, be believable, and trustworthy. Television\nnews credibility is anchored in fairness, respondents have shown. Viewers want news that\nis fair and balanced, but also see trustworthiness, accuracy, objectivity, completeness,\n\n20\n\nbelievability, unbiased, and honesty as elements of fairness. Online news credibility is\nbuilt upon trustworthiness, these respondents feel. For online news to be credible, it must\nbe trustworthy and believable. It must also be accurate, complete, balanced and fair, and\nhonest.\nPerhaps the most interesting element of online news credibility, however, is the\napparent concern for bias expressed by online news users. The existence of a separate\nfactor for bias and objectivity suggests a strong concern for this component of credibility\nof online news and reflects, perhaps, experiences by online users that have led to biased\nand less-than-objective reports at online news sites.\nThis could be due to the relative difficulty of assessing the objectivity, or biases,\nof Web-based news when compared to a newspaper’s content of that a television\nnewscast. Internet users are aware of the ease of uploading a page on the Web, and with a\nlittle design experience, making it look like output of a well-established or professional\norganization. This seems to underline the importance of branding in online news. Readily\nidentifiable news organizations that have moved to a Web presence or Web sites that use\nexisting and know news brands (such as the Associated Press or other news services)\nhave this advantage over news sites that are only on the Web and do not offer branded\nnews.\nReaders understand that editing and other forms of editorial screening occur in\nnewspaper and television newsrooms. While it is easy to find out who publishes or edits a\nnewspaper or holds the license and edits a television newscast, it is much harder\nsometimes to determine who publishes a Website. This might be a factor that leads to\n\n21\n\nmore concern among online news users regarding the objectivity, or lack thereof, of an\nonline news site, and consequently, its overall credibility.\nThere is clearly need for additional analysis of these three credibility scales and\npublic perceptions of the performance of newspapers, television news, and online news.\nFurthermore, it would have been valuable, for example, to have asked respondents about\nthe credibility of newspapers, television, and online news simultaneously. It is clear from\nthe data that asking only regular users about a particular medium gives only one\nperspective upon this complex issue. A side-by-side-by-side comparison of newspapers,\ntelevision, and online news may yield insights into non-users and their views of each of\nthe three news media relative to each other.\nThis exploratory analysis has set the ground work for additional investigation.\nFurther analysis based on demographic characteristics of respondents is needed. These\nshould include news consumption preferences, gender, high and low level users,\ncomputer literacy levels, online access, education, race and ethnicity, and income. It\nwould also be valuable to analyze only individuals who responded to each of the three\nscales to determine their comparative ratings of newspapers, television news, and online\nnews. There is additional need to determine reasons why fewer people use online news. Is\nit solely an access-to-the-Internet issue or is it access combined with perceptions of lower\nonline news credibility? In-depth analysis of non-users may provide insight needed to\nbetter understand the findings presented in this study.\n\n22\n\nTABLE 1\nTYPE OF NEWS MOST READ AND NEWS MEDIA USED\nType of\nnews\n\nNewspaper Television\nUsers\nUsers\n\nOnline\nUsers\n\nLocal\nNational\nInternational\nLocal-National\nLocal-International\nNational-International\nAll\nn\n\n53.3%\n26.4\n6.1\n5.0\n0.7\n1.9\n6.6\n424\n\n13.8%\n49.3\n25.0\n2.0\n0.7\n7.9\n1.3\n152\n\n43.4%\n31.8\n8.5\n6.8\n1.0\n2.3\n6.2\n484\n\nTABLE 2\nPERCEIVED NEWS CREDIBILITY BY MEDIUM\nTitle\n\nNewspapers\n\nTelevision\n\nOnline\n\nTrustworthy\nCurrent\nBiased\nFair\nReport the whole story\nObjective\nDishonest\nUp-to-date\nBelievable\nBalanced\nAccurate\nTimely\n\nMean SD\n0.51 0.88\n1.03 0.68\n-0.60 0.95\n0.22 0.91\n-0.15 1.03\n0.25 0.95\n0.44 0.88\n0.97 0.57\n0.62 0.72\n0.17 0.95\n0.34 0.89\n0.86 0.64\n\nMean SD\n0.51 0.94\n1.08 0.57\n-0.44 1.02\n0.34 0.90\n-0.19 1.04\n0.19 0.97\n0.43 0.87\n1.03 0.57\n0.67 0.75\n0.20 0.98\n0.43 0.85\n1.00 0.56\n\nMean SD\n0.70 0.74\n1.11 0.68\n0.01 0.89\n0.52 0.76\n0.18 0.98\n0.43 0.81\n0.57 0.79\n1.07 0.62\n0.75 0.66\n0.41 0.89\n0.65 0.72\n1.09 0.61\n\nSummated mean\n\n4.27\n\n4.85\n\n7.01\n\n5.45\n\n5.85\n\n5.14\n\n23\n\nTABLE 3\nNEWSPAPER CREDIBILITY FACTOR ANALYSIS\nFactor\n\nBalance\n\nHonesty\n\nCurrency\n\nBALANCE\nBalanced\nReport the whole story\nObjective\nFair\nAccurate\nBiased\n\n.767\n.732\n.669\n.598\n.575\n.403\n\n.103\n.090\n.110\n.430\n.410\n.365\n\n.035\n.231\n.122\n.019\n.139\n-.264\n\nHONESTY\nDishonest\nBelievable\nTrustworthy\n\n.031\n.224\n.413\n\n.812\n.665\n.632\n\n.039\n.224\n.175\n\nCURRENCY\nUp-to-date\nCurrent\nTimely\n\n.115\n.060\n.129\n\n.128\n.069\n.084\n\n.781\n.765\n.749\n\n24\n\nTABLE 4\nTELEVISION CREDIBILITY FACTOR ANALYSIS\nFactor\n\nFairness\n\nCurrency\n\nFAIRNESS\nFair\nBalanced\nTrustworthy\nAccurate\nObjective\nReport the whole story\nBelievable\nBiased\nDishonest\n\n.819\n.738\n.719\n.701\n.701\n.676\n.621\n.563\n.456\n\n.074\n.037\n.238\n.285\n.033\n.150\n.300\n-.208\n.277\n\nCURRENCY\nCurrent\nUp-to-date\nTimely\n\n.073\n.121\n.111\n\n.808\n.798\n.769\n\n25\n\nTABLE 5\nONLINE CREDIBILITY FACTOR ANALYSIS\nFactor\n\nTrustworthiness\n\nTimeliness Bias\n\nTRUSTWORTHINESS\nTrustworthy\nBelievable\nAccurate\nReport the Whole Story\nBalanced\nFair\nDishonest\n\n.783\n.750\n.727\n.684\n.623\n.595\n.337\n\n.255\n.185\n.164\n.106\n-.068\n-.051\n.180\n\n-.019\n.015\n.125\n.032\n.486\n.373\n.046\n\nCURRENCY\nTimely\nCurrent\nUp-to-Date\n\n.148\n.221\n.121\n\n.898\n.867\n.772\n\n.024\n-.065\n.125\n\nBIAS\nBiased\nObjective\n\n-.062\n.482\n\n.062\n.191\n\n.846\n.592\n\n26\n\nREFERENCES\n\nArant, M. D., &amp; Anderson, J. Q. (2000, August). Online media ethics: A survey of U.S.\ndaily newspaper editors. Paper presented to the Newspaper Division, Association\nfor Education in Journalism and Mass Communication, Phoenix.\nCouper, M. P., Traugott, M. &amp; Lamias, M.J. (2002, Summer). Web survey design and\nadministration. Public Opinion Quarterly, 65(2), 230-253.\nFinberg, H. I., Stone, M. L. &amp; Lynch, D. (2002, January 31). Digital journalism\ncredibility study, Online News Association,\nhttp://www.onlinenewsassociation.org, accessed February 1, 2002.\nFlanagin, A. J., &amp; Metzger, M. J. (2000, Autumn). Perceptions of Internet information\ncredibility. Journalism &amp; Mass Communication Quarterly, 77(3), 515-540.\nFlanagin, A. J., &amp; Metzger, M. J. (2001, January). Internet use in the contemporary media\nenvironment. Human Communication Research, 27(1), 153-181.\nGaziano, C. (1987, Fall). News peoples’ ideology and the credibility debate. Newspaper\nResearch Journal, 9(1), 1-18.\nGaziano, C., &amp; McGrath, K. (1986, Autumn). Measuring the concept of credibility.\nJournalism Quarterly, 63(3), 451-462.\nHovland, C. I. &amp; Weiss, W. (1951-52, Winter). The influence of source credibility on\ncommunication effectiveness. Public Opinion Quarterly, 15(4), 635-650.\nInfante, D. A. (1980, Spring). The construct validity of semantic differential scales for the\nmeasurement of source credibility. Communication Quarterly, 28(2), 19-26.\n\n27\n\nJohnson, T. J., &amp; Kaye, B. K. (1997, August). Trusting the media and ‘Joe from\nDubuque’ online: Comparing Internet and traditional sources on media\ncredibility measures. Paper presented to the Mass Communication and Society\nDivision, Association for Education in Journalism and Mass Communication,\nChicago.\nJohnson, T. J., &amp; Kaye, B. K. (1998, Summer). Cruising is believing: Comparing Internet\nand traditional sources on media credibility measures. Journalism &amp; Mass\nCommunication Quarterly, 75(2), 325-340.\nJohnson, T. J., &amp; Kaye, B. K. (2000, Winter). Using is believing: The influence of\nreliance on the credibility of online political information among politically\ninterested Internet users. Journalism &amp; Mass Communication Quarterly, 77(4),\n865-879.\nJupiter Media Metrix (2001, October). U.S. Online Users, 2000-2006, Industry\nProjections, http://www.jmm.com/xp/jmm/press/industryProjections.xml,\naccessed March 27, 2002.\nKiousis, S. (1999, August). Public trust or mistrust? Perceptions of media credibility in\nthe information age. Paper presented to the Mass Communication and Society\nDivision, Association for Education in Journalism and Mass Communication,\nNew Orleans.\nLasica, J. D. (2001, July). How the Net is shaping journalism ethics. Retrieved August\n14, 2001, from http://www.well.com/~jd/newsethics.html\nMeyer, P. (1988, Fall). Defining and measuring credibility of newspapers: Developing an\nindex. Journalism Quarterly, 65(3), 567-574.\n\n28\n\nMulder, R. (1981, Winter). A log-linear analysis of media credibility. Journalism\nQuarterly, 58(4), 635-638.\nMulder, R. (1980, Autumn). Media credibility: A use-gratifications approach. Journalism\nQuarterly, 57(3), 474-477.\nNadarajan, B., &amp; Ang, P. (1999, August). Credibility and journalism on the Internet:\nHow online newspapers handle errors and corrections. Paper presented to the\nCommunication Technology and Policy Division, Association for Education in\nJournalism and Mass Communication, New Orleans.\nNewhagen, J. (1997, September). The role of feedback in the assessment of news.\nInformation Processing &amp; Management, 33(5), 583-594.\nNewhagen, J., &amp; Nass, C. (1989, Summer). Differential criteria for evaluating credibility\nof newspapers and TV news. Journalism Quarterly, 66(2), 277-284.\nNielsen Media Research (1999, May). TV viewing in Internet households. Retrieved\nAugust 18, 2001 from http://www.nielsenmedia.com\nOgnianova, E. (1998, August). The value of journalistic identity on the World Wide Web.\nPaper presented to the Mass Communication and Society Division, Association\nfor Education in Journalism and Mass Communication, Baltimore.\nOnline News Association. (2001, July 21). ONA’s Digital Journalism Credibility Study\noverview. Retrieved August 14, 2001 from\nhttp://www.journalist.org/Programs/Research2Text.htm\nPew Research Center for People &amp; The Press. (1998, June 8). Internet use takes off:\nEvent-driven news audiences: Pew Research Center biennial news consumption\n\n29\n\nsurvey. Retrieved August 18, 2001 from http://www.peoplepress.org/med98rpt.htm\nPryor, L., &amp; Grabowicz, P. (2001, June 13). Privacy disclosure on news sites low:\nDetailed study suggests new media needs to work on public trust. Online\nJournalism Review. Retrieved August 14, 2001 from\nhttp://ojr.usc.edu/content/story.cfm?id=595\nRimmer, T. &amp; Weaver, D. (1987, Summer). Different questions, different answers?\nMedia use and media credibility. Journalism Quarterly, 64(1), 28-36.\nRubin, R., Palmgreen, P., &amp; Sypher, H. (1994). Communication Research Measures: A\nSourcebook. New York: Guilford Press.\nSchaeffer, D.R. &amp; Dillman, D.A. (1998, Autumn). Development of a standard e-mail\nmethodology: Results of an experiment. Public Opinion Quarterly, 62(3), 378397.\nSchweiger, W. (1998). Wer glaubt dem World Wide Web? Ein experiment zur\nglabwurdigkeit von nachrichten in tageszeitungen und im World Wide Web,” in\nRossler, P. (ed.) Online-kommunikation beitrage zu nutzung und wirkung, pp.\n123-45,Opladen: Wesduetscher Verlag.\nSchweiger, W. (2000, March 1). Media credibility – experience or image?: A survey on\nthe credibility of the World Wide Web in Germany in comparison to other media.\nEuropean Journal of Communication, 15, 37-59.\nSelect Phone Pro CD database (2002, winter edition), Ver. 2.1, Info USA, Omaha, Neb.\n\n30\n\nSundar, S. (1996, August). Do quotes affect perception of online news stories? Paper\npresented to the Communication Technology and Policy Division, Association for\nEducation in Journalism and Mass Communication, Anaheim, Calif.\nSundar, S. (1998, Spring). Effect of source attribution on perception of online news\nstories. Journalism &amp; Mass Communication Quarterly, 75(1), 55-68.\nSundar, S. (1999, Summer). Exploring receivers’ criteria for perception of print and\nonline news. Journalism &amp; Mass Communication Quarterly, 76(2), 373-386.\nTseng, S., &amp; Fogg, B. (1999, May). Credibility and computing technology.\nCommunications of the ACM, 42(5), 39-44.\nWanta, W., &amp; Hu, Y. (1994, Spring). The effects of credibility, reliance, and exposure on\nmedia agenda-setting: A path analysis model. Journalism Quarterly, 71(1), 90-98.\n\n</td>
    </tr>
    <tr>
      <th>59</th>
      <td>news</td>
      <td>Fairness beyond “equal”: The Diversity Searcher as a Tool to Detect and\nEnhance the Representation of Socio-political Actors in News Media\nBettina Berendt\nTU Berlin, Weizenbaum Institute, and KU Leuven, bettina.berendt@kuleuven.be\n\nÖZGÜR KARADENIZ\nDept. Computer Science, KU Leuven, oguzozgur.karadeniz@kuleuven.be\n\nSTEFAN MERTENS\nInstitute for Media Studies, KU Leuven, stefan.mertens@kuleuven.be\n\nLEEN D’HAENENS\nInstitute for Media Studies, KU Leuven, leen.dhaenens@kuleuven.be\n“Fairness” is a multi-faceted concept that is contested within and across disciplines. In machine learning, it usually denotes\nsome form of equality of measurable outcomes of algorithmic decision making. In this paper, we start from a viewpoint of\nsociology and media studies, which highlights that to even claim fair treatment, individuals and groups first have to be\nvisible. We draw on a notion and a quantitative measure of diversity that expresses this wider requirement. We used the\nmeasure to design and build the Diversity Searcher, a Web-based tool to detect and enhance the representation of sociopolitical actors in news media. We show how the tool’s combination of natural language processing and a rich user interface\ncan help news producers and consumers detect and understand diversity-relevant aspects of representation, which can\nultimately contribute to enhancing diversity and fairness in media. We comment on our observation that, through\ninteractions with target users during the construction of the tool, NLP results and interface questions became increasingly\nimportant, such that the formal measure of diversity has become a catalyst for functionality, but in itself less important.\nCCS CONCEPTS • Information systems ➝Information Retrieval ➝Content analysis and feature selection •\n\nApplied computing ➝Law, social and behavioral sciences ➝Sociology • Applied computing ➝Computers in\nother domains ➝Publishing\nAdditional Keywords and Phrases:Fairness-aware recommender systems and diversity in\n\nrecommendation, Innovative methods for studying/analyzing the fairness / accountability /\ntransparency and ethics of web platforms, Usability challenges of machine learning\n1 INTRODUCTION\n“Fairness” is a multi-faceted and contested concept. In machine learning, it most often refers to some form of\nequality of measurable outcomes of algorithmic decision-making, where all components of the definition,\n\nincluding what exactly should be equal (or diverge by only a small quantity) are being disputed [40, 19].\nHowever, classifications of people into (e.g.) “protected group” and “unprotected group” and the equalisation\nof some measures of outcomes or natural-language associations that dominate the AI fairness literature can\nonly capture some aspects of a wider notion of distributive justice [7]. In the present paper, we argue that a\nkey prerequisite for being treated fairly in this sense is that an individual or group has to “exist”, to be\nperceived. We investigate a formalisation of diversity that encompasses these two ideas by modelling both\ndistribution and (prior to this) inclusion. We present the Diversity Searcher, a tool that helps investigate these\nquestions by analysing diversity in news media texts.\nThe concepts of pluralism and diversity are quite established in the literature. While pluralism refers to the\nnormative orientation of a media landscape and the democratic role of journalism, diversity is considered as a\nmeasure of heterogeneity of the various media outlets in that media landscape, e.g. [20]. Napoli [26, 27]\nproposed a threefold approach to information diversity: source diversity (referring to media ownership and\noutlets), content diversity (i.e. formats and viewpoints), and exposure diversity. The latter addresses either the\nvariety of information provided by different outlets available to consumers (horizontal diversity) or the variety\nof information provided by a single media outlet (vertical diversity). The journalism imperative of news\ndiversity is its “multi-perspectivality” [15]. Comparing journalism in the US and France, Benson [4] remarks\nthat ‘balance’ is the most used word in the US, whereas ‘polyphony’ is more incorporated in the French\ndebate on what journalism ought to be. Nevertheless, both notions echo the same journalism imperative: as\npeople rely on media to make their political decisions, it is important that they are exposed to a wide range of\npossible perspectives. This supply of diverse perspectives is the key support for the very idea of democracy\nitself. As governance is controlled by the people, they should be well-informed. Building further on Napoli’s\ncontent diversity, with a focus on viewpoint diversity, and from our concern for increased exposure diversity,\nwe argue that while our ultimate goal is a depth of text understanding that is (certainly today) beyond the limits\nof machines, Natural Language Processing (NLP) techniques together with metrics akin to fairness metrics\nand rich human-computer interfaces can help news media producers and news consumers achieve this goal.\nThe Diversity Searcher is a Web-based tool for the analysis and comparison of news media texts. It\ncurrently works on English-language and Dutch-language texts, and it is generalizable to other languages. It\nidentifies socio-political actors in text via techniques for named-entity recognition, enhanced by techniques for\n1\nthe recognition of unnamed entities .\nOur design rests on two approaches: (a) a quantitative measure of content diversity (as a more\ncomprehensive notion that encompasses aspects of fairness, and that is often a prerequisite for fairness), and\n(b) the provision of a rich user interface that allows news producers and news consumers to explore a text\nwith regards to who is present / represented, and how different they are from one another. The tool provides\nthe user many means of customization of its ontology, making it possible to adapt to new domains and entity\ntypes. This design also aims to alleviate the possible bias in crowdsourced data, models and classification\nbased on them by letting the user have a say in the information the tool produces.\n\n1\n\nFurther context and materials of DIAMOND (Diversity and Information Media: New Tools for a\nMultifaceted Public Debate) can be found at https://soc.kuleuven.be/fsw/diamond\n\n2\n\n2 AN EXAMPLE: HOW TO APPROACH FAIRNESS AND DIVERSITY IN A NEWS TEXT?\nOur enhanced notion of fairness (i.e., our conception of diversity) is best explained with an example, taken\nfrom a blog post by Khadijah Abdurahman [1]:\n“If demands for corporate transparency crystalized in the Standing with Dr. Timnit Gebru Petition defines\nthe horizon for tech worker resistance, we are doomed. […] We need a radical reframing away from the lone\nresearcher against Goliath, to reckon with the failure of the Fairness, Accountability, Transparency and\nbroader ethics frameworks that have allowed opportunists to build their brand, taking up the space required to\naddress the core issues of Big Tech’s hegemonic violence as described in Timnit [and colleagues]’s paper.\nWe must support Timnit and acknowledge that support isn’t enough. I appreciate the amount of public support\nTimnit Gebru has received from the professional community but real friends tell each other that representation\npolitics of the urban elite are not adequate […] We’re ruminating about Jeff Dean’s feelings instead of building\na cross class labor movement that defines tech workers broadly, ie researchers, engineers, Uber drivers,\nAmazon warehouse workers, content moderators etc. […] You people […] with your AI resistance headbands\non, with access to capital [:] refugees, the homeless, the policed etc are for better or worse counting on you\nand you’re out here talking about corporate diversity.” [1]\nThe event around which this blogpost revolves is the termination of researcher Timnit Gebru’s work\ncontract at Google (Google’s firing her for some, her resignation for others) in December 2020. The event was\nwidely perceived as relevant for the AI fairness (and ethics in general) discussion, since Gebru was\npresumably hired in large parts for her achievements in fairness, accountability and transparency research,\nbut then met resistance in her efforts to increase recruitment of people of colour into the company as well as\nin the submission of a research paper on shortcomings in Big Tech’s real-life dealings with fairness in the\nsoftware they deploy. The blogpost, however, does more than this. It questions core assumptions in the\n(Twitter mainstream) discussion of the event. It reminds us that fairness itself is often debated from the\nprivileged standpoint of an “urban elite” of engineers and it calls for a broader notion of “tech workers” as well\nas the inclusion of marginalised groups as key indirect stakeholders. It criticises “representation politics” as\ntoo narrow by pushing the representation – in the discourse – of those oft-forgotten stakeholders.\nThe text is complex, requiring background knowledge of the case, the academic field, and the current techcorporation environment. Its argument probably eludes current AI’s/NLP’s capacities for language\nunderstanding. However, as we will show, NLP can capture the facts that the text (a) contains mentions not\nonly of Timnit Gebru, Jeff Dean, and tech workers (like many other articles on the event), but also of Uber\ndrivers, Amazon warehouse workers, refugees, and homeless people. Not only are these latter groups of\npeople often absent in news texts, but (b) they are also more distinct from the former individuals and groups\nthan these (Gebru, Dean, tech workers in the often-used sense of researchers and engineers) are among\nthemselves. Of course, this claim of distinctness may be debated, and the formal definition of “being distinct”\nneeds to be motivated, discussed, and probably contested.\nOne can go further and observe (or claim) that (c) a text in which these different individuals and groups\ntake up “equal space” would, all else being equal, be more balanced and more fair in the sense of a more\nuniform distribution of attention.\nAspects (a)-(c) identify three components of the definition of diversity that we use in the Diversity Searcher\nand that we explain in Section 3.4.\n\n3\n\n3 BACKGROUND AND RELATED WORK\nThe Diversity Searcher is based on work around diversity in media texts, computational tools in media studies\nand journalism, NLP methods, in particular NER and NEL, and the formalisation of diversity.\n3.1 Media texts and diversity\nAs stated in the introduction, in order to be treated fairly, people and groups first need to exist and be\nperceived. Bourdieu [8] argues that the categories through which social agents exist and are known is an\nissue of continuous political struggle over knowledge of the social world:\n“[T]his work of categorisation, i.e., of making- explicit and of classification, is performed incessantly, at\nevery moment of ordinary existence, in the struggles in which agents clash over the meaning of the social\nworld and of their position within it.” [8]\nAccording to Bourdieu, the social world is organised according to the logic of difference in terms of the\nproperties and their distributions subject to this struggle, making it a symbolic system like language. At the\nsame time, the social world is a topology where agents take positions within various semi-autonomous fields\nconstituting it, giving socio-political differences with respect to these properties and symbolic capitals the\nspatial quality of distinction. Agents’ symbolic power, understood as the power to produce and impose\nclassifications, depends on their position in the social world as well as the classifications inscribed in that\nposition [8]. It follows that the categorisation of social actors is simultaneously political, symbolic (assigning\nmeaning) and spatial (distinction based on properties). It is important to emphasise that agents or fields are\nnot equally powerful in this production of meanings, with the political field and the field of cultural production\n(including media) having privilege [14].\n3.2 Computational Tools in Media Studies\nTraditionally used for automation of tasks for which humans are inefficient, computational methods can now\nbe used for insight driven research questions [28]. Their contemporary usage in media studies include\nautomatic fact checking, topic detection, analysis of (fake) news dissemination, detection of certain types of\ndiscourses such as hate speech, ad hominem, irony, e.g. [9, 3, 11, 38]. Media monitoring projects such as\n2\n\n3\n\nGDELT and Europe Media Monitor , which periodically monitor traditional and social media and produce\nimpressive data sets with the extracted information, are another application class relevant to media studies\n4\n\n[16, 13]. For the issue of diversity, the NLP tool Gender Meme [17] and the commercial service CeretAI [10]\nfocus on digital analysis of content in terms gender representation. Both tools aim to answer the question\n“who is speaking”, rather than “who is present”. Gender Meme achieves this by counting how many words are\nquoted from each gendered individual in a text [18]. CeretAI offers a similar analysis, but on audio-visual\nmedia [10].\nWhile gender is a crucial aspect of diversity, our focus on socio-political actors required us to include entity\ntypes (organizations, geopolitical entities) for which gender is not applicable as it is for individuals. Other\nsocio-politically relevant features such as party membership or ideology needed to be included. This focus on\n\n2\n\nhttps://www.gdeltproject.org/\nhttps://emm.newsbrief.eu/overview.html\n4\nhttps://www.gendermeme.org/\n3\n\n4\n\nsocio-political actors and features necessitated implementing actor detection and classification, to which we\nwill turn next.\n3.3 NER and NEL in actor detection and classification\nOur task specifically involves measuring actor diversity. This requires, first of all, recognizing them in a news\ntext. One approach that is potentially suitable for this task is Named Entity Recognition (NER). NER refers to\nthe task of recognition and classification of information units in a text into a set of entities [21, 25]. Existing\napplications typically also perform a coarse-grained classification with categories such as person, geopolitical\nentity and organisation entities [21].\nWhile a coarse-grained classification is a good start for analysing diversity, it is not sufficient for our chosen\nfield of socio-political actors, as actors of the same type may have very disparate positions in the sociopolitical field. This is further complicated by the fact that actors in news texts are not always named entities.\nFor example, a language model could identify Donald Trump correctly as a “Person”, but would treat him as\nhaving a disparity of 0 with Joe Biden despite very different political positions, and not recognise “immigrant”\nas an actor at all.\nThis problem was addressed in an earlier version of our tool, which used a rich hierarchical ontology with\n235 nodes and 176 leaves to represent diversity in named and unnamed socio-political actors [30]. This\nontology was based on annotations, by social scientists, on a corpus of 580 news articles. The ontology was\nimbalanced and fine-grained. The previous version of the tool addressed this by flattening and pruning the\nontology, resulting in relatively high F1 scores for some categories. More fine-grained classifications have\nbeen proposed in different work, e.g. [12, 22]. However, there is no agreement yet in this field on techniques\n[30].\nA related approach is Name Entity Linking (NEL), the process of linking entities to a knowledge base. An\nNEL pipeline typically includes spotting entities, determining candidates, and named entity disambiguation,\nwhich refers to mapping mentions in the document to the real world entities based on a ranking of candidates\n[23, 32]. These steps make NEL an important subtask of tasks like knowledge base population and\ninformation retrieval [32].\nThe knowledge bases used in NEL are typically crowdsourced linked open databases such as Wikidata\nand DBpedia. These knowledge bases are often structured in accordance with semantic web principles in the\nform of graphs of RDF triples [6]. URIs resulting from the disambiguation make it possible to enrich the\nentities with the data retrieved from the knowledge graph. This data can then be used to summarise features\nof the entities that are relevant to the domain in order to formulate feedback to the user about the text. Similar\n5\n6\nenrichment tools that can be used for journalistic tasks exist, such as Open Calais [29] and Enrycher [35] ,\nyet they are more general-purpose, as their focus is not on socio-political entities or diversity.\n3.4 A quantitative measure of diversity\nOnce actors (or other entities) have been identified, one can investigate how diverse the entities in a given\ntext are. The question is how to measure such diversity. This question has been investigated in a wide set of\n\n5\n6\n\nhttps://developers.refinitiv.com/en/api-catalog/open-perm-id/intelligent-tagging-restful-api\nhttps://ailab.ijs.si/tools/enrycher/\n\n5\n\ndomains including ecology, physical, social, life and information sciences, economic and policy studies,\ncommunication, and cultural analysis [36, 31]. For our measure, we draw on an influential proposal of a\nquantitative measure that draws on a meta-analysis of this wider literature. Andy Stirling identified three\ncomponents, which all enhance diversity [36]:\nVariety: many distinct entities are present, e.g. a number of people of different backgrounds in mix;\n-\n\nDisparity: the entities are different from one another, they come from a wide range;\nBalance: the different entities are evenly distributed. This component is a simple form of the “equality\n\nof …” concept found in the fairness literature.\nStirling further proposed a simple formula for capturing these three components. Diversity Δ is defined as\n\nwith variety being captured by the cardinality of the set of all entities i, j ∈ E present in the domain (e.g. a\ntext, a population, …), balance by the frequencies pi (the more uniform the distribution, the higher this\nmultiplicative factor), and disparity by a measure of distance or dissimilarity d(.,.). In addition, the parameters\nα and β allow for a weighting of the importance of balance or disparity.\nStirling’s formula captures all three elements of diversity as well as the requirements of our first two subgoals (a) and (b), derived at the end of Section 2. Variety measures how wide the inclusion is, disparity grows\nwith the variety of included people, and balance measures the equality of the distribution, i.e. our third subgoal (c).\nMore recent work has proposed different operationalisations of variety, disparity, balance, and/or the way\nin which they should be combined mathematically, e.g. [37]. Since to the best of our knowledge, there are no\ntheoretical investigations of whether other measures than the basic form by Stirling are better suited to\nmeasuring diversity in news texts, we employed the basic form.\nWe treat named (and unnamed) entities in the text as our set E. More specifically, we focus on sociopolitical actors. As Beckers and Van Aelst [2] point out, there is no consensus on their classification into types.\nThe term ‘actor’ broadly refers to entities with social agency; encompassing individuals, organisations, and\nnation states [24].\nVariety is then straightforwardly defined via those entities that the tool (with possible user help) can identify\nas actors. Balance is equally straightforward, derived from the counts of these entities considered as\nfrequencies. Disparity, however, presents interesting challenges. We operationalise it with respect to an\nontology and a dissimilarity measure defined on it. This will be described in the subsequent section.\nThe absolute value of this diversity measure (unless it is 0 or 1) is not meaningful and should therefore not\nbe interpreted. It can be useful to compare different inputs (such as, in our case, texts), but also ordinal\ninterpretations should keep in mind that the difference can arise from the three components disparity, variety\nand balance. This is one of the reasons why a black-box tool that only outputs a diversity score would not be\nuseful in our domain.\n\n6\n\n4 THE DISPARITY OF SOCIO-POLITICAL ACTORS\n7\n\nThe Diversity Searcher identifies socio-political actors in text via techniques for named-entity recognition and\nnamed entity linking, enhanced by techniques for the recognition of unnamed entities (an example in Section\n2 are “tech workers”). For this, it relies on a well-established methodology and off-the-shelf NLP tools.\nHowever, how “different” are the identified entities? As Ranaivoson [31] points out, the component\n“disparity” in Stirling’s formula can prove to be a hurdle as it requires huge assumptions about formulating\ndisparity in numeric terms. Clearly, for an unknown text, in general no a priori pairwise distances will be\navailable. Instead, our tool draws on an ontology that is sourced from three directions. The first is based on\nfeature representations, the second and third draw on user input.\n4.1 Feature-based representations and disparity\nA common technique for disparity computations is based on path distances in the underlying tree-shaped (or\nsometimes also DAG-shaped) ontology. However, results can be distorted for example if some parts of the\nontology are more fine-grained (have more levels) than others, e.g. [5, 34]. A further important limitation,\nespecially in tree-shaped ontologies, is that the ontology is created with regard to one criterion for subclassing. However, we also recognise that addressing socio-political disparity requires taking into account that\nactors will rarely fit any single pigeonhole, no matter how fine-grained the ontology may be. They usually have\nmany overlapping facets relevant to their position takings in the socio-political field. To address this\ncomplexity, we start from the traditional categories of actors (person, organisation, and geopolitical entity). A\nmeasure that can also take similarities and dissimilarities along different facets is then needed. It should also\nrecognise that even if (say) a person and a political party are of very different basic ontological types (person\nand organisation), they can still be quite similar (e.g. because they stand for the same political ideology).\nTable 1 shows a (simplified) example. Donald Trump and Hillary Clinton can be considered similar in that\nthey are both American politicians. However, they are also distinct from each other in that they are associated\nwith conservative and liberal parties. When we add other actors to the context, the issue of disparity becomes\nmore complex. For instance, Tayyip Erdogan is similar to Trump and Clinton in that he is a politician. He is\nmore similar to Trump than to Clinton because of his gender, ideology of his party, and holding an office as a\npresident. However, he differs from both of them as he is based in a developing country, making Trump and\nClinton more similar in this aspect. This example can be extended by adding other features, as well as other\ntypes of actors such as institutions, political parties and NGOs. This illustrates that socio-political actors can\nhave many features that can be common or non-common among these actors. We say that a feature (e.g.,\nbeing male) is common between two actors if both have a certain property (e.g., gender) and both have the\nsame value (e.g., male) on this property. The value can in itself be an actor or other entity (e.g., Republican\nParty) that has properties. If two actors have a certain property, but different values on it (e.g., male vs.\nfemale), we say that the feature is non-common. Properties held by only one of the compared actors are\ndisregarded in comparing the actors.\n\n7\n\nThe tool is available at http://diversitysearcher.net:4000. Please contact the authors to obtain a test\naccount.\n\n7\n\n4.2 DBpedia\n8\n\n9\n\nThe Diversity Searcher DBpedia , a Linked Open Database (LOD) based on Wikipedia . Like most LOD,\nDBpedia uses Semantic Web principles, organizing information from Wikipedia in a machine-processable\nformat. One can garner detailed information about any socio-political actor that has an entry in this knowledge\n10\n\nbase by using SPARQL , the query language for RDF databases. For the current application the public\nSPARQL access point with 2016-10 datasets is used.\nTable 1: Some socio-political features of Donald Trump, Hillary Clinton and Tayyip Erdoğan\n\nType\nDonald Trump Person\nHillary Clinton Person\nTayyip Erdogan Person\n\nSubtype\n\nGender Party\n\nParty Ideology\n\nPolitician\nPolitician\nPolitician\n\nMale\nRepublican Party\nFemale Democratic Party\nMale\nAKP\n\nConservative\nLiberal\nConservative\n\nHolds Office\nCountry\n(currently/2020)\nPresident\nUS\nUS\nPresident\nTurkey\n\n4.2.1 Knowledge representation\n11\n\nDBpedia is used in conjunction with the open source Named Entity Linking service DBpedia Spotlight ,\nwhich identifies the entities in the text and returns the links to the corresponding DBpedia entries. The\nDiversity Searcher then retrieves information about the identified entities from DBpedia, and filters it to keep\nonly the properties and features relevant to our task. The current version focuses on socio-political properties\nof the entities, which include political party membership and ideologies for people and organisations,\nmemberships in international organisations such as the EU, and economic parameters for geopolitical entities.\nThese properties and features are then used to calculate how similar and different two entities in the text are\nfrom each other.\nThe socio-political properties of an entity are extracted from DBpedia and transformed into a feature vector\nas follows.\n1. The basic idea is to select the following attribute information that is often (though not always) explicitly\nasserted as an RDF triple: gender, religion and ideology for a Person, ideology for a political party or other\nOrganisation, geography (e.g. which continent/sub-continent), form of government, and membership in\ninternational organisations for countries or other Populated Places. In addition, entity information is enriched\nvia relational information: a person receives additional features via the political party they belong to and by the\ncountry of this party. A political party’s information is enriched by its country information.\n2. This would normally result in fixed feature vectors for persons, organisations, and countries. However,\nwe found that due to the irregularity of the ontological information in DBpedia, this fixed approach yields only\nsparsely populated feature vectors. We therefore developed a more flexible approach, which is realized by\niterated filtering, see Table 2, especially lines (5) to (8).\nThe instruction block from lines (9) to (11) uses a function fp to filter and classify information that is\nrelevant, but stored in DBpedia under the (underspecified) predicates “type” and “subject”. For example, the\n\n8\n\nhttp://dbpedia.org/sparql\nhttps://www.wikipedia.org/\n10\nhttps://wiki.dbpedia.org/public-sparql-endpoint\n11\nhttps://www.dbpedia-spotlight.org/\n9\n\n8\n\ncategory of Membership of the Commonwealth appears as “subject”, but for our purposes needs to be\ntransferred into a value for the feature International Memberships. This mapping is implemented by an Excel\nconfiguration file that presents the function fp as an enumeration of its tuples, such that the test and the\nretrieval in line (11) become table look-up operations. This declarative and explicit notation enables also nonexperts to configure the algorithm (for example, if they want to add demographic person features as relevant\nfor disparity calculation).\nIn case of conflicting information (two values found for the same feature name of a given entity), we use\nthe first value found. This ensures that more specific information is preferred (e.g. the person’s “own” ideology\nrather than that of their party), a heuristic inspired by the common strategy, in knowledge representation, of\nusing the more specific information (e.g. located at the subclass) where available.\nOur inspection of the obtained results suggests that this strategy leads to better knowledge enrichment. In\nparticular, it gathers (in the cases we have seen) relevant but distributed information about, e.g., the ideology\nof politicians, which is directly linked to some but distributed over their associated entities for others. Thus,\ncoverage is larger than for a fixed feature-retrieval strategy. In future work, this conjecture needs to be\nevaluated, in particular with precision-oriented measures of whether correct information is added (recalloriented measures would require a gold-standard ontology, which does not exist).\n4.2.2 Feature-based disparity calculation\nIn the example from Table 1, Hillary Clinton and Donald Trump have three common features, Donald\nTrump and Tayyip Erdogan have five, and Hillary Clinton and Tayyip Erdogan have two. The three pairs of\nactors have further, non-common 14, 26 and 28 features (not shown in Table 1). Using the Jaccard similarity\n12\n\ncoefficient , we derive a feature-based measure of disparity for each pair : the number of non-common\nfeatures divided by the total number of features. We refer to this measure as the “Jaccard Disparity” in the\nuser interface. For example, Hillary Clinton and Donald Trump have a disparity value of (14 / 19 = 0.74). The\nmeasure ranges from 0 (all features are shared, equality) to 1 (no common features, maximum disparity).\nThe disparity information is then combined with the variety (operationalised as the set {Hillary Clinton,\nDonald Trump, Tayyip Erdogan}), and balance is determined by the number of mentions of these actors in the\ntext, via the Stirling equation shown in Section 3.4.\n\n12\n\nThe Jaccard similarity coefficient is (number of common features / number of all features). Using (1 –\nJaccard similarity) gives us a measure of disparity.\n\n9\n\nINPUT: an entity a recognised by DBpedia Spotlight, with a type in {Person, Organisation, PopulatedPlace}\nOUTPUT: a feature vector describing a\n(1) Add feature “TYPE” with value DBpedia type to a\n(2) PUSH a ONTO QUEUE.\n(3) REPEAT UNTIL QUEUE EMPTY:\n(4) TAKE s FROM QUEUE\n(5) Retrieve all triples with subject s and predicate p ∈ {gender, religion, party, ideology, country}\n(6) FOR EACH triple:\n(7) add a feature to a with feature name p and feature value o\n(8) IF o is a URI &amp; has a triple (o,type,X) with X ∈ {Person, Organisation, PopulatedPlace}\nTHEN PUSH o ONTO QUEUE\n(9) Retrieve all triples with subject s and predicate p ∈ {type,subject}\n(10) FOR EACH triple:\n(11) IF fp(o)  NULL THEN add a feature with feature name fp(o) and feature value o\nTable 2: Creating feature values from DBpedia\n\n13\n\n4.3 Custom ontologies and spaCy\n14\n\n15\n\nDBpedia Spotlight can link surface forms to more than 3.5 million entities found in DBpedia [23]. However,\nour analyses of the depth, breadth and quality of this ontology, both in its Dutch-language and in its Englishlanguage versions, showed that some of the relevant named entities in our corpora are not recognised in this\nway. Reasons can be simple, including a comparatively recent rise in popularity of a person, whose entry is\nhowever not included in the most recent online API of DBpedia that we work with (Greta Thunberg is a case in\npoint as of January 2021).\nOther reasons include accuracy and bias issues arising from using DBpedia Spotlight and DBpedia, both\nof which are based on Wikipedia [39]. Moreover, DBpedia Spotlight favour candidate entities with more inlinks in order to rule out more exotic entities [23]. While the approach is well-suited to a general-purpose\nmodel, it resulted in erroneous recognitions in our use tests, such as nation states recognized as football\nteams, or political parties recognized as “the history of” the said party. The blacklisting by type feature of\nSpotlight is of little use in cases like the former, where both entities are of the same type. We therefore\ncomplemented Spotlight and the DBpedia ontology with our custom ontology, and with functionality that\nallows the user to provide further input and corrections.\n\n13\n\nhttps://spacy.io/\nhttps://github.com/dbpedia-spotlight/dbpedia-spotlight-model\n15\nThe most recent version of the Spotlight models (18 November 2020) can be found at\nhttps://databus.dbpedia.org/dbpedia/spotlight/spotlight-model/2020.11.18\n14\n\n10\n\n4.3.1 Knowledge representation\nThis custom ontology contains unnamed entities, compiled from the custom ontology tree based on [30] (see\nabove) and named entities relevant to our context such as Belgian political parties. These custom entities are\nspotted using spaCy’s ‘rule based matcher’. This is supplemented with spaCy’s own named entity recognition\nmodule to spot other named entities in the text that are not recognised by Spotlight or do not have a custom\nrule in Diversity Searcher, but may have significance in the text (as in the Greta Thunberg example).\nFor the entities recognised using a custom rule containing a URI, we attempt to acquire the type\ninformation from DBpedia in the way described in 1.1 to ensure consistency. If the rule does not contain a\nURI, we then use the type entered by the user when populating the rule. Finally, for the remaining entities we\ndefault to the types recognised by spaCy’s NER.\n4.3.2 Disparity calculation\nFor entities identified in this way, we have no access to feature information. As a simple heuristic, we give\ndefault value 0.25 (“small”) to entity pairs of the same type and 1 to other pairs. These default assignments\ncan be edited by the user, as explained in (3) below.\n4.4 Direct user input\nDBpedia is a general-purpose ontology, spaCy’s functionality is generic, and also the custom ontology we\nemploy was built for a specific purpose. As an unavoidable consequence, some entities relevant to the\ndomain of news articles or the even more scope-restricted domains of news such as migration, and/or\ncontained in a concrete article or corpus to be analysed, may not or not sufficiently be represented or\nrecognised. To allow the user to describe these and thereby the Diversity Searcher to process them, we\nadded an interactive component to the tool in which users can add entities.\nThis component offers the user a table to add or remove custom matching patterns for spaCy’s matcher to\nuse temporarily or save for later sessions. The patterns entered by the user are processed the same way as\nthe custom ontology described above, with the options for the user to choose match type (“case sensitive”,\n“case insensitive”, “lemma”), DBpedia link if available, and type of entity (person, organisation, geo-political\nentity).\nThe overall methodology results in ontologies that are richer than custom-built ontologies (since they draw\non a worldwide community of ontology creators and/or the tool users, rather than the – by nature – very\nlimited efforts of dedicated research teams), and they are also more sustainable (as crowd-sourced and/or\nuser-sourced ontologies, they are more up-to-date and do not depend on the temporally bounded funding for\nontology engineering in a research project).\n5 USER INTERFACE AND INTERACTIVITY\nThe interface aims to give feedback to the user about the socio-political actors in the text or corpus, their\nfeatures, their disparities, and diversity. Based on our findings in the workshops and user tests, we strive to\nmake this feedback as intuitive and accessible as possible for all user types.\n\n11\n\nFigure 1. Colour-coded annotations of the three actor types in an excerpt of an article from Guardian 16\n\nFigure 2. Actors found in the text, displayed on a histogram in the “Actors” tab.\n\nFigure 3. The interface tab for editing actor recognition patterns.\n\n16\n\nhttps://www.theguardian.com/us-news/2021/jan/07/georgia-senate-runoff-black-voters-stacey-abrams\n\n12\n\nFigure 4. The interface tab for pairwise actor disparities.\n\nThe most accessible types of feedback the application provides include colour-coded annotations of actors\n(Fig. 1), hover info-boxes populated with their features, descriptions and photographs retrieved from\nDBpedia/Wikipedia, a word-cloud representation of these actors, and histograms and frequency tables for the\nactors (Fig. 2) and analogously for their features. Entities for which additional information is available in a\nhover-box are highlighted in bright colours; other entities in light colours (Fig. 1). All of the frequency tables\ncan be exported as a single Excel file with separate tabs for each of them, providing a convenient way for the\nuser to process the data further, for example with Excel or SPSS. When a corpus is uploaded, every\ndocument within it is represented as a row in the frequency tables in the interface and the exported files.\nFor disparity, a visualisation using multidimensional scaling is provided, on which the actors are colourcoded according to type, scaled according to relative frequency, and positioned within a 2D space with\nrespect to their feature vectors. Pairwise disparities are also presented in a chart editable by the user, with\nhover info-boxes about their method of calculation (Jaccard disparity, or default value if no features are found)\nand the number of common features they share. Diversity is calculated using Stirling’s [36] formula based on\nthese disparities and relative frequencies of the actors, and displayed numerically for each article and\nindividual text. Thus, users can compare different articles or corpora.\nOne issue that surfaced recurringly in user tests was the entities misrecognised or unrecognised by\nSpotlight. To address this, we added a component where the user can customise the rules for recognising\nnamed and unnamed entities (Fig. 3). This component consists of a table populated with all the potential\nentities recognised by spaCy as a default, with options to add or remove rows representing each recognition\nrule. The rules consist of “words to match”, the matching method (“case sensitive”, “case insensitive”,\n“lemma”), DBpedia link (if available), type of entity (person, geopolitical entity, organisation), and whether to\nignore that match in the case of misrecognised entities. The rules can be used in a current session, or saved\nby the user for future use. For example, the user may want to change the wrong classification for “black” from\n\n13\n\n“GPE” to “PERSON” (Fig. 1), or add “black voter” as a new actor type depending on their current interest.\nThis interface also enables user to instruct Diversity Searcher to remove falsely recognized entities.\nA similar interface is also provided for pairwise disparities, where the user can modify disparities of actors\n(Fig. 4). Users can change the coarse values (low/medium/high) in the basic mode or enter numeric values in\nadvanced mode. Such edits are especially useful for entities that do not have entries in DBpedia, for which a\nfeature-based Jaccard disparity cannot be calculated. Finally, the resulting Stirling diversity score is also\nshown in the same interface.\nAfter consulting with various user groups, we have decided to bundle all functionalities in one user\ninterface. While the current version only supports basic authentication, a more sophisticated user\nmanagement is planned for the future which would limit/enable functionality based on user groups such as\nnews producers and news consumers. In addition, the application has a simple/advanced mode switch, which\nmodifies the data presented to the user as well as the interface, allowing for a selection between more\nintuitive access vs. more control.\nThe application includes a corpus upload function. Using this function, users can upload XML files\n17\nexported from GoPress and batch process them, and export the results as an Excel file to be used in further\nanalysis in Excel or SPSS.\n6\n\nSUMMARY, LIMITATIONS AND OUTLOOK ON FUTURE WORK\n\nThe Diversity Searcher tool described in this paper was motivated by the question how we can increase\ndiversity and fairness in media reporting. In our theoretical grounding, we started from a viewpoint of\nsociology and media studies, which highlights that to even claim fair treatment, individuals and groups first\nhave to be visible. We drew on Stirling’s quantitative measure of diversity that expresses this wider\nrequirement. We used the measure to design and build the tool to detect and enhance the representation of\nsocio-political actors in news media. The tool’s combination of natural language processing and a rich user\ninterface can help news producers and consumers detect and understand diversity-relevant aspects of\nrepresentation, which can ultimately contribute to enhancing diversity and fairness in media.\nWhile the core functionality gives valuable information about entities present in the texts, there are multiple\navenues for improvement and additional features.\nOne limitation concerns the downstream effects of re-using third party resources, services and tools.\nDespite having advantages, dependence on third party tools and services posed limitations in the\nperformance of the application. Firstly, using Spotlight for actor recognition limits the recognised actors to\nthose that have a resource on DBpedia. We attempted to alleviate this by using spaCy's NER module to\ninclude recognised entities that do not have a resource in Dbpedia, and its pattern based matcher to add\nnamed and unnamed custom entities. Secondly, dependence on DBpedia brought also limitations in the data\nquality and performance. Currently we attempt to remedy the missing/inaccurate depictions of actors by\nenabling user input of pairwise disparities, but a future solution may be populating a local knowledge base,\n\n17\n\nGo Press (gopress.be) is an online press database covering a large number of international and Belgian\nnews sources, where journalists and media researchers can search and export corpora. The specific source\nand therefore its XML format are relevant for our target users, but the schema could easily be made\nconfigurable. https://www.gopress.be/info/nl\n\n14\n\npossibly using multiple resources such as Wikidata\n\n18\n\n19\n\nand ConceptNet\n\nto improve both issues. A further\n\nlimitation is created by the complex relations between named and unnamed entities. In future work, we plan to\ndevelop coreference resolution between named and unnamed entities, as well as entities and pronouns. An\nimplementation of gendered coreference resolution would also improve the statistics related to actor genders,\nwhich currently only use DBpedia data for named entities.\nThe current tool gives insights about the presence of actors in texts. However, the presence itself does not\nnecessarily imply a favourable representation, or one that is comparable between the different represented\nactors. An actor like “refugee” could be represented as a passive actor, lacking agency, or as the subject of a\ncrime. This points to other avenues for future work. One is the detection and categorisation of the verbs that\nco-occur with the actor entities. A second and related feature would be to determine the active/passive voice\nin which entities appear within the sentence using dependency trees, these two features will provide\nadditional insight into the representation of the entities. Topic detection is another interesting prospect related\nto this aspect of the issue, revealing actors that regularly occur in certain topics. Future work that addresses\nthese aspects of representations would result in an application that can provide more in-depth insight to actor\ndiversity media texts, contributing to fairness in media.\nThe tool was constructed in continuing collaboration between computer scientists and media studies\nscholars, and requirements were iteratively adjusted based on input from target users. Throughout, users\nwere more interested in the rich interface functionality that helps them explore diversity-related aspects of the\ntexts, and less in the final numerical diversity score. This proved to be an interesting demonstration of how\nsuch a formal measure can serve as motivation and heuristic, but then end up in the background of what is\nreally used. At the same time of course, the measure and the ensuing design decisions embody a collection\nof decisions and symbolic power.\nTo return to Bourdieu, the categories that make knowledge of the social world possible constitute the\nstakes in political struggles as they revolve around conserving or transforming them [8]. As the main functions\nof Diversity Searcher involve categorisation and making explicit of actors, it runs the risk of reproducing the\nvery biases and inequalities it attempts to critique/deconstruct. Relying on third party tools based on\ncrowdsourced knowledge may aggravate this limitation, as exemplified by the demonstrable gender bias in\nWikipedia [39]. While containing biases, crowdsourced knowledge also represents a more democratic and\ncritical mode of knowledge production than most alternatives. This makes it a suitable aid in critically and\nreflexively engaging with texts that are produced by individual authors within a media subfield with its own\ncapitals, stakes and interests. In addition, Diversity Searcher gives the user means to alter the ontology and\nentity recognition rules, further negating the biases that may be in the models of DBpedia Spotlight, spaCy, as\nwell as our own ontology.\nLast but not least, evaluations at different levels will need to complement the implementation-driven work\nso far. Where we use third-party resources and software, we have used standard state-of-the-art choices\nsuch as DBpedia or DBpedia Spotlight. As highlighted in Section 4.2.1, our knowledge-representation\nheuristics require a systematic evaluation with information-retrieval methods and measures. Most importantly,\nwe need to evaluate the usability and usefulness of the tool in user studies. While feedback from user\n\n18\n19\n\nhttps://www.wikidata.org/wiki/Wikidata:Main_Pag e\nhttps://conceptnet.io/\n\n15\n\npartners of our project has been encouraging, we have not yet conducted a summative evaluation. Most\ndesign guidelines for the Diversity Searcher resulted from interviews with four key stakeholders from major\nFlemish news media (the editors-in-chief of two alternative (non-mainstream) magazines, the head of\nproduction of one of the leading TV newsrooms and a journalist of a national newspaper) and collaboration\nwith media-studies researchers [30, 2]. Individual features resulted from formative evaluation sessions as well\nas focus-group interviews with students from journalism and Digital Humanities programmes and media21\nstudies scholars . These sessions showed that physical presence is needed to explain the tool and get\nfeedback.\nThe tool is ultimately designed as a means towards improving journalism. Journalism is an institution in\nsociety, but many institutions tend to be somewhat conservative. Although implementing diversity echoes a\njournalism imperative, the tool is new and relies on some conceptual background. “Diversity consciousness”\nand “multimedia consciousness” are both logical parts of contemporary journalism education, but every new\ntool requires an “enculturating” process [18], accompanied by a well-constructed pedagogical approach.\nFuture work also requires us to implement the tool, so that the tool is not only theoretically relevant but also\npractically used. As Siitonen et al. [33] demonstrate, the interaction between computer science students and\njournalism students in pedagogical settings can be valuable in thinking out how to use new applications.\nEventually our goal is not only to integrate the tool in journalism education, but also to present the tool to\njournalists who are currently on the job and hence maximise its impact. Due to corona-induced restrictions,\nthe planned evaluation study had to be postponed into 2021. These studies will contribute to fine-tuning both\nbackend and frontend of the Diversity Searcher for relevant practitioners, and will allow us to gauge its\nusefulness in practice.\nACKNOWLEDGMENTS\nWe thank the Fonds Wetenschappelijk Onderzoek – Vlaanderen (FWO) for funding DIAMOND under project\ncode S008817N.\nREFERENCES\n[1]\n\nJ. Khadijah Abdurahman. 2020. On the Moral Collapse of AI Ethics. Retrieved Dec, 7 2020 from\n\nhttps://upfromthecracks.medium.com/on-the-moral-collapse-of-ai-ethics-791cbc7df872\n[2]\nKathleen Beckers and Peter Van Aelst. 2019. Look who’s talking: An analysis of actors in television\nnews\n(2003–2016).\nJournalism\nStudies\nDOI:https://doi.org/10.1080/1461670X.2018.1463169\n\n20,\n\n6\n\n(April\n\n2019),\n\n872–890.\n\n[3]\nYochai Benkler, Rob Faris, and Hal Roberts. 2018. Network propaganda: manipulation,\ndisinformation, and radicalization in American politics. Oxford University Press, New York.\n\n21\n\nWorkshops with students from KU Leuven Journalism and KU Leuven Digital Humanities programs were\ncarried out in October and December 2019 respectively. In these workshops, participants used an early\nversion of Diversity Searcher to analyze online news articles. The design and development continued with\nregular meetings with colleagues from KU Leuven Media Studies department (beginning February 2020),\nwith their continuous feedback on interface and entity recognition.\n\n16\n\n[4]\n\nRodney Benson. 2013. Shaping Immigration News: A French-American Comparison. Cambridge\n\nUniversity Press, New York. DOI:https://doi.org/10.1017/CBO9781139034326\n[5]\nBerendt, B. &amp; Navigli, R. (2006). Finding your way through blogspace: Using semantics for crossdomain blog analysis. In Proceedings of the AAAI 2006 Symposium on Computational Approaches to\nAnalysing Weblogs. Stanford, CA: March 2006 (pp. 1-8). Technical Report SS-06-03. Menlo Park, CA: AAAI\nPress.\n[6]\n\nTim Berners-Lee, James Hendler, and Ora Lassila. 2001. The Semantic Web: A New Form of Web\n\nContent That is Meaningful\nScientificAmerican.com (2001).\n\nto\n\nComputers\n\nWill\n\nUnleash\n\na\n\nRevolution\n\nof\n\nNew\n\nPossibilities.\n\n[7]\nR Binns, ‘Fairness in Machine Learning: Lessons from Political Philosophy’ in Conference on\nFairness, Accountability and Transparency, FAT 2018 (Proceedings of Machine Learning Research 81, 2018)\n149\n[8]\n\nPierre Bourdieu. 1985. The Social Space and the Genesis of Groups. Theory and Society 14, 6\n\n(Nov. 1985), 723-744 Retrieved January 9, 2021 from www.jstor.org/stable/657373\n[9]\nGiovanni Luca Ciampaglia, Prashant Shiralkar, Luis M. Rocha, Johan Bollen, Filippo Menczer, and\nAlessandro Flammini. 2015. Computational Fact Checking from Knowledge Networks. PLOS ONE 10, 6\n(2015), 1–13. DOI:https://doi.org/10.1371/journal.pone.0128193\n[10]\n[11]\n\nCeretai n.d. Retreived from https://ceretai.com/ on January 5, 2020.\nPieter Delobelle, Murilo Cunha, Eric Massip Cano, Jeroen Peperkamp, and Bettina Berendt. 2019.\n\nComputational Ad Hominem Detection. In Proceedings of the 57th Annual Meeting of the Association for\nComputational Linguistics: Student Research Workshop, Association for Computational Linguistics, Florence,\nItaly, 203–209. DOI:https://doi.org/10.18653/v1/P19-2028\n[12]\nBart Desmet and Véronique Hoste. 2014. Fine-grained Dutch named entity recognition. Lang\nResources &amp; Evaluation 48, 2 (June 2014), 307–343. DOI:https://doi.org/10.1007/s10579-013-9255-y\n[13]\nEurope Media Monitor. n.d. Retrieved from https://ec.europa.eu/jrc/en/scientific-tool/europe-mediamonitor-newsbrief on January 5 2020\n[14]\nWilliam A. Gamson, David Croteau, William Hoynes, and Theodore Sasson. 1992. Media Images\nand the Social Construction of Reality. Annual Review of Sociology 18, 1 (1992), 373–393.\nDOI:https://doi.org/10.1146/annurev.so.18.080192.002105\n[15]\nHerbert J Gans. 2011. Multiperspectival news revisited: Journalism and representative democracy.\nJournalism 12, 1 (Jan. 2011), 3–13. DOI:https://doi.org/10.1177/1464884910385289\n[16]\n[17]\n\nThe GDELT Project. n.d. Retrieved from https://www.gdeltproject.org/ on January 5, 2021\nGender Meme. n.d. Retrieved from https://www.gendermeme.org/ on January 5, 2020\n\n[18]\nDebbie Goh and Ugur Kale. 2015. From Print to Digital Platforms: A PBL Framework for Fostering\nMultimedia Competencies and Consciousness in Traditional Journalism Education. Journalism &amp; Mass\nCommunication Educator 70, 3 (September 2015), 307–323.\n[19]\nB Hutchinson and M Mitchell, ‘50 years of test (un)fairness: Lessons for machine learning’ in\nProceedings of the Conference on Fairness, Accountability, and Transparency. FAT* 2019 (ACM 2019) 49\n[20]\nKari Karpinen. Journalism, Pluralism, and Diversity. Tim P. Vos (Ed.). In Journalism. De Gruyter\nMouton, 2018. 493–510. DOI:https://doi.org/10.1515/9781501500084-025\n\n17\n\n[21]\n\nJing Li, Aixin Sun, Jianglei Han, and Chenliang Li. 2020. A Survey on Deep Learning for Named\n\nEntity Recognition. arXiv:1812.09449\nhttp://arxiv.org/abs/1812.09449\n\n[cs]\n\n(March\n\n2020).\n\nRetrieved\n\nJanuary\n\n12,\n\n2021\n\nfrom\n\n[22]\nXiao Ling and Daniel S. Weld. 2012. Fine-Grained Entity Recognition. In Proceedings of the TwentySixth AAAI Conference on Artificial Intelligence (AAAI’12), AAAI Press, 94–100.\n[23]\nPablo N. Mendes, Max Jakob, Andrés García-Silva, and Christian Bizer. 2011. DBpedia spotlight:\nshedding light on the web of documents. In Proceedings of the 7th International Conference on Semantic\nSystems - I-Semantics ’11, ACM Press, Graz, Austria, 1–8.\n[24]\nJohn W. Meyer and Ronald L. Jepperson. 2000. The “Actors” of Modern Society: The Cultural\nConstruction\nof\nSocial\nAgency.\nSociological\nDOI:https://doi.org/10.1111/0735-2751.00090\n\nTheory\n\n18,\n\n1\n\n(March\n\n2000),\n\n100–120.\n\n[25]\nDavid Nadeau and Satoshi Sekine. 2007. A Survey of Named Entity Recognition and Classification.\nLingvisticae Investigationes 30, (2007). DOI:https://doi.org/10.1075/li.30.1.03nad\n[26]\nPhilip M. Napoli. 1999. Deconstructing the diversity principle. Journal of Communication 49,4 (Dec.\n1999) 7-34. DOI: https://doi.org/10.1111/j.1460-2466.1999.tb02815.x\n[27]\nPhilip M. Napoli. 2003. Audience Economics: Media Institutions and the Audience Marketplace.\nColumbia University Press.\n[28]\nDong Nguyen, Maria Liakata, Simon DeDeo, Jacob Eisenstein, David Mimno, Rebekah Tromble,\nand Jane Winters. 2019. How we do things with words: Analyzing text as social and cultural data.\narXiv:1907.01468 [cs] (July 2019). Retrieved December 7, 2019 from http://arxiv.org/abs/1907.01468\n[29]\nOpen Calais. n.d. Intelligent Tagging – RESTful API | Refinitiv Developers. Retrieved from\nhttps://www.refinitiv.com/en/products/intelligent-tagging-text-analytics\n[30]\nPeperkamp, Jeroen; Berendt, Bettina: Diversity Checker: Toward recommendations for improving\njournalism with respect to diversity, In UMAP '18 Adjunct Publication of the 26th Conference on User\nModeling, Adaptation and Personalization (pp. 35-41). New York: ACM.\n[31]\nHeritiana Ranaivoson. 2013. “Measuring Cultural Diversity with the Stirling Model.” in proceedings of\nNew Techniques and Technologies for Statistics 2013. March 5-7, 2013. 10.2901/Eurostat.C2013.001\n[32]\nWei Shen, Jianyong Wang, and Jiawei Han. 2015. Entity Linking with a Knowledge Base: Issues,\nTechniques, and Solutions. IEEE Trans. Knowl. Data Eng. 27, 2 (February 2015), 443–460.\nDOI:https://doi.org/10.1109/TKDE.2014.2327028\n[33]\nMarko Siitonen, Panu Uotila, Turo Uskali, Jukka Varsaluoma, and Tanja Välisalo. 2019. A Pilot Study\non Developing Newsgames in Collaboration between Journalism and Computer Science Students. Nordicom\nReview 40, 2 (March 2019), 143–155.\n[34]\nThabet Slimani. Description and Evaluation of Semantic Similarity Measures Approaches. CoRR\nabs/1310.8059 (2013)\n[35]\nTadej Stajner, Delia Rusu, Lorand Dali, Blaž Fortuna, Dunja Mladenić, and Marko Grobelnik. 2010. A\nService Oriented Framework for Natural Language Text Enrichment. Informatica (Slovenia) 34, (2010), 307–\n313.\n[36]\n\nAndy Stirling. 2007. A general framework for analysing diversity in science, technology and society.\n\nJ. R. Soc. Interface (2007) 4, 707–719. DOI:10.1098/rsif.2007.0213\n\n18\n\n[37]\n\nAlje van Dam. 2019. Diversity and its decomposition into variety, balance and disparity. R. Soc. open\n\nsci. 6, 7 (July 2019), 190452. DOI:https://doi.org/10.1098/rsos.190452\n[38]\nTony Veale and Yanfen Hao. Detecting Ironic Intent in Creative Comparisons.In proceedings of the\n2010 conference on ECAI 2010: 19th European conference on artificial intelligence. Lisbon, Portugal, August\n16-20\n[39]\nClaudia Wagner, David Garcia, Mohsen Jadidi, and Markus Strohmaier. 2015. It’s a Man’s\nWikipedia? Assessing Gender Inequality in an Online Encyclopedia. arXiv:1501.06307 [cs] (March 2015).\nRetrieved January 14, 2021 from http://arxiv.org/abs/1501.06307\n[40]\nI Zliobaite, ‘Measuring discrimination in algorithmic decision making’ (2017) 31 (4) Data Mining and\nKnowledge Discovery 1060\n\n19\n\n</td>
    </tr>
  </tbody>
</table>