<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>29</th>
      <td>poli</td>
      <td>Political Bias Analysis Arkajyoti Misra Target Corporation Stanford University arkajyot@stanford.eduSanjib Basak Digital River Inc. Stanford University sbasak@stanford.edu Abstract The two major political parties in US are polarized between either the liberal and conservative point of view on a multitude of socio-economical and environmental issues. An algorithmic approach towards detection of such bias is both intellectu- ally challenging and useful in areas like election prediction. There exists very few studies in the literature where modern deep learning techniques are applied to de- tect the personal opinion or bias of an individual. In this work, we have developed an LSTM network that achieved an F1 score of 0.718 on a data set consisting of statements made in the recent past by US election candidates. 1 Introduction The political atmosphere in the US is deeply polarized between two predominant ideologies: liberal and conservative. The twp major parties maintain differences in opinion in different issues like global warming, gay rights, abortions, foreign policies and immigration, to name a few. While the liberals encourage active role for government in society and believe in environmental regulations, conservatives like to have a limited role for government in the society and argue against imposing environmental regulations. In the age of big data, with the help modern technology, this information is being captured in both structured and unstructured form at an unprecedented scale. Particularly, the year of 2016 being a US presidential election year, there is no shortage of active and engaging political discussions in the media fed by the plethora of public debates, interviews and speeches. The sudden eruption of activity in the area of opinion mining and sentiment analysis, which deals with the computational treatment of opinion, sentiment, and subjectivity in text, has generated increased interest in building new applications that deal directly with opinion [1]. The agenda of the political parties are obviously biased over the different issues, but the bias in the different forms of public communication like news media, journals, news channels are at times quite difÔ¨Åcult to comprehend from a cursory look. In many cases, it is certainly challenging, if not impossible, to manually decipher every bit of such information available in the public domain that can be quite useful in predicting the outcome of an election, for example. Our hypothesis is that a sophisticated deep learning algorithm can be trained to detect such bias auto- matically. Natural Language Processing (NLP) and Information Retrieval are becoming increasingly popular in detecting private states such as opinions, sentiment, and beliefs [2], [3] from text. How- ever, the task of detecting political bias is quite non trivial and provided a unique challenge to the NLP community over years. The goal of our project is to build an analyzer capable of detecting political bias from a given body of text. Previous work on bias or ideology detection from a textual document is relatively rare in literature. Most prior work on the topic are based on a bag-of-words representations of the document together with a multitude of hand crafted rule based on deep understanding of the structure of the language. For example, Gerrish and Blei [4] predicted the voting patterns of Congress members based on 1 bag-of-words representations of bills and inferred political leanings of those members; whereas Gentzkow and Shapiro [5] derived a slant index to rate the ideological leaning of newspapers. With the recent success of deep neural network models in the Ô¨Åeld of natural language processing, researchers have started to apply the state of the art models in the Ô¨Åeld of abstract theme or opinion detection [6] and achieved higher accuracy (an F1 score of close to 70.) Models like Recurrent neural network deploy deep architecture with multiple hidden layers and perform well for sequential prediction of tasks. Within the NLP Ô¨Åeld, sentences are viewed as constructed sequence of tokens that need to carry forward the meaning from the beginning of the sentences to the end. With this view, those models have been successfully applied to tasks such as language modeling [7], and spoken language understanding [8] Recursive neural networks is another class of deep neural net architecture within that has been applied to parsing [9], sentence-level sentiment analysis [10], and paraphrase detection [11]. The major inspiration of the present work comes from the recent work by Iyyer et al [12] where the authors applied a Recursive Neural Network (RvNN) based on the Stanford tree parser and achieved a 69% accuracy on a binomial classiÔ¨Åcation of the two prominent political ideologies in the US. 2 Data The data set we used for the project is called the Ideological Books Corpus (IBC), which was com- piled by a group of researchers from the University of Maryland [12]. The data set was based on publicly available US congressional Ô¨Çoor debate transcripts from 2005 [13]. The Ô¨Ånal data set [14] was a compilation of sentences hand picked to be most expressive of political sentiment and man- ually labeled by a majority voting scheme. We are using the entire data set for this project that consists of 2025 liberal and 1701 conservative biased sentences. A typical example of a conservative biased sentence is ‚ÄùEven he would have been in complete shock over Al Gore ‚Äôs ability to scare billions of people into believing humans are killing themselves and suffocating all life on the planet by driving their carbon-emitting cars back and forth to work instead of riding bicycles .‚Äù The example highlights the difÔ¨Åculty of the task at hand. It would be easy for a real human to categorize the sentence as anti-liberal based on prior knowledge of Al Gore‚Äôs political position or that carbon emitting cars are bad for the environment is a predominantly progressive point of view. However, any classiÔ¨Åer that needs to effectively identify the political bias of an example like this must have (a) the ability to capture long distance correlation between words and (b) knowledge of proper context. A typical liberal biased example - ‚ÄùThough the practice can be defended as generating revenue used to improve the college ‚Äôs academic program , the effect is to favor middle-class and less needy applicants .‚Äù - also supports the fact that political bias may not be explicitly expressed through one or many words and knowledge of the general perception about the middle class of the major US political institutions is of paramount importance in classifying the sentence correctly. We also collected data from ontheissues [15] (OTI) that collects political speeches, dialogues and debate transcripts, from candidates of both the major parties, on a multitude of issues. A majority of the content of the data set being statements from the political candidates on an election campaign, the texts consist of generally smaller sentences and are more expressive of the bias of the speaker compared to the previous data set. For each of the issues we created two documents - one with liberal views and another with conservative views. We did not assign a label to a text based on the political afÔ¨Åliation of the speaker; instead we carefully labeled them based on the actual bias expressed in the text. This is a departure from the IBC data set where the text was labeled based on the political afÔ¨Åliation of the speaker. In the OTI data set, a typical conservative biased example on the issue of gun control is: ‚ÄôRestrictive gun laws don‚Äôt stop culture of violence‚Äô; while a liberal biased statement on environment is: ‚ÄôAdopt the Clean Cars Act to Ô¨Åght global warming‚Äô. 2 Figure 1: A rolled out RNN network used in binary classiÔ¨Åcation. 3 Model Recurrent neural networks (RNN) have completely revolutionized the world of Natural Language Processing (NLP) in the last few years. In extremely difÔ¨Åcult NLP challenges like machine trans- lation, question answering and text generation to name a few, RNN have recently outperformed the conventional techniques based on a deep understanding of the structure of the language. Conven- tional RNNs are generative model where the network is built to always predict the next word in a sequence, thereby learning the semantic structure of the language. For the task at hand, we are using the network as a classiÔ¨Åer where the network is tasked with predicting the label at the end of a sequence, at shown in Fig. 1. The task at hand demands that the model capture long range correlation between words in the text. That is because the data loss does not get contribution from every word in the network and is calculated only at the very last time step and the gradient of the loss has to backpropagate to the beginning of the sentence. However, conventional RNNs stuggle to back propagate the gradient over many time steps because of the well known problems of vanishing or exploding gradients [16]. More recently, RNN variants like GRU and LSTM have solved the problem and therefore, an LSTM network was chosen for the task at hand. An LSTM unit is described by the set of activations in Eqs. (1), where htis the hidden state at time stept;i,fandostand for the input, forget and the output gate respectively. The network learns the variousWandUmatrices and ctcontrols how much of the past information has to be retained in the network. The symbol denotes the Hadamard product. i=(xtUi+ht 1Wi) f=(xtUf+ht 1Wf) o=(xtUo+ht 1Wo) g= tanh(xtUg+ht 1Wg) o=(xtUo+ht 1Wo) ct=ct 1f+gi st= tanh(ct)o (1) The binary cross entropy loss is calculated at the last time step ( tend) of the network as follows: lossCE(y;^y) = X iyilog( ^yi); whereyis the true label and the predicted label is calculated using a sigmoid function applied on the hidden state at tend: ^y=(htendU+b) (2) 4 Results and Discussion In a binary classiÔ¨Åcation framework, both the ROC-AUC number and the F1-score are widely ac- cepted to be robust measures. The AUC is the Area Under the Curve of a plot of the true positive rate (TPR) vs the false positive rate (FPR). The metric varies between 0.5 for a completely random prediction and 1 for a perfect prediction. For data sets having highly imbalanced classes present in 3 it, the AUC is a good measure as it properly weights the correct prediction of the minority class too. The F1-score, on the other hand, is deÔ¨Åned as the geometric mean of the precision and recall [17] F1 =2precision recall precision +recall; (3) where precision is the fraction of retrieved instances that are relevant, while recall is the fraction of relevant instances that are retrieved [18]. The F1 score varies between 0 and 1 and the standard goal in a classiÔ¨Åcation project is to maximize the score. Figure 2: Performance of the Naive Bayes model measured by both F1 and AUC metrics on both the data sets used in the study. In our experiment we shall focus on the F1 score as it is most common in the literature but will also track the AUC score as a guide against the model predicting completely random outcomes. Although the F1 score is more frequently reported in classiÔ¨Åcation tasks similar to the present one, the AUC actually looks at all possible prediction thresholds instead of the best possible one. The IBC data set being so challenging, we felt it is important to track both metrics for higher conÔ¨Ådence in the prediction. The previous work [12] on the IBC data set consistently used accuracy as the measure of their model prediction. However, we have experimented with another data set (OTI) that tends to have a larger imbalance between the labels on some topics. So we decided to focus on the F1 and AUC metrics instead. A baseline was established for both sets of data using a Naive Bayes bag of words model that works on the frequency of the unigram and bigrams present in the text. Fig. 2 shows the performance of both the IBC and the OTI data set in terms of F1 and AUC. The basic model performed very poorly with the F1 metric on the IBC data set. Both the metrics perform in a similar fashion for the OTI data set. The F1 score on the IBC data sets a very low baseline clearly illustrating the challenges with the content of the data set. We used a single layer LSTM model for our classiÔ¨Åcation task, where each hidden unit in Ô¨Åg. 1 is replaced by an LSTM unit governed by the set of activations described in eqn. 1. The binary cross entropy loss described in eqn. 2 was minimized by ‚ÄôAdam‚Äô optimizer. We let the optimizer run for an unlimited number of epochs and used a 10 step early stopping scheme to terminate each individual model run. We kept our batch size Ô¨Åxed at 32 for all our experiments. We stuck to a Ô¨Åve fold cross validation scheme for all our experiments, where in each fold the model was trained on 80% of the data and a validation score was calculated on the remaining 20%. Exploratory runs with the IBC data revealed that for learning rates larger than 0.001 the model Ô¨Åts nicely to the training data, while the validation loss kept increasing slowly over hundreds of epochs. We believe the reason for the model‚Äôs failure to decrease the validation loss lies in the very nature 4 Figure 3: Model performance on the IBC Dataset: Variation of F1 and AUC measures as a function of the dropout rate for a range of hidden layer sizes. of the data set as in every run the training data looks quite different from that of the validation data. The poor F1 score of the bag of words model shown in Fig. 2 supports this claim. Fig. 3 shows the performance of the model on the IBC data set. We were careful not to overÔ¨Åt the training data and hence kept the size of the hidden layer at a maximum of 80. The dropout rate had to be pushed to quite extreme limits for the model to start Ô¨Åtting. Again, the extreme low values of dropout, namely 0.1, where the model performs best on both the F1 and AUC metrics suggests the extreme risk of overÔ¨Åtting as discussed before. However, such a large amount of regularization leads to a poor model that cannot even Ô¨Åt the training data well. The best F1 score of 0.568 was obtained by a model with a hidden size of 40 and a dropout rate of 0.05. However poor the F1 scores appear for the model trained on the IBC data set, it must be noted that this is not unprecedented. Using a combination of bi-directional RNN and a bidirectional RvNN Isroy et al [19] obtained a best F1 score in the range of 0.5-0.6 on an opinion extraction task. Figure 4: Model performance on the OTI Dataset: Variation of F1 and AUC measures as a function of the dropout rate for a range of hidden layer sizes. Nonetheless, the results presented in Ô¨Åg. 3 does not show beyond any reasonable doubts, that a state of the art LSTM network is up to the task of capturing implicit meaning of a text. As mentioned before, we strongly believe it is not a shortcoming of the model, rather a combination of complexity and lack of volume of the data led to the results. It should be noted that Iyyer et al [12] extracted better performance from the data set because it was manually labeled to the node level of the parse tree associated with every sentence that was used in building their RvNN model. We argue that this method is not scalable to newer data sets and we wanted to test further on our hypothesis that an LSTM network should be able to extract hidden meaning of a text with just an overall label for the text. To test out hypothesis, we collected and manually cleaned data publicly available on the web to create the OTI dataset. The advantage of the OTI data set over the IBC data set was that almost all the sentences showed a bias that could be detected by a normal human, thereby reducing the 5 possibility of ‚Äôconfusing‚Äô the model. Moreover, the average length of a sentence was 11 in the OTI data set, compared to 37 for the IBC data set, which made the training the model a lot easier. The Ô¨Årst indication of learning by the model became obvious when we did not have to resort un- reasonably strong regularization (very low dropout number). Fig. 4 shows a fundamental change in behavior of the inÔ¨Çuence of dropout on the F1 score. The best performing models had a dropout of 0.9 beyond which overÔ¨Åtting started and the score dropped rather dramatically. There was not a big inÔ¨Çuence coming from the hidden layer size of the network, another clear sign that the model was truly learning from the data without a need of becoming too complex. The AUC score, on the other hand, showed a nearly opposite trend. The model could obtain the best AUC value of 0.642 at a dropout of 0.3. It must be reiterated that the two metrics do not capture the same sensitivity from a model and we kept the AUC as an extra metric to look at. Figure 5: Effect of learning rate of the Adam optimizer as a function of dropout rate for the minimum and maximum hidden layer sizes used in the study. We also looked at the sensitivity of our result as a function of the learning rate in the model. Fig. 5 shows that the peak performance does not suffer from doubling the learning rate from 0.0002 to 0.0004, but a smaller hidden layer size with a faster learning rate lead to poor performance. The RNN and its variants can also be used in a bi-directional network. Meaning of a particular word in context does not always depend on the preceding words, sometimes the meaning of a word gets fully expressed from trailing words. Bi-directional networks try to capture this effect. We experimented with a bi-directional network where we concatenated the the hidden layers from the forward and backward direction. Fig. 6 shows that the network did not learn any extra information from the text. The bi-directional model performed nearly at par with its regular counterpart and the best bi-directional model also had a dropout rate of 0.9 and a hidden layer size of 80. 5 Conclusions In this work we have showed how a state of the art model like LSTM can be used to predict the implicit political bias present in a text even if there are no speciÔ¨Åc words present in the text that obviously relates to one of the two major political ideologies. We have explored two data sets with very different content - one is extracted from speeches of US congressional Ô¨Çoor debates while the other is a collection of statements on multiple socio-political issues by US presidential candidates in most recent history. The model performed poorly on the former data set because of two main reasons: There is very little overlap of contents in the data that led to severe training challenges but more importantly a good portion of the data did not actually show any clear political bias that can be detected by a normal human being. We argue that the work by Iyyer et al [12] on the same data set performed better, although it is not a straight comparison because we used the F1 score instead of accuracy, with a RvNN because it was manually labeled at the node level of the parse tree, none of which we used in our model. Our goal was to build a model that is robust enough so that it can be applied to a variety of different contexts without the need of any detailed manual labeling, which is always difÔ¨Åcult to obtain. 6 Figure 6: A bi-directional LSTM network performs very similarly as that of a uni-directional net- work on the OTI data set. To test our hypothesis, we created a curated data set based on publicly available statements made by political candidates. We were able to obtain an F1 score of 0.718 with a single layer uni-directional LSTM network. This is at par with the best results on bias or opinion detection available in the literature [19]. We want to emphasize the fact that a model performs well only when there exists useful information present in the data. We would also like to point out that the method we developed is general in nature in the sense that the same model can be applied to extract bias or opinion in a different Ô¨Åeld of study without any major modiÔ¨Åcation. The LSTM model we developed works only marginally better than a bag of words based approach on the OTI data set. It is already extensively reported in the literature that deep learning based models need substantially larger amount of data to outperform the traditional methods of the domain. We, therefore, strongly believe the model will outperform the bag of words model substantially if we have more training data at our disposal. References [1] URL:http://www.cs.cornell.edu/home/llee/omsa/omsa.pdf . [2] J. Wiebe T. Wilson and P. Hoffmann. ‚ÄúRecognizing contextual polarity in phrase-level senti- ment analysis‚Äù. In: (2005). [3] B. Pang and L. Lee. ‚ÄúOpinion mining and sentiment analysis. Foundations and trends in information retrieval‚Äù. In: (2008). [4] Sean Gerrish and David Blei. ‚Äú Predicting legislative roll calls from text‚Äù. In: 28th Interna- tional Conference on Machine Learning ().URL:http://www.cs.columbia.edu/ Àúblei/papers/GerrishBlei2011.pdf . [5] Matthew Gentzkow and Jesse M Shapiro. ‚ÄúWhat drives media slant? evidence from us daily newspapers‚Äù. In: Econometrica 78(1) (2010), pp. 35‚Äì71. [6] URL:http://www.cs.cornell.edu/ Àúoirsoy/files/emnlp14drnt.pdf . [7] Tomas Mikolov et al. ‚ÄúExtensions of recurrent neural network language model. In Acoustics, Speech and Signal Processing (ICASSP)‚Äù. In: 2011 IEEE International Conference (2011), 55285531. [8] Yoshua Bengio Deng. ‚ÄúInvestigation of recurrent- neural-network architectures and learning methods for spoken language understanding‚Äù. In: Interspeech (2013). [9] Cliff C and Lin, Andrew Ng, and Chris Manning. ‚ÄúParsing natural scenes and natural language with recursive neural networks‚Äù. In: Proceedings of the 28th International Conference on Machine Learning (ICML-11) (2011), 129136. [10] Richard Socher et al. ‚ÄúSemi-supervised recursive autoencoders for predicting sentiment dis- tributions‚Äù. In: In Proceedings of the Conference on Empirical Methods in Natural Language Processing (2011), 151161. 7 [11] Richard Socher et al. ‚ÄúDynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Advances in Neural Information Processing Systems‚Äù. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (2011), 801809. [12] Mohit Iyyer et al. ‚ÄúPolitical Ideology Detection Using Recursive Neural Networks‚Äù. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (2014), pp. 1113‚Äì1122. [13] URL:http://www.cs.cornell.edu/home/llee/data/convote.html . [14] URL:http://cs.umd.edu/miyyer/ibc . [15] URL:http://www.ontheissues.org/default.htm . [16] Bengio et all. ‚ÄúLearning Long-Term Dependencies with Gradient Descent is difÔ¨Åcult‚Äù. In: IEEE Transactions on Neural Network Vol 5 No. 2 (1994). [17] URL:https://en.wikipedia.org/wiki/F1_score . [18] URL:https://en.wikipedia.org/wiki/Precision_and_recall . [19] URL:https://arxiv.org/pdf/1312.0493.pdf . 8</td>
    </tr>
    <tr>
      <th>44</th>
      <td>poli</td>
      <td>Studies in Visual Communication Studies in Visual Communication  Volume 5  Issue 1 Fall 1978 Article 4  1978  The F orms of Caricatur e: Physiognomy and P olitical Bias The F orms of Caricatur e: Physiognomy and P olitical Bias  Mitchel Goldman  Margaret Hagen  Recommended Citation Recommended Citation  Goldman, M., &amp; Hagen, M. (1978). The F orms of Caricatur e: Physiognomy and P olitical Bias. 5 (1), 30-36.  Retrie ved fr om https:/ /reposit ory.upenn.edu/sv c/vol5/iss1/4  This paper is posted at ScholarlyCommons. https:/ /reposit ory.upenn.edu/sv c/vol5/iss1/4  For mor e information, please contact reposit ory@pobo x.upenn.edu .  The F orms of Caricatur e: Physiognomy and P olitical Bias The F orms of Caricatur e: Physiognomy and P olitical Bias  This contents is a vailable in Studies in Visual Communication: https:/ /reposit ory.upenn.edu/sv c/vol5/iss1/4  THE FORMS OF CARICATURE: PHYSIOGNOMY  AND POLITICAL BIAS1  MITCHEL GOLDMAN and MARGARET HAGEN  The analysis oftechniques of caricature as a system of  communication for transmitting information about picto¬≠ rial s¬∑ubjects has in the past remained primarily the  province of artists and their historian s, for example,  Ashbee (1928), Lynch (1927), Berger (1952), and Rother  (1966). More recently, however, perceptual psychologists  interested in the history and function of art have turned  their attention to the psychological mechanisms which  must underlie the successful perception of the caricatured  subject. Gombrich (1961) has stressed the role of the  creative imagination of the observer in the successful  perception of caricatures, while E. J. Gibson (1969) and J.  J. Gibson (1954, 1971) have emphasized the crucial role  of the information about the subject carried by the  caricature itself. J. J. Gibson (1954) argued that caricature  was a combination of the techniques of geometric projec¬≠ tion and artistic convention. He wrote that it was neces¬≠ sary for the artist to go beyond the projective information  about the subject given in the light coming to the eye and  to impose certain agreed upon conventions of exaggera¬≠ tion and distortion in the production of a successful  caricature. However, Gibson revised this original formu¬≠ lation in a later definition of "picture": "A picture is a  surface so treated that a delimited optic array to a point of  observation is made available which contains the same  kind of information that is found in the ambient optic  arrays of an ordinary environment" (1971 :31).  Of course, Gibson is referring here only to representa¬≠ tive art, to art whose object is the recognizable depiction  of objects and scenes from the natural environment.  Clearly his definition of pictures excludes the very large  class of nonrepresentative, or abstract, art and, indeed, is  not even intended to account for all the variables which  determine the aesthetic character of a work of art. The  purpose of the definition is simply to establish the nature  of the optical correspondence between representative  pictures and the scenes they depict. The concept of  information central to the above definition is Gibson's  (1966) major subject matter.  Mitchel Goldman is a recent graduate of Boston Univer¬≠ sity. He wrote this paper as a distinction work senior  honors thesis at Boston University under the supervision  of Dr. Margaret Hagen. Dr. Hagen is an Assistant Pro¬≠ fessor of Psychology at Boston University whose research  interest focuses on problems in the area of visual percep¬≠ tion, particularly the development of pictorial perception. THE SENSES CONSIDERED AS PERCEPTUAL SYSTEMS  In general, J. J. Gibson has defined optical informa¬≠ tion about an object as the formless and timeless invari¬≠ ants in the structure of an optic array that specify the dis¬≠ tinctive features of the object. E. J. Gibson (1969) has dealt  extensively with the concept of distinctive features, which  she defines as invariant relations that specify a particular  object and allow for its discrimination from a field of  similar objects. Distinctive features are relations, ratios,  proportions , and gradients which remain invariant across  specified sets of transformation. Thus, in this theory, a  caricature is successful to the extent that it preserves the  distinctive features essential to the discrimination of the  particular subject across the exaggeration distortion trans¬≠ formation s of caricature. This concept of invariant infor¬≠ mation or features preserved across transformations is  clearly adapted from geometry and has been formalized  by J. J. Gibson in his theory of ecological optics.  Invariant Features in Caricature  Perkins (1974) was the first psychologist to begin an  analysis of the techniques of caricature within the  framework of the theory described above. He hypoth¬≠ esized that caricature recognition is identical to the  process of ordinary facial recognition and that caricatures  must therefore contain the same attributes as the carica¬≠ tured face itself or photographs of the subject. On the  other hand, as Worth (1977) observed, one might argue  that there are grammars and conventions of caricature  recognition that are different from those of facial recogni¬≠ tion in real life. That is, it may be the case that recognizing  pictures demands some of the properties we need to  recognize objects in real life, but it may also demand  many other things. Still, Perkins's hypothesis that feature  correspondence between picture and subject is the core  of successful facial recognition in caricatures can be  tested by the straightforward process of looking at existing  caricatures and their subjects. This is exactly what Perkins  did. Through informal observation of caricatures and  photos of Richard M. Nixon and through the deletion of  various facial attributes from those pictures, Perkins found  that the four key properties of caricatures of Nixon's face  were jowls, a hairline with bays on either side, a box chin,  and a long nose. The omission of these properties or a  contraindication of any one seriously degraded the repre¬≠ sentative character of a caricature. If Perkins is right about  the criticat nature of these facial properties for the success  of a caricature , it should follow t,hat (1) all artists generally  use what Perkins calls "the rather necessary" key prop¬≠ erties and thus are consistent among themselves in the  nature of their depictions; (2) that any individual artist  should be consistent in his depiction across time; and (3)  that changes over time in the form of the caricature should  be a function of changes in the face itself.  The present authors, while acknowledging the insight¬≠ ful and provocative nature of Perkins's exploratory inves¬≠ tigation of caricature, take issue with several aspects of his  30 STUDIES IN THE ANTHROPOLOGY OF VISUAL COMMUNICATION  analysis. First, Perkins has quite freely taken liberties with  the concepts of invariants across transformation postu¬≠ lated by the Gibsons. He chooses to speak of "individuat¬≠ ing 'properties ' or 'attributes' of the face," a translation  which we feel may well do violence to the essential  relational component of distinctive features. Considera¬≠ tion of faces in terms of feature ratios would more truly  have retained the flavor of the relational concept. Second,  Perkins offers no objective analysis of the data, and the  reader is left to rely on Perkins's own informal observa¬≠ tions. Third, Perkins provides no objective evidence con¬≠ cerning the influence of the individual stylistic bias of the  caricaturist. Finally, in analyzing how the requirement of  recognition influences caricature, he does not address  another important issue: how the political climate also  exerts an influence.  An Empirical Study of Caricature  In consideration of these points, the purpose of the  present investigation was to carry out a systematic empiri¬≠ cal test of the hypotheses which follow from Perkins's  argument , with particular attention to the hypothesis of  consistency within a single artist and that of consistency  across artists and time. We wished to test two aspects of  consistency: consistency in specific features chosen for  exaggeration and consistency in degree of exaggeration.  We hypothesized that any single artist would be consis¬≠ tent with himself, that artists would not be consistent with  one other because of variable sty I istic bias, and that there  would be a lack of consistency across time as a function  of shifting political climate. By shifting political climate  we mean variation in the degree to which a public figure  is evaluated positively and negatively by the public and  by the media. Richard Nixon provides a very clear  example of a public figure who experienced an increas¬≠ ingly negative political climate from his election to the  denouement of Watergate. So, like Perkins, we have  selected caricatures and photographs of Nixon as our data  base. This choice will also facilitate comparisons between  Perkins's work and the present investigation. Also, we  have chosen as our units feature ratios of property mag¬≠ nitude rather than single properties.  The data for the consistency analysis were obtained in  the following manner. Five photographs of Nixon from  1973 were measured by two independent judges, and  eleven mean feature ratios were obtained, such as length  of jowl/vertical head dimension (Perkins's jowl property) ,  width of jowl/length of jowl (box chin), and length of  nose/vertical face dimension (long nose). (See Figure 1 for  a full presentation of feature ratios.) The particular feature  ratios chosen do not exhaust the possibilities but were  selected because they seemed to represent obvious can¬≠ didates for distinctive features and were easily measured.  (The larger of the two dimensions was always the  numerator.)  The interjudge correlation for these measurements was  extremely high (r = . 99). Then, through a search of news  and political magazines and periodicals from 1973, 100  caricatures from 1 7 artists were obtained. The only con-Figure 1 -Cover photograph of Richard M. Nixon  with measured feature magnitudes indicated by bars.  (Newsweek, july 23, 1973.)  straints on selection were clarity of reproduction and  measurability in terms of size. From these 100 caricatures,  one caricature was randomly selected for each of the  seventeen artists. The eleven feature ratios were again  obtained for each drawing. For each feature ratio in every  caricature a deviance score was obtained, expressed as  the percent deviance from the mean photographic ratio.  Thus, if the caricatured feature ratio of width of jowl/  length of jowl equaled the mean photograph ratio, the  deviance score for this ratio for this drawing was 0  percent. Then, for each artist the 11 feature ratios were  ranked from 1 to 11 in terms of least to most deviance  from the photographed ratios. These data are tabulated in  Table 1. In order to illustrate the technique, we will take  the first artist, Cummings, as an example. As one can see  from the table, Cummings modified the relation length of  nose/length of jowl least of all in his drawing, relative to  the magnitude of the relation measured in photographs of  Nixon. Thus this relation is assigned a rank of one (1 ). On  the other hand, the relation length of jowl/width of jowl  was distorted to the greatest extent in the drawing relative  to the photograph, thus receiving the rank of eleven (11 ).  This procedure was followed for all the feature ratios for  all the artists.  31  TABLE 1  RANKS OF DEVIANCE OF FEATURE RATIOS  FROM MEAN PHOTOGRAPHIC RATIOS, BY ARTIST  Feature Ratios  Artist Vert. Head Vert. Head Len. Nose Len. Nose Len. Jowl Len. Nose Vert. Head Len. Nose Vert. Head Vert. Head Vert. Head  Len. Nose Len. Jowl Len. Fore. Len. Ear Wid. Jowl Eye Eye Len. Fore. Len. Jowl Wid. Fore. Len. Ear Eye Eye  1. Cummings 9 10 5 8 11  2. Behrendt 11 10 9 7 3  3. Marlitte 9 11 10 6 2  4. Whitte 11 10 9 8 4  5. Staskyl 10 7 9 8 11  6. Oliphant 9 10 7 8 11  7. Herblock 9 8 7 9 11  8. Wright 5 11 10 9 6  9. Lurie 8 3 7 5 11  10. Simpson 10 11 8 9 5  11. Hill 11 3 8 10 9  12. Engle 10 11 9 8 4  13. Davis 4 10 2 5 3  14. Haynie 10 4 9 8 11  15. Fisher 10 7 9 8 11  16. Scrawls 11 10 9 8 5  17. Sanders 11 9 10 8 3  Mean Ranks 9.4 8.6 8.1 7.7 7.3  Statistical Analysis  Three types of analysis were performed with these rank  data. First, a Kendall coefficient of concordance was  computed, w = 0.597, X2(1 0) = 101.43, p &lt; .001, indi¬≠ cating a very high degree of consistency among artists in  terms of which feature ratios are chosen for exaggeration.  Second, a Friedman analysis of variance for ranked data  was performed and F = 83.13, p &lt; .001, indicating that  the mean ranks for feature ratios differ significantly from  chance ranking. Last, in order to isolate which feature  ratios differed significantly from one another in rank, a  parametric analysis of variance with multiple post hoc  comparisons was performed. The main effect for rank was  significant, F(1 0, 170) = 19.2, p &lt; .02. Newman-Keuls  post hoc comparisons indicated that of the 55 possible  comparisons among feature ratios in terms of rank, 31 of  these comparisons differed from one another in rank with  p &lt; .OS at least. This very high number of significant  differences is another indication of the high level of  consistency among artists in their selection of which  features to caricaturize.  Interpretation of the Analysis  The three types of analysis allow us to conclude several  things about our consistency hypotheses. First, we have  shown that there is a very high level of agreement from  artist to artist in terms of which feature ratios are to be  distorted in the caricatures. Generally speaking, a feature  ratio greatly distorted by one artist will also be greatly  distorted by the others, and a ratio little modified by one  artist is relatively untouched b~' the others. Of course this 7 6 1 3 4 2  8 6 5 2 4 1  7 8 1 4 3 5  7 6 1 3 5 2  5 6 1 3 4 2  6 4.5 1 2 4.5 3  6 3 1 4 5 2  4 8 3 2 7 1  10 1 9 4 2 6  7 3 2 4 6 1  6 2 7 5 4 1  7 6 1 5 3 2  9 7 11 6 1 8  7 3 5 2 1 6  6 5 4 1 3 2  7 6 4 2 3 1  7 5 6 4 2 1  6.8 4.9 3.6 3.4 3.4 2.7  is not true in each and every case, but statistically the  level of agreement is overwhelmingly significant. Second,  we have shown that the relative degree to which a  particular feature ratio is distorted in caricatures is very  stable from artist to artist. Individual feature ratios tend to  stay in the same ranked position as one goes from artist to  artist. The most distorted tends to remain the most dis¬≠ torted, the least, the least, and those ratios in between  tend to maintain constant positions in the ranking. Al¬≠ though this is but another way of saying there is very high  agreement among artists, the interpretation goes even  further: The agreement across artists on what to distort  even extends to this finer level of analysis of individual  feature relations.  INDIVIDUAL FACIAL FEATURES  A comparison of high-and low-ranked feature ratios  also allows for the specification of feature as independent  from feature ratio as the source of exaggeration. It should  be noted, however, that the specification of a particular  feature as a source of distortion always implies underlying  feature ratios. That is, a long nose is long only with respect  to other dimensions of the face. A long nose will stand out  as a feature per se, rather than a component of a ratio,  only if it functions in multiple ratios as a source of  high-ranked deviance. Comparisons of pairs of feature  ratio ranks provide support for Perkins's argument that the  jowls and nose function as major distorted features with  good consistency across artists. When these two features  occur in the same ratio, the ranked deviance from the  photograph is very small (3.6), but when either occurs in  32 STUDIES IN THE ANTHROPOLOGY OF VISUAL COMMUNICATION  conjunction with another minor feature, such as the  vertical dimension of the head, the feature ratio deviance  rank is very high (jowls/head 8.6; nose/head 9.4). That  this is not due to increase or decrease in the vertical  dimension of the head is evident from the low ranks  occupied by other ratios with this dimension such as  eye-eye/vertical head = 2.7 and length ear/vertical  head = 3.5. Such pair comparisons, as well as the three  convergent analyses for consistency, provide consider¬≠ able evidence in support of Perkins's general argument for  consistency among artists in terms of features chosen for  caricature. It should be noted, however, that while there is  significant agreement among artists about what to exag¬≠ gerate there is little agreement about how much to exag¬≠ gerate. Mean percent deviance from photographed ratios  is 53 percent but the means for individual artists range  from 12 percent for Davis to 86 percent for Fisher.  Presumably such variability is due to the artists' individual  bias and style.  Statistical Analysis  The related questions of consistency within an artist's  work and across time were addressed by similar types of  analysis. For these types the data base was generated by  multiple caricatures done by five prolific artists in 1972  and 1973. The five artists were selected solely on the basis  of relative frequency of published drawings observed in  the initial sampling of 17 artists (see Figure 2). They were  Oliphant, with seventeen drawings; Herblock, with nine;  Wright, with twelve; Lurie, with ten; and Haynie, with  five. For each of these five artists for both years, mean  percent deviance from photographs was computed and  ranks assigned to the features ratio from 1 to 11 for least  to most deviance. To address the question of self-consis¬≠ tency, Spearman rank order correlation coefficients were  calculated for each of the five artists and the following  rho values were obtained: Oliphant: r = .964,  t(1 0) = 1 0.8. p &lt; .001; Herblock: r = .75, t(9) = 3.4,  p &lt; .01; Wright: r = .855, t(9) = 4.94, p &lt; .001; Lurie:  r = .44, t ( 9) = 1 .48, p &lt; . 1 0; Haynie : r = . 9 7,  t(9) = 12.6, p &lt; .001. Thus, of the five artists tested, four  showed significant correlations between 1972 and 1973  rank orders for feature ratio distortions, p &lt; .05. Only  Lurie failed to show this significant correlation. Con¬≠ sequently, grouped mean ranks for 1972 and 1973 also  are positively correlated, p = .957, p &lt; .01, reflecting  consistency of treatment from year to year. However,  whereas the rank orders of feature ratios, in terms of  relative degree of deviance from photographed ratios, are  highly correlated between 1972 and 1973, the absolute  size of the percent deviance or distortion increases from  1972 to 1973. Of the eleven feature ratios listed, only one  does not change. Of the ten that change nine increase in  distortion relative to the photographed ratios, and only  one decreases. The results would occur by chance with  p = &lt; .011, so this nearly uniform increase in distortion  reflects a very real change in degree of caricature. In order  to test the significance of the magnitude of this change, a  t-test was performed on percent of distortion of each feature ratio by year relative to photographs from the two  years, and t = 3.18, p = &lt; .01. The mean percent distor¬≠ tion for 1972 was 56 percent; for 1973, 61 percent. Thus  the increase noted in the sign test is also a significant  increase measured parametrically, that is, not only the  directionality of the changes but their size is also signifi¬≠ cantatp = &lt; .01.  Interpretation of the Analysis  The analysis reported above allows for the following  conclusions: First, we have shown that four of the five  artists tested were very consistent from year to year in  terms of which feature ratios they chose to distort. Be¬≠ cause only Lurie was inconsistent from 1972 to 1973, the  group as a whole shows consistency from year to year.  Second, we also reached some conclusions about what  changes from year to year as well as about what remains  the same. We have shown that the choice of what to  exaggerate is quite constant across artists and across time,  but we have also shown that the degree of distortion  varies considerably from artist to artist and from year to  year. We found that the mean degree of distortion varies  from 12 percent for Davis to 86 percent for Fisher. In  addition, when we looked at all five selected artists  together, we found that of the ten mean feature ratios  which changed from 1972 to 1973, nine of them in¬≠ creased in the degree of distortion relative to photographs.  This increase in distortion could be due either to  alteration in political climate (which underwent a very  rapid change vis-a-vis Nixon from 1972 to 1973) or to real  physical changes in Nixon's face due to aging, strain, or  fatigue. In order to control for the effect of this type of  change, photographs from both 1972 and 1973 were  measured and compared for physical change in feature  ratio. Of the nine feature ratios which increased in the  caricatures from 1972 to 1973, only three were observed  to change in photographs-the three involving jowl  length. Measurements of photographs indicate a 30 per¬≠ cent increase in jowl length from early 1972 to 1973. It  may be argued, however, that this finding still leaves the  six jowlless feature ratios, which increased in distortion  from 1972 to 1973, a function of increasingly negative  political climate rather than of real changes in Nixon's  face. Thus this result runs counter to any simplistic  assumptions about caricature as a function of true facial  features. The finding with respect to jowl size, however,  shows that artists are also very sensitive to real changes in  the subject's features.  SUMMARY  The present investigation undertook an empirical  analysis of several of the consistency assumptions which  seemed to follow from Perkins's model of the caricature  process. We looked at the question of consistency of  distorted features in the work of 1 7 artists during 1972 and  found a very high degree of concordance among artists in  33  Time, July 30, 1973  ~You're My Boy'¬∑  (5) HPrblock In Wa~hlngton Post Newsweek, May 7, 1973 34  Figure 2 -Caricatures of Richard M. Nixon, 1973.  @  LURIE  ewsweek, June 25, 1973  ¬∑~?%~  ~-:. ' _:.~  ‚Ä¢ ‚Ä¢ &gt; ~  . ¬∑¬∑:~ .:d  '¬∑¬∑":¬∑,:¬∑ ¬∑~,~  ... ¬∑¬∑.-:  Oliphant ¬© 197 3 Denver Post  A question of priorities: :P.fore for the Pentagon, less for the poor?  sweek, February 12, 1973  Haynle--Loulsv!Ue COurler...Journal  Newsweek, November 12, 1973  35  terms of which feature ratios were most and least dis¬≠ torted. However, with regard to degree of exaggeration of  feature ratio, we observed very great discrepancies among  artists, ranging from 12 percent distortion to 86 percent,  J$&lt; with a mean of 53 percent-rhus we wish to argue that the  ' choice of what to caricature is determined largely by  characteristics of the subject's face, while the degree of  caricature is determined by the individual artist's style and  bias. Of course, our analysis addresses this important  question of artists' styles in a simplistic fashion. We  looked at degree of distortion only as it distinguishes one  artist from another. It is perfectly clear that there are many  other factors which determine the particular style charac¬≠ terizing an artist, and we have no wish to reduce such  complexity to the single dimension of degree of distor¬≠ tion; other features of style are simply beyond the scope of  this study. We also looked at the question of consistency  across time. When features ranked for degree of distortion  were compared for the period 1972-1973, the rank corre¬≠ lation was very high and significant, indicating great  consistency across time in choice of features to be  exaggerated. However, when we again looked at degree  of distortion across time, we found that real physical  changes in the subject's face could not account for the  significant increase in the degree of distortion observed  from 1972 to 1973. We feel strongly that this increase in  distortion was largely a function of the increased negativ¬≠ ity of the political climate surrounding Nixon in 1973. It is  not possible, of course, to directly test this conclusion, but  an indirect method has been suggested by Worth (1977).  If our reasoning is correct, that an increasingly negative  political opinion increases the degree of distortion in  caricatures of a subject, then the opposite of this reason¬≠ ing should also be true. That is, as the political climate  around some public figure becomes increasingly positive,  the degree of distortion in caricatures of the subject  should decrease and be, at least in principle, testable.  We also do not wish to appear to be arguing that simple  exaggeration of feature ratios is all there is to caricature. If  this were true, then increased distortion would be the  unique and inevitable result of increased negativity of  public opinion, which it is not. As Worth (1977) rightly  observed, it might also be noted that by the end of World  War 11, all one needed to caricature Hitler was one  diagonal line and one horizontal line underneath, and  everyone understood the representation of the hair and  the mustache. This increasing economy of line as a  function of familiarity cannot be accounted for by the  above hypothesis. At the same time it is not clear that  increasing economy runs counter to increasing distortion.  It may be that the two processes are parallel in time or, more likely, that the generalized increase in distortion  precedes the selection of the most economical depiction.  Again, the answer to this question is beyond the scope of  this article, but it does seem that caricatures of Hitler  would offer fertile ground for investigating the issue.  In conclusion, then, we found support for Perkins's  analysis of the process of caricature as primarily a func¬≠ tion of true physiognomy but wish to offer, in addition to  his analysis, our evidence for the very important role  played by political climate, personal bias, and style.  Acknowledgment . The authors wish to thank David Perkins for his  kind assistance in preparation of the manuscript. Any errors which  remain in interpretation of his position or data analysis are solely the  responsibility of the present authors.  NOTE  , This research was supported in part by a grant from the National  Institute of Mental Health to the second author, #1 R01 MH27947-0 .  Requests for reprints should be sent to the second author at 64  Cummington Street, Department of Pyschology, Boston University,  Boston, MA 02215.  REFERENCES CITED  Ashbee, C. R.  1928 Caricature. New York: Scribner's.  Berger, 0.  1952 My Victims: How to Caricature. New York: Harper  Brothers.  Gibson, E. j.  1969 Principles of Perceptual Learning and Development. New  York: Meredith.  Gibson, j. J.  1954 A Theory of Pictorial Perception . Audio-Visual Communica¬≠ tion Review 1 (13).  1966 The Senses Considered as Perceptual Systems. Boston:  Houghton-Miff! in.  1971 The Information Available in Pictures. Leonardo 4(27).  Gombrich , E. H.  1961 Art and Illusion: A Study in the Psychology of Pictorial  Representation. Princeton: Princeton University Press.  Lynch, B.  1927 A History of Caricature. Boston: Little, Brown.  Perkins, D.  1974 A Definition of Caricature and Caricature and Recognition.  Studies in the Anthropology of Visual Communication. 2(1): 1-23.  Rother, E.  1966 Drawing Caricatures. Design 67(4).  Worth, S.  1977 Private communication to the author.  36 STUDIES IN THE ANTHROPOLOGY OF VISUAL COMMUNICATION</td>
    </tr>
    <tr>
      <th>13</th>
      <td>poli</td>
      <td>royalsocietypublishing.org/journal/rsif Research Cite this article: Coscia M, Rossi L. 2020 Distortions of political bias in crowdsourcedmisinformation flagging. J. R. Soc. Interface 17: 20200020.http://dx.doi.org/10.1098/rsif.2020.0020 Received: 8 January 2020 Accepted: 13 May 2020 Subject Category: Life Sciences ‚ÄìMathematics interface Subject Areas: computational biology, biotechnology Keywords: social media, social networks, content policing,flagging, fake news, echo chambers Author for correspondence: Michele Cosciae-mail: mcos@itu.dkDistortions of political bias in crowdsourced misinformation flagging Michele Coscia and Luca Rossi IT University of Copenhagen, Kobenhavn, Denmark MC, 0000-0001-5984-5137; LR, 0000-0002-3629-2039 Many people view news on social media, yet the production of news items online has come under fire because of the common spreading of misinforma- tion. Social media platforms police their content in various ways. Primarily they rely on crowdsourced ‚Äòflags ‚Äô: users signal to the platform that a specific news item might be misleading and, if they raise enough of them, the item will be fact-checked. However, real-world data show that the most flagged news sources are also the most popular and ‚Äîsupposedly ‚Äîreliable ones. In this paper, we show that this phenomenon can be explained by the unrea- sonable assumptions that current content policing strategies make about how the online social media environment is shaped. The most realistic assumptionis that confirmation bias will prevent a user from flagging a news item if they share the same political bias as the news source producing it. We show, via agent-based simulations, that a model reproducing our current understandingof the social media environment will necessarily result in the most neutral and accurate sources receiving most flags. 1. Introduction Social media have a central role to play in the dissemination of news [1]. There is a general concern about the low quality and reliability of information viewed online:researchers have dedicated increasing amounts of attention to the problem of so- called fake news [2 ‚Äì4]. Given the current ecosystem of news consumption and pro- duction, misinformation should be understood within the complex set of social andtechnical phenomena underlying online news propagation, such as echo chambers [5‚Äì10], platform-induced polarization [11,12] and selective exposure [13,14]. Over the years two main approaches have emerged to try to address the problem of fake news by limiting its circulation: a technical approach and an expert-based approach. The technical approach aims at building predictive models able to detect misinformation [15,16]. This is often done using one ormore features associated with the message, such as content (through natural language processing (NLP) approaches [17]), source reliability [18] or network structure [19]. While these approaches have often produced promising results,the limited availability of training data as well as the unavoidable subjectivity involved in labelling a news item as fake [20,21] constitute a major obstacle to wider development. The alternative expert-based approach consists of a fact-checker on the specific topic that investigates and evaluates each claim. While this could be the most accurate way to deal with misinformation, given the amount ofnews that circulates on social media every second, it is hard to imagine how this could scale to the point of being effective. For this reason, the dominant approach, which has recently also been adopted by Facebook, 1is based on a combination of methods that first use computationally detected crowd signals, often constituted by users flagging what they consider fake or misleading infor- mation, and then assigning selected news items to external professional fact-checkers for further investigation [22,23]. Although flagging-based systems remain, to the best of our knowledge, widely used, many authors have ques- tioned their reliability, showing how users can flag news items for reasons ¬© 2020 The Authors. Published by the Royal Society under the terms of the Creative Commons AttributionLicense http:/ /creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the originalauthor and source are credited.  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  other than the ones intended [24,25]. Recently, researchers proposed methods to identify reliable users and improve, in that way, the quality of the crowd signal [20,23]. Regardless of the ongoing efforts, fake news and mislead- ing information still pollute online communications and no immediate solution seems to be available. In 2018, Facebook released, through the Social Science One initiative, theFacebook URL Shares dataset [26], a preview of the larger dataset released recently. 2The dataset contains the web page addresses (URLs) shared by at least 20 unique accountson Facebook between January 2017 and June 2018. Together with the URLs, the dataset also details whether the specific link had been sent to the third-party fact-checkers thatcollaborate with Facebook. We accessed the most shared links in the Italian subset, which revealed some curious patterns and inspired the pre-sent work. We exclusively use this dataset for the motivation and validation of our analysis, leaving the use of the newer full dataset for future work. Table 1 shows the top 10 most reported domains, which are exclusively major national newspapers, news sites and a satirical website. A further analysis of the data reveals, as figure 1 shows,a positive correlation ( y¬º bxafit, with slope Œ±= 0.2, scale Œ≤= 1.22 and p&lt; 0.0013) between a source ‚Äôsp o p u l a r i t ya n dt h e number of times a domain has been checked by Facebook ‚Äôs third-party fact-checkers. We measure the popularity of the source through Alexa ‚Äôs (https://www.alexa.com) page views per million users (PVPM). It is worth observing that all the news reported in the top 10 most reported domains have been fact-checked astrue legitimate news (with the obvious exception of the satirical website, which was fact-checked as satire).These observations create the background for the present paper. Our hypothesis is that users are polarized and that polarization is an important driver of the decision of whetherto flag or not a news item: a user will only flag it if it is not perceived truthful enough andif it has a significantly differ- ent bias from that of the user (polarity). Sharing the samebias would act against the user ‚Äôs flagging action. Thus, we introduce a model of online news flagging that we call the ‚Äòbipolar ‚Äômodel, since we assume for simplicity that there are only two poles ‚Äîroughly corresponding to ‚Äòliberal ‚Äôand ‚Äòconservative ‚Äôin the US political system. The bipolar model of news-flagging attempts to capture the main ingredients thatwe observe in empirical research on fake news and disinforma- tion‚Äîecho chambers, confirmation bias, platform-induced polarization and selective exposure. We show how the proposedmodel provides a reasonable explanation of the patterns that we observe in Facebook data. The current crowdsourced flagging systems seem to assume a simpler flag-generating model. Despite being some- how similar to the bipolar model we propose, in this simple case the model does not account for users ‚Äôpolarization, thus we will call it the ‚Äòmonopolar ‚Äômodel. In the monopolar model, users do not gravitate around two poles and perceived truthfulness constitutes the only parameter. Users flagnews items only if they perceive an excessive ‚Äòfakeness ‚Äôof the news item, depending of their degree of scepticism. We show how the monopolar model relies on unrealistic expectationsand that it is unable to reproduce the observed flag-generating patterns. Lastly, we test the robustness of the bipolar model against various configurations of the underlying network structure and the actors ‚Äôbehaviour. We show, on the one hand, how the model is always able to explain the observed flaggingphenomenon and, on the other hand, that a complex social network structure is a core element of the system. 2. Methods In this section, we present the main model on which we base the results of this paper. It is possible to understand the bipolar andmonopolar models as a single model with or without users ‚Äô polarization. However, a user ‚Äôs polarization has a significant impact on the results, and it seriously affects the social networkunderlying the flagging and propagation processes. For theseTable 1. The top 10 most Ô¨Çagged domains among the Italian links shared on the Facebook URL Shares dataset. domain reported PVPM type 1 repubblica.it 270.00 54.00 national newspaper 2 ilfattoquotidiano.it 85.00 21.00 national newspaper 3 corriere.it 83.00 30.00 national newspaper 4 fanpage.it 49.00 5.00 national news site 5 ansa.it 47.00 12.00 national news site 6 huf Ô¨Ångtonpost.it 40.00 7.20 national news site 7 ilmessaggero.it 34.00 2.00 national newspaper 8 ilsole24ore.com 32.00 4.00 national newspaper 9 lercio.it 29.00 3.00 satire10 tgcom24.mediaset.it 28.00 28.00 national news site110102103 10‚Äì210‚Äì11 10 102no. flags PVPM Figure 1. The relationship between the web traffic of a website ( x-axis) and the number of flags it received on Facebook ( y-axis). Traffic is expressed in PPVM, which indicates what fraction of all the page views by Alexa toolbar users go to a particular site.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000202  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  reasons, in the paper, we will refer to them as two different models with two different names, which makes the comparisoneasier to grasp. In the following, we start by giving a general overview of the bipolar model (¬ß2.1). In the subsequent sections, we provide themodel details, motivating each choice on the basis of real-worlddata. We conclude by showing the crucial differences betweenthe bipolar and monopolar models (¬ß2.5). We note that our model shares some commonalities with the bounded confidence model [27]. 2.1. Model overview Figure 2 shows a general depiction of the bipolar model. In the bipo-lar model, we have two kinds of agents: news sources and users. News sources are characterized by three values: popularity, polarity and truthfulness. The popularity distributes broadly:there are a few big players with a large following while themajority of sources are followed by only a few users. The polaritydistributes quasi-normally. Most sources are neutral and there areprogressively fewer and fewer sources that are more polarized.Truthfulness is linked to polarity, with more polarized sourcestending to be less truthful. This implies that most news sourcesare truthful, and less trustworthy sources are more and morerare. Each news item has the same polarity and truthfulnessvalues as the news source publishing it. Users only have polarity. The polarity of the users distributes in the same way as that of the news sources. Most users aremoderate and extremists are progressively more rare. Usersfollow news sources, preferentially those of similar polarity(selective exposure). Users embed in a social network, preferen- tially being friends of other users of similar polarity (homophily). A user can see a news item if the item is either published by a source the user is following or reshared by one of their friends. Ineither case, the user can do one of three things: 1. reshare ‚Äîif the polarity of the item is sufficiently close to their own andthe item is sufficiently truthful; 2. flag ‚Äîif the polarity of the item is sufficiently different from their own orthe item is not truthful enough; 3. consume ‚Äîin all other cases, meaning that the item does not propagate and nor is it flagged. We expect the bipolar model to produce mostly flags in the moderate and truthful part of the spectrum. We base this expec-tation on the following reasoning. Since most news sources aremoderate and truthful, the few very popular sources are over- whelmingly more likely to be moderate and truthful. Thus wewill see more moderate and truthful news items, which aremore likely to be reshared. This resharing activity will causethe news items published by the moderate and truthful newssources to be shared to the polarized parts of the network.Here, given that the difference between the polarization of theuser and the polarization of the source plays a role in flaggingeven relatively truthful items, moderate and truthful newsitems are likely to be flagged. Polarized and untruthful items, on the other hand, are unli- kely to be reshared. Because of the polarization homophily thatcharacterizes the network structure, they are unlikely to reachthe more moderate parts of the network. If polarized itemsare not shared, they cannot be flagged. A neutral item is morelikely to be shared, and thus could reach a polarized user, whowould flag it. Thus, most flags will hit moderate and truthfulnews items, rendering the whole flagging mechanism unsuitablefor discovering untruthful items. 2.2. Agents In this section, we detail how we build the main agents in ourmodel: the news sources and the users. As mentioned previously, news sources have a certain popu- larity. The popularity of a news source is the number of usersfollowing it. We generate the source popularity distribution asa power law. This means that the vast majority of news sourceshave a single follower, while the most popular sources have thousands of followers. This is supported by real-world data. Figure 3 ashows the complement cumulative distribution of the number of followersof Facebook pages. These data come from CrowdTangle. 4As we can see, the distribution has a long tail: two out of three Face-book pages have 10 000 followers or fewer. The most popularpages are followed by more than 60 million users. As for the user and source polarities ( p uand pi), we assume that they distribute quasi-normally. We create a normal distributionwith average equal to zero and standard deviation equal to 1.Then we divide it by its maximum absolute value to ensure thatthe distribution fully lies between ‚àí1 and 1. In this way we ensure that most users are moderates; more extreme users/sourcesare progressively more rare, at both ends of the spectrum. This is also supported by the literature [28] and by real-world data. Figure 3 bshows the distribution of political leaning in the USA across time [29], collected online. 5These data were collectedsourcespopularity polarity truth userspolarit ypublish reshare degreefrom friend flagfi,u =ti |pi ‚Äì pu| consumefi,u = 1 ‚Äìfi,u fi,u + 1 fi,u &lt; r fi,u &gt; f Figure 2. The overview of the bipolar model. From left to right, we show: the characteristics of the agents (source ‚Äôs polarities, popularity and truthfulness; and user ‚Äôs polarity); the model ‚Äôs structures (the bipartite source ‚Äìuser follower network and the unipartite user ‚Äìuser social network); and the agents ‚Äôactions (source publishing and users resharing, consuming and flagging news items).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000203  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  by surveying a representative sample of the US electorate via phone and face-to-face interviews. While not perfectly normally distributed, the data show that the majority of Americans either feel they are moderate or do notknow to which side they lean. ‚ÄòModerate ‚Äôor‚Äòdon‚Äôt know ‚Äôis always the mode of the distribution, and their combinationis always the plurality option. Finally, sources have a degree of truthfulness t i. Here, we make the assumption that this is correlated with the newssource ‚Äôs polarity. The more a source is polarized, the less it is interested in the actual truth. A polarized source wants tobring readers onto their side, and their ideology clouds theirbest judgement of truthfulness. This reasonable assumption isalso supported by the literature [30]. Mathematically , this means that t i=1‚àí|pi|+œµ, with ‚àí0.05‚â§ œµ‚â§0.05 being extracted uniformly at random, ensuring then that ti remains between 0 and 1 by capping it to these values. 2.3. Structures There are two structures in the model: the user ‚Äìsource bipartite network and the user ‚Äìuser social network. 2.3.1. User ‚Äìsource network The user ‚Äìsource network connects users to the news sources they are following. This is the primary channel through which usersare exposed to news items. We fix the degree distribution of the sources to be a power law, as we detailed in the previous section. The degree distribution ofthe user depends on the other rules of the model. There is a certainnumber of users with degree zero in this network. These users donot follow any news source and only react to what is shared bytheir circle of friends. We think this is reasonably realistic. We connect users to sources to maximize polarity homophily. The assumption is that users will follow news organizationssharing their polarity. This assumption is supported by theliterature [31,32]. For each source with a given polarity and popularity, we pick the required number of individuals with polarity values in aninterval around the source polarity. For instance, if a sourcehas popularity of 24 and polarity of 0.5, we will pick the 24users whose polarity is closest to 0.5 and we will connect themto the source. 2.3.2. Social network Users connect to each other in a social network. The social net-work is the channel through which users are exposed to newsitems from sources they are not following.We aim at creating a social network with realistic character- istics. For this reason, we generate it via an Lancichinetti ‚Äì Fortunato ‚ÄìRadicchi (LFR) benchmark 6[33]. The LFR benchmark ensures that the social network has a community structure, abroad degree distribution, and communities are overlapping,i.e. they can share nodes. All these characteristics are typical ofreal-world social networks. We fix the number of nodes to‚âà16 000, while the number of communities is variable and not fixed by the LFR ‚Äôs parameters. We need an additional feature in the social network: polarity homophily. People are more likely to be friends with like-mindedindividuals. This is supported by studies of politics on socialmedia [34]. We ensure homophily by iterating over all communitiesgenerated by the LFR benchmark and assigning to users grouped inthe same community a portion of the polarity distribution. For instance, if a community includes 12 nodes, we take 12 con- secutive values in the polarity distribution and we assign themto the users. This procedure generates extremely high polarityassortativity. The Pearson correlation of the polarity values at thetwo endpoints of each edge is ‚âà0.89. 2.4. Actions A news source publishes to all the users following it an item i carrying the source ‚Äôs polarity piand truthfulness ti. Every time a user sees an item i, it calculates how acceptable the item is, using the function fi,u. An item is acceptable if it is (i) truthful and (ii) it is not far from the user in the polarity spectrum ‚Äî experiments [35] show how this is a reasonable mechanics:users tend to trust more sources with a similar polarity to theirown. Mathematically, (i) means that f i,uis directly proportional toti; while (ii) means that fi,uis inversely proportional to the difference between piand pu fi,u¬ºti jpi/C0puj: The acceptability function fi,uhas two issues: first, its domain spans from 0 (if ti=0 )t o+ ‚àû(ifpi=pu). This can be solved by the standard transformation x/(x+ 1), which is always between 0 and 1 if x‚â•0. Second, for the discussion of our parameters and results, it is more convenient to estimate a degree of ‚Äòunacceptability ‚Äô, which is the opposite of the acceptability fi,u. This can be achieved by the standard transformation 1 ‚àíx. Putting the two transformations together, the unacceptability fi,uof item ifor user uis fi,u¬º1/C0fi,u fi,u√æ1:10‚Äì410‚Äì310‚Äì210‚Äì11 1 10 102103p (followers ‚â• x) followers (√ó10 k)0100200300400500600700 EL L SL M DK SC C ECcount polarit y(b)(a) Figure 3. (a) The cumulative distribution of source popularity on Facebook in our dataset: the probability ( y-axis) of a page to have a given number of followers or more ( x-axis). ( b) The polarity distribution in the USA from 1994 (light) to 2016 (dark). Biannual observation, except for missing years 2006, 2010 and 2014. EL, extremely liberal; L, liberal; SL, slightly liberal; M, moderate; DK, don ‚Äôt know; SC, slightly conservative; C, conservative; EC, extremely conservative.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000204  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  Users have a finite tolerance for how unacceptable a news item can be. If the item exceeds this threshold, meaning fi,u.f, the user will flag the item. On the other hand, if the news item has low to zero unacceptability, meaning fi,u,r, the user will reshare it to their friends. If r/C20fi,u/C20f, the user will neither flag nor reshare the item. The parameters œïand œÅregulate which and how many news items are flagged, and thus we need to tune them to generaterealistic results ‚Äîas we do in the Results section. 2.5. Monopolar model The monopolar model is the result of removing everything related to polarity from the bipolar model. The sharing and flag-ging criteria are the same as in the bipolar model ‚Äîtesting fi,u against the œÅand œïparameters, with the difference being in how fi,uis calculated. The unacceptability of a news item is now simply the opposite of its truthfulness, i.e. fi,u¬º1/C0ti. Moreover, in the monopolar model users connect to random news sources and there is no polarity homophily in thesocial network. The monopolar model attempts to reproduce the assumption of real-world crowdsourced flagging systems: only the least truthfularticles are flagged. However, we argue that it is not a good rep-resentation of reality because truthfulness assessment is not anobjective process: it is a subjective judgement and it includes pre-existing polarization of both sources and users. The bipolar modelcan capture such polarization while the monopolar model cannot. 2.6. Example To understand what happens in the bipolar and monopolarmodels, consider figure 4 as a toy example. Table 2 a,bcalculates fi,ufor all user ‚Äìsource pairs in the bipolar and monopolar models, respectively. Table 3 a,bcounts the number of flags received by each source for different combinations of the œÅand œïparameters in the bipolar and monopolar models, respectively. A few interesting differences between the bipolar and monopolarmodels appear. In the monopolar model, only the direct audience of a source can flag its news items and, if one member of the direct audienceflags, so will all of them. This is because fi,uis equal for all nodes, thus either fi,u.fand the entire audience will flag the item (and no one will reshare it) or fi,u,rand the entire network ‚Äînot just the audience ‚Äîwill reshare the item, and no one will ever flag it. This is not true for the bipolar model. S1 (figure 4) can be either flagged by its entire audience ( œï= 0.14); by part of its audi- ence ( œï= 0.3); or by nodes who are not in its audience at all (users U5 and U6 for œï= 0.44; or user U7 for œï= 0.6). On the other hand, in our examples, S2 is never flagged by its audience (U7). WhenS2 is flagged, it is always because it percolated to a user for which fi,u.f, via a chain of users for which fi,u,r, because fi,uis not constant across users any longer. 3. Results 3.1. Parameter tuning Before looking at the results of the model, we need to identify the range of parameter values that can support robust andU5S2 S1 U3 U1 U7 U2 U4 U6pi = 0.5 ti = 0.55 pu = 0.8 pu = 0.6 pu = 0.4 pu = 0.2 pu = ‚Äì0.2 pu = ‚Äì0.45 pu = 0pi = ‚Äì0.5 ti = 0.45 Figure 4. Two simple structures with sources (squares) and users (circles). Edges connect sources to the users following them and users to their friends. Each s ource has an associated tiand pivalue and each user has an associated puvalue next to their respective nodes. Table 2. The fi,uvalue for each user ‚Äìsource pair from Ô¨Ågure 4 in the ( a) bipolar and ( b) monopolar models. (a) bipolar ‚Äôsfi,u (b) monopolar ‚Äôsfi,u user S1 S2 user S1 S2 U1 0.35 0.74 U1 0.45 0.55 U2 0.15 0.71 U2 0.45 0.55 U3 0.15 0.66 U3 0.45 0.55 U4 0.35 0.61 U4 0.45 0.55U5 0.48 0.52 U5 0.45 0.55 U6 0.56 0.40 U6 0.45 0.55 U7 0.62 0.10 U7 0.45 0.55 Table 3. The number of Ô¨Çags each source in Ô¨Ågure 4 gets in the ( a) bipolar and ( b) monopolar models, for varying values of œÅandœï. (a) bipolar ( b) monopolar œÅœï S1 S2 œÅœï S1 S2 0.67 0.7 0 2 0.67 0.7 0 0 0.57 0.6 1 1 0.57 0.6 0 0 0.49 0.54 1 1 0.49 0.54 0 1 0.36 0.44 2 0 0.36 0.44 4 10.2 0.3 2 1 0.2 0.3 4 1 0.1 0.6 0 0 0.1 0.6 0 0 0.1 0.5 0 0 0.1 0.5 0 1 0.1 0.14 4 0 0.1 0.14 4 1royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000205  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  realistic results. The most important of the two parameters isœï, because it determines the number of flags generated in the system. Figure 5 ashows the total number of flags generated per value of œï. As expected, the higher the œï, the fewer the flags, as the user finds more news items acceptable. The sharp drop means that, for œï&gt; 0.6, we do not have a sufficient number of flags to support our observation of the model ‚Äôs be- haviour. Thus, hereafter, we will only investigate the behaviour of the model for œï‚â§0.6. œÅis linked to œï; specifically , its value is capped by œï. Aworld with œÅ‚â•œïis unreasonable, because it would be a scenario where a user feels enough indignation by an item that theywill flag it, but then they will also reshare it to their social network. Thus, we only test scenarios in which œÅ&lt;œï. Another important question is what combination of œïand œÅvalues generates flags that can reproduce the observed relation between source popularity and the number of flagswe see in figure 1. To do so, we perform a grid search, testing many combinations of œï‚ÄìœÅvalues. Our quality criterion is the absolute difference in the slope of the power fit betweenpopularity and the number of flags. The lower the difference, the better the model is able to approximate reality. Figure 5 bshows such a relationship. We can see that there is an area of high performance at all levels of œï. 3.2. Bipolar model Figure 6 shows the distribution of the polarity of the flagged news items, for different values of œïand setting œÅ= 0.08, an interval including the widest spectrum of goodness of fit asshown in figure 5 b. We run the model 50 times and take the average of the results, to smooth out random fluctuations. We can see that our hypothesis is supported: in a polarized environment the vast majorityofflagged news items are neutral. This happens for œï‚â§0.3, which, as we saw in figure 5 b,i st h e most realistic scenario. For œï‚â•0.4, our hypothesis would not be supported, but, as we can see in figure 5 b, this is the area in red, where the model is a bad fit for the observations anyway ‚Äîsince here we are looking at œÅ= 0.08 results. Figure 7 shows the distribution of truthfulness of the flagged items. These distributions show that, by flagging following their individual polarization, users in the bipolarmodel end up flagging the most truthful item they can ‚Äîif œïis high enough, items with t i‚àº1 cannot be flagged almost regardless of the polarity difference.The two observations put together mean that, in the bipolar model, the vast majority of flags come from extremists who are exposed to popular neutral and truthful news. The extremists do not follow the neutral and truthful news sources, but getin contact with neutral and truthful viewpoints because of their social network. The bipolar model results ‚Äîin accordance with the obser- vation from figure 1 ‚Äîsuggest that more popular items are s h a r e dm o r ea n dt h u sf l a g g e dm o r e .O n ec o u l db et e m p t e dt o identify and remove fake news items by taking the ones receivingmore than their fair shares of flags given their popularity. How- ever, such a simple system would not work in reality. Figure 1 is based on data coming after Facebook ‚Äôs machine learning pre- processor, the aim of which is to minimize false positives. 7 Thus, even after controlling for a number of factors ‚Äîsource popularity, reputation, etc. ‚Äîmost reported flags still end up attached to high-popularity, high-reputability sources. 3.3. Monopolar model In the monopolar model, we remove all aspects related topolarity, thus we cannot show the polarity distribution of the flags. Moreover, as we have shown in ¬ß2.6, the effect ofœÅand œïis marginal. Thus we only show in figure 8 the truth- fulness distribution of the flags, for only œï= 0.1 and œÅ= 0.08, noting that all other parameter combinations result in apractically identical distribution. The monopolar results show the flag truthfulness distribution as the ideal result. The distribution shows a dispro-portionate number of flags going to low truthfulness news items, as they should ‚Äîthe drop for the lowest truthfulness value is due to the fact that there are few items at that lowlevel of truthfulness, and that they are not reshared. Is this ideal result realistic? If we use the same criterion as we used for the bipolar model to evaluate the quality of themonopolar model, the answer is no. The absolute slope difference in the popularity ‚Äìflag regression between obser- vation and the monopolar model is ‚âà0.798 for all œï‚ÄìœÅ combinations. This is a significantly worse performance than the worst-performing versions of the bipolar model ‚Äî figure 5 bshows that no bipolar version goes beyond a slope difference of 0.5. Thus we can conclude that the monopolar model is not a realistic representation of reality, even if we would expect it tocorrectly flag the untruthful news items. The bipolar model is a better approximation, and results in flagging truthful news items. 0.1 0.2 0.3 0.4 0.5 0.6 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45r 00.050.100.150.200.250.300.350.400.450.50 abs slo pe difference 02.0 √ó 1054.0 √ó 1056.0 √ó 1058.0 √ó 1051.0 √ó 1061.2 √ó 1061.4 √ó 1061.6 √ó 1061.8 √ó 1062.0 √ó 106 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9no. flags ff(b) (a) Figure 5. (a) The number of flags ( y-axis) in the bipolar model for different values of œï(x-axis). ( b) The slope difference (colour; red = high, green = low) between the real world and the bipolar fit between the source popularity and the number of flags received, per combination of œïandœÅvalues ( x‚Äìyaxis).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000206  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  3.4. Robustness Our bipolar model makes a number of simplifying assumptions that we need to test. First, we are showing results for a model in which all news sources have the same degree of activity ,meaning that each source will publish exactly one news item. This is not realistic: data from Facebook pages show that there is a huge degree of activity heterogeneity (figure 9 a). There is a mild positive correlation between the popular- ity of a page and its degree of activity (log-log Pearson correlation of ‚âà0.12; figure 9 b). For this reason, we use the real-world distribution of page popularity and we lock it in with its real-world activity level. This is the weighted bipolar model, in which each synthetic news source is the model ‚Äôs equivalent of a real page, with its popularity and activity. A second simplifying assumption of the bipolar model is that the reshareability and flaggability parameters œÅand œïarethe same for every individual in the social network. However, people might have different trigger levels. Thus we create thevariable bipolar model, where each user has its own œÅ uand œïu. These values are distributed normally, with their average /C22r¬º0:08 (and standard deviation 0.01) and /C22fdepending on which average value of œïwe are interested in studying (with the standard deviation set to one-eighth of /C22f). Figure 10 shows the result of the weighted and variable variants against the original bipolar model. In figure 10 a, we report the dispersion (standard deviation) of the polariz- ation values of the flags. A low dispersion means that flagscluster in the neutral portion of the polarity spectrum, mean- ing that most flags signal neutral news items. In figure 10 b, we report the average truthfulness of flagged items. We can see that taking into account the pages ‚Äôactivities increases the dispersion by a negligible amount and only020406080100120140no. flags polarity010203040506070no. flags polarity 0510152025 ‚Äì1.0‚Äì0.9‚Äì0.8‚Äì0.7‚Äì0.6‚Äì0.5‚Äì0.4‚Äì0.3‚Äì0.2‚Äì0.100.10.20.30.40.50.60.70.80.91.0 ‚Äì1.0‚Äì0.9‚Äì0.8‚Äì0.7‚Äì0.6‚Äì0.5‚Äì0.4‚Äì0.3‚Äì0.2‚Äì0.100.10.20.30.40.50.60.70.80.91.0no. flags polarity012345678no. flags polarity 00.20.40.60.81.01.21.4 ‚Äì1.0‚Äì0.9‚Äì0.8‚Äì0.7‚Äì0.6‚Äì0.5‚Äì0.4‚Äì0.3‚Äì0.2‚Äì0.100.10.20.30.40.50.60.70.80.91.0‚Äì1.0‚Äì0.9‚Äì0.8‚Äì0.7‚Äì0.6‚Äì0.5‚Äì0.4‚Äì0.3‚Äì0.2‚Äì0.100.10.20.30.40.50.60.70.80.91.0‚Äì1.0‚Äì0.9‚Äì0.8‚Äì0.7‚Äì0.6‚Äì0.5‚Äì0.4‚Äì0.3‚Äì0.2‚Äì0.100.10.20.30.40.50.60.70.80.91.0 ‚Äì1.0‚Äì0.9‚Äì0.8‚Äì0.7‚Äì0.6‚Äì0.5‚Äì0.4‚Äì0.3‚Äì0.2‚Äì0.100.10.20.30.40.50.60.70.80.91.0no. flags polarity00.010.020.030.040.050.060.070.080.090.10no. flags polarity(e)( f)(b) (a) (c) (d) Figure 6. Flag count per polarity of items at different flaggability thresholds œïfor the bipolar model. Reshareability parameter œÅ= 0.08. Average of 50 runs. (a)œï= 0.1, ( b)œï= 0.2, ( c)œï= 0.3, ( d)œï= 0.4, ( e)œï= 0.5 and ( f)œï= 0.6.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000207  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  for high values of œï. This happens because there could be some extremely active fringe pages spamming fake content, which increases the likelihood of extreme flags. There is no difference in the average truthfulness of flagged items. Having variable œïandœÅvalues, instead, actually decreases dispersion, making the problem worse ‚Äîalthough only for larger values of œï. In this configuration, a very tolerant society with high (average) œïwould end up flagging mostly neutral reporting ‚Äîas witnessed by the higher average truthfulness of the reported items. This is because lower-than-average œÅu users will be even less likely to reshare the most extreme news items. So far we have kept the reshareability parameter constant atœÅ= 0.08. If we change œÅ(figure 11) the dispersion of a flag ‚Äôs polarity (figure 11 a) and its average truthfulness value (figure 11 b) do not significantly change. The changes are050100150200250 00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0 00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0 0.00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0no. flags truthfulness020406080100120140no. flags truthfulness 05101520253035404550no. flags truthfulness0246810121416no. flags truthfulness 00.51.01.52.02.53.0no. flags truthfulness00.020.040.060.080.100.120.140.160.180.20no. flags truthfulness(e)( f)(b) (a) (c) (d) Figure 7. Flag count per truthfulness of items at different flaggability thresholds œïfor the bipolar model. Reshareability parameter œÅ= 0.08. Average of 50 runs. (a)œï= 0.1, ( b)œï= 0.2, ( c)œï= 0.3, ( d)œï= 0.4, ( e)œï= 0.5 and ( f)œï= 0.6. 00.51.01.52.02.53.03.54.0 00.10.20.30.40.50.60.70.80.91.0no. flags truthfulness Figure 8. Flag count per truthfulness of items for the monopolar model for œï= 0.6. Average of 50 runs.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000208  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  10‚Äì410‚Äì310‚Äì210‚Äì11 1 10 102103p (shares ‚â•x) shares01234567 00.5 1.0 1.5 2.0 2.5 3.0 3.5log (followers) log (shares) 110102 no. sources(b) (a) Figure 9. (a) The cumulative distribution of source activity in Facebook in our dataset: the probability ( y-axis) of a news source sharing a given number of items or more ( x-axis). ( b) The relationship between activity ( x-axis) and popularity ( y-axis) in our Facebook dataset. 00.10.20.30.40.50.6s(pi)bipolar weighted variable 00.10.20.30.40.50.60.70.80.9 0.1 0.2 0.3 0.4 0.5 0.6m(ti) f0.1 0.2 0.3 0.4 0.5 0.6 fbipolar weighted variable(b) (a) Figure 10. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items in the bipolar model and its weighted and variable variants.s(pi) 0.1 0.2 0.3 0.4 0.5 0.6m(ti) f0.1 0.2 0.3 0.4 0.5 0.6 f(b) (a) 00.10.20.30.40.50.6 r = 0.03 r = 0.04 r = 0.05 r = 0.06 r = 0.07 r = 0.08 00.10.20.30.40.50.60.70.80.9 r = 0.03 r = 0.04 r = 0.05 r = 0.06 r = 0.07 r = 0.08 Figure 11. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items for different values of reshareability œÅ.s(pi) m(ti) 0.1 0.2 0.3 0.4 0.5 0.6 f0.1 0.2 0.3 0.4 0.5 0.6 f(b) (a) 00.10.20.30.40.50.60.7 bipolar no-homophily no-community 00.10.20.30.40.50.60.70.80.91.0 bipolar no-homophily no-community Figure 12. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items in the bipolar and alternative models.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000209  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  due to the fact that œÅsimply affects the number of flags: a higher œÅmeans that users are more likely to share news items. More shares imply more news items percolating through the social network and thus more flags. The bipolar model contains many elements besides the œÅ and œïparameters. For instance, it imposes that the social net- work has several communities and that social relationshipsare driven by homophily. These two elements are based on existing literature, yet we should test their impact on the model. First, keeping everything else constant, the no-homophily variant allows users to connect to friends ignoring their polarity value. In other words, polarity is randomly distribu- ted in the network. Second, keeping everything else constant,the no-community variant uses an Erdo Ããs‚ÄìR√©nyi random graph as the social network instead of an LFR benchmark. The Erdo Ããs‚ÄìR√©nyi graph extracts connections between nodes uniformly at random and thus it has, by definition, no com- munity structure. Figure 12 shows the impact on flag polarity dispersion (figure 12 a) and average truthfulness (figure 12 b). The no-homophily variant of the bipolar model has a significantly higher dispersion in the flag polarity distribution, and lowertruthfulness average, and the difference is stable (though stronger for values of œÅabove 0.3). This means that polarity homophily is playing a key role in ensuring that flags are pre-dominantly assigned to neutral news items: if we remove it, the accuracy in spotting fake news increases. In contrast, removing the community structure from the net- work will result in a slightly smaller dispersion of flag ‚Äôs polarity and higher average flag truthfulness. The lack of communities might cause truthful items to spread more easily, and thus beflagged, increasing the average flag truthfulness. 4. Discussion In this paper, we show how the assumption of traditionalcrowdsourced content policing systems is unreasonable. Expecting users to flag content carries the problematic assump- tion that a user will genuinely attempt to estimate the veracityof a news item to the best of their capacity. Even if that was a reasonable expectation to have, a user ‚Äôs estimation of veracity will be made within their individual view of the world andvariable polarization. This will result in assessments that will give an easier pass to biased content if they share such bias. This hypothesis is supported by our bipolar agent-basedmodel. The model shows that even contexts that are extremely tolerant towards different opinions, represented by our flagg- ability parameter œï, would still mostly flag neutral content, and produce results that fit well with observed real-world data. Moreover, by testing the robustness of our model, we show how our results hold both for the amount of heterogen-eity of source activity and for individual differences in both tolerance and propagation attitudes. Removing polarization from the model, and thus testing what we defined as the monopolar model, attempts to repro- duce the assumptions that would make a classical content policy system work. The monopolar model, while seeminglybased on reasonable assumptions, is not largely supported by established literature in the area of online behaviour and social interaction, differently from the bipolar model.Moreover, it is not able to deliver on its promises in terms of ability to represent real-world data.Our paper has a number of weaknesses and possible future directions. First, our main results are based on a simu- lated agent-based model. The results hold as long as the assumptions and the dynamics of the models are an accurateapproximation of reality. We provided evidence to motivate the bipolar model ‚Äôs assumptions, but there could still be fac- tors unaccounted for, such as the role of originality [36] or ofspreaders ‚Äôeffort [37] in making content go viral. Second, many aspects of the model were fixed and should be investi- gated. For instance, there is a strong polarity homophilybetween users and news sources, and in user ‚Äìuser connec- tions in the social network. We should investigate whether such strong homophily is really supported in real-world scen-arios. Third, the model has an essentially static structure. The users will never start/stop following news sources, nor befriend/unfriend fellow users. Such actions are commonin real-world social systems and should be taken into account. Fourth the model only assumes news stories worth interacting with. This is clearly different from the realitywhere, in a context of overabundant information, most stories are barely read and collect few reshares or flags. Including those news stories in the model could certainly affect theoverall visibility of other items. Finally, the model does not take into account reward and cost functions for both users and news sources. What are the repercussions for a newssource of having its content flagged? Should news sources attempt to become mainstream and gather following? Such reward/cost mechanisms are likely to greatly influence ouroutcomes. We plan to address the last two points in future expansions of our model. Ethics. No individual-level data have been accessed in the develop- ment of this paper. The paper ‚Äôs experiments rely on synthetic simulations. Motivating data provided by the Social Science Research Council fulfil the ethical criteria required by Social Science One. Data accessibility. The archive containing the data and code necessary for the replication of our results can be found at http://www.michelec-oscia.com/wp-content/uploads/2020/03/20200304_ffff.zip Authors ‚Äôcontributions. L.R. collected the data. M.C. performed the exper- iments. M.C. and L.R. jointly designed the study, analysed the data, prepared the figures, and wrote and approved the manuscript. Competing interests. We declare we have no competing interest. Funding. No funding has been received for this article. Acknowledgements. This study was supported in part by a dataset from the Social Science Research Council within the Social Data Initiative. CrowdTangle data access has been provided by Facebook in collabor- ation with Social Science One. The authors also thank Fabio Gigliettoand the LaRiCA, University of Urbino Carlo Bo, for data access, and Clara Vandeweerdt for insightful comments. Endnotes 1https://www.facebook.com/facebookmedia/blog/working-to- stop-misinformation-and-false-news (April 2017, date of access 3 March 2020). 2https://socialscience.one/blog/unprecedented-facebook-urls-data- set-now-available-research-through-social-science-one (February 2020, date of access 3 March 2020). 3From a least-squares fit in a log-log space. Alternative hypotheses such as linear relationship or exponential relationship are discarded, with p-values approximately 0.98 and 0.34, respectively. 4https://www.crowdtangle.com/ 5https://electionstudies.org/resources/anes-guide/top-tables/?id= 29 (date of access 11 November 2019). 6https://sites.google.com/site/andrealancichinetti/files 7https://about.fb.com/news/2018/06/increasing-our-efforts-to- fight-false-news/ (date of access 7 January 2020).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 2020002010  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  References 1. Newman N, Fletcher R, Kalogeropoulos A, Nielsen R. 2019 Reuters institute digital news report 2019 , vol. 2019. Oxford, UK: Reuters Institute for the Study of Journalism. 2. Allcott H, Gentzkow M. 2017 Social media and fake news in the 2016 election. J. Econ. Perspect. 31, 211 ‚Äì36. (doi:10.1257/jep.31.2.211) 3. Lazer DMJ et al. 2018 The science of fake news. Science 359, 1094 ‚Äì1096. (doi:10.1126/science. aao2998) 4. Vosoughi S, Roy D, Aral S. 2018 The spread of true and false news online. Science 359, 1146 ‚Äì1151. (doi:10.1126/science.aap9559) 5. Adamic LA, Glance N. 2005 The political blogosphere and the 2004 US election: divided they blog. In Proc. of the 3rd Int. Workshop on Link Discovery, Chicago, IL, 21 ‚Äì24 August 2005 , pp. 36 ‚Äì43. New York, NY: ACM. 6. Garrett RK. 2009 Echo chambers online? Politically motivated selective exposure among internet news users. J. Comput.-Mediated Commun. 14, 265 ‚Äì285. (doi:10.1111/j.1083-6101.2009.01440.x) 7. Nikolov D, Oliveira DFM, Flammini A, Menczer F. 2015 Measuring online social bubbles. PeerJ Comput. Sci. 1, e38. (doi:10.7717/peerj-cs.38) 8. Quattrociocchi W, Scala A, Sunstein CR. 2016 Echo chambers on Facebook. See https://papers.ssrn.com/ sol3/papers.cfm?abstract_id=2795110. 9. Flaxman S, Goel S, Rao JM. 2016 Filter bubbles, echo chambers, and online news consumption. Public Opin. Q. 80, 298 ‚Äì320. (doi:10.1093/poq/ nfw006) 10. Dubois E, Blank G. 2018 The echo chamber is overstated: the moderating effect of politicalinterest and diverse media. Inf. Commun. Soc. 21, 729 ‚Äì745. (doi:10.1080/1369118X.2018.1428656) 11. Del Vicario M, Vivaldo G, Bessi A, Zollo F, Scala A, Caldarelli G, Quattrociocchi W. 2016 Echo chambers: emotional contagion and group polarization on Facebook. Sci. Rep. 6, 37825. (doi:10.1038/ srep37825) 12. Garimella K, De Francisci Morales G, Gionis A, Mathioudakis M. 2018 Political discourse on socialmedia: echo chambers, gatekeepers, and the price of bipartisanship. In Proc. of the 2018 World Wide Web Conference, Lyon, France, 23 ‚Äì27 April 2018 , pp. 913 ‚Äì922. Geneva, Switzerland: International World Wide Web Conferences Steering Committee. 13. An J, Quercia D, Crowcroft J. 2013 Fragmented social media: a look into selective exposure to political news. In Proc. of the 22nd Int. Conf. on World Wide Web, Rio de Janeiro, Brazil, 13 ‚Äì17 May 2013 , pp. 51 ‚Äì52. New York, NY: ACM.14. Bakshy E, Messing S, Adamic LA. 2015 Exposure to ideologically diverse news and opinion on Facebook. Science 348, 1130 ‚Äì1132. (doi:10.1126/science. aaa1160) 15. Conroy NJ, Rubin VL, Chen Y. 2015 Automatic deception detection: methods for finding fake news. Proc. Assoc. Inf. Sci. Technol. 52,1‚Äì4. (doi:10.1002/ pra2.2015.145052010082) 16. Shu K, Sliva A, Wang S, Tang J, Liu H. 2017 Fake news detection on social media: a data miningperspective. ACM SIGKDD Explor. Newsl. 19,2 2 ‚Äì36. (doi:10.1145/3137597.3137600) 17. Wei W, Wan X. 2017 Learning to identify ambiguous and misleading news headlines. In Proc. of the 26th Int. Joint Conf. on Artificial Intelligence, Melbourne, Australia, 19 ‚Äì25 August 2017 , pp. 4172 ‚Äì4178. Palo Alto, CA: AAAI Press. 18. Li Y, Li Q, Gao J, Su L, Zhao B, Fan W, Han J. 2015 On the discovery of evolving truth. In Proc. of the 21th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, Sydney, Australia, 10 ‚Äì13 August 2015 , pp. 675 ‚Äì684. New York, NY: ACM. 19. Wu L, Liu H. 2018 Tracing fake-news footprints: characterizing social media messages by how they propagate. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, CA, 5 ‚Äì9 February 2018 , pp. 637 ‚Äì645. New York, NY: ACM. 20. Tschiatschek S, Singla A, Gomez Rodriguez M, Merchant A, Krause A. 2018 Fake news detection in social networks via crowd signals. In Companion Proc. of the Web Conf. 2018, Lyon, France, 23 ‚Äì27 April 2018 , pp. 517 ‚Äì524. Geneva, Switzerland: International World Wide Web Conferences Steering Committee. 21. Giglietto F, Iannelli L, Valeriani A, Rossi L. 2019 ‚ÄòFake news ‚Äôis the invention of a liar: how false information circulates within the hybrid news system. Curr. Sociol. 67, 625 ‚Äì642. 22. Myslinski LJ. 2013 Social media fact checking method and system, 4 June 2013. US Patent 8,458,046. 23. Kim J, Tabibian B, Oh A, Sch√∂lkopf B, Gomez- Rodriguez M. 2018 Leveraging the crowd to detect and reduce the spread of fake news and misinformation. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, 5 ‚Äì9 February 2018 , pp. 324 ‚Äì332. New York, NY: ACM. 24. Crawford K, Gillespie T. 2016 What is a flag for? Social media reporting tools and the vocabulary of complaint. New Media Soc. 18, 410 ‚Äì428. (doi:10. 1177/1461444814543163) 25. Gillespie T. 2018 Custodians of the Internet: platforms, content moderation, and the hidden decisions that shape social media . New Haven, CT: Yale University Press.26. Messing S, State B, Nayak C, King G, Persily N. 2018 Facebook URL Shares. See https://doi.org/10.7910/ DVN/EIAACS. 27. Mathias J-D, Huet S, Deffuant G. 2016 Bounded confidence model with fixed uncertainties and extremists: the opinions can keep fluctuating indefinitely. J. Artif. Soc. Soc. Simul. 19, 6. (doi:10. 18564/jasss.2967) 28. Giglietto F, Iannelli L, Rossi L, Valeriani A, Righetti N, Carabini F, Marino G, Usai S, Zurovac E. 2018Mapping italian news media political coverage in the lead-up to 2018 general election. See https:// papers.ssrn.com/sol3/papers.cfm?abstract_id=3179930. 29. American National Election Studies. 2008 The ANES guide to public opinion and electoral behavior. Seehttps://electionstudies.org/resources/anes-guide/ top-tables/?id=29. 30. Lewandowsky S, Ecker UKH, Cook J. 2017 Beyond misinformation: understanding and coping with the ‚Äòpost-truth ‚Äôera. J. Appl. Res. Memory Cogn. 6, 353 ‚Äì369. (doi:10.1016/j.jarmac.2017.07.008) 31. Iyengar S, Hahn KS, Krosnick JA, Walker J. 2008 Selective exposure to campaign communication: the role of anticipated agreement and issue publicmembership. J. Politics 70, 186 ‚Äì200. (doi:10.1017/ S0022381607080139) 32. Stroud NJ. 2008 Media use and political predispositions: revisiting the concept of selective exposure. Pol. Behav. 30, 341 ‚Äì366. (doi:10.1007/ s11109-007-9050-9) 33. Lancichinetti A, Fortunato S, Radicchi F. 2008 Benchmark graphs for testing community detection algorithms. Phys. Rev. E 78, 046110. (doi:10.1103/ PhysRevE.78.046110) 34. Conover MD, Ratkiewicz J, Francisco M, Gon√ßalves B, Menczer F, Flammini A. 2011 Political polarizationon twitter. In Proc. 5th Int. AAAI Conf. on Weblogs and Social Media, Barcelona, Spain, 17 ‚Äì21 July 2011. Palo Alto: AAAI Press. 35. Swire B, Berinsky AJ, Lewandowsky S, Ecker UKH. 2017 Processing political misinformation: comprehending the Trump phenomenon. R. Soc. open sci. 4, 160802. (doi:10.1098/rsos.160802) 36. Coscia M. 2017 Popularity spikes hurt future chances for viral propagation of protomemes. Commun. ACM 61,7 0 ‚Äì77. (doi:10.1145/3158227) 37. Pennacchioli D, Rossetti G, Pappalardo L, Pedreschi D, Giannotti F, Coscia M. 2013 The threedimensions of social prominence. In Proc. Int. Conf. on Social Informatics, Kyoto, Japan, 25 ‚Äì27 November 2013 , pp. 319 ‚Äì 332. New York, NY: Springer.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 2020002011  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022</td>
    </tr>
    <tr>
      <th>96</th>
      <td>news</td>
      <td>Toward Fairness in Misinformation Detection Algorithms\nJinkyung Park, Rahul Ellezhuthil, Ramanathan Arunachalam, Lauren Feldman, and Vivek Singh\nSchool of Communication &amp; Information, Rutgers University\n{jp1767, re263, ra831, lauren.feldman, v.singh}@rutgers.edu\n\nAbstract\nMisinformation in online spaces can stoke mistrust of\nestablished media, misinform the public and lead to radicalization. Hence, multiple automated algorithms for\nmisinformation detection have been proposed in the\nrecent past. However, the fairness (e.g., performance\nacross left- and right- leaning news articles) of these algorithms has been repeatedly questioned, leading to decreased trust in such systems. This work motivates and\ngrounds the need for an audit of machine learning based\nmisinformation detection algorithms and possible ways\nto mitigate bias (if found). Using a large (N &gt; 100K)\ncorpus of news articles, we report that multiple standard\nmachine learning based misinformation detection approaches are susceptible to bias. Further, we find that an\nintuitive post-processing approach (Reject Option Classifier) can reduce bias while maintaining high accuracy\nin the above setting. The results pave the way for accurate yet fair misinformation detection algorithms.\n\nIntroduction\nThe growth of social media has resulted in an increasing\nnumber of users consuming, sharing, and even producing\nonline news. On the positive side, this has democratized\nnews and information by reducing the agenda-setting control of large professional news outlets. On the negative side,\nthis has left the public unprotected from the spread of misinformation by stripping out the gate-keeping role of traditional media (Shoemaker and Vos 2009). The lower barriers\nto entry, combined with the monetized network structure of\nsocial media, have contributed to the rapid proliferation of\nmisinformation online. Indeed, false information on Twitter\nis typically retweeted more often, and far more rapidly, than\ntrue information, especially when the topic is related to politics (Vosoughi, Roy, and Aral 2018). Decision-making based\non misinformation entails potential social costs. It poses serious threats to democratic institutions by misinforming the\npublic (Allcott and Gentzkow 2017), deepening political divisions (Faris et al. 2017), fueling mistrust of legitimate media (Guess et al. 2021), reducing demand for accuracy (Allcott and Gentzkow 2017), and even leading to radicalization\nand violence (Greenhill and Oppenheim 2017). Therefore,\nCopyright ¬© 2022, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n\nverifying online news and preventing the spread of misinformation is critical for enabling trustworthy online environments and protecting democracy.\nThe traditional way to verify online news via manual factchecking has become difficult (or almost impossible) due to\nthe enormous volume of information that is generated and\ndisseminated online. This problem has led researchers and\nplatform developers to devise automated algorithms to detect misinformation based on the content and the patterns\nof the news (Conroy, Rubin, and Chen 2015). However, the\nvery algorithms that are intended to fight off one threat (misinformation) may inadvertently be falling prey to another\ncritical threat (bias of the automatic detection algorithms).\nTo some extent, the problems of algorithmic bias are the\nsame as those of human-based decision-making. For example, multiple politically right-leaning groups have accused\nFacebook and YouTube‚Äôs content moderators to be in favor of the political left (Cummings 2018; Koebler and Cox\n2018; Jiang, Robertson, and Wilson 2020; Darcy 2021).\nHowever, the impact gets amplified with the application of\nautomatic algorithms that scale the process dramatically. In\nrecent years, machine learning algorithms have been found\nto systematically discriminate and favor one group over another based on demographic characteristics in multiple domains (e.g., automated decisions on parole or college admission) (Calmon et al. 2017; Buolamwini and Gebru 2018).\nIt is possible that misinformation detection algorithms also\nmay exhibit bias, but in this case, based on the political leaning of the news in question. If such discrimination exists, it\ncan lead to the erosion of public trust online and exacerbate\npolitical polarization. Hence, it is important to audit misinformation detection algorithms for political bias and redress\nproblems, if found.\nThe main research questions in this work are:\nRQ1: Are misinformation detection algorithms susceptible to bias in terms of political leaning?\nRQ2: Can the level of bias in misinformation detection\nalgorithms be reduced while maintaining accuracy?\n\nRelated Work\nMisinformation Detection Scholars have used various\nterms to describe the phenomenon of misinformation. ‚ÄúMisinformation‚Äù is an umbrella term used to represent false\nor misleading information, whereas ‚Äúdisinformation‚Äù repre-\n\nsents false information that is ‚Äúpurposely spread to deceive\npeople‚Äù (Lazer et al. 2018). Other scholars see misinformation and disinformation as symptomatic of a broader ‚Äúinformation disorder‚Äù plaguing the media environment (e.g.,\n(Wardle and Derakhshan 2017)). The term ‚Äúfake news‚Äù\nhas been used to describe news articles that are ‚Äúintentionally and verifiably false and could mislead readers‚Äù (Allcott and Gentzkow 2017) or ‚Äúfabricated information that\nmimics news media content in form but not in organizational process or intent‚Äù (Lazer et al. 2018). Media analyses\nhave found strong structural similarity between ‚Äúfake news‚Äù\nand traditional journalism (MouraÃÉo and Robertson 2019;\nTandoc Jr, Thomas, and Bishop 2021); ‚Äúfake news‚Äù is thus\nunderstood as a form of ‚Äúgenre blending‚Äù that combines ‚Äúelements of news ideals with features exogenous to the normative model of professional journalism: misinformation,\nsensationalism, clickbait, and bias‚Äù (MouraÃÉo and Robertson\n2019).\nAlthough some scholars have moved away from the term\n‚Äúfake news‚Äù given its use by politicians and others to undermine news that they perceive to be disagreeable, we follow\nothers (MouraÃÉo and Robertson 2019; Grinberg et al. 2019;\nTandoc Jr, Thomas, and Bishop 2021) in retaining the ‚Äúfake\nnews‚Äù label to refer to media sources that publish false, misleading, hyperpartisan, and sensational content. We also use\nthe term ‚Äúmisinformation‚Äù to refer to media content that\nis false or misleading, and use labels provided by NewsGuard (https://www.newsguardtech.com/) to operationalize\nit. NewsGuard is a company that employs expert journalists\nand follows journalistic norms to rate the credibility of news\nand information websites.\nScholars, policymakers, and media professionals continue\nto make efforts to stem the flow of misinformation (Lazer et\nal. 2018). One potential technological approach entails the\nuse of algorithms to detect misinformation online. Misinformation detection has been studied in two broad ways: by\nanalyzing the content of misinformation and by analyzing\nthe spread of misinformation. The former examines contentrelated features (e.g., textual and images properties), and the\nlatter focuses on network features of the spreading phenomena in assessing the authenticity of the news articles (Zhou\nand Zafarani 2020; Singh, Ghosh, and Sonagara 2021;\nPotthast et al. 2017).\nIn previous literature, the credibility of news has typically been estimated based on the general reputation of the\nsource concerning known fact-checked claims. Most works\non misinformation detection which relied on source-level labels assumed that all articles from the source are equally\nreliable or unreliable depending on the reputation of the\nmedium (Horne et al. 2018; Grinberg et al. 2019). For example, (Horne et al. 2018) trained machine-learning algorithms to predict whether the news article is coming from\na factual or unreliable source. In their work, the assumption was that all news articles from a given source share\nthe same credibility level. We also follow this approach by\nevaluating misinformation at the level of news sources rather\nthan at the level of individual news articles. We do this for\ntwo reasons. First, the source of the news article often determines the presence of misinformation, based on the pro-\n\ncesses of the publisher (Grinberg et al. 2019). According to\n(Lazer et al. 2018), media outlets that publish false news\ntend to lack strong journalistic ‚Äúnorms and processes for\nensuring the accuracy and credibility of information.‚Äù Secondly, there is a dearth of fine-grained labels which have\nbeen defined at the news article level. State of the art creation of machine learning algorithms for misinformation detection focuses on source level labels for misinformation\n(N√∏rregaard, Horne, and Adalƒ± 2019; Grinberg et al. 2019;\nSitaula et al. 2020); hence, it makes sense for the bias analysis to be undertaken at the same resolution.\nPolitical Asymmetry in Misinformation Dissemination\nof and susceptibility to misinformation occurs asymmetrically across the political spectrum. Research by (Faris et al.\n2017) points to a broader asymmetry in the U.S. political\nmedia ecosystem that bears on the flow and uptake of misinformation on the political right . Their analysis finds that\nconservative media are more partisan and more insular than\nleft-leaning media. This relative insularity allows for misinformation and misleading claims from politically extreme\nsites to more easily receive amplification and legitimation\nwithin the right-wing media sphere.\nPolitical psychology research points to additional asymmetries in the media use and preferences of liberals and conservatives. Studies have shown that how physically threatened or fearful an individual feels is one of the key factors\nthat predicts whether an individual holds conservative political attitudes (Napier et al. 2018; Jost et al. 2017). In turn, research has found that liberals and conservatives are drawn to\ndifferent types of political media based on their psychological characteristics; for example, conservatives are attracted\nto information that monitors for threats and is aggressive\nin tone (Young 2019). Other research has demonstrated that\nliberals and conservatives are swayed by different features of\npersuasive message appeals (Jost and Krochik 2014). Therefore, it is plausible that misinformation targeting conservative and liberal audiences may use different mechanisms\n(e.g., news frames, emotional appeals, linguistic attributes,\netc.) based on assumptions about what might appeal to and\ninfluence the intended audience.\nGiven the ideological asymmetries in the production, proliferation, and interpretation of political misinformation, it is\npossible that algorithms could be biased in their detection of\nmisinformation in left- versus right-leaning news. In other\nwords, potential differences between left- and right-leaning\nnews may have implications for the fairness of algorithms\nto detect misinformation. Thus, any solutions for combating misinformation must take ideological asymmetry into\naccount (Lazer et al. 2018).\nAlgorithmic Fairness The potential issues of the\n(un)fairness of machine learning algorithms are not limited\nto misinformation detection algorithms. Various algorithms\nare applied to make important decisions that were made by\nhumans. However, even with the best intentions, data-driven\nmachine learning algorithms can inherently reflect existing\nsocial biases or introduce new ones. The emerging literature\non fair machine learning algorithms has identified multiple ways that the algorithms can make a discriminatory\n\ndecision. Some of the common scenarios for algorithmic\nbias include when (a) input data has unequal representation\nfrom different groups, (b) historically there is not enough\npositive outcome for the unprivileged group, and when (c)\nthe algorithm processes are (deliberately or inadvertently)\ndesigned to yield unequal decisions (Kamishima et al. 2012;\nLepri et al. 2018). Accordingly, techniques to mitigate\nalgorithmic bias attempt to modify the process of the\ntraining data (pre-processing), the learning algorithms\n(in-processing), and the prediction (post-processing) (Lepri\net al. 2018).\nMore specifically, pre-processing techniques focus on optimizing the data before it goes into any algorithms. For\ninstance, disparate impact remover tweaks feature values\nto increase fairness while preserving rank-order within the\ngroup. In this way, it allows each of the considered groups\n(e.g., political-left and political right) to have equal opportunities to score high on the considered features (Feldman et\nal. 2015).\nTo counter the bias stemming from the algorithm processes themselves, an in-processing technique such as\nadding a ‚Äúregularizer‚Äù can be used. Regularizer acts as a\nprejudice remover by penalizing discriminatory outcomes\ngenerated by an algorithm (Kamishima et al. 2012). Similarly, with the adversarial debiasing technique, classifiers\nlearn to minimize an adversary‚Äôs ability to predict sensitive\nfeatures (Alasadi, Al Hilli, and Singh 2019).\nPost-processing techniques are often used when it is impossible or undesirable to change the incoming data or the\n(potentially proprietary) algorithms. Reject Option Classification approach, one of the post-processing techniques, applies rejection options and labels instances to reduce discrimination (Kamiran et al. 2018). More specifically, it tries\nto balance the outcomes of algorithms by giving desirable\noutcomes to the unprivileged group and giving undesirable\noutcomes to the privileged group in the ‚Äúcritical region‚Äù i.e.,\nthe area near the decision boundary.\nRegardless of how algorithmic bias is mitigated, the above\ntechniques share a common idea: responsibility for the social impact generated by algorithmic decision-making. As\nalgorithms are products that involve both human and machine learning, redressing the potential bias inherent in the\nalgorithms is a step forward toward accountable machine\nlearning systems (O‚Äôneil 2016).\nThe issue of human bias in identifying misinformation has\nbeen addressed in some of the previous literature. For example, Babaei et al. (Babaei et al. 2021) have investigated the\nbiases in the human process of identifying fake news. Raza\net al., (Raza, Reji, and Ding 2022) have identified ways to\nidentify bias (e.g., use of gendered language) within articles\nand ways to reduce them.\nHowever, no research has been done on political asymmetry in the algorithms automatically predicting misinformation. In this work, we address the problem of identifying and reducing discriminatory decisions made by misinformation detection algorithms based on the political identity of the news source. Particularly, we focus on the scenario where there is an unequal representation of politically\nleft- and right-aligned sources in the training data and hence\n\npotentially impact fairness in misinformation detection algorithms.\n\nMaterials and Methods\nWe used the NELA-2018 dataset (N√∏rregaard, Horne, and\nAdalƒ± 2019) for analyzing bias in misinformation classification. The original dataset contained 713k news articles with\nsource-level labels for credibility and political leaning, compiled from several data sources including NewsGuard, Pew\nResearch Center, Wikipedia, BuzzFeed, and others.\nWe relied on credibility labels from NewsGuard for\nmultiple reasons. First, NewsGuard‚Äôs labels cover the\nhighest percentage (35%) of the entire sample. Second, it follows a rigorous labeling process. NewsGuard\n(https://www.newsguardtech.com/) utilizes trained journalists rather than algorithms to assess the credibility and transparency of news websites. Their analysis creates a points\nsystem across 9 dimensions to derive an overall label for\ncredibility. In addition, they allow respective news outlets to\ncomment on the assigned ratings before making them public.\nFinally, NewsGuard‚Äôs methodology has been used in recent\nmisinformation detection literature (N√∏rregaard, Horne, and\nAdalƒ± 2019; Singh, Ghosh, and Sonagara 2021).\nSimilarly, we relied on BuzzFeed‚Äôs labels for political\nleaning (i.e., left vs. right), as the labels cover 36.3% of the\nsample in the dataset. We excluded news articles that did not\nhave labels from both BuzzFeed and NewsGuard, leaving\n102k articles for further analysis.\nThe dataset includes political leaning as a sensitive feature\n(i.e., the dimension to be considered for fairness), having\ntwo categorical values (left-aligned and right-aligned). Out\nof 102k data points, 37.5k points (approximately 36.7%) belonged to left-aligned sources. The remaining 64.5k points\nbelong to right-aligned sources. Table 1 presents a list of\nnews sources in the dataset, their respective number of articles, political leanings, and credibility (e.g., real/fake).\n\nFeature Design\nMachine learning literature suggests two major approaches\nto feature extraction: deep learning and hand-crafted approaches. With large computational resources such as a large\ndataset, recent deep learning approaches can yield high accuracy. However, they often work as black boxes and do\nnot provide interpretability for the feature extraction (Zihni\net al. 2020). Meanwhile, hand-crafted machine learning approaches are often designed by domain experts. These approaches are more interpretable because the role of individual features is more obvious compared to the deep learning approaches. Furthermore, they tend to work well even\nwith the modest size of data and computational resources\navailable. We consider interpretability as an important aspect of our work on fairness in machine learning algorithms,\nand hence follow the route of theory-driven and hand-crafted\nfeature extraction approaches.\nThe features were identified based on a combination of 1)\nthe concepts of journalistic news values, 2) relevant theories,\nand 3) the array of recent empirical studies on misinformation detection.\n\nNews Source\n\nNumber of\nArticles\n\nPolitical\nAlignment\n\nReal/Fake\n\nShareblue\nMotherJones\nAlternet\nPoliticus\nUSA\nPalmer\nReport\nCrooks and\nLiars\nSalon\nMediaMattersforAmerica\nBipartisan\nReport\nMSNBC\nRaw Story\nDaily Kos\nDrudge\nReport\nFrontPage\nMagazine\nInstapundit\nBreitbart\nFox News\nCNS News\nNews Busters\nInfowars\nBearing Arms\nNational\nReview\nReal Clear\nPolitics\nDaily Signal\n\n2134\n1128\n4816\n4018\n\nLeft\nLeft\nLeft\nLeft\n\nFake\nReal\nReal\nReal\n\n3539\n\nLeft\n\nFake\n\n2465\n\nLeft\n\nReal\n\n1702\n2316\n\nLeft\nLeft\n\nReal\nReal\n\n4060\n\nLeft\n\nFake\n\n6604\n3719\n994\n18884\n\nLeft\nLeft\nLeft\nRight\n\nReal\nReal\nFake\nFake\n\n892\n\nRight\n\nFake\n\n15479\n1877\n3106\n5263\n3240\n2518\n1193\n5129\n\nRight\nRight\nRight\nRight\nRight\nRight\nRight\nRight\n\nFake\nFake\nReal\nReal\nReal\nFake\nReal\nReal\n\n7206\n\nRight\n\nReal\n\n308\n\nRight\n\nReal\n\nTable 1: News sources, number of articles, political alignment, and credibility.\nJournalistic news values refer to journalists‚Äô ‚Äúshared operational understanding that informs the mediated world that\nis presented to news audiences‚Äù (Tandoc Jr, Thomas, and\nBishop 2021). We focused on deviations from journalistic\nnews values (e.g., objectivity, balance) (Tandoc Jr, Thomas,\nand Bishop 2021; Lazer et al. 2018) when identifying relevant features in misinformation detection algorithms.\nIn addition, theories in psychology and social science\n(e.g., social identity theory, four-factor theory, Undeutsch\nhypothesis, information manipulation theory) grounded our\nselection of the features. Undeutsch hypothesis suggests that\nthe factual statement differs from a fabricated or fictitious\nstatement in content style and in quality (Amado, Arce,\nand FarinÃÉa 2015). Information manipulation theory states\nthat extreme information quantity exists in deceptive statements (McCornack 1992). According to the four-factor theory (Zuckerman, DePaulo, and Rosenthal 1981), lies are expressed differently in terms of arousal, emotion, and thinking from the truth. Social identity theory suggested that\nawareness of one‚Äôs group membership justifies maintaining\nsocial distance from the out-group, and this social distance\nis explained by the feeling of less acceptance, trust, or liking\nof the out-group members (Ashforth and Mael 1989). This\nout-group animosity is a powerful predictor of the sharing\n\nof political misinformation. Similarly, in-group favoritism\nis also used in misinformation because individuals tend to\nsee what is favorable to their partisan orientation (Rathje,\nVan Bavel, and van der Linden 2021).\nThese theories helped us consider the difference between\nreliable contents and deceptive contents in terms of linguistic style of the texts (Amado, Arce, and FarinÃÉa 2015;\nMcCornack 1992), subjectivity (Amado, Arce, and FarinÃÉa\n2015), emotional expressions (Zuckerman, DePaulo, and\nRosenthal 1981), and social identity manifestations (Ashforth and Mael 1989).\nFinally, after reviewing the relevant empirical studies, we\nidentified four broad categories of features: structure, subjectivity, sentiment, and social identity. The detailed explanations of the four categories of features are present below:\n1. Structure: this category consists of the features describing the organization of the content into different stylistic\nstructures, such as the syntax, text style, and grammatical\nelements of news content and title. Following the theories\nof the Undeutsch hypothesis and information manipulation theory and an empirical study (Zhou et al. 2020), we\nused features such as ‚Äúnumber of words,‚Äù ‚Äúaverage words\nper sentence,‚Äù and ‚Äúnumber of question marks‚Äù and complexity measures (e.g., Flesch-Kincaid readability index).\nComplexity measures were computed using the Textstat\nPython library, and the other features were computed using LIWC (Pennebaker et al. 2015).\n2. Subjectivity: this category consists of the features that\nprovide evidence of an effort to convey a certain opinion or viewpoint rather than facts. The category of subjectivity was considered as the deviation from the journalistic news value of ‚Äúobjectivity,‚Äù impartially pursuing\nthe evidence and demonstrating faith in ‚Äúfacts‚Äù (Schudson\n1981). Also, Undeutsch hypothesis theoretically grounds\nthat a fictitious statement differs in quality from a true\nstatement. A recent study added empirical evidence to the\ntheory that more than half of the articles published by unreliable news sites contained the personal opinion of the\nauthor(s) (Tandoc Jr, Thomas, and Bishop 2021). Therefore, we used ‚Äúcognitive processes‚Äù (e.g. cause, know,\nought), ‚Äúperceptual processes‚Äù (e.g., look, heard, feeling),\nand ‚Äúinformal language‚Äù (e.g., swear words) categories\nand their subcategories from LIWC 2015 (Pennebaker et\nal. 2015) as the features in this category.\n3. Sentiment: this category refers to the emotion-arousing\naspects of the news stories that contain misinformation.\nTheoretically, lies are expressed differently in terms of\narousal, emotion, and thinking from the truth (Zuckerman, DePaulo, and Rosenthal 1981). Empirically, sentiment features such as positive words, negative words, exclamation marks, and sentiment polarity were used in machine learning algorithms to detect misinformation (Bond\net al. 2017; Zhou et al. 2020). Based on the four-factor\ntheory and the empirical studies, we included the ‚Äúemotional tone‚Äù (i.e., positive, neutral, and negative emotions)\n(Hutto and Gilbert 2014) and ‚Äúaffective processes‚Äù category (e.g., happy, cried) and its subcategories (e.g., anxiety, sadness) from LIWC 2015 (Pennebaker et al. 2015)\n\nas the sentiment feature to detect misinformation.\n4. Social Identity: this category consists of the features that\nreveal the qualities or beliefs that make a particular group\ndifferent from others. Social identity theory (Ashforth and\nMael 1989) and prior literature confirmed that readers\nare more easily persuaded by the use of social identity\nwords, such as second-person pronouns (e.g., you), that\nare unlikely to appear in reliable news articles (Horne\nand Adali 2017; Singh, Ghosh, and Sonagara 2021). Following the theory and the previous literature, we selected\n‚Äúpersonal pronouns‚Äù category and its subcategories from\nLIWC 2015 (Pennebaker et al. 2015), ‚Äúliberal identity\nwords‚Äù (e.g., left-wing, democrat), ‚Äúconservative identity\nwords‚Äù (e.g., right-wing, republican), and ‚Äúmoral words‚Äù\n(e.g., guilt, innocent, blame) from the dictionaries created\nby (Osmundsen et al. 2021).\nTable 2 shows the summary of the features that were used\nin this study. Note that some of the features did not fall exclusively under one category. In this case, we organized the\nfeatures under the most relevant category in the context of\nthe current study. In addition, we computed separate values\nof each feature for the title and the body of the news articles. This is because not only the content of the news articles\nbut also the news titles are a strong factor in distinguishing\nmisinformation from reliable news (Horne and Adali 2017).\nGiven that the news titles are short in length, some structural\nfeatures (e.g., number of paragraphs) were computed only\nfor the body of the news article.\n\nPre-processing and Model Training\nBefore applying any of the machine learning algorithms, the\nmissing values were filled with the median values of corresponding features. To reduce the impact of features with\nhigh variance, features were standardized by centering their\nmean to zero and by scaling them to unit variance.\nThe obtained features were passed to several classification algorithms. Based on a survey of recent literature\non machine learning algorithms for misinformation detection (Singh, Ghosh, and Sonagara 2021; Fang et al. 2019;\nShu et al. 2020), we considered five frequently used algorithms: Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, and Multilayer Perceptron Neural\nNetworks. Each of these was implemented using the Sci-kit\nLearn library (Pedregosa et al. 2011).\nWe split the dataset in a random manner where 80% of the\ndataset was set aside for training the machine learning algorithms and the remaining 20% was utilized as a test-set. The\nsplit is performed in a stratified manner using labels. This\nensures that the proportion of real and fake news articles in\ntrain and test sets are same. We ran all the algorithms for\n100 iterations and the Random Forest approach yielded the\nhighest accuracy (see Table 3; details follow). Since there\nis often a trade-off between accuracy and fairness (i.e., as\nfairness increases, accuracy decreases), the model with the\nhighest accuracy (Random Forest) was picked as the baseline model for further inspection of its fairness towards the\nsensitive feature (i.e., political leaning). The Random Forest\n\nmodel has 100 estimators/number of trees in the forest with\nno limits on the maximum depth of the forest.\n\nAuditing for Bias\nWe selected ‚Äòpolitical leaning‚Äô as the sensitive feature in this\nwork. Given multiple recent claims that media platforms favor articles from politically left-leaning sources in moderation (Cummings 2018; Koebler and Cox 2018), we consider articles from right-aligned sources to be the unprivileged group when empirically auditing the algorithms for\nbias. Note that this sensitive feature is not part of the training data but is used at test time to compute various fairness\nmetrics.\nThere are multiple interpretations of algorithmic fairness\nsuch as maximizing utility for groups or respecting various\nrules such as individual rights and freedoms (Duster 1996).\nIn the current study, we follow John Rawl‚Äôs interpretation\nof distributive justice which equates fairness and justice, arguing broadly that fairness is ‚Äúa demand for impartiality‚Äù\n(Rawls 1999). In other words, the algorithm should yield\nsimilar outcomes for different groups irrespective of their\ndemographic description. Focusing on the notion of distributive justice, we consider an algorithm to be fair if its performance does not vary for news articles from the politically\nleft- and right-aligned news sources.\nThere exist at least two different interpretations within\nthe above mentioned distributive justice paradigm to quantify bias. One approach focuses on equal predictive performance, i.e., an equal ability to identify the ‚Äúground truth‚Äù labels for the two classes. We consider one such metric: delta\naccuracy, in this work. It is easy to interpret and follows naturally from the traditional accuracy metric, which remains\nan unquestionable goal for any classification system.\nThe other interpretation focuses on the concept of ‚Äúdisparate impact,‚Äù i.e., when a facially neutral practice has an\nunjustified adverse impact on members of a protected class\n(Civil Rights Act 1964). This approach questions the validity of past ‚Äúground truth‚Äù data that is used to train algorithms. For instance, while using SAT scores to decide on\ncollege admissions may ‚Äúappear‚Äù to be objectively fair, it is\nnear impossible to tease apart the impact of systemic injustices which yield poorer SAT scores for under-represented\nminorities. Hence, irrespective of the learning data and the\nlearning process, this interpretation would require that different demographic groups have equal probability of positive outcomes. In fact, in the US legal system, a process is\nconsidered biased, irrespective of the intent of the designers,\nif there is less than 0.8 under-representation in the probability of positive outcome for a demographic group (Civil\nRights Act 1964; Feldman et al. 2015). We consider two related metrics based on this line of reasoning: disparate impact and statistical parity difference, in this work.\nDelta accuracy Delta accuracy indicates the difference in\nthe accuracy of samples belonging to the privileged and unprivileged groups. If delta accuracy is not zero, it means that\nthe algorithm is classifying more accurately on one group of\nsamples than on the other.\n‚àÜacc = acc(S = unprivileged) ‚àí acc(S = privileged)\n\n(1)\n\nTypes of Features\n\nFeatures\n\nTheoretical Support\n\nEmpirical Support\n\nStructure\n\nTitle and Body: Number of words, Number of nouns,\nNumber of verbs, Number of Adverbs, Number of Exclamation marks, Number of question marks, Number\nof quotation marks, complexity\nBody only: Number of sentences, Number of paragraphs, Average sentences per paragraph, Average\nwords per sentence, Average punctuation per sentence,\nAverage characters per word\nCognitive processes, Perceptual processes, Informal\nlanguage\nAffective processes, Positive/Neutral/Negative sentiment\nPersonal pronouns, moral words, liberal identity words,\nconservative identity words\n\nUndeutsch Hypothesis\n(Amado et al., 2015), Information Manipulation\nTheory\n(McCornack,\n1992)\n\nZhou et al., 2020, Horne\n&amp; Adali, 2017\n\nUndeutsch Hypothesis\n(Amado et al., 2015)\nFour-factor\ntheory\n(Zuckerman, 1981)\nSocial Identity Theory\n(Ashforth, 1989)\n\nTandoc et al., 2021\n\nSubjectivity\nSentiment\nSocial Identity\n\nBond et al., 2017, Zhou et\nal., 2020\nSingh et al., 2020, Rathje\net al., 2021\n\nTable 2: Summary of features that were used to build machine learning models\nwhere acc is accuracy and S is the sensitive feature.\nDisparate impact Disparate impact (DI) captures the ratio\nof the probability of favorable outcomes being assigned by\nthe algorithm for the unprivileged group compared to that\nof the privileged group. Ideally, the value of the disparate\nimpact needs to be 1.0.\np(YÃÇ = 1|S = unprivileged)\np(YÃÇ = 1|S = privileged)\n\n(2)\n\nStatistical parity difference Statistical parity difference\n(SPD) calculates the difference in the probability of favorable outcomes obtained by the unprivileged group to that of\nthe privileged group. A favorable outcome in the considered\nsetting would be to get assigned a ‚Äúreal‚Äù label (as opposed to\na ‚Äúfake‚Äù label) for the news article. For an ideal fair model,\nthe statistical parity difference is expected to be zero.\nSP D = p(YÃÇ = 1|S = unprivileged) ‚àí p(YÃÇ = 1|S = privileged) (3)\n\nFollowing recent literature on fairness in machine learning, bias audit was undertaken via a statistical t-test on the\nmeans of the abovementioned fairness metrics for the two\n(left-aligned and right-aligned) groups (Alasadi, Al Hilli,\nand Singh 2019; Singh and Hofenbitzer 2019).\n\nan instance X closer to 1 or 0, assigns the label with confidence. However, if the same classifier predicts the posterior\nprobability closer to 0.5, it gets into the dilemma of deciding the appropriate label. If an instance belonging to the unprivileged group lies in the critical region, then that label is\nassigned a positive label (Y + ), otherwise, it is assigned a\nnegative label (Y ‚àí ). The rest of the instances belonging to\nthe unprivileged group that lie outside the critical region are\nclassified as per usual; meaning that if the posterior probability of P(Y + |X) is greater than P(Y ‚àí |X), then the instance\nis classified as positive, otherwise, it is classified as negative.\nUsing the IBM AIF360 library (Bellamy et al. 2018), we\nimplemented the ROC algorithm (optimization metric = statistical parity difference) and ran the classification algorithm\n100 times with each iteration having a shuffled version of the\ndataset.\nNote that a classification algorithm is considered to have\nbecome less biased if there are changes in the metrics for\nbias defined above. Specifically, a less biased algorithm will\nyield reduced delta accuracy and statistical parity difference,\nand the disparate impact score will get closer to 1.0.\n\nResults\n\nBias Reduction Approach\n\nMisinformation Classification Results with\nDifferent Algorithms\n\nReject Option Classification (ROC) proposed by (Kamiran\net al. 2018), was used as a bias reduction approach in this\nstudy. ROC is a post-processing algorithm that makes the\npre-trained classifier discrimination-aware at the time of prediction. It is useful for a broad range of applications (Kamiran et al. 2018; Iqbal, Karim, and Kamiran 2019), as it does\nnot require any changes in the classification algorithm, nor\ndoes it amend or pre-process the dataset before applying the\nclassification algorithm.\nROC labels the instances from the unprivileged groups\nthat lie in the critical region (i.e., near the decision boundary\nin which labels are difficult to identify) as desirable labels.\nSimilarly, the instances belonging to privileged groups that\nlie in the critical region are assigned an undesirable label. A\nclassifier that predicts the posterior probability p(Y|X) for\n\nTable 3 summarizes the average results obtained after 100\nrounds of experiments for the different algorithms considered. As can be seen, the best performing automated machine learning algorithm (Random Forest) achieved 87.85%\naccuracy at automatically classifying the credibility of the\nnews article. Random Forests outperforming other algorithms is consonant with trends reported in the past literature, and the obtained accuracy results are also within\nthe range reported in the current state of the art in misinformation detection (Singh, Ghosh, and Sonagara 2021;\nZhou and Zafarani 2020).\nThe three most predictive features for the classification\nalgorithm remained consistent over the 100 iterations. They\nwere the neutrality (sentiment) of the article, the number of\nwords in the title, and the number of words in the article.\n\nThe mean values for these features for the four groups:\nleft+true, right+true, left+false, and right+false are shown\nin Figure 1. The differences in the values for these features\nacross true and false news appear to be different depending\non the political leaning of the article. For instance, while\nright+true articles were more neutral toned than left+true articles, right+false articles were less neutral toned than the\nleft+false articles. Similar transposition occurs in the case of\n‚Äúnumber of words in news articles,‚Äù while the effect is less\npronounced in the case of ‚Äúnumber of words in title.‚Äù These\nresults suggest that political leaning can play an important\nrole in mediating the production of misinformation.\n\n-25.29% to -3.86%. Both these changes were large improvements in terms of fairness and were found to be statistically\nsignificant based on a t-test (p-values &lt; .001).\nAt the same time, there was a modest dip in overall accuracy from 87.85% to 82.67%. There was also a small increase in the absolute value of delta accuracy from 1.36% to\n1.98%. However, given that accuracy stays above 80% and\ndelta accuracy stays below 2%, we consider these changes to\nbe reasonable trade-offs for the much bigger improvements\nobtained in terms of the DI and SPD fairness metrics.\n\nAuditing Misinformation Detection Algorithms for\nPolitical Bias\n\nThis study reported on the performance of the misinformation detection algorithm in terms of the political leaning of\nthe news source and the potential to reduce the discriminatory performance of the algorithm using the ROC technique.\nThe first research question in this work was: (RQ1) Are\nmisinformation detection algorithms susceptible to bias in\nterms of political leaning?\nAs shown in Table 3, the results indicated that the multiple misinformation classification algorithms performed differently based on political leaning of the news source. While\nthe differences in terms of delta accuracy were small (&lt;4%),\nthere were noticeable differences in terms of Disparate Impact and Statistical Parity Difference.\nWhile prior literature motivated an audit on the relative\nperformance of misinformation detection algorithms across\npolitical left and right, the precise nature of bias found was\nunexpected. The bias was found to be lot more noticeable\nin terms of some metrics (DI, SPD) and not as noticeable or\nconsistent in terms of others (delta accuracy). This motivates\nfuture work with more fine-tuned hypothesis development in\nthe space of algorithmic bias in political information.\nA potential reason for the observed difference in the probabilities of the positive outcome for left and right might lie\nin the skew present in the dataset used. This work used one\nof the largest datasets available for this analysis (&gt; 100k articles with labels for political leaning and true/false news),\nbut the ‚Äúground truth‚Äù labels had a nearly 80% higher probability of true labels for the left leaning articles.\nThis could partially be a function of the reported higher\nprevalence of fake news on right leaning channels (Faris et\nal. 2017). At the same time, conservatives already are concerned about bias in political fact-checks (Shin and Thorson 2017), content moderation (Usher 2018), and platform\nregulation (Darcy 2021). For instance, the suspension of the\n(then) US President Donald Trump from Facebook was considered unfair by multiple stakeholders, and underscores the\nneed to build approaches that are fair and auditable by thirdparties (Darcy 2021). Hence, it is unlikely that the conservative population will be accepting of a fake news detector\nthat has a noticeable higher probability of assigning positive\noutcomes for left-leaning articles. In fact, the value of wellcreated algorithms lies in being able to create equitable algorithms despite having to work with skewed datasets. This\nis a challenge, and multiple bias reduction approaches have\nbeen proposed in recent literature (Bellamy et al. 2018).\nThe second research question in this work was: (RQ2)\n\nThe accuracy levels achieved with different algorithms when\nfocusing only on the left-aligned and right-aligned sources,\nand the delta between them, are also shown in Table 3. As\ncan be seen, the level of accuracy varied across algorithms\nbut there was no clear trend of the accuracy being better for\nthe left-leaning or right leaning articles. The accuracy was\nhigher for right-leaning articles when using two algorithms\nwhile it was lower in other three algorithms. Importantly, all\nsuch differences were below 4%.\nOn the other hand, we found a strong deviation from the\nideal values of 1.0 and 0% respectively in terms of Disparate Impact and Statistical Parity Difference metrics. The\nDI scores were consistently below the legally required level\nof 0.8, indicating that the unprivileged group (political right)\nhad significantly lower odds of getting a positive label from\nthe algorithm. A statistical t-test comparing the obtained DI\nvalues with the ideal value of 1.0 showed that the results\nwere statistically significantly different from the ideal values (p-values &lt; .001) for all five algorithms.\nThe trends were similar in terms of Statistical Parity Difference. All five algorithms provided noticeably lower probability of positive outcomes for the political right (values\nranged from -16% to -25%). The observed SPD values were\nstatistically significantly different from the ideal value of 0\n(p-values &lt; .001) for all five algorithms.\nIn summary, while there were minor differences in terms\nof accuracy across left and right, there were significant differences between the odds of a positive outcome being assigned to a news article based on its political leaning. These\nresults will not be able to meet the legal standards of parity\nexpected (Feldman et al. 2015) and hence, it is important to\nreduce this bias.\n\nReducing Algorithmic Bias in Misinformation\nDetection\nWe utilized the ROC post-processing method for bias reduction and the various fairness metrics after that process are\nreported in Table 4. For comparison, the results before bias\nreduction are also presented.\nThe most noticeable differences were those in Disparate\nImpact and Statistical Parity Difference fairness metrics. For\nDisparate Impact (ideal value = 1.000), the value moved\nfrom 0.6038 (before) to 0.9340 (after). For Statistical Parity Difference (ideal value = 0%), the value changed from\n\nDiscussion\n\nFigure 1: Average values for the four groups (true+right, true+left, false+right, false+left) for the three most predictive features\nin the misinformation classifier.\nMethod\n\nAccuracy\n\nRandom Forest\nDecision Tree\nLogistic Regression\nMulti Layer Perceptron\nSupport Vector Machine\n\n87.85%\n81.05%\n63.89%\n78.30%\n64.04%\n\nLeft Accuracy\n86.98%\n82.19%\n61.49%\n79.47%\n62.05%\n\nRight Accuracy\n88.34%\n80.40%\n65.27%\n77.62%\n65.19%\n\nDelta Accuracy\n-1.36%\n1.79%\n3.78%\n1.86%\n-3.14%\n\nDisparate\nImpact\n0.6038\n0.6485\n0.7319\n0.6709\n0.7437\n\nStat. Parity\nDifference\n-25.29%\n-22.86%\n-16.06%\n-20.93%\n-15.56%\n\nTable 3: The average accuracy and fairness levels for various models used for misinformation detection after 100 iterations.\nMetric\nAccuracy\nDelta Accuracy\nDisparate Impact\nStatistical Parity Difference\n\nIdeal Value\n100.00%\n0.00%\n1.0000\n0.00%\n\nBefore Bias Reduction\n87.85%\n-1.36%\n0.6038\n-25.29%\n\nAfter Bias Reduction\n82.67%\n-1.98%\n0.9340\n-3.86%\n\nTable 4: Comparison of delta accuracy, statistical parity difference and disparate impact before and after bias reduction processing. Average values after 100 iterations using Random Forest classifier.\nCan the level of bias in misinformation detection algorithms\nbe reduced while maintaining accuracy?\nBased on the observation in the considered dataset, we\nfound that the ROC bias-reduction approach is effective in\nreducing the disparity in the performance of misinformation\ndetection algorithms across the political leaning of the news\nsource. As shown in Table 4, in terms of DI and SPD (the\nfairness metrics with noticeable issues in the before condition), there was a noticeable improvement in fairness upon\napplying the ROC bias-reduction approach, and the level of\naccuracy was still above 80%. Given that the trade-offs between fairness and accuracy are common in similar studies, a\nmodest decrease in accuracy with significant improvements\nin bias reduction was considered reasonable (Pessach and\nShmueli 2020).\nTo increase public confidence in misinformation detection practices and subsequent corrections, it is critical to establish fairness in misinformation detection algorithms, toward which this study makes an important first contribution.\nMoreover, improving the fairness of misinformation detection algorithms helps ensure that the practices used to deter\nthe spread of misinformation are not inadvertently exacerbating existing asymmetries in the political media environment or introducing new ones.\nThe current work has some limitations. It focused on\nsource-level labels for misinformation and political leaning. Yet not all articles published by a particular source\n\nare uniformly reliable vs. unreliable (MouraÃÉo and Robertson 2019) or conservative-leaning vs. liberal-leaning. In future research, it will be important to explore and extend these\nresults by developing article-level labels. Also, we acknowledge that there are other approaches to build misinformation algorithms and reduce bias than discussed in this work.\nFor instance, going beyond textual features, the misinformation detection algorithms can also use image features or networked propagation features for improving accuracy. Hence,\nthe work undertaken cannot be considered a final word in\nthis space. Rather, its contribution lies in motivating and\ngrounding a new research direction: political bias audit for\nmisinformation detection algorithms and identifying ways to\nreduce such bias.\n\nConclusion\nThis paper grounds the use of political-leaning as a sensitive\nfeature to study fairness in misinformation classification algorithms. The audit of the existing misinformation classification algorithm revealed that the probability of obtaining a\npositive outcome from the algorithm varied significantly depending on the political leaning. This disparity in the performance was found to be reduced noticeably after the application of a bias reduction algorithm (ROC) without modifying\nthe discriminatory data or tweaking a specific classification\nalgorithm. The results significantly move forward the literature on misinformation classification, particularly with po-\n\nlitical leaning as a sensitive feature. Future work could consider reducing bias in misinformation detection algorithms\nat the article-level, and a newer approach to creating fair\nand accurate misinformation news classification algorithms\nto develop and maintain trustworthy online environments.\nThe results also have implications for our understanding\nof political media. The disparity in the algorithm‚Äôs performance points to potential differences in the structure and\nfeatures of conservative versus liberal fake news articles\nand/or in their overlap with traditional news. This offers an\nimportant area for future research in media and journalism\nstudies.\n\nReferences\nAlasadi, J.; Al Hilli, A.; and Singh, V. K. 2019. Toward\nfairness in face matching algorithms. In Proceedings of the\n1st International Workshop on Fairness, Accountability, and\nTransparency in MultiMedia, 19‚Äì25.\nAllcott, H., and Gentzkow, M. 2017. Social media and fake\nnews in the 2016 election. Journal of economic perspectives\n31(2):211‚Äì36.\nAmado, B. G.; Arce, R.; and FarinÃÉa, F. 2015. Undeutsch hypothesis and criteria based content analysis: A meta-analytic\nreview. The European Journal of Psychology Applied to Legal Context 7(1):3‚Äì12.\nAshforth, B. E., and Mael, F. 1989. Social identity theory and\nthe organization. Acad. of management review 14(1):20‚Äì39.\nBabaei, M.; Kulshrestha, J.; Chakraborty, A.; Redmiles,\nE. M.; Cha, M.; and Gummadi, K. P. 2021. Analyzing biases in perception of truth in news stories and their implications for fact checking. IEEE Transactions on Computational\nSocial Systems.\nBellamy, R. K.; Dey, K.; Hind, M.; Hoffman, S. C.; Houde,\nS.; Kannan, K.; Lohia, P.; Martino, J.; Mehta, S.; Mojsilovic,\nA.; et al. 2018. Ai fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic\nbias. arXiv preprint arXiv:1810.01943.\nBond, G. D.; Holman, R. D.; Eggert, J.-A. L.; Speller, L. F.;\nGarcia, O. N.; Mejia, S. C.; Mcinnes, K. W.; Ceniceros, E. C.;\nand Rustige, R. 2017. ‚Äòlyin‚Äôted‚Äô,‚Äòcrooked hillary‚Äô, and ‚Äòdeceptive donald‚Äô: Language of lies in the 2016 us presidential\ndebates. Applied Cognitive Psychology 31(6):668‚Äì677.\nBuolamwini, J., and Gebru, T. 2018. Gender shades: Intersectional accuracy disparities in commercial gender classification. In Conference on fairness, accountability and transparency, 77‚Äì91. PMLR.\nCalmon, F.; Wei, D.; Vinzamuri, B.; Ramamurthy, K. N.; and\nVarshney, K. R. 2017. Optimized pre-processing for discrimination prevention. In Advances in Neural Information\nProcessing Systems, 3992‚Äì4001.\nCivil Rights Act. 1964. Civil Rights Act of 1964. Title VII,\nEqual Employment Opportunities.\nConroy, N. K.; Rubin, V. L.; and Chen, Y. 2015. Automatic\ndeception detection: Methods for finding fake news. Proceedings of Association for Information Science and Technology\n52(1):1‚Äì4.\n\nCummings, W. 2018. Diamond and silk tell congress, ‚Äòfacebook censored our free speech!,‚Äô. USA Today. Available online: https://bit.ly/3r6FsJp.\nDarcy, O.\n2021.\nRepublicans and right-wing\nmedia use facebook oversight board‚Äôs trump decision to claim bias.\nCNN.\nAvailable online:\nhttps://www.cnn.com/2021/05/05/media/facebook-oversightboard-trump-right-wing-reaction/index.html.\nDuster, T. 1996. Individual fairness, group preferences, and\nthe california strategy. Representations 55:41‚Äì58.\nFang, Y.; Gao, J.; Huang, C.; Peng, H.; and Wu, R. 2019. Self\nmulti-head attention-based convolutional neural networks for\nfake news detection. PloS one 14(9):e0222713.\nFaris, R.; Roberts, H.; Etling, B.; Bourassa, N.; Zuckerman,\nE.; and Benkler, Y. 2017. Partisanship, propaganda, and disinformation: Online media and the 2016 us presidential election. Berkman Klein Center Research Publication 6.\nFeldman, M.; Friedler, S. A.; Moeller, J.; Scheidegger, C.; and\nVenkatasubramanian, S. 2015. Certifying and removing disparate impact. In Proc. ACM SIGKDD international conference on knowledge discovery and data mining, 259‚Äì268.\nGreenhill, K. M., and Oppenheim, B. 2017. Rumor has it:\nThe adoption of unverified information in conflict zones. International Studies Quarterly 61(3):660‚Äì676.\nGrinberg, N.; Joseph, K.; Friedland, L.; Swire-Thompson, B.;\nand Lazer, D. 2019. Fake news on twitter during the 2016 us\npresidential election. Science 363(6425):374‚Äì378.\nGuess, A. M.; BarberaÃÅ, P.; Munzert, S.; and Yang, J. 2021.\nThe consequences of online partisan media. Proceedings of\nthe National Academy of Sciences 118(14).\nHorne, B., and Adali, S. 2017. This just in: Fake news packs a\nlot in title, uses simpler, repetitive content in text body, more\nsimilar to satire than real news. In Proceedings of the AAAI\nConference on Web and Social Media, volume 11.\nHorne, B. D.; Dron, W.; Khedr, S.; and Adali, S. 2018. Assessing the news landscape: A multi-module toolkit for evaluating the credibility of news. In Companion Proceedings of\nthe The Web Conference 2018, 235‚Äì238.\nHutto, C., and Gilbert, E. 2014. Vader: A parsimonious rulebased model for sentiment analysis of social media text. In\nProceedings of the International AAAI Conference on Web\nand Social Media, volume 8.\nIqbal, M.; Karim, A.; and Kamiran, F. 2019. Balancing prediction errors for robust sentiment classification. ACM Trans.\non Knowledge Discovery from Data (TKDD) 13(3):1‚Äì21.\nJiang, S.; Robertson, R. E.; and Wilson, C. 2020. Reasoning\nabout political bias in content moderation. In Proceedings\nof the AAAI Conference on Artificial Intelligence, volume 34,\n13669‚Äì13672.\nJost, J. T., and Krochik, M. 2014. Ideological differences\nin epistemic motivation: Implications for attitude structure,\ndepth of information processing, susceptibility to persuasion,\nand stereotyping. In Advances in motivation science, volume 1. Elsevier. 181‚Äì231.\nJost, J. T.; Stern, C.; Rule, N. O.; and Sterling, J. 2017. The\npolitics of fear: Is there an ideological asymmetry in existential motivation? Social cognition 35(4):324‚Äì353.\n\nKamiran, F.; Mansha, S.; Karim, A.; and Zhang, X. 2018.\nExploiting reject option in classification for social discrimination control. Information Sciences 425:18‚Äì33.\nKamishima, T.; Akaho, S.; Asoh, H.; and Sakuma, J. 2012.\nFairness-aware classifier with prejudice remover regularizer.\nIn Joint European Conference on Machine Learning and\nKnowledge Discovery in Databases, 35‚Äì50. Springer.\nKoebler, J., and Cox, J.\n2018.\nThe impossible job: Inside facebook‚Äôs struggle to moderate two billion people - motherboard.\nMotherboard.\nAvailable online.https://motherboard.\nvice.com/en_us/article/xwk9zd/\nhow-facebook-content-moderation-works.\nLazer, D. M.; Baum, M. A.; Benkler, Y.; Berinsky, A. J.;\nGreenhill, K. M.; Menczer, F.; Metzger, M. J.; Nyhan, B.;\nPennycook, G.; Rothschild, D.; et al. 2018. The science of\nfake news. Science 359(6380):1094‚Äì1096.\nLepri, B.; Oliver, N.; LetouzeÃÅ, E.; Pentland, A.; and Vinck, P.\n2018. Fair, transparent, and accountable algorithmic decisionmaking processes. Philosophy &amp; Technology 31(4):611‚Äì627.\nMcCornack, S. A. 1992. Information manipulation theory.\nCommunications Monographs 59(1):1‚Äì16.\nMouraÃÉo, R. R., and Robertson, C. T. 2019. Fake news as\ndiscursive integration: An analysis of sites that publish false,\nmisleading, hyperpartisan and sensational information. Journalism Studies 20(14):2077‚Äì2095.\nNapier, J. L.; Huang, J.; Vonasch, A. J.; and Bargh, J. A. 2018.\nSuperheroes for change: Physical safety promotes socially\n(but not economically) progressive attitudes among conservatives. European Journal of Social Psychology 48(2):187‚Äì195.\nN√∏rregaard, J.; Horne, B. D.; and Adalƒ±, S. 2019. Nela-gt2018: A large multi-labelled news dataset for the study of\nmisinformation in news articles. In Proceedings of the International AAAI Conference on Web and Social Media, volume 13, 630‚Äì638.\nO‚Äôneil, C. 2016. Weapons of math destruction: How big data\nincreases inequality and threatens democracy. Crown.\nOsmundsen, M.; Bor, A.; Vahlstrup, P. B.; Bechmann, A.; and\nPetersen, M. B. 2021. Partisan polarization is the primary\npsychological motivation behind political fake news sharing\non twitter. Am. Political Science Review 115(3):999‚Äì1015.\nPedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.;\nThirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss,\nR.; Dubourg, V.; Vanderplas, J.; Passos, A.; Cournapeau, D.;\nBrucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikitlearn: Machine learning in Python. Journal of Machine\nLearning Research 12:2825‚Äì2830.\nPennebaker, J. W.; Boyd, R. L.; Jordan, K.; and Blackburn,\nK. 2015. The development and psychometric properties of\nliwc2015. Technical report.\nPessach, D., and Shmueli, E. 2020. Algorithmic fairness.\narXiv preprint arXiv:2001.09784.\nPotthast, M.; Kiesel, J.; Reinartz, K.; Bevendorff, J.; and\nStein, B. 2017. A stylometric inquiry into hyperpartisan and\nfake news. arXiv preprint arXiv:1702.05638.\nRathje, S.; Van Bavel, J. J.; and van der Linden, S. 2021. Outgroup animosity drives engagement on social media. Proceedings of the National Academy of Sciences 118(26).\n\nRawls, J. 1999. A theory of justice: Revised edition. Harvard\nuniversity press.\nRaza, S.; Reji, D. J.; and Ding, C. 2022. Dbias: Detecting\nbiases and ensuring fairness in news articles. International\nJournal of Data Science and Analytics 1‚Äì23.\nSchudson, M. 1981. Discovering the news: A social history\nof American newspapers. Basic books.\nShin, J., and Thorson, K. 2017. Partisan selective sharing:\nThe biased diffusion of fact-checking messages on social media. Journal of Communication 67(2):233‚Äì255.\nShoemaker, P. J., and Vos, T. 2009. Gatekeeping theory.\nRoutledge.\nShu, K.; Mahudeswaran, D.; Wang, S.; Lee, D.; and Liu, H.\n2020. Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake\nnews on social media. Big Data 8(3):171‚Äì188.\nSingh, V. K., and Hofenbitzer, C. 2019. Fairness across network positions in cyberbullying detection algorithms. In 2019\nIEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining (ASONAM), 557‚Äì559. IEEE.\nSingh, V. K.; Ghosh, I.; and Sonagara, D. 2021. Detecting\nfake news stories via multimodal analysis. Journal of the Assoc. for Information Science and Technology 72(1):3‚Äì17.\nSitaula, N.; Mohan, C. K.; Grygiel, J.; Zhou, X.; and Zafarani,\nR. 2020. Credibility-based fake news detection. In Disinformation, Misinformation, and Fake News in Social Media.\nSpringer. 163‚Äì182.\nTandoc Jr, E. C.; Thomas, R. J.; and Bishop, L. 2021. What\nis (fake) news? analyzing news values (and more) in fake stories. Media and Communication 9(1):110‚Äì119.\nUsher, N. 2018. How republicans trick facebook and twitter\nwith claims of bias. The Washington Post. Available online:\nhttps://wapo.st/3Jk7NSU.\nVosoughi, S.; Roy, D.; and Aral, S. 2018. The spread of true\nand false news online. Science 359(6380):1146‚Äì1151.\nWardle, C., and Derakhshan, H. 2017. Information disorder: Toward an interdisciplinary framework for research and\npolicy making. Council of Europe report 27.\nYoung, D. G. 2019. Irony and outrage: The polarized landscape of rage, fear, and laughter in the United States. Oxford\nUniversity Press, USA.\nZhou, X., and Zafarani, R. 2020. A survey of fake news:\nFundamental theories, detection methods, and opportunities.\nACM Computing Surveys (CSUR) 53(5):1‚Äì40.\nZhou, X.; Jain, A.; Phoha, V. V.; and Zafarani, R. 2020. Fake\nnews early detection: A theory-driven model. Digital Threats:\nResearch and Practice 1(2):1‚Äì25.\nZihni, E.; Madai, V. I.; Livne, M.; Galinovic, I.; Khalil, A. A.;\nFiebach, J. B.; and Frey, D. 2020. Opening the black box\nof artificial intelligence for clinical decision support: A study\npredicting stroke outcome. Plos one 15(4):e0231166.\nZuckerman, M.; DePaulo, B. M.; and Rosenthal, R. 1981.\nVerbal and nonverbal communication of deception. In Adv. in\nexperimental social psychology, volume 14. Elsevier. 1‚Äì59.\n\n</td>
    </tr>
    <tr>
      <th>49</th>
      <td>news</td>
      <td>DS4RRS Workshop                                                                   KDD ‚Äô22, August 14‚Äì18, 2022, Washington DC, USA.\n\n\n\n           An Approach to Ensure Fairness in News Articles\n              Shaina Raza                                  Deepak John, Reji                                  Dora D. Liu\n            University of Toronto                 Environmental Resources Management                DeepBlue Academy of Sciences\n             Toronto, Canada                                Bangalore, India                                   China\n    Shaina.raza@utoronto.ca                             deepak.reji@erm.com                      liudongmei_0506@163.com\n\n                           Syed Raza, Bashir                                                   Usman Naseem\n                        Toronto Metropolitan University                                     The University of Sydney,\n                               Toronto, Canada                                                  Sydney, Australia\n                    syedraza.bashir@ryerson.ca                                     usman.naseem@sydney.edu.au\n\nABSTRACT                                                                 data with little or no control over the quality of training data [25].\n                                                                         Research [18] shows that it is highly important to eliminate these\nRecommender systems, information retrieval, and other\n                                                                         biases early in the data gathering process, before they enter the\ninformation access systems present unique challenges for\n                                                                         system and are reinforced by model predictions, resulting in\nexamining and applying concepts of fairness and bias mitigation\n                                                                         biases in the model decisions. [7,17].\nin unstructured text. This paper introduces Dbias\n(https://pypi.org/project/Dbias/), which is a Python package to          Bias and fairness are hot topics both in academia and industry.\nensure fairness in news articles. Dbias is a trained Machine             Recently, some comprehensive surveys have emerged on these\nLearning (ML) pipeline that can take a text (e.g., a paragraph or        topics, shedding light on the source(s) of bias and potential\nnews story) and detects if the text is biased or not. Then, it detects   solutions [17,21,30]. Bias can be, conventionally, defined as an\nthe biased words in the text, masks them, and recommends a set of        anomaly in the data or output of an ML algorithm caused by\nsentences with new words that are bias-free or at least less biased.     prejudiced assumptions [17], such as related to gender, race,\nWe incorporate the elements of data science best practices to            demographics, economic status, or religion [17]. Bias in natural\nensure that this pipeline is reproducible and usable. We show in         language processing (NLP) [5], generally, refers to harmful\nexperiments that this pipeline can be effective for mitigating           prejudices against certain groups expressed as toxic or offensive\nbiases and outperforms the common neural network architectures           words [2,5,11]. The goal of fairness is to identify and mitigate the\nin ensuring fairness in the news articles.                               effects of various biases [20], as well as to build ML models to\n                                                                         prevent repeating human and societal biases or adding new biases.\nCCS Concepts                                                             In this work, we aim to eliminate biases in the text data.\n‚Ä¢ Information systems ‚Üí Information retrieval ‚Ä¢ Information              According to research [2,24,27], news media can be extremely\nsystems applications ‚Üí Data mining ‚Üí Computing                           biased, and biased news can result in ‚Äúfilter bubbles‚Äù or ‚Äúecho\nmethodologies ‚Üí Machine learning                                         chambers‚Äù [6,25], which may lead to a lack of understanding of\n                                                                         specific issues and a narrow, one-sided perspective. This\nKeywords                                                                 motivates us to train Dbias to counteract media bias. We\n                                                                         summarize our contributions as:\nBiases, Fairness, Transformer, Deep               neural    network,\nClassification, Masked language modelling.                               (1) We develop a fair ML pipeline, which we name as Dbias (de-\n                                                                         biasing). This pipeline consists of multiple sequential steps that\n1. INTRODUCTION                                                          perform bias detection, bias recognition, and bias mitigation tasks,\nInformation retrieval, recommendation systems and information            as well as recommend bias-free information.\naccess systems are often trained on a large text corpus which may        (2) We make Dbias available as a python package that includes\nintroduce biases into the models. These biases can arise in a            documentation, usage, and tutorials to assist data scientists and\nvariety of contexts, including observations that comprise the data,      practitioners in integrating this package into their work products.\ntraining, development, evaluation, and application of the\nunderlying models [21]. Data-centric systems, like news                  (3) Dbias is released as a reusable and self-contained pipeline that\nrecommender systems, are also trained on massive amounts of              has its algorithms for detecting and mitigating biases. This makes\n                                                                         it different from existing fair ML pipelines [1,3,4,28], which use\n                                                                         off-the-shelf bias detection or bias mitigation models. We develop\n KDD 2022 Workshop on Data Science and Artificial Intelligence\n for Responsible Recommendations (DS4RRS), August 14‚Äì18, 2022,           this pipeline according to the widely accepted data science\n Washington DC, United States.                                           pipeline structure [12], so this pipeline is reusable. The only\n                                                                         requisite is to train the model on domain-specific data.\n                                                                         The rest of the paper is organized as: Section 2 is the proposed\n                                                                         approach. Section 3 is experiments and results. Section 4 is the\n                                                                         conclusion.\nDS4RRS Workshop                                                                   KDD ‚Äô22, August 14‚Äì18, 2022, Washington DC, USA.\n\n\n\n\n                                            Figure 1: Dbias, a fair ML pipeline and its workflow\n\n\n2. PROPOSED APPROACH                                                     2.3.1 Bias Detection\n                                                                         This is the first module in the Dbias pipeline, as shown in Figure\n2.1 Problem Definition                                                   2. We use the DistilBert (a distilled version of BERT) and fine-\nGiven a collection of news articles that may contain a variety of        tune it on the MBIC dataset. For binary classification, we use\nbiases, the objective is to detect, recognize, and eliminate these       binary-cross entropy loss [19] with a sigmoid activation function.\nbiases from the data. The goal is to enable end-users to shift           The output from the bias detection model is a set of news articles\nseamlessly from raw data that may be biased to a fair model.             that are classified as biased or non-biased.\nNext, we explain each phase of the Dbias pipeline.\n\n2.2 Data\nIn this work, we primarily use MBIC ‚Äì A Media Bias Annotation\nDataset [27], which consists of news articles from different news\nsources (HuffPost, MSNBC, USA Today and others). We use the\nextended version of MBIC dataset1 containing thousands of\nrecords, with both biased and non-biased sentences. In the original\ndataset, these biases are identified through crowdsourcing. We\nidentified more biases (these biases are related to gender, race,\nethnicity, education, religion, language) from the literature [11,15]\nand also added some biases manually. The dataset features used in\nthis work are news snippet; URL; news source; topic; age; gender;\neducation; biased words and label.\n\n2.3 Methodology                                                                          Figure 2: Bias detection module\nThe specific tasks to perform in this work are:\nBias detection: To detect whether a news article is biased or not.       2.3.2 Bias Recognition\nBias recognition: To recognize the biased words/ phrases in news.        The second module in the Dbias pipeline is the bias recognition\nBias masking: To mask (hide) the biased words.                           module. This task is different from the bias detection task that\nDe-biasing: To de-bias the data by replacing the biased words            takes a whole news or sentence and classifies if it is biased or not.\nwith the unbiased or less biased word(s).                                In bias recognition, we use the named entity recognition task of\n                                                                         NLP to identify the biased words from the text.\n1\n    https://zenodo.org/record/5861846#.YoT6wajMK5d\nDS4RRS Workshop                                                                   KDD ‚Äô22, August 14‚Äì18, 2022, Washington DC, USA.\n\n\n\nThis module takes as input a set of news articles that have been         In our work, we only mask those words that have been flagged as\nidentified as biased in the preceding module (bias detection), and       biased by the previous bias recognition module. We propose a\noutputs a set of news articles with biased words that are identified     unique mask shifting technique that can mask and unmask more\nand recognized. For example, the news ‚ÄúDon't buy the pseudo-             than one token at a time in a sentence. For example, as shown in\nscientific hype about tornadoes and climate change‚Äù has been             Figure 4, we see that both instances are processed sequentially via\nclassified as biased by the preceding bias detection module, and\n                                                                         the mask shifting technique, and each masked token is filled one\nthe biased recognition module can now identify the term ‚Äúpseudo-\nscientific hype‚Äù as a biased word.                                       at a time before the final sentence is constructed.\n                                                                         Fairness infilling: we propose a fairness infilling stage, which can\n                                                                         be considered as generalizing the cloze task (Wu et al. 2019) from\n                                                                         single tokens to spans of unknown length. Our assumption behind\n                                                                         this fairness filling is that the new words that are filled in are less\n                                                                         or non-biased, which has been validated through our\n                                                                         demonstration and experiments.\n                                                                         2.3.4 De-biasing and recommendations\n                                                                         We recommend a couple (5, 10, 15 or so) of substitute tokens that\n                                                                         can be used to infill each masked token during the fairness\n                                                                         infilling stage. We send the top-k recommended sentences\n                                                                         (infilled with new tokens) again to the bias detection model (first\n                                                                         module) to see the probability of biasness. If the probability of\n               Figure 3: Bias recognition module                         biasness is less than 0.5 or less than the probability of the previous\n                                                                         de-biased sentence, we output the sentence as the final output.\nThough, the standard named entity recognition (NER) task is not          3. EXPERIMENTS AND RESULTS\ndirectly related to bias identification, it can be used to find biases\nin data [9,17]. For example, one NER model [16] has been used to         3.1 Experimental Setup\nfind if there are more female names tagged as non-person than            We implemented this pipeline in TensorFlow. We run our\nmale names. Another NER model has identified biases based on             experiments on Google Colab Pro (NVIDIA P100, 24 GB RAM,\noccupation, race, and demographics [9]. In this work, we refer to        2 x vCPU). Common parameters used in Dbias are a batch size of\neach entity in the NER as a bias-bearing entity that is manifested       16, 10 epochs, sequence length 512, and number of labels for\nin syntax, semantics or linguistic context.                              news is 2 (bias, non-biased). We use the distilbert-base-uncased\n                                                                         with these details: Uncased: 6-layer, 768-hidden, 12-heads, 66M\nWe use the RoBERTa [14] along with Spacy English Transformer\n                                                                         parameters, in the bias detection module. We use RoBERTa-base,\nNER pipeline [10]. The final output from the bias recognition\n                                                                         12-layer, 768-hidden, 12-heads, 125M parameters in the bias\nmodule is a set of news articles, where the biased words have\n                                                                         recognition module. The learning rate, warm-up setups, the drop-\nbeen identified. We show our bias recognition module, which is a\n                                                                         out rate and other parameters for each module are optimized\npipeline, in Figure 3.\n                                                                         according to their best settings. For a fair comparison, we tune all\n2.3.3 Bias Masking                                                       the other methods (our method and baselines) to their optimal\nBias Masking: In the bias masking stage, we mask the position of         hyperparameter settings and report the best results.\neach biased word (token) within each news article. We use                To assess the performance of our proposed model, we use the\nMasked Language Modeling (MLM) [26] for masking biased                   accuracy (ACC), precision (PREC), recall (Rec) and F1-score\nwords. Typically, the MLM task takes a sentence, randomly                (F1), following standard metrics in this line of research [4]. To\nmasks 15% of words in the input and then runs the entire masked          our knowledge, there is no single model or pipeline that can\nsentence through the model to predict masked words.                      perform all three tasks simultaneously, so, we evaluate Dbias\n                                                                         performance for main tasks (bias detection and recognition).\n\n                                                                         3.2       Results and Analysis\n                                                                         The results are shown and discussed next:\n\n                                                                         3.2.1 Effectiveness of bias detection module\n                                                                         In this experiment, we evaluate the performance of our framework\n                                                                         for the bias detection module (the first module of the Dbias)\n                                                                         against the following state-of-the-art baselines:\n                                                                         LG-TFIDF: We use the Logistic Regression (LG) [29] with\n                                                                         TfidfVectorizer (TFIDF) word embeddings[22].\n                                                                         LG-ELMO: We use LG with ELMO embeddings [23].\n                                                                         MLP-ELMO: We use MultiLayer Perceptron (MLP), a\n                                                                         feedforward artificial neural network with ELMO embeddings.\n                                                                         BERT: We use Bidirectional Encoder Representations from\n                                                                         Transformers (BERT) [8] and its bert-based uncased version.\n                 Figure 4: Bias masking example\nDS4RRS Workshop                                                               KDD ‚Äô22, August 14‚Äì18, 2022, Washington DC, USA.\n\n\n\nRoBERTa: We use Robustly Optimized BERT Pre-training                 recall, F1-score and accuracy. This is because a Transformer-\nApproach (RoBERTa) [13] with RoBERTa-base.                           based model can identify entities and relations within the text with\nThe results are shown in Table 1.                                    rich contexts. We also find that bias recognition tasks show better\n                                                                     accuracy with larger model size. This is likely because the larger\n           Table 1: Performance of bias detection task               model contains a greater number of parameter settings and data\n    Model                 PREC            REC          F1            points, all of which affect the model's predictive performance.\n                                                                     However, these benefits come at the expense of resource\n    LG-TFIDF              62%             61%          62%\n                                                                     utilization, memory, CPU cycles, and latency delay. Based on\n    LG- ELMO              67%             69%          68%           these results, we choose to work with core-trf.\n    MLP- ELMO             69%             68%          68%\n    Bert                  72%             69%          71%           3.3 Working of Dbias\n    RoBERTa               76%             70%          73%           We release Dbias as a python package that can be used to detect\n    Our approach          77%             74%          75%           and mitigate biases in texts. The input to the model can be any\n                                                                     sentences that may contain biased words and we get the de-biased\nOverall, the results in Table 1 show the better performance of our   output. We show a working example based on a piece of biased\napproach (based on distilBERT fine-tuned on MBIC dataset)            news in Figure 5.\ncompared to the baseline methods for the bias detection task. The\nresult also shows that deep neural embeddings, in general, can\noutperform traditional embedding methods (e.g., TFIDF) in the\nbias classification task. This is shown by the better performance\nof deep neural network embeddings (i.e., ELMo) compared to\nTFIDF vectorization when used with LG. This is probably\nbecause deep neural embeddings can better capture the context of\nthe words in the text in different contexts. The deep neural\nembeddings and deep neural methods (MLP, BERT, RoBERTa)\nalso perform better than traditional ML method (LG).\nWe also observe that Transformer-based methods outperform\nother methods (ML and simple deep learning methods) in the bias\ndetection task. Among the Transformer-based approaches,\nRoBERTa outperforms the BERT model by approximately 2% in\nthe F1-score, while our approach based on DistilBERT\noutperforms the RobBERTa by ~2%. DistilBERT is smaller,\nfaster, and lighter than BERT and RoBERTa. When we use                                 Figure 5: Example on Dbias\nDistilBERT in our work, it also performs better than all the other\nmodels. So, we choose to work with the DistilBERT for the bias       As illustrated in Figure 5, given a news article or any text that\ndetection task.                                                      may contain biased words, our model can determine whether or\n                                                                     not the text is biased. This is made possible by the first module:\n3.2.2 Effectiveness of bias recognition module                       the bias detection module. The output is then forwarded to the\nWe choose the following baselines for NER task based on similar\n                                                                     next module, namely the bias recognition module, which\nstructure as in our bias recognition module.\n                                                                     identifies bias-bearing words. The text with identified biased\nSpacy core web small pipeline (core-sm)2.\n                                                                     words is then sent to the de-biasing module, which masks the\nSpacy core web medium pipeline (core-md)3\n                                                                     biased words and makes suggestions for new words to replace\nSpacy core web large pipeline (core-lg)4\n                                                                     them. The final output is a set of non-biased or at least minimally\nOur approach is based on Spacy core web transformer pipeline\n                                                                     biased sentences for each input sentence.\n(core-trf)5. The results of different NER methods are shown in\nTable 2.                                                             4. Conclusion\n                                                                     We build Dbias, a pipeline for fair ML that has stages: bias\n          Table 2: Performance of bias recognition task\n                                                                     detection, bias recognition, bias masking and de-biasing. We\n    Model            PREC      REC         F1         ACC            develop Dbias as a downloadable package that can be used as it or\n    Core-sm          59%       27%         37%        37%            integrated in a system like a news recommender system or so.\n    Core-md          61%       45%         52%        53%            This research serves as a forum for researchers interested in de-\n    Core-lg          60%       62%         60%        67%            biasing the text.\n    Our approach     66%       65%         63%        72%                Limitations and future works: We need to investigate a wide\n                                                                     variety of biases in news media to determine the definitions of\nThe results in Table 2 show that our approach based on core-trf\n                                                                     biases and that of fairness. So far, we use a manually annotated\noutperforms all the other NER methods in terms of precision-\n                                                                     news dataset to identify bias-bearing words. We encourage\n                                                                     researchers to identify more biases in the text to annotate one such\n2\n  en_core_web_sm                                                     data. The fundamental requirement for our system is to fine-tune\n3\n  en_core_web_md\n4                                                                    it using the domain data. While this is a start, we may need to\n  en_core_web_lg\n5\n  en_core_web_trf                                                    investigate additional domains to enrich the Dbias pipeline.\nDS4RRS Workshop                                                               KDD ‚Äô22, August 14‚Äì18, 2022, Washington DC, USA.\n\n\n\nREFERENCES                                                                  Nanyun Peng, and Aram Galstyan. 2020. Man is to person\n[1]    Julius A Adebayo and others. 2016. FairML: ToolBox for               as woman is to location: Measuring gender bias in named\n       diagnosing bias in predictive modeling. Massachusetts                entity recognition. Proc. 31st ACM Conf. Hypertext Soc.\n       Institute of Technology.                                             Media, HT 2020 (2020), 231‚Äì232.\n[2]    Ramy Baly, Georgi Karadzhov, Dimitar Alexandrov, James        [17]   Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena,\n       Glass, and Preslav Nakov. 2020. Predicting factuality of             Kristina Lerman, and Aram Galstyan. 2021. A Survey on\n       reporting and bias of news media sources. In Proceedings of          Bias and Fairness in Machine Learning. ACM Comput. Surv.\n       the 2018 Conference on Empirical Methods in Natural                  54, 6 (2021).\n       Language Processing, EMNLP 2018, 3528‚Äì3539.                   [18]   Cristina Monzer, Judith Moeller, Natali Helberger, and\n[3]    Niels Bantilan. 2018. Themis-ml: A fairness-aware machine            Sarah Eskens. 2020. User Perspectives on the News\n       learning interface for end-to-end discrimination discovery           Personalisation Process: Agency, Trust and Utility as\n       and mitigation. J. Technol. Hum. Serv. 36, 1 (2018), 15‚Äì30.          Building Blocks. Digit. Journal. 8, 9 (2020), 1142‚Äì1162.\n[4]    R. K.E. Bellamy, A. Mojsilovic, S. Nagar, K. Natesan          [19]   Kevin P Murphy. 2012. Machine learning: a probabilistic\n       Ramamurthy, J. Richards, D. Saha, P. Sattigeri, M. Singh,            perspective. MIT press.\n       K. R. Varshney, Y. Zhang, K. Dey, M. Hind, S. C.              [20]   Aileen Nielsen. 2020. Practical Fairness. O‚ÄôReilly Media.\n       Hoffman, S. Houde, K. Kannan, P. Lohia, J. Martino, and S.    [21]   Kalia Orphanou, Jahna Otterbacher, Styliani Kleanthous,\n       Mehta. 2019. AI Fairness 360: An extensible toolkit for              Khuyagbaatar Batsuren, Fausto Giunchiglia, Veronika\n       detecting and mitigating algorithmic bias. IBM J. Res. Dev.          Bogina, Avital Shulner Tal, Alan Hartman, and Tsvi Kuflik.\n       63, 4‚Äì5 (2019).                                                      2022. Mitigating Bias in Algorithmic Systems-A Fish-Eye\n[5]    Su Lin Blodgett, Solon Barocas, Hal Daum√© III, and Hanna             View. ACM Comput. Surv. (2022).\n       Wallach. 2020. Language (Technology) is Power: A Critical     [22]   F Pedregosa, G Varoquaux, A Gramfort, V Michel, B\n       Survey of ‚ÄúBias‚Äù in NLP. 5454‚Äì5476.                                  Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V\n[6]    Axel Bruns. 2019. It‚Äôs not the technology, stupid: How the           Dubourg, J Vanderplas, A Passos, D Cournapeau, M\n       ‚ÄòEcho Chamber‚Äôand ‚ÄòFilter Bubble‚Äômetaphors have failed               Brucher, M Perrot, and E Duchesnay. 2011. Scikit-learn:\n       us. Int. Assoc. Media Commun. Res. (2019).                           Machine Learning in {P}ython. J. Mach. Learn. Res. 12,\n[7]    Simon Caton and Christian Haas. 2020. Fairness in Machine            (2011), 2825‚Äì2830.\n       Learning: A Survey. (2020), 1‚Äì33. arXiv Prepr.                [23]   Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt\n       arXiv2010.04053 (2020).                                              Gardner, Christopher Clark, Kenton Lee, and Luke\n[8]    Jacob Devlin, Ming Wei Chang, Kenton Lee, and Kristina               Zettlemoyer.      2018.      Deep      contextualized    word\n       Toutanova. 2018. BERT: Pre-training of deep bidirectional            representations.\n       transformers for language understanding. arXiv Prepr.         [24]   Shaina Raza. 2021. A News Recommender System\n       arXiv1810.04805 (2018).                                              Considering Temporal Dynamics and Diversity. arXiv\n[9]    Elizabeth Excell and Noura Al Moubayed. 2021. Towards                Prepr. arXiv2103.12537 (2021).\n       Equal Gender Representation in the Annotations of Toxic       [25]   Shaina Raza, Syed Raza Bashir, Dora D Liu, and Usman\n       Language Detection. (2021). arXiv Prepr. arXiv2106.02183             Naseem. 2021. Balanced News Neural Network for a News\n       (2021).                                                              Recommender System. In 2021 International Conference on\n[10]   Explosion AI. 2017. spaCy - Indusrtial-strength Natural              Data Mining Workshops (ICDMW), 65‚Äì74.\n       Language Processing in Python. Retrieved March 3, 2022        [26]   Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau,\n       from https://spacy.io/                                               Adina Williams, and Douwe Kiela. 2021. Masked language\n[11]   Danielle Gaucher, Justin Friesen, and Aaron C. Kay. 2011.            modeling and the distributional hypothesis: Order word\n       Evidence That Gendered Wording in Job Advertisements                 matters pre-training for little. arXiv Prepr. arXiv2104.06644\n       Exists and Sustains Gender Inequality. J. Pers. Soc.                 (2021).\n       Psychol. 101, 1 (2011), 109‚Äì128.                              [27]   Timo Spinde, Lada Rudnitckaia, Kanishka Sinha, Felix\n[12]   Hannes Hapke and Catherine Nelson. 2020. Building                    Hamborg, Bela Gipp, and Karsten Donnay. 2021. MBIC ‚Äì\n       Machine Learning Pipelines. O'Reilly Media (2020).                   A Media Bias Annotation Dataset Including Annotator\n[13]   Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar               Characteristics. Proc. iConference 2021 (2021), 1‚Äì8.\n       Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke                [28]   Florian Tram√®r, Vaggelis Atlidakis, Roxana Geambasu,\n       Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A                  Daniel Hsu, Jean Pierre Hubaux, Mathias Humbert, Ari\n       Robustly Optimized BERT Pretraining Approach. (2019),                Juels, and Huang Lin. 2017. FairTest: Discovering\n       2383‚Äì2392. Retrieved December 20, 2021 from                          Unwarranted Associations in Data-Driven Applications.\n       https://github.com/deepset-ai/COVID-QA.                              Proc. - 2nd IEEE Eur. Symp. Secur. Privacy, EuroS P 2017\n[14]   Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar                (2017), 401‚Äì416.\n       Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke                [29]   Raymond E Wright. 1995. Logistic regression. (1995).\n       Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A           [30]   Yao Wu, Jian Cao, and Guandong Xu. 2021. Fairness in\n       Robustly Optimized BERT Pretraining Approach. 2020,                  Recommender Systems : Evaluation Approaches Fairness in\n       (2019), arXiv Prepr. arXiv1907.11692                                 Recommender Systems : Evaluation Approaches and\n[15]   Kat Matfield. 2016. Gender Decoder: find subtle bias in job          Assurance Strategies. (2021).\n       ads. Retrieved from http://gender-decoder.katmatfield.com/\n[16]   Ninareh Mehrabi, Thamme Gowda, Fred Morstatter,\n</td>
    </tr>
    <tr>
      <th>56</th>
      <td>news</td>
      <td>1\n\nInternational Journal of Data Science and Analytics (2022)\n\nDbias: Detecting biases and ensuring Fairness in news\narticles\nShaina Raza1*, Deepak John Reji2, Chen Ding3\nAbstract\nThe problem of fairness is garnering a lot of interest in the academic and broader literature due to the increasing use of datacentric systems and algorithms in machine learning. This paper introduces Dbias (https://pypi.org/project/Dbias/), an opensource Python package for ensuring fairness in news articles. Dbias can take any text to determine if it is biased. Then, it detects\nbiased words in the text, masks them, and suggests a set of sentences with new words that are bias-free or at least less biased.\nWe conduct extensive experiments to assess the performance of Dbias. To see how well our approach works, we compare it to\nthe existing fairness models. We also test the individual components of Dbias to see how effective they were. The experimental\nresults show that Dbias outperforms all the baselines in terms of accuracy and fairness. We make this package (Dbias) as publicly\navailable for the developers and practitioners to mitigate biases in textual data (such as news articles), as well as to encourage\nextension of this work.\nKeywords: Bias; fairness; Transformer-based models; deep learning; entity recognition; classification; masking\n\n1\n\nIntroduction\n\nNatural language processing (NLP) is a branch of\nartificial intelligence (AI) that assists computers in\nunderstanding, interpreting, and manipulating human\nlanguage [1]. NLP problems can be solved with the\nhelp of Machine Learning (ML), which can automate\nprocesses and deliver accurate responses [2]. In recent\nyears, the deep learning techniques have demonstrated\npromising results in narrowing down the gap between\nsequence-to-sequence learning approaches and humanlike performance in a variety of NLP tasks [3]. One\ncommon thing about ML models is that they are often\ntrained on a large text corpus (e.g., Google BERT,\nFacebook BART and so other industry driven\nproducts), which may introduce substantial biases into\nthe models. These biases are usually passed on to the\nmodels during the training time [4, 5], and often the\ndevelopers are unaware of these biases [6].\n\nShaina Raza Shaina.raza@utoronto.ca\nDeepak John Reji deepak.reji@erm.com\nChen Ding cding@ryerson.ca\n1\n\nUniversity of Toronto, Ontario, Canada\nEnvironmental Resources Management, Bangalore, India\n3\nRyerson University, Toronto, Ontario, Canada\n2\n\nThere are numerous examples of biases in ML\nmodels due to data, such as Amazon's hiring algorithm\n[7] that favored men, Facebook targeted housing\nadvertising that discriminated on the basis of race and\ncolor [8], and a healthcare algorithm [9] that exhibited\nsignificant racial biases in its recommendations [10].\nData-heavy systems, such as news recommender\nsystems, are also trained on huge volumes of data with\nlimited control over the quality of the training data [11].\nThese news recommenders often inherit biases from\nthe data [12], potentially influencing the beliefs and\nbehaviors of news consumers [13]. To mitigate biases,\nthe biased models are frequently eliminated, as was the\ncase with Amazon's hiring algorithm [7], which is not\nalways a feasible solution. As discussed in the literature\n[5, 14, 15], it is necessary to eliminate these biases early\nin the data collection process, before they enter the\nsystem and are reinforced by model predictions,\nresulting in biases in the model's decisions. In this\nstudy, we aim to eliminate biases in the original data as\nsoon as possible, such as during the data ingestion time.\nBias detection and mitigation are hot topics both in\nacademia and industry. Fairness and bias have been\ndefined in a variety of ways by the academic\nresearchers. Traditionally, the bias is defined as\nprejudice in favour of or against a particular thing,\nperson, or group in comparison to another, usually in\nan unjust manner [6, 16].\n1\n\n2\n\nInternational Journal of Data Science and Analytics (2022)\n\nFigure 1: Debias ‚Äì a fair ML pipeline for news articles\nFor example, gender, race, demographic or sexual\norientation are some of the examples of the biases [5].\nThe objective of fairness is to identify and reduce the\nimpacts of various biases [17]. The goal of fiarness is\nto prepare these ML systems to avoid perpetuating\nhuman and societal biases or adding new biases into the\ncontext.\nBiases in the ML models can be mitigated at three\nstages: early, mid, and late [17]. The early stage would\nbe to reduce bias by manipulating the training data\nbefore training the algorithm [10, 18, 19]. The mid\nstage would be to de-bias the model itself [4, 19‚Äì21],\nwhich is also framed as an optimization problem [22].\nThe late stage refers to reducing the biases by\nmanipulating the output predictions after training the\nalgorithm [23, 24]. Prior research [25‚Äì27] has\ndemonstrated that missing the chance to detect bias at\nan early stage of the ML pipeline might make\nalgorithmic fairness (mid or late stages of bias\nmitigation) difficult to achieve. In this paper, we\npropose a fair ML pipeline that takes raw data and debiases it early on, ensuring fairness throughout the\npipeline's phases.\nA ML pipeline is composed of several steps that\nfacilitate the automation of ML workflows [28]. Many\nreal-world applications, for example, the Netflix\nrecommender system [29], Spark healthcare [30] and\nUber forecasting [28] are often represented as ML\npipelines. Usually, these pipelines are designed to input\nsome data as features and generates a score that\npredicts, classifies or recommends future outcomes. In\ncontrast to typical product-driven ML pipelines, we\npropose a fair ML pipeline, designed exclusively for\nmitigating data biases and leveraging fairness in\napplications. We develop, Dbias ‚Äì a fair ML pipeline,\nshown in Figure 1, which mitigates biases in the data\nand propagates fairness through different steps (data\npreprocessing, model training, analysis and\ndevelopment) of the pipeline.\nAs shown in Figure 1, Dbias first detects biases in\nthe text, then it recognizes the biased words, masks and\n\nreplace those biased words with new (non-biased or at\nleast less biased) words to de-bias the text. Each of\nthese phases in Dbias pipeline consists of its own\ntraining and inference steps (shown in Figure 2).\nTo the best of our knowledge, there is no ML\npipeline developed exclusively to mitigate biases in\ndata. The majority of research on fairness in ML has\nfocused on classification tasks [16, 31‚Äì33]. By\nfocusing exclusively on the fairness of classifiers (e.g.,\nDecision Tree, Logistic Regression), we miss the\nimpact of fairness on other stages in a standard ML\npipeline.\nFairML [34], FairTest [33], Themis-ml [35] and\nAIF360 [6] are some of the well-known ML fair\npipelines that implement and evaluate the state-of-theart fairness algorithms. This means that these pipelines\nuse and evaluate off-the-shelf fair ML models [16, 31‚Äì\n33, 36, 37]. In comparison to these approaches (fairness\nmethods and pipelines), Dbias is a self-contained fair\nML pipeline that has its own algorithms for detecting\nand mitigating biases. Dbias ensures that the fairness is\nmaintained throughout the pipeline.\nThe Dbias can detect biases in any kind of text. The\nonly requisite is to train the model on the domainspecific data. However, in this paper, we will focus on\nnews media bias. According to research [11, 38, 39]\nnews media can be biased, and this biased coverage has\nthe potential to significantly influence public\nperceptions of the reported topics. Biased news media\ncan also result in "filter bubbles" or "echo chambers"\n[11, 40, 41], which can lead to a lack of understanding\nof specific concerns as well as a narrow and one-sided\npoint of view. This inspires us to train Dbias to mitigate\nnews media biases.\nContributions: We summarize our contributions as:\n1. We develop a fair ML pipeline, which we name as\nDbias (de-biasing) that de-bias the text (e.g., news\ntext). To make it easier for practitioners to use, we\nfollow the widely acknowledged data science ML\npipeline structure [42] to build Dbias. We develop\nand package different algorithms for bias detection,\n2\n\n3\n\nInternational Journal of Data Science and Analytics (2022)\n\nrecognition, masking and de-biasing into the Dbias\npipeline.\n2. We make Dbias available as an open-source\npackage distributed under the MIT1 License. It is\npublicly shared in the GitHub repository2 and as\nthe PyPi project3. The released package also\n\nFairness [17] is a multi-faceted concept that varies\nby culture and context. It is quite difficult to have a\nstandard definition of fairness as each definition\ndepends on a different use case and organization.\nDistinct definitions of fairness can lead to different\noutcomes [45]. There exists at least 21 mathematical\n4\n\nAs AI is increasingly used in highly sensitive domains\nsuch as news, health care, hiring, journalism, and\ncriminal justice, there is a growing awareness of the\nconsequences of embedded biases and unfairness.\nNumerous studies have shown that AI is capable of\nembedding and deploying human and societal biases\ninto the solutions [5, 6, 23]. For example, the\nCorrectional Offender Management Profiling for\nAlternative\nSanctions\n(COMPAS)\nalgorithm\nmislabeled African-American defendants nearly twice\nas often as white defendants [44]. The inability of ML\nmodels to mitigate these undesirable biases is a\nsignificant impediment to AI reaching its full potential.\n\ndefinitions for fairness in politics [46]. A decision tree\non different definitions of fairness is provided by the\nUniversity of Chicago. Overall, it is quite difficult to\nmeet many definitions of fairness at the same time [14].\nMost of the definitions on fairness focus on either\nindividual fairness (treating similar individuals fairly)\n[17, 37] or group fairness (equitably distributing the\nmodel's predictions or outcomes across groups) [17,\n47]. Individual fairness aims to ensure that statistical\nmeasures of outcomes are equal for people who are\nstatistically similar. Group fairness divides a\npopulation into distinct groups based on protected\ncharacteristics, with the goal of ensuring that statistical\nmeasures of outcomes are comparable across groups.\nBias is defined as an inclination or prejudice for or\nagainst one person or group, especially in an unfair\nmanner [5]. While algorithmic bias is frequently\ndiscussed in the literature of ML, in most situations it\nis the underlying data that introduces bias. For\nexample, if there had been an equal amount of data for\nmen and women in Amazon's recruiting[7] algorithm,\nthe algorithm might not have biased as much.\nFairness algorithms: In the research of AI and ML\nfairness [6, 17], the bias mitigation algorithms are\ncategorized into three broad types: (1) pre-processing\nalgorithms; (2) in-processing algorithms and (3) postprocessing algorithms. These algorithms are briefly\ndiscussed below.\nPre-processing algorithms: The pre-processing\nalgorithms attempt to learn a new representation of data\nby removing the information associated with the\nsensitive attribute, while retaining as much of the actual\ndata as possible. This technique manipulates the\ntraining data prior to training the algorithm. Wellknown pre-processing algorithms are:\n- A reweighting [10] algorithm generates weights for\nthe training samples in each (group, label), without\nchanging the actual feature or label values.\n- The learning fair representations [19] algorithm\ndiscovers a latent representation that encodes the\ndata, while concealing information about protected\nattributes. Protected attributes are those attributes\n\n1 https://opensource.org/licenses/MIT\n\n3 https://pypi.org/project/Dbias/\n\n2\n\n4\n\nincludes introductory tutorials to the concepts, as\nwell as documentation, usage and guidance to\nassist data scientists and practitioners in\nincorporating this package into their work\nproducts.\n3. Even though Dbias is released as a generic fair ML\npipeline, it can be applied to any other text data.\nHowever, focusing on news media biases in this\nwork, we demonstrate in our GitHub tutorials how\nwe can use Dbias in conjunction with API code\nblocks (such as those found in Google News API)\nto reduce biases in news articles.\n4. We conducted extensive experiments to compare\nDbias' performance to that of cutting-edge fairness\nmethods. We also put the individual components of\nDbias through their paces to see how well they\nperform in various bias mitigation tasks.\nFurthermore, we demonstrate through our\nexperiments that there exists a trade-off between\naccuracy and fairness, which also previous\nresearch [6, 10, 43].\nThe rest of the paper is organized as follows: Section\n2 is the related work, section 3 is the working of the\nDbias architecture, section 4 is about the experimental\nsetup, section 5 is the discussion about results and\nanalysis, section 6 is the discussion section, and finally\nsection 7 is the conclusion.\n\n2\n\nLiterature Review\n\nhttps://github.com/dreji18/Fairness-in-AI\n\nhttp://aequitas.dssg.io/static/images/metrictree.png\n\n3\n\n4\n\nthat divide a population into groups whose\noutcomes should be comparable (such as race,\ngender, caste, and religion) [17].\n- The disparate impact remover [31] algorithm\nmodifies feature values to improve group fairness,\nwhile keeping rank ordering within groups.\n- Optimized pre-processing [48] algorithm learns a\nprobabilistic transformation that edits data features\nand labels for individual and group fairness.\nUsually, pre-processing techniques are easy to use as\nthe modified data can be used for any downstream tasks\nwithout requiring any changes to the model itself.\nIn-processing algorithms: In-processing algorithms\npenalize the undesired biases from the model, to\nincorporate fairness into the model. The in-processing\ntechnique influences the loss function during the model\ntraining to mitigate biases. In the past, the in-processing\nalgorithms [49, 50] have been used to provide equal\naccess to racially and ethnically diverse group. Some of\nthe example in-processing algorithms are listed below:\n- Prejudice remover [49] augments the learning\nobjective\nwith\na\ndiscrimination-aware\nregularization term.\n- Adversarial De-biasing [4] algorithm learns a\nclassifier to maximize the prediction accuracy\nwhile decreasing an adversary's ability to deduce\nthe protected attribute from the predictions.\n- Exponentiated gradient reduction [51] algorithm\nbreaks down fair classification into a series of costsensitive classification problems, returning a\nrandomized classifier with the lowest empirical\nerror subject to fair classification constraints.\n- Meta fair classifier [50] algorithm inputs the\nfairness metric and returns a classifier that is\noptimized for the metric.\nThe in-processing technique is model or taskspecific, and it requires changes within the algorithm,\nwhich is not always a feasible option.\nPost-processing algorithms: The post-processing\nalgorithms manipulate output predictions after training\nto reduce bias. These algorithms can be applied without\nretraining the existing classifiers (as in in-processing).\nSome of the post-processing algorithms are:\n- Reject option classification [36] algorithm gives\nfavorable outcomes (labels that provide advantage\nto an individual or group, e.g., being hired for a job,\nnot fired) to unprivileged groups.\n- Equalized odds [24] algorithm changes the output\nlabels to optimize equalized odds through linear\nprogramming.\n\nInternational Journal of Data Science and Analytics (2022)\n\n-\n\nCalibrated equalized [23] odds optimizes score\noutputs to find probabilities with which to change\noutput labels with an equalized odds objective.\nUsually, the post-processing technique requires access\nto protected attributes late in the pipeline.\nRecently, the software engineering community has\nalso started to work on fairness in ML, specifically\nfairness testing [33, 52]. Some work has been done to\ndevelop automated tools, such as AI Fairness 360 [6],\nFairML [34] , Aequitas [53], Themis-ML [35], FairTest\n[33], that follows a software development lifecycle.\nTransfer learning techniques: Transfer learning is a\ntechnique to transfer the knowledge contained in larger,\ndifferent but related source domain to a target domain\n[54]. The goal is to improve the performance of target\ndomain with the existing knowledge of the source\ndomain. Bidirectional Encoder Representations from\nTransformers (BERT) [55] is an example, which has\nshown state-of-the-art performance in many tasks like\nclassification, question-answering and so.\nWe discuss the state-of-the-art transfer learning\nmethods used in the bias mitigation and fairness\nresearch. Li et al. 2021 [56] study the gender bias inside\nthe Transformer-based model (BERT). They [56]\ncalculate the attention scores for the corresponding\ngender pronouns and occupations, swap the gender\npronouns to eliminate the position effect on bias\njudgement, and then again check the consistency of the\ngender bias associated with the occupation. Sinha and\nDasgupta [57] employ the BERT model to detect biases\nfrom the text. Both these models, while equally\nimportant, are primarily concerned with the detection\nand extraction of biased sentences.\nThe task of identifying a named entity (a real-world\nobject or concept) in unstructured text and then\nclassifying the entity into a standard category is known\nas named entity recognition [58]. Mehrabi et al. 2020\n[32] used named entities to determine whether female\nnames are more frequently tagged as non-person than\nmale names. Some other researchers [59, 60] use the\nnamed entities to identify biases based on occupation,\nrace, and demographics. These named entity\nrecognition models usually recognize the biased\nentities from the data, without mitigating them.\nThe masked language modeling is also used to\nidentify biases. Based on two crowdsourced datasets,\nKaneko and Bollegala 2021 [61] propose a technique\nto accurately predict different types of social biases in\ntext. They [61] demonstrate that social biases do exist\nin masked language models and suggest developing\n4\n\n5\n\nmethods to robustly debias pre-trained masked\nlanguage models as a future direction.\nFairness toolkits: We discuss fairness toolkits here:\n- FairML [34] is a toolkit that uses few ranking\nalgorithms to quantify the relative effects of\nvarious inputs on a model‚Äôs predictions, which can\nbe used to assess the fairness in models.\n- FairTest [33] is a python package that learns a\nspecial decision tree that divides a user population\ninto smaller subgroups with the greatest possible\nassociation between protected (such as gender,\nrace, and other characteristics deemed sensitive\nfeatures) and algorithm outputs.\n- Themis-ml [35] is a python library that implements\nseveral state-of-the-art fairness-aware methods that\ncomply with the sklearn API.\n- AIF360 [6] consists of a number of fairness metrics\nfor datasets and state-of-the-art ML models to\nmitigate biases in the datasets and models.\nFairness metrics: To ensure the fairness, the ML\ncommunity has also proposed various fairness metrics.\nFor example, the disparate impact ratio compares the\nrate at which an underprivileged groups (groups having\nsystematic biases e.g., females) receives a particular\noutcome compared to a privileged group (groups with\nsystematic advantages, e.g., males) [31]. In some works\n[17], the number of positives and negatives for each\nindividual or group, difference of means, odds ratio are\nalso computed to measure fairness.\nComparison with the state-of-the-art approaches:\nWhile each of the previous works discussed in this\nsection is valuable and incremental, they are primarily\nconcerned with fairness across different tasks (preprocessing, in-processing, and post-processing). These\nmodels either remove biases and ensure fairness either\nduring pre-processing, in-processing or postprocessing. The fairness toolkits (AIF360, FairML,\nFairTest, etc.) also take the existing approaches to\nmitigate the biases in different groups (gender,\npopulations, religions).\nIn this work we combine the strength of deep neural\nnetworks and Transformer-based architecture into our\nfair ML pipeline. We propose that fairness can be\nachieved by ensuring that each component of the ML\npipeline is fair. We do not rely on existing built-in\nfairness models to ensure that data or model is fair;\nrather, we construct a fair ML pipeline comprised of\nmultiple components that takes raw data and de-biases\nit. Also, compared to other methods [32, 56, 60, 61],\n\nInternational Journal of Data Science and Analytics (2022)\n\nwhich either detect, recognize or only mask the biased\nwords/sentences, we consider all these aspects of bias\ndetection and mitigation in a single pipeline. Different\nfrom the previous works, we do not only focus on the\nspecific biases (gender, race, ethnicity), infact, we\ndevelop the Dbias to detect and mitigate many kinds of\nbiases from the text data. The only requisite is to finetune the model on the domain specific data.\n\n3\n\nDBias, a fair ML pipeline\n\nIn this section, we define the preliminaries, problem\ndefinition, overview, and underlying working of Dbias.\n3.1 Preliminaries\nWe use the following key terms [5, 17] in this work.\n- Bias is a type of systemic error.\n- A protected attribute divides a population into\ngroups, for example, race, gender, caste, and\nreligion.\n- A privileged value of a protected attribute denotes\na group that historically has a systematic\nadvantage, for example, male gender, white race.\n- An underprivileged group faces prejudice based on\nsystematic biases such as gender, race, age,\ndisability, and so on.\n- Group fairness means that the protected attribute\nreceives similar treatments or outcomes.\n- Individual fairness means that similar individuals\nreceive similar treatments or outcomes.\n- Equalized odds [62] is a statistical notion of\nfairness that ensures classification algorithms do\nnot discriminate against protected groups.\n- Fairness or fair is a broad term used in ML and\ngenerally refers to the process of undoing the\neffects of various biases in the data and algorithms.\nThe goal of fairness is to mitigate the unwanted biases\nthat benefits privileged groups and disadvantages\nunprivileged.\nTable 1: Some biases in news domain\nBias\nGender\n\nExample\nAll man hours in his area of responsibility\nmust be approved.\nAge\nApply if you are a recent graduate.\nRacial/\nPolice are looking for any black males who\nEthnicity may be involved in this case.\nDisability Genuine concern for the elderly and\nhandicapped.\nMental\nAny experience working with retarded\nhealth\npeople is required for this job.\nOther biases addressed: Religion, education, political\nideology (liberal, conservative)\n\n5\n\n6\n\nInternational Journal of Data Science and Analytics (2022)\n\nFigure 2: Dbias and its debiasing workflow\nIn Table 1, we define some of the biases in news media\n[38, 63] that we try to mitigate in this work. However,\ndepending on the data on which our model is finetuned, we can also address many other types of biases\nacross other domains.\n3.2 Problem definition\nGiven a set of news articles that may contain a variety\nof biases, the task is to detect, recognize and undo\nthose biases from the data. The goal of this research is\nto mitigate unfairness in the news domain.\n3.3 Overview of the Dbias\nIn this section, we present the workflow of the Dbias.\nFigure 2 shows Dbias, which is a fair ML pipeline. We\noften use the word fair ML pipeline, in this work, to\nrefer to multiple sequential steps that perform steps\nfrom data extraction to preprocessing, data\npreprocessing to modeling, data transformation and\ndeployment in the Dbias pipeline. The main phases in\nthis pipeline are bias detection, bias recognition, bias\n\nmasking and de-biasing. Each phase gets the input\nfrom the preceding phase, except for the first phase\n(bias detection phase) that gets the input from a news\nAPI (e.g., Google news). Each phase has a training,\nvalidation, and testing task. The transformation of the\ndata from one phase to another phase is shown by a\ntrapezoid.\nEach model is served as an inference API and can\nfunction individually as well. The output from each\ntrapezoid goes to the respective inference API. For\nexample, the transformed data from the bias detection\nphase goes into the bias detection inference API. Once\nthe models are trained and tested, each of them is\nregistered and deployed so that it can be used as a\ncallable API. The goal of the inference API is to\nexecute inference queries over the new transformed\ndata without the need of loading all the heavy\nweighted python libraries. The final output of the\npipeline is the news articles (or any text) that are free\n6\n\n7\n\nfrom biases. There are also various stages in the\npipeline where we evaluate the modules using fairness\nmetrics (not pictured). These will be discussed in the\nevaluation section.\nOur goal is to enable end-users to shift seamlessly\nfrom raw biased data to a fair model. Next, we explain\neach phase of Dbias pipeline.\n3.3.1 Data collection and preparation phase\nWe prepare the annotated dataset MBIC (Media Bias\nIncluding Characteristics) [38] that represents various\nbias instances in the news articles to train our models.\nMore details about the dataset are given in Section 4.\n3.3.2 Model training, fine-tuning, and testing\nIn this work, we fine-tune the state-of-the-art\npretrained Transformer models, such as BERT\n(Devlin et al. 2018), DistilBERT (Sanh et al. 2019),\nRoBERTa (Liu et al. 2019) on our MBIC dataset for\nvarious downstream tasks. We use the training\ncheckpoints of these models (BERT, DistilBERT and\nRoBERTa) and fine-tune them using MBIC dataset.\nFor example, we fine-tune the DistilBERT model on\nthe MBIC dataset for the bias classification task.\nSimilarly, we fine-tune the RoBERTa on our MBIC\ndataset for the bias recognition task. We also adapt the\nBERT architecture for masking the biased words and\nfilling in those masked words with the non-biased\nwords. We discuss the details of each of such tasks in\nSection 3.4.\n3.3.3 Model registering and sharing\nWe have registered and shared our models as\nTensorFlow checkpoints on the Huggingface.co\nwebsite. We create the model cards for the tasks: bias\ndetection5 and recognition6. Model cards are the\nmarkdown files providing useful information for\ndiscoverability, reproducibility and sharing of the\nmodel. We also provide the inference (running live\ndata points) API along with each model card. Our\npurpose is to make it easier for the other researchers\nand developers to use our model and to contribute.\n\nInternational Journal of Data Science and Analytics (2022)\n\n3.4 Methodology\nThe specific tasks to perform in this work are:\n- Bias detection: To detect whether a news article is\nbiased or not.\n- Bias recognition: To recognize the biased words\nor phrases from the news articles.\n- De-biasing: To de-bias the data by replacing the\nbiased words or phrases from the news article with\nunbiased or at least less biased word(s). The debiasing also consists of masking, i.e., to hide the\nbiased words.\n3.4.1 Bias detection module\nThe input to the Dbias is a set news articles that\npotentially contain biased instances. The task of the\nbias detection module is to predict if a sentence is\nbiased or non-biased. For instance, given the news\nheadline, ‚ÄúDon‚Äôt buy the pseudo-scientific hype about\ntornadoes and climate change‚Äù [64], the bias detection\nmodule should be able to detect the sentence's bias and\nclassify it as biased news.\nThe Bias detection module is built upon the BERT\n(Devlin et al. 2018) architecture. BERT has achieved\nstate-of-the-art results in a variety of NLP tasks,\nincluding text classification and natural language\nunderstanding, so we fine-tune it for our specific use\ncase of bias detection. In our preliminary experiments,\nwe fine-tuned and evaluated various Transformerbased models (e.g., BERT, GPT-2, and others from the\nHuggingface Transformers‚Äô library) on our dataset\nand discovered that the DistilBERT (Sanh et al. 2019)\nmodel achieves both higher accuracy and faster\ninference speed, which is why we chose to work with\nit. DistilBERT is a distilled (approximate, faster and\nsmaller) version of BERT.\n\n3.3.4 Packaging\nWe group different modules of Dbias pipeline into a\nsingle package. Our whole package is hosted on\nhttp:/pypi.org under the MIT licence and can be\ninstalled using the command ùëùùëñùëù ùëñùëõùë†ùë°ùëéùëôùëô ùê∑ùëèùëñùëéùë†.\nNext, we discuss our methodology and cover the\ndetails about bias detection, recognition, and debiasing steps.\n5\n\nhttps://huggingface.co/d4data/en_pipeline\n\nFigure 3: Bias detection module\n\n6\n\nhttps://huggingface.co/d4data/bias-detection-model\n\n7\n\n8\n\nInternational Journal of Data Science and Analytics (2022)\n\nFigure 4: Bias recognition pipeline\nWe use the DistilBert (distilbert-base-uncased) with\nthese details: Uncased: 6-layer, 768-hidden, 12-heads,\n66M parameters, and we fine-tune it on MBIC dataset.\nFor binary classification, we use binary-cross entropy\nloss [65] with sigmoid activation function. The output\nfrom the bias detection model is a set of news articles\nthat are classified as biased or non-biased. Our bias\ndetection module is shown in Figure 3.\n3.4.2 Biased recognition module\nThe second module in the Dbias pipeline is the bias\nrecognition module. The task of the bias recognition\nmodule is to annotate the biased words in the news\narticles with tags, indicating that each tagged word is\nbiased. This module takes as input a set of news\narticles that have been identified as biased in the\npreceding module (bias detection), and outputs a set of\nnews articles where the biased words are picked and\nrecognized. The news headline "Don't buy the pseudoscientific hype about tornadoes and climate change,"\nfor example, has already been classified as a biased\nsentence by the preceding bias detection module, and\nthe biased recognition module can now identify the\nterm "pseudo-scientific hype" as a biased word.\nTraditionally, named entity recognition (NER) is\nthe task of identifying a named entity (a real-world\nobject or concept) in unstructured text and then\nclassifying the entity into a standard category [58].\nThough NER is not directly related to bias\nidentification, the research [5, 59] shows that NER\nmodels can be used to examine the existence and level\nof biasness in data, which obviously helps in\nmitigating biases in various applications. For example,\na NER model can be used to find if there are more\nfemale names tagged as non-person than male names\n[32] or to identify biases based on occupation, race,\nand demographics [59].\nIn our work, we take a unique approach to\nidentifying biases in news articles. Rather than\nlooking for conventional entities (Name, Location,\nEvent, and Organization, which are primarily nouns),\n\nwe look for bias-bearing words associated with each\nentity. Specifically, we refer to each entity in the NER\ntask as an bias-bearing entity that is manifested in\nsyntax, semantics or in the linguistic context (e.g., the\nword 'pseudo-scientific hype‚Äô is a biased word).\nWe show our bias recognition module, which is also\na pipeline, in Figure 4:\nWe use a Transformer-based model in our bias\nrecognition module. A standard NER [58] task has\ntraditionally been viewed as a sequence labelling\nproblem with word-level tags. The standard NER\nmodels are based on dictionaries or rules that may fail\nto recognize references to unknown entities in the text\n(for example, biased words as in our work). Therefore,\nwe employ a Transformer-based model as a wrapper\nfor the bias recognition task. According to recent\nresearch [66, 67], the Transformer-based model can\nalso detect long-term context in data, allowing us to\nidentify more bias-bearing words in the text.\nWe employ the RoBERTa (Liu et al. 2019), a\nretrained version of BERT with enhanced training\nmethodology and fine-tune it on our dataset. We use\nthe RoBERTa with these details: RoBERTa-base, 12layer, 768-hidden, 12-heads, 125M parameters along\nwith Spacy English Transformer NER pipeline7. By\nincluding the transfer learning [68] paradigm in the\nstandard NER pipeline, our bias recognition model\ncan now identify many other biased words that are not\nin our dataset. The final output from the bias\nrecognition module is a set of news articles, where the\nbiased words have been identified.\n3.4.3 De-biasing module\nThe de-biasing module is the most important part of\nDbias. The purpose of this entire workflow is to reduce\nthe bias effects of news text while maintaining its\nsemantic content, which has a wide range of\napplications in many domains also. For example, we\ncould convert the biased news headline ‚ÄúDon‚Äôt buy the\npseudo-scientific hype about tornadoes and climate\nchange‚Äù to a non-biased sentence as ‚ÄúDon‚Äôt buy the\n\n7 en_core_web_trf\n\n8\n\n9\n\nInternational Journal of Data Science and Analytics (2022)\n\ninformation about tornadoes and climate change‚Äù.\nOur third module, de-biasing module is specifically\ndesigned to accomplish this goal.\nThe input to the de-biasing module is a collection of\nnews articles from the bias recognition module with\nidentified biased words, and the output is a list of\nrecommendations for each news article with nonbiased or at least less biased words.\nOur de-biasing approach comprises of two stages:\nBias Masking and Fairness Infill stages. In the bias\nmasking stage, we mask the position of each biased\nword (token) within each news article. In the fairness\ninfill stage, we fill the masked token positions with\nnew words according to its context in the sentence.\nBias Masking: Our approach to masking is different\nfrom the Masked Language Modeling (MLM) [69]\ntask of the standard BERT model. Typically, the MLM\ntask takes a sentence, and randomly masks 15% of the\nwords in the input and then run the entire masked\nsentence through the model to predict the masked\nwords. In our work, we only mask words that have\nbeen flagged as biased by the previous bias\nrecognition module. We demonstrate our approach to\nbias masking through an example from the news\nheadline [70] in Figure 5.\n\ndifferent from the MLM task of a standard BERT\nmodel. We propose a unique mask shifting technique\nthat can mask and unmask more than one token at a\ntime in a sentence. For example, our mask shifting\ntechnique can breakdown the above news headline\n(Figure 5) to two instances (based on two token\nmasks) as below:\n- "Billie Eilish issues apology for [MASK] an antiAsian derogatory term in a resurfaced video."\n- "Billie Eilish issues apology for mouthing an antiAsian [MASK] in a resurfaced video."\nThen, both instances will be processed sequentially\nvia mask shifting technique, and each masked token\nwill be filled one at a time before the final sentence is\nconstructed.\nOur proposed Fairness Infilling stage can be\nconsidered as generalizing the cloze task (Wu et al.\n2019) from single tokens to spans of unknown length.\nOur assumption behind this unique fairness filling is\nthat the new words that are filled in are less or nonbiased, which has been validated through our\ndemonstration and experiments.\nWe recommend a couple of substitute tokens that\ncan be used to infill for each masked token during the\nFairness Infilling stage. For example, we can\nrecommend top-k (k=5,10 or so) substitutes for each\nmasked token in the de-biased sentence. We send the\ntop-k recommended sentences (infilled with new\ntokens) again to the bias detection model (first\nmodule) to see the probability of biasness. If the\nprobability of biasness is less than 0.5 or less than the\nprobability of the previous de-biased sentence, we\noutput the sentence as the final output.\n\n4\n\nFigure 5: De-biasing example with MLM\nAs can be seen in Figure 5, we have provided two\nmasks in the news headline. Both of these words have\nbeen identified as consisting of biases by the bias\nrecognition module. This approach is different from a\ntypical MLM masking task [71] where only one token\nis masked and infilled at a time.\nFairness Infilling: We use the MLM technique from\nthe BERT model, however, our masking technique is\n\nExperimental setup\n\nFairness is a complex concept with no one-size-fits-all\nsolution. Considering various definitions [43, 72] and\nsolutions of fairness [6, 73, 74], it is not possible to\nfind one benchmark solution for mitigating biases and\nto have a fair solution. However, it is still important to\nevaluate the working of our Dbias pipeline. We\nevaluate our architecture with two goals in mind: (1)\nto demonstrate capabilities of our package in terms of\nbias detection and mitigation algorithms, and (2) to\ndemonstrate how a user can understand the behavior\nof bias mitigation algorithms on the dataset and make\nan appropriate choice based on the business need.\n4.1\nDataset\nIn this work, we primarily use MBIC ‚Äì A Media Bias\nAnnotation Dataset [38]. MBIC is made up of around\n9\n\n10\n\n1,700 sentences from approximately 1,000 news\narticles from different news sources (HuffPost,\nMSNBC, AlterNet, Fox News, Breitbart, USA Today\nand Reuters and other). The data collection focuses on\nnews articles depicting racial, gender, religious,\npolitical, age and related biases, some of these biases\nare also mentioned in Table 1. The current dataset\nalready significantly extends the existing MBIC data\nunique and more reliable insights into the perception\nof bias. In this work, we use the extended version8 of\nMBIC dataset with 17,000 records, with 10,000 biased\nsentences and 7,000 non-biased sentences.\nWe chose this dataset as our primary source of data\nbecause the articles in this dataset cover a broad range\nof topics (political, scientific, ethnicity and so), all of\nwhich are relevant to our objective of identifying\nvarious textual biases.\nIn the original dataset, these biases are identified\nthrough crowdsourcing, where the crowdsourced\nannotators picked the bias-bearing words from the\nnews text. We calculated the biases (gender, race,\nethnicity, educational, religion, and language) from\nthe sentences, which are different from the annotators'\ngender, age, and education labels. Some of the biasbearing words are taken from this source [75, 76],\nwhile others bias-bearing words are added manually:\nsome of these words added by annotators of the MBIC\ndataset, while we also went through all the record one\nby one and added more bias-bearing words in the\nwords list. The goal is to have a populated list of\nbiased words from the text that will be later used to\ntrain the model.\nThe dataset features used in this work are:\n- Sentence: Sentence from the news article\n- News Link: URL of the news.\n- News Outlet: News sources (USA today,\nMSNBC)\n- Topic: Topic of news (gun-control, coronavirus,\nwhite-nationalism and so)\n- Age: Age of the person annotating the sentence as\nbiased or non-biased\n- Gender: Gender of annotator\n- Education: Education of the annotator\n- Biased words: some of the biased words added by\nannotators and some are others by us from [75, 76]\n- Label: News as biased or non-biased\nThe age feature in the dataset is found as the numeric\nvalues, however, we categorize it into 3 groups (elder,\n8\n\nInternational Journal of Data Science and Analytics (2022)\n\nyoung, adult). We also categorize the education\ngroups based on degrees (high school, undergraduate,\ngraduate) information.\nIn this work, we consider the following protected\nattributes from the dataset: ‚Äògender‚Äô: [Male, Female],\n‚Äòage‚Äô [‚ÄòElder‚Äô, ‚ÄòYoung‚Äô, ‚ÄòAdult‚Äô], ‚Äòeducation‚Äô:\n[‚ÄòCollege degree‚Äô, ‚Äòhigh school‚Äô], ‚Äòlanguage‚Äô:\n[‚ÄòEnglish speaker‚Äô, ‚Äònon-English speaker‚Äô]. We also\nconsider the following privileged attributes: ‚ÄòMale‚Äô\n(gender), ‚ÄòCollege degree‚Äô (education), ‚ÄòEnglish\nSpeaker‚Äô (language). In addition, we consider the\nfollowing unprivileged attributes: ‚ÄòFemale‚Äô (gender),\n‚Äòhigh school (education), Non-English Speaker‚Äô\n(language).\nSome exploratory analysis on data is shown below:\n\nFigure 6: Biased words in the news articles\nFigure 6 shows a word cloud made up of text from\nthe news articles. Among the notable words are\n‚Äúunholy," "radical‚Äù, ‚Äúracist‚Äù, ‚Äúslammed‚Äù, "rightwing," and "rage-tweeting," some of which represent\npolitical biases during the 2020 US elections.\n\nFigure 7 (a): Bigrams of biased words in the news\n\nmbic-a-media-bias-annotation-dataset\n\n10\n\n11\n\nInternational Journal of Data Science and Analytics (2022)\n\nTable 2: Baseline methods\nModel\nDisparate impact\nremover [31]\n\nReweighing [10]\n\nAdversarial Debiasing [4]\n\nExponentiated Gradient\nReduction [51]\n\nCalibrated Equalized\nOdds Postprocessing [23]\nEqualized Odds\npostprocessing [24]\nDbias\n\nDescription\nFairness Pre-processing models\nDisparate Impact Remover is a pre-processing approach for increasing fairness between\ngroups (privileged and unprivileged). This technique edits the feature values (e.g., the features\nthat are privileged, unprivileged) so that the data can be made unbiased while preserving\nrelevant information in the data. Once this algorithm has been implemented, any machine\nlearning or deep learning model can be built using the repaired data. The Disparate Impact\nmetric is then used to validate if the model is unbiased (or within an acceptable threshold). In\nthis baseline method, we use a couple of methods using AutoML and reporting the results\nwith the best performing model. For this baseline, the Logistic Regression [77] gave us the\nbest results.\nReweighing is a preprocessing technique that weighs the examples in each group (such as\nprivileged, unprivileged groups) to ensure fairness before classification. This algorithm\ntransforms the dataset to have more equity in positive outcomes on the protected attribute(s)\nfor both the privileged and unprivileged groups. We run a couple of algorithms on the\ntransformed data and report the result with the best performing model, which is Support\nVector Machine (SVM) [78] in this experiment.\nFairness In-processing Models\nAdversarial debiasing is based on the generative adversarial network (GAN) model proposed\nby Goodfellow et al. [79]. Through training, this model debiases the word and general feature\nembeddings. This is an in-processing technique that learns the definitions of fairness, such as\ndemographic parity, equality of odds, and quality of opportunity [72], so that a discriminator\n(part of GAN) has been tasked with predicting the protected attribute encoded in the bias of\nthe original feature vector, while a competing generator (part of GAN) has been tasked with\nproducing more debiased embeddings to compete with the discriminator.\nExponentiated gradient reduction is an in-processing technique that reduces the fair\nclassification down into a series of cost-sensitive classification problem. It also returns a\nrandomized classifier with the lowest empirical error (approximation of the expected error),\nif the fair classification rules are met.\nFairness post-processing models\nCalibrated equalized odds postprocessing is a postprocessing technique that optimizes over\ncalibrated classifier score outputs to find probabilities for changing output labels with an\nequalized odds objective.\nEqualized odds postprocessing is a post-processing technique that uses a linear program to\nfind probabilities for changing output labels in order to optimize equalized odds.\nOur approach\nOur approach mitigates biases during the pre-processing stage and ensures that fairness is\ncarried on throughout the ML pipeline to give a fair representation of data.\n\nFigure 7 (a) and (b) shows the top biased bigrams and\ntrigrams respectively from the news articles.\n\nFigure 7 (b): Trigrams of biased words in the news\n\nSome of the biased words that we see in these news\narticles are related to Elections 2020, COVID-19,\nclimate change, students‚Äô loan and so on.\n4.2 Baselines Methods\nWe could not find a single state-of-the-art model that\ncan perform all these tasks: (1) bias detection; (2) bias\nrecognition (3) bias masking, mitigation and\nrecommendation, altogether. Thus, we use the fairness\nbaseline methods as categorized in the related work\n[17]. These categories are based on the stages of the\nML pipeline at which bias is detected and mitigated,\nwhich are briefly defined as:\n- Fairness pre-processing methods are concerned\nwith the early stages of bias detection and\nmitigation. It preprocesses and converts the data\n11\n\n12\n\ninto non-biased inputs and make it ready for the\nmachine learning training.\n- Fairness in-processing methods focus on fairness\ninterventions during the model training process.\n- Fairness post-processing: these methods focus on\nfairness interventions after the data has been preprocessed and the model has been trained.\nIn addition to comparison with baselines (Table 2),\nwe also use other baseline methods to evaluate the\neffectiveness of individual modules of Dbias, which\nare detailed in their respective sections.\n\nInternational Journal of Data Science and Analytics (2022)\n\nThe purpose of all this evaluation strategy is to\ncompare Dbias pipeline and its individual modules to\nstate-of-the-art methods.\n4.4 Evaluation metrics\nTo assess the performance of our proposed model, we\nuse the accuracy (ACC), precision (PREC), recall\n(Rec), F1-score (F1), and Disparate Impact (DI) as the\nevaluation metrics. A confusion matrix determines the\ninformation about actual and predicted values, as\nshown in Table 3.\nTable 3: Confusion Matrix\n\nActual Fake\nActual Real\n4.3 Evaluation strategy\nOur evaluation strategy is given below:\nPredicted Fake\nTP\nFP\nEvaluating the Dbias against state-of-the-art\nPredicted Real\nFN\nTN\nbaselines: To our knowledge, there is no single model\nor pipeline that can perform all three tasks\nThe variables TP, FP, TN, and FN in the confusion\nsimultaneously: bias detection, bias recognition, and\nmatrix refer to the following:\nde-biasing. By examining and implementing these\n- True Positive (TP): number of biased news that\nbaseline methods (Table 2), we discover that most of\nare identified as biased.\nthem are based on a task for bias detection and\n- False Positive (FP): number of unbiased news\nmitigation. Thus, we evaluate these baselines and our\nthat are identified as fake news.\nDbias pipeline, with a particular emphasis on the task\n- True negative (TN): number of unbiased news that\nof bias detection and mitigation. This evaluation\nare identified as unbiased news.\nstrategy is inspired by the AIF 360 [6] evaluation\n- False negative (FN): number of biased news that\ntechnique. The outline of this evaluation is:\nare identified as unbiased news.\n- First, we evaluate the ability of each method in\nFor the Prec, Rec, F1 and ACC, we perform the\ndetecting the biases from the data using the\nspecific calculation as shown in the Equation (1), (2),\naccuracy measure.\n(3) and (4) respectively:\nùëáùëÉ\n- Second, we de-bias the data using each of the\n(1)\nùëÉùëüùëíùëê =\nùëáùëÉ + ùêπùëÉ\nmethod‚Äôs specific approach. This de-biased data is\nùëáùëÉ\n(2)\nùëÖùëíùëê =\na transformed data from the original data.\nùëáùëÉ + ùêπùëÅ\nùëáùëÉ\n- Third, we evaluate the ability of each method on\n(3)\nùêπ1 =\n1\nfairness (i.e., how many biases are mitigated by\nùëáùëÉ + (ùêπùëÅ + ùêπùëÉ)\n2\neach method). We also test each method again to\nùëáùëÉ + ùëáùëÅ\n(4)\nùê¥ùê∂ùê∂\n=\ndetect the remaining biases in transformed data.\nùëáùëÉ + ùëáùëÅ + ùêπùëÉ + ùêπùëÅ\nEvaluating the effectiveness bias detection module of\nDisparate Impact (DI) [33] is an evaluation metric to\nDbias: We evaluate the performance of Dbias for the\nevaluate fairness. It compares the proportion of\nbias detection module. We evaluate various\nindividuals that receive a positive output for two\nclassification, Transformer-based and embedding\ngroups: an unprivileged group and a privileged group.\nmodels with our fine-tuned DistilBERT to determine\nThe industry standard for DI is a four-fifths rule [80]\nwhich model/setting yields the most accurate results.\nwhich means if the unprivileged group receives a\nEvaluating the effectiveness bias recognition module\npositive outcome less than 80% of their proportion of\nof Dbias: We evaluate the performance of Dbias for\nthe privileged group, this is a disparate impact\nthe bias recognition module. We compared several\nviolation. An acceptable threshold should be between\nconfigurations of different NER models to test which\n0.8 and 1.25, with 0.8 favoring the privileged group,\nsetting gives us the most best results.\nand 1.25 favoring the unprivileged group [81].\nEvaluating the effectiveness masking technique of\nMathematically, it can be defined as:\nDbias: We explore the influence of different masking\nprobability to find the best setting for the masking.\nTable 3: Comparison of our framework with the baseline methods.\n12\n\n13\n\nInternational Journal of Data Science and Analytics (2022)\n\nPost\n\nIn\n\nPre\n\nModel\nDisparate impact remover\nReweighing\nAdversarial Debiasing\nExponentiated Gradient Reduct.\nCalibrated Equalized Odds\nEqualized Odds\nDbias\n\nPREC\n0.593\n0.613\n0.624\n0.612\n0.568\n0.498\n0.735\n\nBefore de-biasing\nREC\nF1\nACC\n0.549 0.570 0.587\n0.535 0.572 0.619\n0.600 0.612 0.641\n0.587 0.599 0.626\n0.479 0.520 0.560\n0.487 0.492 0.577\n0.784 0.759 0.776\n\nùê∑ùëñùë†ùëùùëéùëüùëéùë°ùëí ùëñùëöùëùùëéùëêùë° ùëüùëéùë°ùëñùëú =\n(\n\n_\n\n(\n\n)/\n\n_\n\n(\n\n))\n\n(\n\n_\n\n(\n\n)/\n\n_\n\n(\n\n))\n\n(5)\n\nwhere num_positives are the number of individuals in\nthe group: either privileged=False (unprivileged), or\nprivileged=True (privileged), who received a positive\noutcome. The num_instances are the total number of\nindividuals in the group.\nThe DI calculation is the proportion of the\nunprivileged group that received the positive outcome\ndivided by the proportion of the privileged group that\nreceived the positive outcome. This means DI ratio is\nthe ratio of positive outcomes (Bias=1) in the\nunprivileged group (in our case, females, elderly, nonEnglish speakers, no higher education) divided by the\nratio of positive outcomes in the privileged group\n(males, adults, English speakers, higher education).\n4.5 Common Hyperparameter\nThe common hyperparameters that we use in Dbias are\na batch size of 16, 10 epochs, sequence length 512,\nnumber of labels for news is 2 (bias, non-biased). The\nlearning rate, warm-up setups, the drop-out rate and\nother parameters for each module are optimized\naccording to their best settings. For fair comparison,\nwe tune all the other methods (baselines) to their\noptimal hyperparameter settings and report the best\nresults.\n\n5\n\nResults and Analysis\n\nThe results and analysis are shown and discussed here.\n5.1 Comparison between baselines and Dbias\nThese experiments are conducted in two-fold manner:\n(1) evaluation before de-biasing, and (2) evaluation\nafter the debiasing.\nIn the evaluation before de-biasing, we first\ncalculate the DI metric that simply takes the values of\nprotected variables to measure the DI ratio. Then we\nrun the classification methods provided by each\n9\n\nDI\n0.702\n0.702\n0.702\n0.702\n0.702\n0.702\n0.702\n\nPREC\n0.532\n0.591\n0.592\n0.589\n0.563\n0.487\n0.690\n\nAfter debiasing\nREC\nF1\nACC\n0.414 0.466 0.541\n0.524 0.555 0.604\n0.587 0.590 0.610\n0.557 0.573 0.606\n0.479 0.518 0.523\n0.488 0.487 0.505\n0.704 0.697 0.743\n\nDI\n0.804\n0.832\n0.923\n0.896\n0.829\n0.818\n1.012\n\nmethod to test the ability of each method in detecting\nthe biases from the data. Some of these baseline\nmethods do not have a classification method (the preprocessing ones), so, we use AutoML9 to select the\nbest performing classification method. Finally, we\nevaluate the performance of each method for the\nclassification accuracy.\nIn the evaluation after de-biasing, we apply the bias\nmitigation method provided by each method on the\noriginal data to create a transformed dataset. The\ntransformed data is assumed to be a fairer dataset\nbecause the transformation is learned as a new\nrepresentation of the data using some mapping or\nproject functions. Lastly, we compute all the metrics\n(PREC, REC, F1, ACC and DI) on the transformed\ndataset.\nNext, we present the results of all methods\n(baseline and Dbias) in Table 3.\nOverall results: Overall, the results in Table 3 shows\nthat our approach outperforms all the baseline\nmethods in detecting the biases. This is demonstrated\nby our model having the highest PREC, REC, F1, and\nACC scores when compared to the baseline models in\nthe 'before de-biasing' testing. The DI ratio of all\nmodels in the 'before de-biasing' evaluation phase is\nconstant. This is because the DI is calculated based on\nthe original dataset before we apply any technique to\nour dataset.\nIn the 'after de-biasing' evaluation, our approach\nalso performs its best to identify the biases. In this\nphase, our model's DI ratio is also a good value. A\ngood DI value is one that is between 0.8 and 1.25,\nensuring that different groups (gender, race,\neducation, and such) are balanced [15, 33, 81]. Our\nmodel has a DI ratio of 1.012, which indicates we are\nable to mitigate biases among various groups in an\nappropriate and balanced manner.\n\nautoml\n\n13\n\n14\n\nBaselines comparison: Among the baselines, the\ngeneral performance of the fairness in-processing\nmethods is better than the pre-processing methods,\nwhich is better than the post-processing methods. This\nis most likely due to the fact that the fairness inprocessing models have explicit control over the\noptimization function of a model. As a result, these\nmodels can better optimize the measure of fairness\nduring the model training. The pre- and postprocessing approaches do not change a model\nexplicitly. This means that, in their current state, any\nML library can be used for model training in pre- and\npost-processing approaches. However, this comes at\nthe cost of having no direct control over the\noptimization function of the ML model. Thus, each\ntechnique has a tradeoff, depending on whether we\nneed more explicit control over the method (as in inprocessing) or whether we need to incorporate fairness\nwithout affecting model training (as in pre- and postprocessing).\nAmong the baselines, the in-processing methods\nprovide much fairer results by mitigating the biases.\nIn-processing methods work by incorporating one or\nmore fairness measures into the model optimization\nfunctions in order to converge on a model\nparameterization that maximizes both performance\nand fairness [17]. Between the two in-processing\nbaselines, we see that the performance of Adversarial\nDebiasing [4] is better than the Exponentiated\nGradient Reduction method [51]. This is demonstrated\nby the higher precision, recall, F1 and accuracy scores\nof Adversarial Debiasing method when compared to\nthe other method in both phases of the evaluation\n(before and after debiasing). Adversarial Debiasing\nhas a DI ratio of 0.923, while Exponentiated Gradient\nReduction has a ratio of 0.896. A value close to 0.8\nindicates that the privileged group benefits more.\nBased on above results, the Adversarial Debiasing\nproduces more fair predictions (a value between 0.8\nand 1.25 i.e., close to 1) between the two in-processing\ntechniques. The Adversarial Debiasing methods uses\nthe adversarial training method to enforce a fairness\nconstraint during the model optimization. The\nExponentiated Gradient Reduction yields a\nrandomized classifier with the lowest (empirical) error\nsubject to the desired fairness constraints. This result\nindicates that adversarial training can be a useful\ntechnique to ensure fairness in NLP solutions.\nNext, comes the performance of pre-processing\nmethods. Pre-processing methods usually change the\n\nInternational Journal of Data Science and Analytics (2022)\n\nsample distributions of protected variables or perform\ntransformations on the data to make it less\ndiscriminatory in the training set [15, 17]. In this case,\nthe main idea is to train a model on a ‚Äòrepaired‚Äô\ndataset. Between the two pre-processing methods\namong our baselines, we see that the general\nperformance of Reweighing [10] is better than the\nDisparate impact remover method [31]. This is shown\nwith the better scores of Reweighing during both\nevaluation phases. The DI ratio of Reweighing after\nde-biasing is 0.832, which is better than that of the\nDisparate impact remover method and also better than\nits own 'before debiasing' evaluation score. However,\na value of 0.832 is still close to 0.8, which means that\nit is favoring privileged groups.\nLast comes the performance of post-processing\nmethods. Post-processing methods tend to apply\ntransformations to model predictions to improve\nfairness [17]. Between the two post-processing\nmethods, the general performance of Calibrated\nEqualized Odds [23] is better than the Equalized Odds\nmethod [24]. This is shown with the better scores of\nCalibrated Equalized Odds during both evaluation\nphases. The DI ratio of Calibrated Equalized Odds is\n0.829, which is a better value than the other method\nbut still not close to 1 (a value around 1 means\nbalancing between different groups).\nCompared to the baselines, our method is able to\nachieve the highest classification accuracy during both\nevaluation modes. The DI ratio of our approach is also\nclose to 1, which shows that we are able to achieve a\nbalance between unprivileged and privileged groups.\nTradeoff between accuracy and fairness: Overall,\nthese results indicate that there is a tradeoff between\naccuracy and the fairness (DI ratio) measures. Usually,\nwhen one goes high, the other metric value goes down,\nas demonstrated in the previous research also [6, 17,\n43]. However, a good model is one that is able to\nachieve a good value of DI ratio without much loss in\naccuracy. Our Dbias model achieves highest accuracy\nscores in ‚Äòbefore-de-biasing‚Äô and it does not lose much\naccuracy in ‚Äòafter de-biasing‚Äô testing. It also achieves\na good balance between these two measures. The\nsuperiority of our approach is attributed to its fair ML\ndesign that is able to detect, recognize and mitigate\nbias in a workflow. In addition to having a good\naccuracy and fairness values, our model can also\nmitigate with many other kinds of biases from the data,\nwhich are not covered by the other models.\n14\n\n15\n\n5.2 Effectiveness of the Bias Detection Module\nIn this experiment, we evaluate the performance of our\nframework for the bias detection module (the first\nmodule of the Dbias). We fine-tune the bias detection\nmodule using different models and embeddings. The\ngoal is to see which model gives us the best results for\nthe classification task. We also compare these\nmethods with our fine-tuned DistilBERT model.\nWe use the following models in this experiment.\nSome of these methods are traditional ML methods\nand some are deep neural network methods, we also\nuse the Transformer-based methods in this\nexperiment, which are advanced deep neural methods\nwith self-attention [82].\nLogistic Regression-TFIDF Vectorization (LG TFIDF): We use the Logistic Regression (LG) [77]\nwith TfidfVectorizer10 word embedding method [83].\nTFIDF Vectorization converts a collection of raw\ndocuments to a matrix of TF-IDF features. Logistic\nregression + TFIDF Vectorization has shown to be a\ngood baseline method for many classifications tasks,\nsuch as hate speech detection [84], text classification\n[85]. This is a classical ML approach.\nRandom Forest + TFIDF Vectorization (RFTFIDF): We use the Random Forest (RF) classifier\n[86] with TfidfVectorizer word embedding method.\nRandom Forest is a classifier that uses a number of\ndecision trees on different subsets of a dataset to\nimprove predictive accuracy. Random Forest + TFIDF Vectorization are also used for text classification,\nsentiment analysis and related tasks [86, 87], so it can\nserve as good method for bias detection. This is a\nclassical ML approach.\nGradient Boosting Machine + TFIDF Vectorization\n(GBM-TFIDF): We use the Gradient Boosting\nMachine (GBM) [88] with TfidfVectorizer word\nembedding method. GBM is forward learning\nensemble method that has shown good predictive\nresults through increasingly refined approximations\n[88]. This is a classical ML approach.\nLogistic Regression + ELMO (LG-ELMO): We use\nLG with ELMO embeddings. ELMo is a contextual\nword embedding technique based on bi-directional\nLSTM [89]. Unlike TFIDF methods, which look at a\ndictionary of words and build corresponding vectors,\nELMo looks at the entire sentence before assigning\neach word in the embedding. However, compared to\nTFIDF, creating ELMO embeddings is a\n10 TfidfVectorizer\n11\n\nInternational Journal of Data Science and Analytics (2022)\n\ncomputationally heavy task. LG and ELMO can be\nused for a variety of classification tasks. This is a mix\nof classical ML approach (LG method) with deep\nneural embeddings.\nMultiLayer Perceptron + ELMO (MLP- ELMO): We\nalso use the MLP11, a feedforward artificial neural\nnetwork with ELMO embeddings, which has shown\ngood performance for the classification tasks [90, 91].\nThis is a deep neural network-based method.\nBert-base: Bidirectional Encoder Representations\nfrom Transformers (BERT) is a deep neural network\nmodel pretrained on a large corpus of English data in\na self-supervised fashion [55], which has shown stateof-the-art performance in a variety of classification\ntasks [92]. We use the bert-based uncased12 in this\nwork. This is a Transformer-based approach.\nRoBERTa-base: Robustly Optimized BERT Pretraining Approach (RoBERTa) [93] optimizes the\ntraining of BERT with improved training\nmethodology. RoBERTa has also shown good\nperformance in many classification tasks, including\ntext classification [94]. This is a Transformer-based\napproach.\nDistillBERT: We also use the DistilBERT [95], which\nis a small, fast, cheap and light Transformer model\ntrained by distilling BERT base. It has 40% less\nparameters than bert-base-uncased, runs 60% faster\nwhile preserving over 95% of BERT‚Äôs performances.\nThis is a Transformer-based approach.\nThe results for the evaluation of bias detection\nmodule are shown in Table 4.\nTable 4: Effectiveness of different classification\nmodels for bias detection task\nModel\nLG-TFIDF\nRF-TFIDF\nGBM - TFIDF\nLG- ELMO\nMLP- ELMO\nBert-base\nRoBERTa-base\nDistilbert\n\nPREC\n0.62\n0.65\n0.65\n0.66\n0.69\n0.72\n0.75\n0.76\n\nREC\n0.61\n0.64\n0.66\n0.68\n0.67\n0.69\n0.70\n0.74\n\nF1\n0.61\n0.64\n0.65\n0.67\n0.68\n0.70\n0.72\n0.75\n\nOverall, the results in Table 4 show the better\nperformance of deep neural network embeddings (i.e.,\nELMo) compared to TFIDF vectorization when used\nwith LG, RF and GBM. The deep neural embeddings\nand the deep neural methods (MLP, BERT, RoBERTa\nand DistilBERT) also perform better than the\ntraditional ML methods.\n12 bert-base-uncased\n\nMLP\n\n15\n\n16\n\nInternational Journal of Data Science and Analytics (2022)\n\nThere is a slight performance difference among the\nthree classical ML approaches (LG-TFIDF, RFTFIDF, and GBM-TFIDF), with GBM-TFIDF\nmarginally performs better than the other two models.\nThis is demonstrated by GBM- TFIDF's performance,\nwhich results in a 1% higher in F1-score when\ncompared to RF-TFIDF and a 4% increase when\ncompared to LG-TFIDF.\nUsing ELMO embeddings, we can see that the LG\nmodel's performance has improved by about 5%\ncompared to LG-TFIDF. This is demonstrated by LGELMO having a higher F1-score (0.70) than LGTFIDF (0.65). Additionally, the LG-ELMO\noutperforms other traditional machine learning\napproaches by approximately 1-6 % better F1- scores.\nThe results in Table 4 also show that the deep neural\nbaseline MLP-ELMO performs better than traditional\nML baselines as well as the LG-ELMO (a mix of\nclassical ML and deep neural network embedding\nmodel). The result shows that deep neural\nembeddings, in general, can outperform traditional\nembedding method (e.g., TFIDF) in text classification\ntasks (e.g., the bias detection in this work). This is\nprobably because, deep neural embeddings can better\ncapture the context of the words in the text. The use of\ndeep neural embeddings in conjunction with a model\nbased on deep learning, such as MLP, further\nimproves the results, as demonstrated by the better\nperformance of MLP-ELMO model compared to ML\nbaselines and LG-ELMO. Though the deep neural\nnetwork methods perform better in many NLP tasks,\nthe traditional ML methods are usually faster and\ncomputationally less expensive, which is also\ndiscussed in the literature [96].\nWe also use the Transformer-based embeddings,\nsuch as from BERT, which are on dynamic word\nembeddings. Transformers are large encoder-decoder\nmodels that employ a sophisticated attention\nmechanism to process an entire sequence [82]. The\nresults show that Transformer-based methods\noutperform the other methods (ML and simple deep\nlearning-based methods) in the bias detection task.\nAmong the Transformer-based approaches, RoBERTa\noutperforms the BERT model by approximately 2% in\nterms of F1-score, while DistilBERT outperforms the\nRobBERTa model by approximately 3%.\nDistilBERT is a smaller, faster, and lighter than\nBERT and RoBERTa. When we apply DistilBERT to\n\nour dataset, it also performs significantly better than\nall the other models, as shown in Table 4. As a result,\nwe choose to work with the DistilBERT in our bias\ndetection module,\n\n13 en_core_web_sm\n\n15 en_core_web_lg\n\n14\n\n16\n\nen_core_web_md\n\n5.3 Effectiveness of bias recognition module\nWe also test the effectiveness of our biased\nrecognition module. We compared several\nconfigurations of NER models, such as ML-based\nNER pipelines, Transformer-based approach until we\nobtained a configuration that we consider to be the\nbest for our goals. Next, we see the performance of\ndifferent NER pipelines for the bias recognition task:\nSpacy core web small (sm) pipeline13 (core-sm): This\npipeline consists of following components: token-tovector, tagger part-of-speech tagging, parser, Sentence\nRecognizer, Named Entity Recognition, attribute ruler\nand a lemmatizer. It is an English pipeline trained on\nwritten web text (blogs, news, comments), which\nincludes vocabulary, syntax and entities. It is called as\n‚Äòcore‚Äô as it is based on traditional ML and packaged in\nthe Spacy Core library, which use a CPU-optimized\npipeline. The ‚Äòsmall‚Äô in this pipeline refers to the size\nof mode, which is 13 MB in this case.\nSpacy core web medium (md) pipeline14 (core-md):\nThis is the same pipeline as core-sm but with medium\nsize, which is 43 MB. The model size refers to\ndifferent configurations, e.g., more data points,\ndifferent parameters, iterations, vector size and such.\nSpacy core web large (lg) pipeline15 (core-lg): This is\nthe Spacy core NER pipeline like as core-sm and as\ncore-md but with large size, which is 741 MB.\nSpacy core web transformer (trf) pipeline16(core-trf):\nThis is spacy core NER pipeline, but it has\nTransformer as the vectorizer. The difference between\ncore-trf and other core pipelines is in the embedding\nmodel. The core-trf uses the RoBERTa [93],\nTransformer as embedding model that helps to\nautomatically identify and extract entities from the\ntext. The results of different NER pipelines to\nrecognize the biases are shown in Table 5.\nTable 5: Evaluation of different NER pipelines for\nthe bias recognition task\nModel\nCore-sm\nCore-md\nCore-lg\nCore-trf\n\nPREC\n0.59\n0.61\n0.60\n0.66\n\nREC\n0.27\n0.45\n0.62\n0.65\n\nF1\n0.37\n0.52\n0.60\n0.63\n\nACC\n0.37\n0.53\n0.67\n0.72\n\nen_core_web_trf\n\n16\n\n17\n\nInternational Journal of Data Science and Analytics (2022)\n\nThe results in Table 5 show that core-trf outperforms\nall the other NER methods in terms of precision recall,\nF1-score and accuracy. This is because a Transformerbased model can identify entities and relations within\nthe text and can generate a text representation that\ntakes the context of each term into account.\nAdditionally, these findings indicate that model\nperformance in terms of accuracy metrics improves as\nmodel size increases. This is likely due to the fact that\nthe larger model contains a greater number of\nparameter settings and data points, all of which affect\nthe model's predictive performance. However, these\nbenefits come at the expense of resource utilization,\nmemory, CPU cycles, and latency delay. Based on\nthese results, we choose to work with core-trf to\nrecognize the bias-bearing words from the news\narticles.\n5.4 Effectiveness of masking technique\nIn this section, we explore the influence of masking in\nthe MLM technique. We use different settings for the\nmask: we replace 5% of the input sequence with\n[MASK] with a probability p of 0.1, 0.3, 0.5, 0.8 and\n1.0, as in related works [55, 69]. There is no standard\nmasking percentage, but we use 5% based on the\nsentence length (around 10-40 words) of news text in\nour dataset. We then compare these settings with our\nmasking technique where we only replace the biasbearing words and we don‚Äôt make use of any random\nprobability as in typical MLM tasks [55, 69]. The goal\nof this experiment is to see if using different masking\ntechniques (with different probabilities) affects the\nfinal output. The results of our model with different\nMLM settings are shown in Figure 8.\n80.0%\n\nF-SCIRE\n\n60.0%\n40.0%\n20.0%\n0.0%\n0.1 p 0.3 p 0.5 p 0.7 p 0.9 p Exact\nMASKING\n\nFigure 8: probability p vs exact bias mask\nThe results in Figure 8 show that the performance\nof Dbias improves when probability p increases from\n0.1 till 0.7. When p is too small, the model perhaps\n17\n\ntends to overfit, since our model has many parameters.\nThus, the performance is not optimal. However, when\np is too large i.e., 0.9, the performance of model starts\nto decline. In contrast, our exact masking of biased\nwords shows the best performance. The general\nconclusion that we can draw from these results is that\nif we replace the input sequence with [MASK] using\nvarying probabilities, the model performance may be\naffected, as the model may be learning to detect only\nthe masked word, rather than actual word\nrepresentations. As our use case in this work is\nmasking the biased words only from the text, so an\nexact match can give us better results.\n5.5 Working of Dbias model\nWe release our Dbias package 17 that is used to detect\nand mitigate biases in NLP tasks. The model tasks are\nsummarized as shown in Table 6:\nTable 6: Dbias tasks\nFeature\nText Debiasing\nBias Classification\nBias Words/Phrases\nRecognition\nBias masking\n\nOutput\nReturns\ndebiased\nnews\nrecommendations with bias\nprobability\nClassifies whether a news\narticle is biased or not with\nprobability\nExtract Biased words or phrases\nfrom the news fragment\nReturns the news fragment with\nbiased words masked out\n\nThe model can be installed using the commands:\n- pip install Dbias\n- pip install\nhttps://huggingface.co/d4data/en_\npipeline/resolve/main/en_pipeline\n-any-py3-none-any.whl\nThe input to the model can be any sentences that may\ncontain biased words and we get the de-biased output.\nWe show the working our model in Figure 9.\nAs illustrated in Figure 9, given a news article or\nany text that may contain biased words, our model can\ndetermine whether or not the text is biased. This is\nmade possible by the first module: bias detection\nmodule. The output is then forwarded to the\nnext module, namely the bias recognition module,\nwhich identifies bias-bearing words. The text with\nidentified biased words is then sent to the de-biasing\nmodule, which masks the biased words and makes\nsuggestions for new words to replace them. The final\noutput is a set of non-biased or at least minimally\nbiased sentences for each input sentence.\n\nhttps://pypi.org/project/Dbias/\n\n17\n\n18\n\nInternational Journal of Data Science and Analytics (2022)\n\nFigure 9: Working of Dbias\nWe also show the bias probability that is achieved\nfrom an original news article to a de-biased article in\nFigure 10. We perform a forward pass to compute\nlogits and apply softmax to calculate probabilities. A\nlower score, here, means that less bias exists and\ntherefore detected less.\n\nFigure 10: Bias probability in a news article\nAs shown in Figure 10, our Dbias framework can\nreduce the biasness of a news article to about 50%.\n\n6\n\nDiscussion\n\nFairness in ML and AI is a relatively new but rapidly\ngrowing field of study in fields such as information\nretrieval, recommender systems, and so on. The\n\nbroader literature on fairness in ML is a crucial\nstarting point, therefore, we undertook this research\nwith great care and compassion to avoid any pitfalls\nthat result in overbroad or ungeneralizable claims.\nAs with any research study, there are limitations. In\norder to help our readers understand and generalize the\nresults, we have taken extra care to disclose the\nlimitations of the data, metrics, and methods used.\nThere are some limitations that we want to discuss\nhere, and we also discuss some future\nrecommendations.\nDifferent definitions of biases and fairness: There is\ncurrently no universally accepted definition of what\nconstitutes bias and fairness [14, 15]. The findings\ndrawn about one bias cannot be generalized to other\nbiases. Additionally, biases manifest in a variety of\nways (e.g., the bias definition of gender cannot be\napplied to ethnicity or social status). While more\nstandard definitions of biases and fairness may be\ndiscovered in the future, we must first investigate a\nwide variety of biases in different applications to\ndetermine the fairness of data and algorithms.\nBiases evolve over time: While much of the research\nin this field considers a small number of biases (social,\ndemographic, and so on), we emphasize that there are\n18\n\n19\n\nmany other types of biases that are overlooked in the\nresearch. These biases also evolve over time [41]. For\ninstance, numerous biases have arisen in recent years\nas a result of COVID-19 or U.S ELECTIONS 2016\nand 2020. Taking this limitation into account, we\ndevelop a system capable of dynamically removing\nbiases from data. This dynamic definition [14] states\nthat an initially fair system may become unfair over\ntime if users respond in a biased manner, or that it may\nevolve toward a fairer system if users respond\npositively to recommendations that improve overall\nfairness. The fundamental requirement for our system\nis to fine-tune it using the domain data. While this is a\nstart, we may need to investigate additional domains\nto enrich the Dbias pipeline.\nFairness metrics: There are many fairness metrics, for\nexample, statistical parity [97], predictive parity [98],\ncalibration [45], pairwise fairness [99] and other\n[100], in the literature. There is still much work left to\ndo to understand how best to apply and interpret these\nfairness metrics in our study.\nUse of appropriate data: Data collection is a\nsignificant challenge for fairness research because it\nfrequently requires sensitive data that cannot be\ncollected via standard information retrieval or\nrecommender system data sets. We use a manually\nannotated news dataset in this study to identify biasbearing words. We encourage researchers to use\nunstructured data to identify and mitigate more biases\nin the text without focusing exclusively on specific\ndata points (e,.g., race, gender, education).\nTransfer learning: In our Dbias modules, we used the\ntransfer learning technique. We recognize that transfer\nlearning may introduce additional biases. However,\nwe find that carefully fine-tuning the models on the\nappropriate data can be useful. For example, we finetune our modules on news data and then these models\nhelp us to detect and mitigate various biases from the\nnews data.\nScarcity of labelled biased data: One of the research's\nlimitations is the scarcity of labelled biased data. So\nfar, we have relied on the MBIC dataset to assist us in\ndetecting and mitigating bias, which has been\nvalidated through extensive experiments. However,\nwe would like to acquire more labelled data in the\nfuture to train our package.\nThere is still much work to be done toward\nachieving fairness in ML, and we hope that others in\nthe research community will continue to contribute\ntheir own approaches to fairness and bias checking,\n\nInternational Journal of Data Science and Analytics (2022)\n\nmitigation, and explanation to the toolkit. This\npackage is developed to de-bias news articles, anyone\ncan use it to train on other types of data, such as\njournalism, hiring applications, prison sentencing or\nhealth science, and then use it to de-bias that data. As\na result, one future direction is to extend the toolkit's\napplication to additional datasets and scenarios.\n\n7\n\nConclusion\n\nWe build the Dbias, a pipeline for fair ML, which is\ncomposed of three main modules: bias detection, bias\nrecognition, and de-biasing. We develop a\nTransformer-based model to detect biased news using\nlabelled news data; we develop a named entity\nrecognition model based on the Transformer\narchitecture to identify biased words in biased news\narticles; and we use the masked language modelling\ntechnique to replace the biased words in the text with\nneutral words. We compare Dbias' performance to\nstate-of-the-art fairness methods. Additionally, we\nevaluate the efficacy of individual components of\nDbias. We release Dbias as a freely downloadable\npackage for the users and practitioners. This research\nserves as a forum for researchers interested in debiasing the text. This package can be used by\ndevelopers to detect and mitigate bias.\n\nCompliance with Ethical Standards\nConflict of Interest: On behalf of all authors, the\ncorresponding author states that there is no conflict of\ninterest.\n\nReferences\n1.\n\n2.\n\n3.\n\n4.\n\n5.\n\n6.\n\nCollobert, R., Weston, J., Bottou, L., Karlen, M.,\nKavukcuoglu, K., Kuksa, P.: Natural language\nprocessing (almost) from scratch. J. Mach. Learn.\nRes. 12, 2493‚Äì2537 (2011)\nAzure, M.: Artificial Intelligence vs. Machine\nLearning\n|\nMicrosoft\nAzure,\nhttps://azure.microsoft.com/enus/overview/artificial-intelligence-ai-vs-machinelearning/#introduction\nRadford, A., Wu, J., Child, R., Luan, D., Amodei,\nD., Sutskever, I.: Language models are\nunsupervised multitask learners. OpenAI blog. 1, 9\n(2019)\nZhang, B.H., Lemoine, B., Mitchell, M.: Mitigating\nunwanted biases with adversarial learning. In:\nProceedings of the 2018 AAAI/ACM Conference\non AI, Ethics, and Society. pp. 335‚Äì340 (2018)\nMehrabi, N., Morstatter, F., Saxena, N., Lerman,\nK., Galstyan, A.: A Survey on Bias and Fairness in\nMachine Learning. ACM Comput. Surv. 54,\n(2021). https://doi.org/10.1145/3457607\nBellamy, R.K.E., Mojsilovic, A., Nagar, S.,\n19\n\n20\n\n7.\n\n8.\n\n9.\n\n10.\n11.\n\n12.\n\n13.\n\n14.\n15.\n16.\n\n17.\n18.\n\n19.\n\n20.\n\nInternational Journal of Data Science and Analytics (2022)\nRamamurthy, K.N., Richards, J., Saha, D.,\nSattigeri, P., Singh, M., Varshney, K.R., Zhang, Y.,\nDey, K., Hind, M., Hoffman, S.C., Houde, S.,\nKannan, K., Lohia, P., Martino, J., Mehta, S.: AI\nFairness 360: An extensible toolkit for detecting\nand mitigating algorithmic bias. IBM J. Res. Dev.\n63,\n(2019).\nhttps://doi.org/10.1147/JRD.2019.2942287\nJeffrey Dastin: Amazon scraps secret AI recruiting\ntool that showed bias against women,\nhttps://www.reuters.com/article/us-amazon-comjobs-automation-insight-idUSKCN1MK08G\nThe Guardian: Facebook charged with housing\ndiscrimination in targeted ads | Facebook | The\nGuardian,\nhttps://www.theguardian.com/technology/2019/ma\nr/28/facebook-ads-housing-discriminationcharges-us-government-hud\nObermeyer, Z., Powers, B., Vogeli, C.,\nMullainathan, S.: Dissecting racial bias in an\nalgorithm used to manage the health of populations.\nScience (80-. ). 366, 447‚Äì453 (2019)\nKamiran, F., Calders, T.: Data preprocessing\ntechniques\nfor\nclassification\nwithout\ndiscrimination. (2012)\nRaza, S., Ding, C.: News recommender system: a\nreview of recent progress, challenges, and\nopportunities. Artif. Intell. Rev. 1‚Äì52 (2021).\nhttps://doi.org/10.1007/s10462-021-10043-x\nRaza, S., Ding, C.: News Recommender System\nConsidering Temporal Dynamics and News\nTaxonomy. In: Proceedings - 2019 IEEE\nInternational Conference on Big Data, Big Data\n2019. pp. 920‚Äì929. Institute of Electrical and\nElectronics Engineers Inc. (2019)\nRibeiro, F.N., Henrique, L., Benevenuto, F.,\nChakraborty, A., Kulshrestha, J., Babaei, M.,\nGummadi, K.P.: Media bias monitor: Quantifying\nbiases of social media news outlets at large-scale.\nIn: Twelfth international AAAI conference on web\nand social media (2018)\nEkstrand, M.D., Das, A., Burke, R., Diaz, F.:\nFairness and Discrimination in Information Access\nSystems. 1‚Äì98 (2021)\nCaton, S., Haas, C.: Fairness in Machine Learning:\nA Survey. 1‚Äì33 (2020)\nDacon, J., Liu, H.: Does Gender Matter in the\nNews? Detecting and Examining Gender Bias in\nNews\nArticles.\n385‚Äì392\n(2021).\nhttps://doi.org/10.1145/3442442.3452325\nNielsen, A.: Practical Fairness. O‚ÄôReilly Media\n(2020)\nFeldman, M., Friedler, S.A., Moeller, J.,\nScheidegger, C., Venkatasubramanian, S.:\nCertifying and Removing Disparate Impact *.\nhttps://doi.org/10.1145/2766XXX.XXXXXXX\nZemel, R., Wu, Y., Swersky, K., Pitassi, T., Dwork,\nC.: Learning fair representations. In: International\nconference on machine learning. pp. 325‚Äì333\n(2013)\nWexler, J., Pushkarna, M., Bolukbasi, T.,\nWattenberg, M., Vi√©gas, F., Wilson, J.: The what-if\n\n21.\n22.\n\n23.\n24.\n25.\n\n26.\n\n27.\n28.\n29.\n\n30.\n31.\n\n32.\n\n33.\n\n34.\n35.\n\ntool: Interactive probing of machine learning\nmodels. IEEE Trans. Vis. Comput. Graph. 26, 56‚Äì\n65 (2019)\nDonahue, J., Kr√§henb√ºhl, P., Darrell, T.:\nAdversarial feature learning. arXiv Prepr.\narXiv1605.09782. (2016)\nRaza, S., Ding, C.: A Regularized Model to Tradeoff between Accuracy and Diversity in a News\nRecommender System. In: 2020 IEEE International\nConference on Big Data (Big Data). pp. 551‚Äì560\n(2020)\nPleiss, G., Raghavan, M., Wu, F., Kleinberg, J.,\nWeinberger, K.Q.: On fairness and calibration.\narXiv Prepr. arXiv1709.02012. (2017)\nHardt, M., Price, E., Srebro, N.: Equality of\nopportunity in supervised learning. Adv. Neural Inf.\nProcess. Syst. 29, 3315‚Äì3323 (2016)\nDixon, L., Li, J., Sorensen, J., Thain, N.,\nVasserman, L.: Measuring and mitigating\nunintended bias in text classification. In:\nProceedings of the 2018 AAAI/ACM Conference\non AI, Ethics, and Society. pp. 67‚Äì73 (2018)\nHolstein, K., Wortman Vaughan, J., Daum√© III, H.,\nDudik, M., Wallach, H.: Improving fairness in\nmachine learning systems: What do industry\npractitioners need? In: Proceedings of the 2019 CHI\nconference on human factors in computing systems.\npp. 1‚Äì16 (2019)\nKirkpatrick, K.: It‚Äôs not the algorithm, it‚Äôs the data.\nCommun. ACM. 60, 21‚Äì23 (2017)\nXu, F., Shao, G.: Building Scalable Streaming\nPipelines for Near Real-Time Features, (2021)\nWeAreNetflix: Netflix Research: Analytics,\nhttps://research.netflix.com/researcharea/recommendations%0Ahttps://research.netflix.\ncom/researcharea/recommendations%0Ahttps://www.youtube.c\nom/watch?v=sAQmj8a_aI8&amp;feature=emb_logo\nLabs, J.S.: John Snow Labs | NLP &amp; AI in\nHealthcare, https://www.johnsnowlabs.com/\nFeldman, M., Friedler, S.A., Moeller, J.,\nScheidegger, C., Venkatasubramanian, S.:\nCertifying and removing disparate impact. In:\nproceedings of the 21th ACM SIGKDD\ninternational conference on knowledge discovery\nand data mining. pp. 259‚Äì268 (2015)\nMehrabi, N., Gowda, T., Morstatter, F., Peng, N.,\nGalstyan, A.: Man is to person as woman is to\nlocation: Measuring gender bias in named entity\nrecognition. Proc. 31st ACM Conf. Hypertext Soc.\nMedia,\nHT\n2020.\n231‚Äì232\n(2020).\nhttps://doi.org/10.1145/3372923.3404804\nTram√®r, F., Atlidakis, V., Geambasu, R., Hsu, D.,\nHubaux, J.P., Humbert, M., Juels, A., Lin, H.:\nFairTest: Discovering Unwarranted Associations in\nData-Driven Applications. Proc. - 2nd IEEE Eur.\nSymp. Secur. Privacy, EuroS P 2017. 401‚Äì416\n(2017). https://doi.org/10.1109/EuroSP.2017.29\nAdebayo, J.A., others: FairML: ToolBox for\ndiagnosing bias in predictive modeling, (2016)\nBantilan, N.: Themis-ml: A fairness-aware machine\nlearning interface for end-to-end discrimination\n20\n\n21\n\n36.\n\n37.\n\n38.\n\n39.\n\n40.\n41.\n\n42.\n\n43.\n\n44.\n\n45.\n\n46.\n47.\n\n48.\n\nInternational Journal of Data Science and Analytics (2022)\ndiscovery and mitigation. J. Technol. Hum. Serv.\n36, 15‚Äì30 (2018)\nKamiran, F., Karim, A., Zhang, X.: Decision theory\nfor discrimination-aware classification. In: 2012\nIEEE 12th International Conference on Data\nMining. pp. 924‚Äì929 (2012)\nBiega, A.J., Gummadi, K.P., Weikum, G.: Equity\nof attention: Amortizing individual fairness in\nrankings. In: The 41st international acm sigir\nconference on research \&amp; development in\ninformation retrieval. pp. 405‚Äì414 (2018)\nSpinde, T., Rudnitckaia, L., Sinha, K., Hamborg, F.,\nGipp, B., Donnay, K.: MBIC ‚Äì A Media Bias\nAnnotation\nDataset\nIncluding\nAnnotator\nCharacteristics. Proc. iConference 2021. 1‚Äì8\n(2021)\nBaly, R., Karadzhov, G., Alexandrov, D., Glass, J.,\nNakov, P.: Predicting factuality of reporting and\nbias of news media sources. In: Proceedings of the\n2018 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2018. pp. 3528‚Äì\n3539 (2020)\nBruns, A.: It‚Äôs not the technology, stupid: How the\n‚ÄòEcho Chamber‚Äôand ‚ÄòFilter Bubble‚Äômetaphors have\nfailed us. Int. Assoc. Media Commun. Res. (2019)\nRaza, S., Ding, C.: Fake news detection based on\nnews content and social contexts: a transformerbased approach. Int. J. Data Sci. Anal. (2022).\nhttps://doi.org/10.1007/s41060-021-00302-z\nHapke, H., Nelson, C.: Building Machine Learning\nPipelines,\nhttp://oreilly.com/catalog/0636920260912/errata%\n0Ahttps://github.com/Building-MLPipelines/building-machine-learning-pipelines,\n(2020)\nDutta, S., Wei, D., Yueksel, H., Chen, P.Y., Liu, S.,\nVarshney, K.R.: Is there a trade-off between\nfairness and accuracy? A perspective using\nmismatched hypothesis testing. In: 37th\nInternational Conference on Machine Learning,\nICML 2020. pp. 2783‚Äì2793 (2020)\nKirchner, L., Mattu, S., Larson, J., Angwin, J.:\nMachine\nBias\n‚Äî\nProPublica,\nhttps://www.propublica.org/article/machine-biasrisk-assessments-in-criminal-sentencing\nKleinberg, J., Mullainathan, S., Raghavan, M.:\nInherent trade-offs in the fair determination of risk\nscores. Leibniz Int. Proc. Informatics, LIPIcs. 67,\n(2017).\nhttps://doi.org/10.4230/LIPIcs.ITCS.2017.43\nNarayanan, A.: Fairness Definitions and Their\nPolitics. In: Tutorial presented at the Conf. on\nFairness, Accountability, and Transparency (2018)\nDwork, C., Ilvento, C.: Group fairness under\ncomposition. In: Proceedings of the 2018\nConference on Fairness, Accountability, and\nTransparency (FAT* 2018) (2018)\nCalmon, F.P., Wei, D., Vinzamuri, B.,\nRamamurthy, K.N., Varshney, K.R.: Optimized\npre-processing for discrimination prevention. Adv.\nNeural Inf. Process. Syst. 2017-Decem, 3993‚Äì4002\n(2017)\n\n49.\n\n50.\n\n51.\n\n52.\n\n53.\n\n54.\n\n55.\n\n56.\n\n57.\n\n58.\n59.\n60.\n61.\n62.\n63.\n64.\n\nKamishima, T., Akaho, S., Asoh, H., Sakuma, J.:\nFairness-aware classifier with prejudice remover\nregularizer. In: Lecture Notes in Computer Science\n(including subseries Lecture Notes in Artificial\nIntelligence and Lecture Notes in Bioinformatics).\npp. 35‚Äì50 (2012)\nCelis, L.E., Huang, L., Keswani, V., Vishnoi, N.K.:\nClassification with fairness constraints: A metaalgorithm with provable guarantees. In:\nProceedings of the conference on fairness,\naccountability, and transparency. pp. 319‚Äì328\n(2019)\nAgarwal, A., Beygelzimer, A., Dud\‚Äô\ik, M.,\nLangford, J., Wallach, H.: A reductions approach to\nfair classification. In: International Conference on\nMachine Learning. pp. 60‚Äì69 (2018)\nUdeshi, S., Arora, P., Chattopadhyay, S.:\nAutomated directed fairness testing. In:\nProceedings of the 33rd ACM/IEEE International\nConference on Automated Software Engineering.\npp. 98‚Äì108 (2018)\nSaleiro, P., Kuester, B., Hinkson, L., London, J.,\nStevens, A., Anisfeld, A., Rodolfa, K.T., Ghani, R.:\nAequitas: A bias and fairness audit toolkit. arXiv\nPrepr. arXiv1811.05577. (2018)\nTan, C., Sun, F., Kong, T., Zhang, W., Yang, C.,\nLiu, C.: A survey on deep transfer learning. In:\nInternational conference on artificial neural\nnetworks. pp. 270‚Äì279 (2018)\nDevlin, J., Chang, M.W., Lee, K., Toutanova, K.:\nBERT: Pre-training of deep bidirectional\ntransformers for language understanding. arXiv\nPrepr. arXiv1810.04805. (2018)\nLi, B., Peng, H., Sainju, R., Yang, J., Yang, L.,\nLiang, Y., Jiang, W., Wang, B., Liu, H., Ding, C.:\nDetecting Gender Bias in Transformer-based\nModels: A Case Study on BERT. (2021)\nSinha, M., Dasgupta, T.: Determining Subjective\nBias in Text through Linguistically Informed\nTransformer based Multi-Task Network. In:\nProceedings of the 30th ACM International\nConference on Information \&amp; Knowledge\nManagement. pp. 3418‚Äì3422 (2021)\nNadeau, D., Sekine, S.: A survey of named entity\nrecognition and classification. Lingvisticae\nInvestig. 30, 3‚Äì26 (2007)\nExcell, E., Moubayed, N. Al: Towards Equal\nGender Representation in the Annotations of Toxic\nLanguage Detection. (2021)\nMishra, S., He, S., Belli, L.: Assessing\nDemographic Bias in Named Entity Recognition.\n(2020)\nKaneko, M., Bollegala, D.: Unmasking the Mask-Evaluating Social Biases in Masked Language\nModels. arXiv Prepr. arXiv2104.07496. (2021)\nG√∂lz, P., Kahng, A., Procaccia, A.D.: Paradoxes in\nfair machine learning. Adv. Neural Inf. Process.\nSyst. 32, (2019)\nMastrine, J.: Types of Media Bias and How to Spot\nIt | AllSides, https://www.allsides.com/mediabias/how-to-spot-types-of-media-bias, (2018)\nNY Times: Don‚Äôt buy the psuedo-scientific hype\n21\n\n22\n\n65.\n66.\n67.\n\n68.\n\n69.\n\n70.\n71.\n\n72.\n\n73.\n74.\n75.\n\n76.\n77.\n78.\n79.\n\n80.\n\nInternational Journal of Data Science and Analytics (2022)\nabout\ntornadoes,\nclimate\nchange,\nhttps://nypost.com/2021/12/12/dont-buy-thepsuedo-scientific-hype-about-tornadoes-climatechange\nMurphy, K.P.: Machine learning: a probabilistic\nperspective. MIT press (2012)\nYan, H., Deng, B., Li, X., Qiu, X.: TENER:\nAdapting Transformer Encoder for Named Entity\nRecognition. (2019)\nYan, H., Qian, T., Xie, L., Chen, S.: Unsupervised\ncross-lingual model transfer for named entity\nrecognition\nwith\ncontextualized\nword\nrepresentations. PLoS One. 16, e0257230 (2021).\nhttps://doi.org/10.1371/journal.pone.0257230\nTorrey, L., Shavlik, J.: Transfer learning. In:\nHandbook of research on machine learning\napplications and trends: algorithms, methods, and\ntechniques. pp. 242‚Äì264. IGI global (2010)\nSinha, K., Jia, R., Hupkes, D., Pineau, J., Williams,\nA., Kiela, D.: Masked language modeling and the\ndistributional hypothesis: Order word matters pretraining for little. arXiv Prepr. arXiv2104.06644.\n(2021)\nBBC: Billie Eilish sorry for mouthing anti-Asian\nslur in resurfaced video - BBC News,\nhttps://www.bbc.com/news/newsbeat-57564878\nWu, X., Zhang, T., Zang, L., Han, J., Hu, S.: Mask\nand infill: Applying masked language model to\nsentiment transfer. IJCAI Int. Jt. Conf. Artif. Intell.\n2019-Augus,\n5271‚Äì5277\n(2019).\nhttps://doi.org/10.24963/ijcai.2019/732\nBarocas, S., Hardt, M., Narayanan, A.: Limitations\nand Opportunities Solon Barocas , Moritz Hardt ,\nArvind Narayanan. Fairness Mach. Learn. Limit.\nOppotunities. (2019)\nGoogle, M.M., Vinodkumar, B., Google Brain, P.,\nChang, K.-W., Rom√°n, V.O.: Bias and Fairness in\nNLP. (2019)\nKnights, L.: Fair. Danc. Times. 107, 74‚Äì77 (2016).\nhttps://doi.org/10.2307/j.ctt1b7x5pt.3\nGaucher, D., Friesen, J., Kay, A.C.: Evidence That\nGendered Wording in Job Advertisements Exists\nand Sustains Gender Inequality. J. Pers. Soc.\nPsychol.\n101,\n109‚Äì128\n(2011).\nhttps://doi.org/10.1037/a0022530\nMatfield, K.: Gender Decoder: find subtle bias in\njob ads, http://gender-decoder.katmatfield.com/,\n(2016)\nWright, R.E.: Logistic regression. (1995)\nChang, C.-C., Lin, C.-J.: LIBSVM: a library for\nsupport vector machines. ACM Trans. Intell. Syst.\nTechnol. 2, 1‚Äì27 (2011)\nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu,\nB., Warde-Farley, D., Ozair, S., Courville, A.,\nBengio, Y.: Generative adversarial nets. Adv.\nNeural Inf. Process. Syst. 27, (2014)\nBobko, P., Roth, P.L.: The four-fifths rule for\nassessing adverse impact: An arithmetic, intuitive,\nand logical analysis of the rule and implications for\nfuture research and practice. In: Research in\npersonnel and human resources management.\nEmerald Group Publishing Limited (2004)\n\n81.\n\n82.\n\n83.\n\n84.\n\n85.\n\n86.\n87.\n88.\n89.\n90.\n91.\n\n92.\n\n93.\n\n94.\n95.\n\nIBM Cloud Paks: Fairness metrics overview - IBM\nDocumentation,\nhttps://www.ibm.com/docs/en/cloud-paks/cpdata/4.0?topic=openscale-fairness-metricsoverview\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J.,\nJones, L., Gomez, A.N., Kaiser, ≈Å., Polosukhin, I.:\nAttention is all you need. In: Advances in neural\ninformation processing systems. pp. 5998‚Äì6008\n(2017)\nPedregosa, F., Varoquaux, G., Gramfort, A.,\nMichel, V., Thirion, B., Grisel, O., Blondel, M.,\nPrettenhofer, P., Weiss, R., Dubourg, V.,\nVanderplas, J., Passos, A., Cournapeau, D.,\nBrucher, M., Perrot, M., Duchesnay, E.: Scikitlearn: Machine Learning in {P}ython. J. Mach.\nLearn. Res. 12, 2825‚Äì2830 (2011)\nGinting, P.S.B., Irawan, B., Setianingsih, C.: Hate\nspeech detection on twitter using multinomial\nlogistic regression classification method. In: 2019\nIEEE International Conference on Internet of\nThings and Intelligence System (IoTaIS). pp. 105‚Äì\n111 (2019)\nWang, Y., Zhou, Z., Jin, S., Liu, D., Lu, M.:\nComparisons and selections of features and\nclassifiers for short text classification. In: IOP\nConference Series: Materials Science and\nEngineering. p. 12018 (2017)\nAli, J., Khan, R., Ahmad, N., Maqsood, I.: Random\nforests and decision trees. Int. J. Comput. Sci.\nIssues. 9, 272 (2012)\nFauzi, M.A.: Random Forest Approach fo\nSentiment Analysis in Indonesian. Indones. J.\nElectr. Eng. Comput. Sci. 12, 46‚Äì50 (2018)\nFriedman, J.H.: Greedy function approximation: a\ngradient boosting machine. Ann. Stat. 1189‚Äì1232\n(2001)\nPeters, M.E., Neumann, M., Iyyer, M., Gardner, M.,\nClark, C., Lee, K., Zettlemoyer, L.: Deep\ncontextualized word representations, (2018)\nWindeatt, T.: Accuracy/diversity and ensemble\nMLP classifier design. IEEE Trans. Neural\nNetworks. 17, 1194‚Äì1211 (2006)\nWang, Y., Sohn, S., Liu, S., Shen, F., Wang, L.,\nAtkinson, E.J., Amin, S., Liu, H.: A clinical text\nclassification paradigm using weak supervision and\ndeep representation. BMC Med. Inform. Decis.\nMak.\n19,\n1‚Äì13\n(2019).\nhttps://doi.org/10.1186/s12911-018-0723-6\nSun, C., Qiu, X., Xu, Y., Huang, X.: How to FineTune BERT for Text Classification? In: Lecture\nNotes in Computer Science (including subseries\nLecture Notes in Artificial Intelligence and Lecture\nNotes in Bioinformatics). pp. 194‚Äì206 (2019)\nLiu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen,\nD., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov,\nV.: RoBERTa: A Robustly Optimized BERT\nPretraining Approach. 2383‚Äì2392 (2019)\nSchick, T., Sch√ºtze, H.: Exploiting cloze questions\nfor few shot text classification and natural language\ninference. arXiv Prepr. arXiv2001.07676. (2020)\nSanh, V., Debut, L., Chaumond, J., Wolf, T.:\n22\n\n23\n\n96.\n\n97.\n98.\n\nInternational Journal of Data Science and Analytics (2022)\nDistilBERT, a distilled version of BERT: smaller,\nfaster, cheaper and lighter. arXiv Prepr.\narXiv1910.01108. (2019)\nDacrema, M.F., Cremonesi, P., Jannach, D.: Are we\nreally making much progress? A worrying analysis\nof recent neural recommendation approaches. In:\nProceedings of the 13th ACM Conference on\nRecommender Systems. pp. 101‚Äì109 (2019)\nChouldechova, A.: Fair prediction with disparate\nimpact: A study of bias in recidivism prediction\ninstruments. Big data. 5, 153‚Äì163 (2017)\nMacCarthy, M.: Standards of fairness for disparate\n\n99.\n\n100.\n\nimpact assessment of big data algorithms. Cumb. L.\nRev. 48, 67 (2017)\nBeutel, A., Chen, J., Zhao, Z., Chi, E.H.: Data\ndecisions and theoretical implications when\nadversarially learning fair representations. arXiv\nPrepr. arXiv1707.00075. (2017)\nGarg, P., Villasenor, J., Foggo, V.: Fairness\nmetrics: A comparative analysis. In: 2020 IEEE\nInternational Conference on Big Data (Big Data).\npp. 3662‚Äì3666 (2020)\n\n23\n\n</td>
    </tr>
    <tr>
      <th>93</th>
      <td>news</td>
      <td>doi:10.1111/j.1662-6370.2011.02015.x\n\nThe Fairness of Media Coverage in Question:\nAn Analysis of Referendum Campaigns on\nWelfare State Issues in Switzerland\nLionel Marquis, Hans-Peter Schaub &amp; MarleÃÄne Gerber\nUniversity of Lausanne and University of Berne\n\nAbstract: The mass media are assigned an important role in political campaigns on popular votes.\nThis article asks how the press communicates political issues to citizens during referendum campaigns, and whether some minimal criteria for successful public deliberation are met. The press coverage of all 24 ballot votes on welfare state issues from 1995 to 2004 in Switzerland is examined,\ndistinguishing seven criteria to judge how news coverage compares to idealized notions of the media‚Äôs role in the democratic process: coverage intensity, time for public deliberation, balance in media\ncoverage, source independence and inclusiveness, substantive coverage, and spatial homogeneity.\nThe results of our quantitative analysis suggest that the press does fulÔ¨Ål these normative requirements to a reasonable extent and that fears about biased or deceitful media treatment of ballot\nissues are not well-founded. However, some potential for optimizing the coverage of referendum\ncampaigns by the Swiss press does exist.\n\nKeywords: Referendum campaigns, media fairness, press coverage, welfare state, Switzerland\n\n1. Introduction1\nInstruments of direct democracy are at the heart of the Swiss political system. They are\nwidely used, so much in fact that Switzerland alone accounts for half of all referendums\nheld at the national level all over the world (Kaufmann et al. 2005; DuVivier 2006). Quite\nexpectedly, this unequalled degree of direct democratic practice has triggered research to\nexplore the determinants, conditions, and outcomes of the use of initiatives and referendums, as well as research to Ô¨Ånd out the causes of their success or failure. For example,\nSwiss scholars have directed their attention to the institutional eÔ¨Äects of the referendum on\nthe integration of political forces and to its role in shaping the Swiss concordance system\n(e.g., Neidhart 1970; Papadopoulos 1998; Vatter 2002). Another important area of inquiry\nfocused on individual and aggregate citizen behaviour in referendum votes, relating voting\npatterns to the level of elite support or to structural properties of campaign propaganda\n(e.g., Hertig 1982; Trechsel and Sciarini 1998; BuÃàtzer and Marquis 2002).\n1\n\nThis research was carried out at the University of Berne in the framework of a project on the ‚Äò‚ÄòPolitical Consequences of Attitudes Toward the Welfare State‚Äô‚Äô funded by the Swiss National Science Foundation, whose Ô¨Ånancial\nsupport is gratefully acknowledged (grant #100012‚Äì108274). The authors would like to thank Klaus Armingeon\nand Nathalie Giger for their support, as well as Hans Hirter, head of the Anne¬¥e Politique Suisse series, for giving\nus access to its invaluable archive of Swiss press releases. We also thank two anonymous reviewers for their extremely helpful comments on an earlier draft of our manuscript.\n\n 2011 Swiss Political Science Association\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nSwiss Political Science Review 17(2): 128‚Äì163\n\n129\n\nIn this study, we follow a complementary approach. SpeciÔ¨Åcally, we ask how political\nissues are communicated to citizens during referendum campaigns, and whether some minimal criteria for successful public deliberation are met. Our analysis is based on the press\ncoverage of twenty-four ballot votes on welfare issues, spanning more than two legislative\nperiods (1995‚Äì2004) of highest importance for the development of the Swiss welfare state.\nAccordingly, our aim is to shed light on the journalistic perception of ballot campaigns.\nHowever, the views of political actors directly involved in partisan campaigns (e.g., parties,\nbusiness associations) are also reÔ¨Çected in their agenda-building eÔ¨Äorts to capture and manage media attention. It is from the interplay between these two perspectives on the news\nprocess ‚Äî the journalists‚Äô gatekeeping role and the elites‚Äô agenda-building role ‚Äî that the\nfocal questions of this study arise. What is the degree of media autonomy? How inclusive\nare journalists‚Äô accounts of the political actors involved in campaigns? How biased are their\nportrayals of issues?\nIn the next section of the paper we present some current ideas about public deliberation\nand provide theoretical insights into the structure and functions of referendum campaigns.\nWe thus set a number of criteria for assessing whether media campaigns may be regarded as\nwise guides to sound decision-making. Section 3 then presents the empirical data collected\nand the methods used for measuring the quality of media campaign coverage. Sections 4 to\n7 oÔ¨Äer evidence of how journalists report on welfare state issues. We show that the press\ntreatment of these issues does not fall short of expectations as concerns seven distinct criteria\nof ‚Äò‚Äòfair coverage‚Äô‚Äô. On this overall basis, we conclude in Section 8 that some fears about\nskewed or deceitful media treatment of ballot issues are not justiÔ¨Åed, but also that the\ncommunication and framing of issues does not meet all conceivable normative requirements.\n\n2. Theoretical background: Criteria of fair media coverage\nThis article focuses on the ‚Äò‚Äòsupply side‚Äô‚Äô of referendum campaigns. SpeciÔ¨Åcally, we attempt\nto deÔ¨Åne a number of dimensions on which to judge the fairness and democratic utility of\nthe coverage of referendum issues in the Swiss media. The importance of articulating ‚Äò‚Äòdemocratic expectations of media performance‚Äô‚Äô has been emphasized in several contributions\n(e.g., Gurevitch and Blumler 1990; McLeod et al. 2002). In particular, the ‚Äò‚Äòsocial responsibility‚Äô‚Äô of the media has attracted much attention, leading scholars to deÔ¨Åne a number of\ndesirable qualities of media content ‚Äì‚Äì some of which may be properly regarded as ‚Äò‚Äòethical‚Äô‚Äô, but others are more directly related to the functioning of democratic systems (e.g.,\nBunton 1998; Christians and Nordenstreng 2004).\nOur questioning in this article takes place in the interplay of several disciplines ‚Äî including media ethics and the theory of deliberative democracy. These are broad and currently\nexpanding disciplinary areas rather than formalized theories coupled with established methods and Ô¨Åeldwork, as the example of deliberative theory suggests (see BaÃàchtiger et al. 2010).\nThese theoretical accounts do not provide a clear and agreed-upon indication of what\nmedia fairness should be conceived of, let alone how to measure fairness. However, to the\nextent that the media are an important arena where democratic deliberation may occur, one\nmajor conceptual distinction from deliberative theory is helpful for framing our approach\nto media fairness.\nScholars in the deliberative framework usually advance that democratic decision-making\nand deliberation may be appraised (and purportedly justiÔ¨Åed) either from an epistemic or\nfrom a procedural standpoint (see Cohen 1986; Estlund 1997; List and Goodin 2001). The\ndistinction is captured in the question of ‚Äò‚Äòwhether we want our political outcomes to be\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nright or whether we want them to be fair‚Äô‚Äô (List and Goodin 2001: 277). To be sure, democratic processes oriented toward the search for ‚Äò‚Äòtruth‚Äô‚Äô or toward the observance of procedures may often bring about similar outcomes. It is nevertheless easy to imagine cases\nwhere ‚Äò‚Äòcorrectness‚Äô‚Äô lacks procedural fairness (e.g., one individual ‚Äò‚Äòrightly‚Äô‚Äô chooses for all\nothers) and other cases where procedural rigidity is misplaced from procedure-independent\nstandards (e.g., it violates some notion of the ‚Äò‚Äòcommon good‚Äô‚Äô).\nThe Ô¨Åeld of media ethics is concerned with the same kind of questions, asking whether\nand how the ‚Äò‚Äòfairness‚Äô‚Äô goal of media coverage can put up with the sometimes dissonant\nideal of the ‚Äò‚Äòcorrectness‚Äô‚Äô of the views being presented ‚Äî beyond the mere question of\ninformation ‚Äò‚Äòaccuracy‚Äô‚Äô. In this article we adopt a procedural stance and examine how media\ncoverage fulÔ¨Åls a number of formal rules regarding the form, provenance, and diÔ¨Äusion of\ninformation.2 Even though correctness criteria may appear to involve considerations of a\nmore normative nature, it is however obvious that any set of formal-procedural rules is\nitself not ‚Äò‚Äògiven‚Äô‚Äô. As will become clear, some of the procedural criteria described below\nhave been the subject of considerable speculation and debate. Moreover, ‚Äò‚Äòfairness‚Äô‚Äô, as the\npivotal concept of procedural approaches, is to be taken here in a generic sense, as it\nextends beyond the notions of fairness developed in careful theoretical analyses of ‚Äò‚Äòdemocratic proceduralism‚Äô‚Äô (Cohen 1989; Estlund 1997).3 This enlarged concept of media fairness\nposits that, whatever the media induce citizens to think and choose, they must do so within\ncertain procedural boundaries.\nIn this article we will focus on seven criteria that appear particularly relevant to evaluating the fairness of the media coverage of referendum campaigns in Switzerland. In this and\nthe following sections we identify these criteria at a fairly abstract level, based on the available literature, and we show how each of them provides an appropriate dimension for\nassessing the achievements of campaign coverage from a normative perspective. Our goal in\nthis contribution is primarily comparative, as we aim at showing how fairness varies across\nissue domains, across media outlets, over time, and across geographical units. Therefore,\nwe deliberately avoid setting precise boundaries between ‚Äò‚Äòfair‚Äô‚Äô and ‚Äò‚Äòunfair‚Äô‚Äô coverage. On\nthe other hand, the measurement of relevant criteria should be as precise and abstracted\nfrom context as possible, in order to allow for valid and meaningful comparisons. Besides,\nin order to avoid conceptual ambiguities, let us make clear that the term ‚Äò‚Äòfairness‚Äô‚Äô is used\nhere to denote the ‚Äò‚Äòpositive side‚Äô‚Äô on each dimension of media coverage. Thus we do not\nwish to imply, for instance, that a short, two-week campaign coverage is deliberately\n‚Äò‚Äòunfair‚Äô‚Äô or intended to fool voters, but only that a longer time period is more desirable\naccording to some formal-procedural normative standard.\nBased on this broad deÔ¨Ånition, we now delineate seven speciÔ¨Åc criteria for appraising the\nfairness of media campaign coverage.\n2\nBy choosing a procedural rather than epistemic perspective, we do not mean to imply any superiority or higher\ndesirability of the former perspective in dealing with our subject.\n3\nNevertheless, the fact that the elaboration and selection of procedural criteria is no less subjective than that of\nepistemic principles does not mean that the fundamental distinction between the two types of considerations is\nblurred. Generally speaking, our approach to media fairness is blind to information which may be of uttermost\nimportance from an epistemic perspective ‚Äî the speciÔ¨Åc opinions and origins of information purveyed in media\ncoverage. We do not say that journalists are not (or should not be) driven by an orientation toward the common\ngood, as when they downplay opinions that are disruptive and threatening for the democratic order ‚Äî for example,\nBritish and German journalists have totally ignored extreme right parties in their coverage of election campaigns in\nthe 1980s and 1990s (Bornschier 2010: 174-5). We simply say that this reference to the explicit content and implicit\nintent of media coverage is not relevant for our present purposes.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n130\n\n131\n\n1. SuÔ¨Écient media coverage of issues. We Ô¨Årst consider the information function of the\nmass media and the public knowledge of political issues that is expected to stem from media\ninformation. Learning eÔ¨Äects are extremely important from a normative perspective, since\nthey attest to the capacity of the people to understand politics and to exert inÔ¨Çuence on\npolicies, as emphasized by classical democratic theory (e.g., Berelson 1952; Kelley 1960;\nKrouse and Marcus 1984; but see Pateman 1970). As a matter of fact, it has long been\nshown that media exposure generates knowledge about issues and candidates, and enhances\nopinion strength and attitude integration (e.g., Berelson et al. 1954: chap. 11; Delli Carpini\nand Keeter 1996: chap. 5; Jerit et al. 2006). These eÔ¨Äects are usually not overwhelming, but\nthey are quite robust across a wide range of contexts. Accordingly, learning eÔ¨Äects have\nbeen observed in the Swiss direct democratic context as well (Kriesi 1994; Kriesi 2005: chap.\n4; Marquis 2006). Information holding, in turn, matters for political judgments and voting\ndecisions (Bartels 1996; Sturgis 2003). For example, a lack of knowledge causes citizens to\nbe more conservative on some issues and more liberal on others (Althaus 1998; Gilens\n2001), and it usually prompts reliance on heuristic cues that can lead to serious misÔ¨Åts\nbetween the people‚Äôs actual choices and their own values and interests (e.g., Kuklinski and\nQuirk 2000). Therefore, the overall intensity of media campaign coverage probably matters\nboth for the public knowledge of issues and for the Ô¨Ånal outcome of the ballots. In fact,\nfew would question that a suÔ¨Écient amount of information is necessary for the proper functioning of democratic institutions. However, as argued below, the content of information\nalso deserves attention, especially as concerns value-laden information (e.g., Hofstetter\net al. 1999).\n2. SuÔ¨Écient time for public deliberation. Time is needed for the public to become\ninformed about the issues and to ponder the pros and cons of a ballot proposal. If all campaign coverage takes place in a last-minute avalanche, then it is unlikely to beneÔ¨Åt citizens,\nhowever extensive it may be in terms of sheer volume. Quite logically, the inÔ¨Çuence of a\ncampaign usually concentrates on citizens who make up their minds during that campaign,\nthat is, for people whose voting decision was neither clear from the outset nor delayed until\nthe very last campaign days (e.g., ChaÔ¨Äee and Choe 1980; Fournier et al. 2004; Marquis\n2006). Were campaigns so short-lived as to be virtually nonexistent for the purpose of\ndeliberation, the collective decision-making process would be essentially reduced to the use\nof last-minute shortcuts (e.g., status quo bias) or of long-standing attitudes and prejudices\n(e.g., a personal bias against ‚Äò‚Äòbig government‚Äô‚Äô). The longer the referendum campaigns, the\nmore likely it is that the same issues will be tackled and thus the same arguments will be\nrepeated. In turn, this cumulative exposure may be expected to facilitate information acquisition by citizens (see Marquis and Bergman 2009). In other words, frequent exposure to\ncampaign information enhances the accessibility of the relevant concepts (e.g., Higgins\n1996; FoÃàrster and Liberman 2007) and heightens the likelihood that they will permeate the\ncitizens‚Äô voting considerations.\n3. No outright bias in media coverage. A relatively unbiased media coverage of issues may\nbe stressed as a prerequisite for sound collective deliberation. This ‚Äò‚Äòimpartiality‚Äô‚Äô or ‚Äò‚Äòbalance‚Äô‚Äô assumption is more or less explicitly present in the writings of political philosophers\nsuch as Arendt, Elster, and Habermas, but also in concrete experiments designed to mimic\nideal deliberative procedures (e.g., Yankelovich 1991: chap. 12; Luskin et al. 2002). Likewise, the norm of balance is deeply enmeshed in Western (primarily Anglo-American) culture and values (Schudson 2001). It looms large in the self-descriptions and perceived\nprofessional standards of journalists (e.g., Tuchman 1972; Patterson 1998) and in academic\nstudies of media coverage unveiling their structural biases (e.g., Gitlin 1980; Hallin 1984;\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nEntman 2004; Bennett et al. 2007).4 In addition, the development of ‚Äò‚Äòmedia watchdog journalism‚Äô‚Äô monitoring media bias is, in part, reÔ¨Çective of the increasingly acute perception of\nthe media bias problem in Western societies (Graber 2006; Hayes 2008). For our present\npurposes, such ‚Äò‚Äòissue neutrality‚Äô‚Äô may come in several forms: the media may simultaneously\npresent the arguments of both sides on an issue, or they may successively alternate between\npros and cons (and thus act neutrally on an aggregate basis), or else they may restrict themselves to presenting ‚Äò‚Äòfacts‚Äô‚Äô and avoid matters of opinion. Meanwhile, the requirement that\nthere be no outright bias in media coverage must not be taken to mean that the media\nshould display no partisan bias, or that they should avoid expressing opinions altogether.\nActually, some bias is inevitable and probably inconsequential, provided that it is not systematic and identical across all media outlets and issues. In addition, some mix of factual\ninformation and opinion statements is probably preferable to either one alone, for voters\nmost certainly need ‚Äì‚Äì and look for ‚Äì‚Äì both types of information to make up their minds.\nAs one study has shown, a voter‚Äôs general need for orientation toward media information is\ncodetermined by her interest in acquiring knowledge about facts and about journalistic evaluations (Matthes 2005).\n4. Source independence. Similar to balance, the ‚Äò‚Äòsource independence‚Äô‚Äô norm implies\nthat the media are assigned responsibility for addressing issues in an autonomous manner.\nIn this case, the normative expectation is that journalists should not depend too heavily\non government, political parties and special interests for getting and framing information\non campaign issues. Actually, there is a widespread belief in Western societies, including\nSwitzerland, that journalists have ‚Äò‚Äòsurrendered to complexity‚Äô‚Äô and mainly serve as emissaries or ‚Äò‚Äòpostmen‚Äô‚Äô, as Wuerth (1999: 373) put it. According to the ‚Äò‚Äòdetermination\nhypothesis‚Äô‚Äô and similar accounts of media-politics relationships, most news originates\nfrom oÔ¨Écial sources, including government and various branches of the administration,\nand especially from governmental public relations activities. Such source dependency, so\nthe critics say, would lead to the formation of a misinformed and quiescent public (e.g.,\nBaerns 1979; King and Schudson 1995; Shoemaker and Reese 1995; Bentele 2003). For\ninstance, Grossenbacher et al. (2006) found that the press conferences held by two Swiss\ncantonal governments were indeed covered extensively by the local media, and that the\npress releases issued on these occasions were often published in original or only slightly\nabridged form, reproducing the local authorities‚Äô positive self-assessments and issue priority. Likewise, more than half of the news stories in the U.S. press persistently emanate\nfrom oÔ¨Écial sources (e.g., Sigal 1973; Graber 2006). However, some scholars have cast\ndoubt on the generalizability of such Ô¨Åndings. For instance, it was found that the parties‚Äô\npress releases rarely Ô¨Ånd their way into the German print media and ‚ÅÑ or that they are frequently altered and reframed by journalists (e.g., Donsbach and Wenzel 2002; FroÃàhlich\nand RuÃàdiger 2006). To some extent, journalists and their political sources are interdependent, both from a historical perspective (SchoÃànhagen 2008) and in terms of role relationships (Merritt 1995). Journalists themselves are ambivalent about the autonomy issue. On\nthe one hand, they increasingly value public relations sources and practitioners in the\n4\n\nBiased coverage may occur in relatively subtle ways, such as when the photographs of candidates in newspapers\nare more or less favourable, depending on the Ô¨Åt between the candidate‚Äôs and the paper‚Äôs political leanings (Barrett\nand Barrington 2005). However, no consensus can be found in the literature as to whether media coverage is structurally biased, for instance conservative-leaning vs. liberal-leaning, or pro- vs. anti-establishment. Interestingly, the\npublic perception that the media are biased toward liberal views may not be due to ‚Äò‚Äòreal-world‚Äô‚Äô media coverage\nbias, but to media self-coverage about biased media content (Watts et al. 1999).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n132\n\n133\n\ncourse of their professional experience (Sallot and Johnson 2006), not least because by\ncreating long-term relationships with insiders they are granted routine access to valuable\nÔ¨Årst-hand information. On the other hand, ‚Äò‚Äòautonomy‚Äô‚Äô is seen as an important journalistic norm (e.g., Gurevitch and Blumler 1977; McDevitt 2003), admittedly with some important diÔ¨Äerences between national contexts (Patterson 1998; Statham 2006).5 In the present\nstudy, we will assess to what extent journalistic accounts of the campaign issues are elaborated ‚Äò‚Äòindependently‚Äô‚Äô or based instead on ‚Äò‚Äòself-serving‚Äô‚Äô sources of information such as\ngovernment, parties, and referendum committees.\n5. Source inclusiveness. The norm of inclusion calls for the coverage of the whole diversity of viewpoints, arguments, and groups engaged in a referendum campaign. This norm\nthus concerns the question of how broad the variety of sources to which journalists refer\n(and which they make available to the public) should be. From another perspective, it\nasks how open or restricted the access to the media should be for diÔ¨Äerent actors to\nvoice their standpoints toward a referendum issue. Several democratic theorists have\nstressed the importance of an unrestricted and equal access for all individuals and societal groups to democratic processes in general (e.g., Dahl 1989: 119‚Äì131) and to the processes of public deliberation and will-formation in particular. The inclusiveness of the\nlatter is especially prominent in theories of deliberative democracy. Cohen (1989: 21‚Äì23,\n30; see also Dryzek 1990; Habermas 1992) regards inclusiveness and open access as a\ncrucial aspect of an ‚Äò‚Äòideal deliberative procedure‚Äô‚Äô.6 However, various empirical studies\nhave raised doubts about whether the media in reality live up to these expectations of\ndemocratic theorists (e.g., Page 1996; Gerhards 1997; Graber 2003). Pfetsch (2004) and\nBerkowitz (2009) argue that the degree of inclusiveness heavily varies depending on factors such as the cultural context, the journalists‚Äô social characteristics, or the issue at\nstake. SpeciÔ¨Åcally for Swiss referendums, Marquis and Bergman (2009) report a quite\nmarked decrease in the variety of actors involved in advertisement campaigns in the\n1990s. One reason for a low variety of sources might be the increasing commodiÔ¨Åcation\nand commercialization of the media, which presses them to restrict themselves to sources\ncompatible with the mainstream (Meier and Jarren 2002). Second, an increasing professionalization in the PR departments of the more established political actors might raise\nthe hurdles for less prominent and Ô¨Ånancially disadvantaged groups to Ô¨Ånd their way\ninto the media (Gurevitch and Blumler 1990). Third, while there do exist strategies for\npolitical ‚Äò‚Äòoutsiders‚Äô‚Äô to get included in a mediated political discourse, established political\nactors have also developed counter-strategies to hold outsiders and their arguments oÔ¨Ä\nthe media attention (Kriesi 2003: 221‚Äì225). In the following analysis, we will assess the\nvariety of reported viewpoints by the number of diÔ¨Äerent groups of actors which journalists draw on as information sources.\n6. Substantive coverage. For many observers, it is not enough that media information\nbe balanced and independent of special interests ‚Äî in addition, it has to address the\nsubstance of political issues. In fact, an essential part of campaign news coverage is\n5\n\nFurther, journalists may feel committed to autonomy as a result of their own audiences‚Äô support for the norm\nof impartial coverage (Hargreaves and Thomas 2002) and as a result of their commitment being challenged by\n‚Äò‚Äòpopular commentators‚Äô‚Äô such as bloggers (Singer 2007). In fact, public trust in the media may be undermined by\nexcessive governmental control (Connolly and Hargreaves Heap 2007).\n6\nThe inclusion of the whole diversity of opinions and societal groups is also a core request of the so-called ‚Äò‚ÄòdiÔ¨Äerence democrats‚Äô‚Äô, who emphasize that it enhances not only the legitimacy of the opinion-building process, but also\nthe stock of social knowledge and information available to the participants in the public discourse, thus facilitating\nwell-informed and rational decisions (Young 1990: 119; 2000: 81‚Äì120; see also Connolly 1991).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nframed in terms of non-substantive features of elections, such as their ‚Äò‚Äògame‚Äô‚Äô or\n‚Äò‚Äòhorserace‚Äô‚Äô aspects, and ignores their underlying issues (e.g., StroÃàmbaÃàck and Dimitrova\n2006). A strong case has been made against the pervasiveness and deleterious inÔ¨Çuence\nof horserace information in a variety of election campaigns (e.g., Gollin 1980; Bartels\n1988; Patterson 1994). We therefore only brieÔ¨Çy discuss the relevance of the issue for\nthe Swiss direct democratic environment. As pointed out by Rothmayr and Hardmeier\n(2002) and Longchamp (1998), the practice of direct democracy in Switzerland has\ninhibited rather than stimulated the development and use of opinion polls by both the\nmedia and governmental agencies. This is because frequent and ‚Äò‚Äòreal‚Äô‚Äô voting results\nare widely considered to provide a better account of public opinion than ‚Äò‚Äòunrealistic‚Äô‚Äô,\n‚Äò‚Äòout-of-context‚Äô‚Äô opinion polls. However, Swiss journalists may Ô¨Ånd such polls attractive\nto report, in light of the news media‚Äôs preference for the ‚Äò‚Äòhorserace‚Äô‚Äô aspects of campaigns and for warfare and sports narratives. Moreover, they may Ô¨Ånd it convenient to\ndraw on such ready-to-use information, without paying too much attention to its technical validity and practical relevance (see Hardmeier 1999). As a way to gauge the\nextent of horserace coverage, we will compare the amounts of ‚Äò‚Äòcampaign-oriented‚Äô‚Äô and\nof ‚Äò‚Äòissue-oriented‚Äô‚Äô information provided by the media.\n7. Spatial homogeneity. In a multicultural society such as Switzerland, the protection\nof minorities is usually a pressing issue. In addition, there is widespread concern that\ndirect democratic decisions might heighten the risk of some ‚Äò‚Äòtyranny of the majority‚Äô‚Äô\n(e.g., Donovan and Bowler 1998; Hajnal et al. 2002). In Switzerland, diÔ¨Äerences between\nlinguistic regions, particularly as concerns voting behaviour in referendums, constitute\none of the most salient political cleavages (e.g., Kriesi 1998; Linder et al. 2008). This\ncleavage is also one that is clearly identiÔ¨Åable and frequently reported on in the news\nmedia, probably because it is conÔ¨Çict-laden and thus has a high news value (Kriesi et al.\n1996; Hardmeier 2000: 388). The Swiss media system is itself highly segmented along linguistic lines (Kriesi et al. 1996; Wuerth 1999; Blum 2003; Tresch 2008), and even the\npublic service media Ô¨Ånd it increasingly diÔ¨Écult to promote national cohesion, as this\ntask is incompatible with economic imperatives (Meier and Schanne 1994: 37‚Äì39). In\nfact, concerns about majority rule are not substantiated by empirical evidence in general\nterms, as referendum voting patterns are much more homogeneous than heterogeneous\nacross cantonal and linguistic units (Diskin et al. 2007). In some cases, however, these\nconcerns may be justiÔ¨Åed, as suggested by parliamentary votes or referenda results on welfare state issues, showing support for welfare policies to be signiÔ¨Åcantly higher in the\nFrench- than in the German-speaking region (e.g., Leuthold et al. 2007). To be sure, it is\nperfectly legitimate for journalists from diÔ¨Äerent places and cultural backgrounds to pursue their own agendas, for example as they index their treatment of job issues to real or\nperceived unemployment rates in their own area. Likewise, journalists may choose diÔ¨Äerent speciÔ¨Åc information ‚Äò‚Äòformats‚Äô‚Äô (e.g., heavily biased ‚Äò‚Äòopinion‚Äô‚Äô articles or more balanced ‚Äò‚Äòpoints of view‚Äô‚Äô articles) depending on their cultural environment and on how\nparochial the interests at stake are (e.g., Robinson 1995: 360‚Äì362). Accordingly, there is\nno reason to expect equal issue coverage all over the country. However, the inÔ¨Çuence of\nthe media on voters can diÔ¨Äer between the linguistic areas (e.g., Kriesi 1994; Marquis\n2006: 623‚Äì628). Hence, heterogeneity of media content may reinforce existing cleavages\nand (re)produce undesirable tensions between linguistic communities. In the cases where\nthe majority group prevails, it may fuel the argument of a ‚Äò‚Äòtyranny of the majority‚Äô‚Äô. In\nsum, small between-region variations in media coverage are arguably preferable to great\nvariations.\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n134\n\n135\n\n3. Methods and measurements\nThis study bears on the 24 ballot votes dealing with welfare state issues which were held in\nSwitzerland between 1995 and 2004 (see Table A1 in Appendix). Our empirical data consists of press articles collected in twenty-eight daily or weekly newspapers during an eightweek period preceding each ballot. The papers together account for a daily circulation Ô¨Ågure of about two million copies and they are quite representative of the various Swiss\nregions.7 However, they were selected mainly for availability reasons, as they are consulted\non a daily basis by the collaborators of the Anne¬¥e Politique Suisse at the University\nof Berne, Switzerland, and their content is classiÔ¨Åed into Ô¨Åne-grained thematic categories.\nIt was thus easy to Ô¨Ånd out all campaign-related articles and to code the relevant\ninformation.\nTwo levels of analysis: articles and issue statements. Overall 4303 articles were found and\ncoded. From these, a one-quarter sample of 1088 articles was randomly selected for additional analysis of the campaign issue statements.8 A maximum of three issue statements per\narticle were coded, with the selection occurring on the basis of internal importance within\neach article. In total, 2859 issues were coded out of our sample, making for an average of\n2.63 issues per article.\nIntensity and length. The number of articles and their size (in centimetres squared, then\nconverted in number of standard newspaper pages) were used to determine the intensity of\ncampaign coverage.9 Based on the date on which an article was published, the number of\ndays remaining before voting day was used to compute a measure of the ‚Äò‚Äòaverage campaign\nday‚Äô‚Äô (mean of days remaining for separate ballots or newspapers).\nSource independence and inclusiveness. Up to Ô¨Åve sources per article were coded to determine who the ‚Äò‚Äòspeakers‚Äô‚Äô were, i.e., which categories of individuals or groups were primarily involved in determining the content of an article. Multiple sources were considered; for\nexample, when a journalist interviews a political leader, two separate sources are coded.\nSimilarly, up to two sources were coded for each issue statement within an article. We thus\ncontrol for the fact that the original issue arguments delivered by a given source are often\nembedded in the discourse of a diÔ¨Äerent ‚Äò‚Äòspeaker‚Äô‚Äô through positive or negative references.\nFor example, it can be the case that all issue statements contained in an article where\n7\n\nThe 1998 circulation Ô¨Ågures are taken from the WEMF marketing research institute. The two related outlets\n‚Äò‚ÄòBlick‚Äô‚Äô and ‚Äò‚ÄòSonntags-Blick‚Äô‚Äô are considered here as one and the same paper. In contrast, the French-speaking\ntabloid ‚Äò‚ÄòLe Matin‚Äô‚Äô was not available in the archive of the Anne¬¥e Politique Suisse, although it is one of the major\nSwiss papers. However, a glimpse at the data for ‚Äò‚ÄòBlick‚Äô‚Äô, its counterpart in the German-speaking region, suggests\nthat tabloids play a relatively minor role in the coverage of referendum campaigns. As a matter of fact, the 28 outlets are edited in 16 diÔ¨Äerent Swiss cantons (out of a total of 26 cantons). Further, according to survey data, a\nmajority of people in all but three cantons (SO, TG, ZH) are ‚Äò‚Äòheavy‚Äô‚Äô or ‚Äò‚Äòmedium users‚Äô‚Äô of at least one newspaper\namong those considered here (http://www.remp.ch/fr/glossar/index.php [accessed: 15.02.2010]).\n8\nThe selection was performed by simply picking every fourth article in the database, reinitializing the count for\neach ballot issue. Checks were made to ensure that the obtained sample was not diÔ¨Äerent from the whole dataset as\nconcerns provenance, format, and article bias. An issue statement is deÔ¨Åned here as an argument or set of arguments related to one speciÔ¨Åc matter addressed in the campaign about a ballot measure. It may pertain to a policy\ntheme (e.g., environment, energy), a driving value or principle (e.g., solidarity), distinctive qualities of the proposed\nmeasure (e.g., Ô¨Çexibility), or the larger context of the ballots (e.g., rationale for a tactic vote). Issue statements have\nbeen classiÔ¨Åed into thirty-three categories (full list available upon request from the authors). For reasons of space\nlimitation, however, we will not dwell on the question of which speciÔ¨Åc issues were emphasized in the various referendum campaigns.\n9\nFor various reasons (e.g., missing part), 24 articles could not be coded as to their size and were assigned the median value of all calculated sizes (266 cm2).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\n‚Äò‚Äòjournalists‚Äô‚Äô are identiÔ¨Åed as the speaker category are in fact attributable to other actors to\nwhich journalists refer (e.g., partisan sources, government, and employees‚Äô associations).\nBoth speakers and issue statements‚Äô sources were coded into fourteen mutually exclusive\ncategories: (1) parties, politicians, and other party-related groups or individuals; (2) committees; (3) journalists and press agencies; (4) employers‚Äô organizations; (5) employees‚Äô\norganizations; (6) economic associations; (7) national government; (8) local government; (9)\nscience- and education-related groups; (10) health-related groups; (11) disabled people‚Äôs\ngroups; (12) women‚Äôs and families‚Äô groups; (13) other non-proÔ¨Åt organizations; (14) other\nactors. Together, categories (1) and (2) represent what we call ‚Äò‚Äòpartisan actors‚Äô‚Äô.10\nThe importance of journalists (category 3) will be compared with that of the other actor\ncategories (both as ‚Äò‚Äòspeakers‚Äô‚Äô and as sources of issue statements) to assess the degree of\nthe press‚Äô ‚Äò‚Äòsource independence‚Äô‚Äô. Note, however, that the total for any two groups of\nactors may exceed 100 percent since, by deÔ¨Ånition, several actors may be considered as the\n‚Äò‚Äòsources‚Äô‚Äô of an article or issue statement.\nFurther, we used the same source categories to build our measure of inclusiveness. It is\nsimply the number of discrete categories from which at least one source of issue statements\nis drawn. In some of the forthcoming analyses, we will satisfy ourselves with this Ô¨Årst measure (NBCAT). However, in order to control for the fact that some sources may be only\nmarginally involved in agenda-building (and inclusiveness may thus be overestimated), we\nalso assessed the degree of ‚Äò‚Äòequality‚Äô‚Äô in the total references to sources of issue statements.\nThis was achieved through the Index of Qualitative Variation (IQV):\n\n\nk\nP\n2\n2\nk N  fi\nIQV ¬º\n\ni¬º1\n\nN2 √∞k  1√û\n\n;\n\nwhere k is the total number of source categories, N is the total number of (weighted) issue\nstatements, and fi is the frequency of all issue statements attributable to source i (N and f\nmay be computed either as absolute numbers or as proportions). IQV scores can be integrated with NBCAT into a standardized measure of inclusiveness: INC=(NBCAT ‚ÅÑ 14) ¬∑\nIQV. Somewhat surprisingly, NBCAT and IQV scores are totally uncorrelated at the level of\nballot measures or of separate media outlets (r &lt; .06). In fact, restriction of range in IQV\nvalues (M = 0.87, SD = 0.04, N = 24 ballot measures) explains why NBCAT has a much\ngreater impact in determining INC scores.11 It also justiÔ¨Åes using NBCAT alone, for simpliÔ¨Åcation purposes, when IQV scores barely vary in cross-temporal and spatial comparisons.\nSubstantive coverage. The ‚Äò‚Äòformat‚Äô‚Äô of each article was coded following a three-fold distinction: (1) ‚Äò‚Äòopinion articles‚Äô‚Äô (i.e., editorials, interviews, op-eds, free columns, or letters to\nthe editor); (2) ‚Äò‚Äòfactual articles‚Äô‚Äô (i.e., mere reporting); and (3) ‚Äò‚Äòhorserace information‚Äô‚Äô\n(i.e., voting cues by parties and groups, opinion polls and other predictions, coverage of\ncampaign events). The percentage of articles of the ‚Äò‚Äòhorserace‚Äô‚Äô type is used to assess the\namount of ‚Äò‚Äònon-substantive‚Äô‚Äô information. Among ‚Äò‚Äòsubstantive articles‚Äô‚Äô, the percentage of\n10\n\nUnlike in other policy areas such as foreign policy (see Marquis 2006), virtually all committees on welfare state\nissues are backed by parties and politicians.\n11\nAt the level of ballots and papers, INC is strongly associated with NBCAT (r &gt; 0.96) but not with IQV scores\n(r &lt; 0.19). This raises the question whether the aggregation rule (unweighted multiplication of the two measures)\nis appropriate, since both NBcat and IQV are important on theoretical grounds. At the empirical level, however, it\nmakes sense not to give more weight to the variable with lesser variation.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n136\n\n137\n\n‚Äò‚Äòopinion‚Äô‚Äô and ‚Äò‚Äòfactual‚Äô‚Äô articles is used to shed light on the ‚Äò‚Äòorientation‚Äô‚Äô and ‚Äò‚Äòinformation‚Äô‚Äô functions of press coverage, respectively.\nBias in coverage. Five broad categories aimed to assess the overall thrust of each article,\nbased on the general slant of its arguments: (1) predominantly pro (i.e., suggesting a ‚Äòyes‚Äô\nvote on the ballot question); (2) predominantly con; (3) neutral; (4) mixed, i.e., controversial\nand including both sides; and (5) no argument. Similarly, the bias of each issue statement\nwas coded on the basis of the same categories (excepting the ‚Äò‚Äòno argument‚Äô‚Äô category,\nwhich is irrelevant). The categories were collapsed across ballot measures or other relevant\nunits of analysis (newspapers, language areas, etc.) and combined to produce a summary\nindicator of coverage bias:\n\n\n\npro √æ neu √æ mix\nB¬º\n 0:5  2;\npro √æ con √æ 2  √∞neu √æ mix√û\nwhere pro is the number of positive items, con is the number of negative items, neu is the\nnumber of neutral items, and mix is the number of controversial items.12 Unbiased coverage\nis denoted by a B value of 0, while B values of ‚Äì1 and +1 indicate the highest possible bias\nagainst and in favour of some proposal, respectively.\nHowever, B scores are not well adapted for comparing bias in coverage across several\nballot measures, since the meaning of pros and cons depends on how the ballot question\nwas framed. One strategy is to rely on absolute values (i.e., |B| scores) to get an estimation\nof the overall extent of bias, regardless of direction. Another strategy is to devise a measure\nthat expresses bias in terms of endorsement or opposition of welfare state policies. This\nrequires that ‚Äò‚Äòpro‚Äô‚Äô and ‚Äò‚Äòcon‚Äô‚Äô categories be inverted for ballots in the ‚Äò‚Äòretrenchment‚Äô‚Äô category, i.e., measures that seek to reduce welfare beneÔ¨Åts or to limit welfare expansion. Thus\nan original B score of +0.2 remains unchanged for expansion measures but its polarity is\ninverted and shifted to ‚Äì0.2 for retrenchment measures. We call this new measure B*. Computing B* scores also implies that ballot measures can be clearly identiÔ¨Åed as ‚Äò‚Äòexpansion‚Äô‚Äô\nor ‚Äò‚Äòretrenchment‚Äô‚Äô measures. In other words, only media contents that can be clearly\nassigned to ‚Äò‚Äòpro-welfare‚Äô‚Äô and ‚Äò‚Äòanti-welfare‚Äô‚Äô positions should be considered. This leads us\nto remove three ‚Äò‚Äòpopulist‚Äô‚Äô proposals (ballots 724, 732, and 781; see Table A1) from the\nanalysis whenever media bias is analyzed by means of B* scores.13 Except in this case, however, and unless indicated otherwise, all indicators used in this study are based on the total\nnumber of ballots (i.e., 24).\n\n12\nWe take into account ‚Äò‚Äòneutral‚Äô‚Äô and ‚Äò‚Äòmixed‚Äô‚Äô items because failing to do so leads to serious distortions in the\ncases where coverage is mostly neutral but where only a few biased stories would result in meaninglessly high scores\nof coverage bias. Thus, for example, a number of positive items twice larger than that of negative items but equal\nto the number of non-valenced (i.e., neutral and controversial) items yields a B of ‚Äò‚Äòonly‚Äô‚Äô about 0.14. By the same\ntoken, B scores are expected to be more polarized when measured at the level of issue statements rather than at the\nlevel of articles, because in the former case the number of non-valenced items is considerably lower. Note also that\nB is very strongly correlated (r &gt; 0.98) with alternative measures of media bias, such as that used by Zaller and\nChiu (1996).\n13\nFor our purposes, we deÔ¨Åne populist proposals as emanating from right-wing nationalist parties and groups,\nand being opposed by other parties. They consist of ‚Äò‚Äòradical‚Äô‚Äô, often ‚Äò‚Äòsimplistic‚Äô‚Äô solutions to welfare problems,\nusually charging ‚Äò‚Äòbig business‚Äô‚Äô, high-proÔ¨Åt sectors, or available public wealth. However, as these proposals do not\nalign with the traditional ideological cleavages on welfare issues, opposition to them does not imply an endorsement of the welfare system. Accordingly, these proposals are hardly comparable with other proposals.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nSpatial homogeneity. Indicators for each of the six above criteria of media fairness can\nbe compared between the two main cultural areas in order to assess the homogeneity\nof media coverage. Simple diÔ¨Äerences are calculated between values for the majority\n(German-speaking) cultural area and those of minority areas. The only Italian-speaking\npaper in our database (i.e., Corriere del Ticino) is considered together with the Frenchspeaking outlets.14\nValidity checks. Each of the two independent coders read half the selected articles and\nmeasured all particular aspects listed above. Intercoder disagreement was examined from a\nsample of all coded articles and settled through discussion, resulting in more Ô¨Åne-grained\nand univocal coding procedures. The issue statements of all the 1088 selected articles were\nthen coded again. Finally, a sample of 24 articles (one for each proposal) was drawn to\ncheck for coding consistency. Intercoder reliability was found to be satisfactory (Cohen‚Äôs\nkappa=0.704).15\nWeighting procedures. Except for analyses bearing solely on the sheer number of articles,\ntwo weighting procedures were applied. First, in keeping with the literature on public attention and response (e.g., Neuman 1990; Price and Zaller 1993), the size of articles was logged\nand used as a weighting factor to account for the notion that marginal returns of an\nincrease in news volume are generally diminishing. That is, for example, the diÔ¨Äerence\nbetween a Ô¨Åve-inch-squared, barely visible, short article and a half-page article is probably\nmore consequential than the diÔ¨Äerence between a full-page and a double-page article.\nSecond, the ‚Äò‚Äòinternal length‚Äô‚Äô of issue statements was used to weigh their importance within\nour sample.16\n\n4. An overall view of press performance\nTable 1 gives an overview of six of the seven criteria of media fairness presented in the theoretical and measurement sections ‚Äî the ‚Äò‚Äòspatial homogeneity‚Äô‚Äô dimension shall be analyzed\nseparately below.\n\nIntensity of coverage\nThere is little reason to expect journalists to devote equal attention to all subject matters;\nsome issues are of greater concern to them (and to their readers) and are thus more likely\nto Ô¨Ånd their way onto the media agenda. In fact, there is a good deal of variation in the\n\n14\n\nJournalists and political actors from the two minority cultural areas usually share the same general orientation\ntoward welfare politics (though not in other important policy Ô¨Åelds) and are probably closer to each other than\nthey are to journalists and political actors from the German-speaking majority. More importantly, diÔ¨Äerences\nbetween majority and all minority areas are more commented upon and likely to be more consequential for\nnational cohesion than diÔ¨Äerences between minorities.\n15\nThis is actually a more than ‚Äò‚Äòfair‚Äô‚Äô performance according to the standard interpretation by Landis and Koch\n(1977: 165). 67 issue statements were coded by the two coders simultaneously, i.e., an average of 2.8 issues per article. Three issues were coded by only one coder and were removed from the analysis, thus very slightly overestimating intercoder reliability by obfuscating disagreement over the sheer number of issue statements present in a press\narticle. However, when the three issues are taken into account, the level of disagreement rises by a very small\namount, and j is still 0.67.\n16\nFive rough categories approximating the ‚Äò‚Äòinternal length‚Äô‚Äô of issue statements were recoded into Ô¨Åve ratios\nreÔ¨Çecting their share in the whole article: 0.20, 0.35, 0.50, 0.65, and 0.80.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n138\n\n 2011 Swiss Political Science Association\n\n22.5\n\n45.1\n\n23.8\n\n60.0\n\n64.5\n\n74.9\n\n71\n\n171\n\n100\n\n186\n\n238\n\n275\n\n21.1\n\n82\n\n48.9\n\n19.8\n\n83\n\n156\n\n64.7\n\n258\n\n48.9\n\n61.5\n\n216\n\n156\n\n95.1\n\n317\n\n91.7\n\n64.3\n\n185\n\n312\n\n96.7\n\nSurfaceb\n\n301\n\nNumbera\n\n0.757\n\n0.628\n\n0.732\n\n0.505\n\n0.587\n\n0.389\n\n0.444\n\n0.444\n\n0.729\n\n0.488\n\n0.434\n\n0.762\n\n0.618\n\n0.858\n\n0.666\n\n0.694\n\nInclusivenessc\n\n25.9\n\n26.2\n\n26.4\n\n20.9\n\n25.5\n\n22.0\n\n26.4\n\n26.4\n\n26.7\n\n23.3\n\n18.6\n\n24.5\n\n19.5\n\n23.0\n\n22.7\n\n22.7\n\nAverage\ncampaign\ndayd\n\n)0.315\n)0.013\n)0.122\n)0.208\n\n)0.071\n)0.046\n)0.064\n)0.086\n\n0.168\n\n)0.489\n\n)0.255\n\n0.075\n\n)0.139\n\n)0.098\n\n)0.210\n\n)0.176\n\n)0.151\n\n)0.071\n\n0.089\n\n)0.098\n\n)0.103\n\n)0.050\n\n0.249\n\n87.3\n\n)0.108\n\n)0.074\n\n0.054\n\n78.6\n\n)0.042\n\n)0.006\n\n89.8\n\n89.9\n\n92.1\n\n83.0\n\n89.1\n\n93.7\n\n85.5\n\n85.5\n\n81.5\n\n78.6\n\n78.8\n\n81.0\n\n81.6\n\n)0.142\n\n)0.062\n\n84.3\n\n% Journalists\n(articles)f\n\n0.144\n\nIssue\nbiase\n\n0.075\n\nArticle\nbiase\n\n21.0\n\n22.2\n\n4.6\n\n20.1\n\n12.1\n\n20.1\n\n19.6\n\n19.6\n\n21.8\n\n21.8\n\n3.2\n\n22.3\n\n15.2\n\n13.0\n\n21.7\n\n18.5\n\n% Parties\n(articles)f\n\n25.5\n\n17.2\n\n22.9\n\n31.1\n\n28.2\n\n44.9\n\n31.0\n\n31.0\n\n31.2\n\n17.1\n\n15.0\n\n20.4\n\n35.2\n\n22.8\n\n39.4\n\n28.7\n\n% Journalists\n(issues)f\n\n47.7\n\n57.7\n\n29.6\n\n57.1\n\n36.6\n\n23.0\n\n47.1\n\n47.0\n\n44.6\n\n47.5\n\n34.7\n\n42.8\n\n40.4\n\n39.6\n\n38.8\n\n43.7\n\n% Parties\n(issues)f\n\n42.0\n\n36.6\n\n61.9\n\n52.0\n\n63.8\n\n46.7\n\n49.2\n\n48.6\n\n53.6\n\n45.6\n\n35.5\n\n50.6\n\n50.8\n\n47.5\n\n49.2\n\n48.4\n\n% Reportingg\n\n31.7\n\n32.8\n\n33.2\n\n38.6\n\n27.8\n\n42.2\n\n39.9\n\n40.5\n\n35.4\n\n41.2\n\n33.6\n\n41.4\n\n42.2\n\n38.6\n\n36.8\n\n33.7\n\n% Opiniong\n\n26.3\n\n30.6\n\n4.9\n\n9.3\n\n8.4\n\n11.2\n\n10.9\n\n10.9\n\n11.0\n\n13.2\n\n30.9\n\n8.0\n\n7.0\n\n13.9\n\n14.0\n\n17.9\n\n% Horseraceg\n\n139\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n571 R ‚ÅÑ Reform of pension\nsystem (1995)\n572 I ‚ÅÑ ‚Äò‚ÄòFor extending the\npension system‚Äô‚Äô (1995)\n602 R ‚ÅÑ Labour (weekend ‚ÅÑ night work) (1996)\n622 R ‚ÅÑ Unemployment\ninsurance (1997)\n643 I ‚ÅÑ Retirement age\n(1998)\n654 R ‚ÅÑ Labour (night\nwork, maternity) (1998)\n684 R ‚ÅÑ Disability\ninsurance (1999)\n685 R ‚ÅÑ Maternity\ninsurance (1999)\n721 I ‚ÅÑ Retirement age for\nwomen (2000)\n722 I ‚ÅÑ ‚Äò‚ÄòFlexible\nretirement age‚Äô‚Äô (2000)\n724 I ‚ÅÑ ‚Äò‚ÄòReduced hospital\ncosts‚Äô‚Äô (2000)\n732 I ‚ÅÑ ‚Äò‚ÄòCheaper drugs‚Äô‚Äô\n(2001)\n752 I ‚ÅÑ ‚Äò‚ÄòSecure pension\nsystem‚Äô‚Äô (2001)\n762 I ‚ÅÑ Reduction of work\ntime (2002)\n781 I ‚ÅÑ ‚Äò‚ÄòGold to pensions‚Äô‚Äô\n(2002)\n782 CP ‚ÅÑ ‚Äò‚ÄòGold to\npensions‚Äô‚Äô (2002)\n\nProject (R=referendum,\nI=initiative,\nCP=counterproposal)\n\nTable 1: Indicators of fairness for media coverage of 24 ballot issues\n\nMedia Coverage of Referendum Campaigns\n\n 2011 Swiss Political Science Association\n\n29.0\n\n48.9\n\n40.3\n\n109\n\n170\n\n131\n\n197.0\n(63.5)\n121.5\n(41.2)\n273.0\n(39.0)\n122.5\n(40.5)\n173.8\n(91.0)\n\nNumbera\n\n57.6\n(19.1)\n34.8\n(12.8)\n76.8\n(14.9)\n33.2\n(12.2)\n51.0\n(29.5)\n\nSurfaceb\n\n52.0\n(R=1248.1)\n22.4\n\n45.4\n\n163\n\n179.3\n(R=4303)\n73.5\n\n49.9\n\n152\n\n61.9\n\n21.8\n\n92\n\n234\n\n47.5\n\nSurfaceb\n\n145\n\nNumbera\n\n0.606\n(0.120)\n0.533\n(0.091)\n0.781\n(0.052)\n0.621\n(0.133)\n0.667\n(0.155)\n\nInclusivenessc\n\n0.131\n\n0.623\n\n0.834\n\n0.475\n\n0.683\n\n0.645\n\n0.754\n\n0.629\n\n0.525\n\n0.674\n\nInclusivenessc\n\n25.0\n(2.1)\n22.9\n(3.5)\n25.6\n(1.1)\n23.9\n(0.6)\n22.8\n(2.8)\n\nAverage\ncampaign\ndayd\n\n2.8\n\n24.1\n\n24.6\n\n27.2\n\n27.4\n\n22.9\n\n24.5\n\n26.5\n\n17.6\n\n26.9\n\nAverage\ncampaign\ndayd\n\n0.079\n(0.021)\n0.138\n(0.076)\n0.073\n(0.019)\n0.121\n(0.054)\n0.051\n(0.030)\n\nArticle\nbiash\n0.135\n(0.070)\n0.300\n(0.179)\n0.353\n(0.103)\n0.308\n(0.098)\n0.061\n(0.042)\n\nIssue\nbiash\n\n0.138\n\n0.182h\n\n0.086h\n0.049\n\n0.456\n\n0.252\n\n0.091\n\n0.114\n\n0.026\n\n0.008\n\n)0.046\n0.081\n\n0.406\n\n)0.008\n\n)0.070\n0.067\n\n0.387\n\n0.156\n\nIssue\nbiase\n\n0.156\n\n0.064\n\nArticle\nbiase\n\n86.3\n(4.5)\n88.3\n(4.2)\n87.6\n(6.1)\n80.5\n(1.9)\n86.4\n(4.0)\n\n% Journalists\n(articles)f\n\n5.2\n\n86.4\n\n93.7\n\n93.1\n\n92.0\n\n85.1\n\n82.4\n\n88.7\n\n81.8\n\n96.0\n\n% Journalists\n(articles)f\n\n20.8\n(1.2)\n17.7\n(3.6)\n17.2\n(4.6)\n19.2\n(2.5)\n8.8\n(4.9)\n\n% Parties\n(articles)f\n\n5.2\n\n17.3\n\n12.6\n\n21.0\n\n21.6\n\n14.3\n\n16.7\n\n17.3\n\n21.3\n\n13.1\n\n% Parties\n(articles)f\n\n25.9\n(7.4)\n28.6\n(10.5)\n28.6\n(2.5)\n17.6\n(0.5)\n23.6\n(6.7)\n\n% Journalists\n(issues)f\n\n7.9\n\n25.8\n\n26.1\n\n21.8\n\n13.1\n\n33.8\n\n18.1\n\n26.0\n\n15.5\n\n22.1\n\n% Journalists\n(issues)f\n\n48.2\n(6.6)\n40.4\n(16.1)\n44.5\n(0.1)\n46.8\n(0.7)\n36.3\n(4.6)\n\n% Parties\n(issues)f\n\n9.5\n\n43.5\n\n44.3\n\n42.5\n\n57.8\n\n41.2\n\n46.0\n\n66.7\n\n35.3\n\n32.5\n\n% Parties\n(issues)f\n\n49.3\n(6.2)\n50.9\n(7.5)\n55.5\n(1.9)\n51.4\n(5.8)\n47.2\n(9.5)\n\n%\nReportingg\n\n7.5\n\n50.6\n\n57.5\n\n58.0\n\n58.3\n\n44.1\n\n57.2\n\n48.0\n\n45.1\n\n64.8\n\n% Reportingg\n\n36.1\n(3.6)\n37.3\n(5.8)\n28.8\n(6.6)\n35.2\n(6.0)\n33.0\n(4.2)\n\n% Opiniong\n\n5.3\n\n35.2\n\n22.2\n\n34.3\n\n31.7\n\n26.6\n\n29.1\n\n37.6\n\n41.8\n\n32.0\n\n% Opiniong\n\n14.6\n(7.6)\n11.8\n(2.2)\n15.7\n(4.7)\n13.4\n(0.2)\n19.7\n(10.8)\n\n% Horseraceg\n\n7.7\n\n14.2\n\n20.3\n\n7.7\n\n10.0\n\n29.3\n\n13.6\n\n14.4\n\n13.1\n\n3.2\n\n% Horseraceg\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nLabour regulation (N = 4)\n\nDisability (N = 2)\n\nMaternity (N = 2)\n\nHealth (N = 4)\n\nPensions (N = 10)\n\nMeans for categories of\nproject (standard\ndeviations in parentheses)\n\nStd. dev.\n\n792 R ‚ÅÑ Unemployment\nbeneÔ¨Åts (2002)\n802 R ‚ÅÑ Financing of\nhospital treatments (2003)\n815 I ‚ÅÑ ‚Äò‚ÄòHealth must\nremain aÔ¨Äordable‚Äô‚Äô (2003)\n816 I ‚ÅÑ ‚Äò‚ÄòEqual rights for\ndisabled‚Äô‚Äô (2003)\n819 I ‚ÅÑ ‚Äò‚ÄòApprenticeship\nplaces‚Äô‚Äô (2003)\n831 R ‚ÅÑ Increase of\npension age for women\n(2004)\n832 R ‚ÅÑ Financing\npensions through VAT\n(2004)\n844 R ‚ÅÑ Maternity\ninsurance (2004)\nMean (N = 24)\n\nProject (R=referendum,\nI=initiative,\nCP=counterproposal)\n\nTable 1: (Continued)\n\n140\n\n 2011 Swiss Political Science Association\n\n180.5\n(35.5)\n205.2\n(83.5)\n160.0\n(68.6)\n172.8\n(67.3)\n189.4\n(87.7)\n162.1\n(51.1)\n\nNumbera\n\n54.5\n(7.0)\n61.8\n(26.9)\n44.0\n(17.1)\n49.7\n(20.0)\n55.1\n(27.9)\n47.3\n(14.6)\n\nSurfaceb\n0.646\n(0.028)\n0.669\n(0.110)\n0.535\n(0.104)\n0.622\n(0.134)\n0.638\n(0.137)\n0.599\n(0.122)\n\nInclusivenessc\n23.2\n(3.7)\n23.8\n(2.7)\n24.6\n(1.8)\n24.1\n(2.9)\n23.4\n(3.4)\n24.6\n(1.9)\n\nAverage\ncampaign\ndayd\n0.069\n(0.005)\n0.079\n(0.050)\n0.137\n(0.083)\n0.079\n(0.029)\n0.089\n(0.045)\n0.084\n(0.054)\n\nArticle\nbiash\n0.132\n(0.024)\n0.114\n(0.064)\n0.337\n(0.116)\n0.178\n(0.140)\n0.191\n(0.132)\n0.175\n(0.149)\n\nIssue\nbiash\n87.4\n(8.6)\n85.1\n(6.7)\n90.9\n(2.0)\n86.0\n(4.5)\n86.2\n(6.2)\n86.3\n(4.3)\n\n% Journalists\n(articles)f\n14.2\n(1.1)\n17.2\n(3.7)\n18.1\n(4.4)\n17.1\n(5.9)\n16.7\n(5.6)\n17.5\n(4.9)\n\n% Parties\n(articles)f\n28.7\n(6.6)\n23.2\n(7.3)\n30.1\n(11.4)\n25.9\n(6.8)\n22.6\n(6.8)\n28.7\n(8.0)\n\n% Journalists\n(issues)f\n36.4\n(3.9)\n43.6\n(7.8)\n39.1\n(14.3)\n44.4\n(8.7)\n42.1\n(6.7)\n44.5\n(11.7)\n\n% Parties\n(issues)f\n57.8\n(7.0)\n52.6\n(6.8)\n49.0\n(11.2)\n50.2\n(6.7)\n51.4\n(7.8)\n50.7\n(7.2)\n\n%\nReportingg\n\n37.1\n(5.1)\n36.6\n(4.3)\n34.2\n(6.0)\n34.8\n(5.5)\n35.1\n(5.5)\n35.5\n(5.2)\n\n% Opiniong\n\n5.1\n(1.9)\n10.9\n(4.8)\n16.7\n(9.9)\n15.0\n(7.8)\n13.5\n(7.2)\n13.8\n(7.7)\n\n% Horseraceg\n\n141\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNotes: a: Number of articles. b: Surface in standard newspaper pages (one page=1247 cm2). c: Number of actor categories ¬∑ IQV (see text for calculation details). d: Mean number of days remaining before voting day. e: B scores comprised between -1 (all articles ‚ÅÑ issues against project) and\n+1 (all articles ‚ÅÑ issues in favour of project); see text for calculation details. f: Sum of categories ‚Äò‚Äòjournalists‚Äô‚Äô (including press agencies) and ‚Äò‚Äòparties‚Äô‚Äô (including referendum ‚ÅÑ initiative committees) may exceed 100%, since several actors may be considered as the ‚Äò‚Äòsources‚Äô‚Äô of an article. g: Percentage of articles in each category (see text for deÔ¨Ånition). h: Means computed from absolute values for each ballot, i.e. |B|. i: Not considered\nhere: counterproposal to the ‚Äò‚Äògold‚Äô‚Äô initiative (ballot #782; see Appendix).\n\nInitiative (N = 12)i\n\nExpansion proposal\n(N = 15)\nReferendum (N = 11)i\n\nRetrenchment proposal\n(N = 6)\nPopulist proposal (N = 3)\n\nUnemployment (N = 2)\n\nMeans for categories of\nproject (standard\ndeviations in parentheses)\n\nTable 1: (Continued)\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nintensity of media coverage of the various ballot issues (SD is about 22 full newspaper\npages for an overall mean of 52 pages). As shown in Table 1, the intensity of press coverage\nvaries between the speciÔ¨Åc policy Ô¨Åelds subsumed under the heading ‚Äò‚Äòwelfare state issues‚Äô‚Äô.\nMaternity seems by far the most important category of issues; in contrast, health and disability are of less importance. Further, it seems that retrenchment proposals lead to more\nintense campaigns than expansion or populist proposals. This is understandable, since cutting back beneÔ¨Åts may lead to more mobilization by target groups than the promise of\ndeveloping beneÔ¨Åts can possibly achieve. As noted above, though, the two proposals to\nintroduce a maternity insurance are a notable exception in this regard as they elicited substantial press coverage, probably due to the fact that the constitutional mandate to implement a maternity leave program dated back to the end of World War II and thus the issue\nwas a recurring one.17 Likewise, referendums are somewhat more covered by the press than\ninitiatives, probably because they bear more frequently on retrenchment programs, but the\ndiÔ¨Äerence is modest.\nIn brief, the intensity of press coverage appears to vary between the diÔ¨Äerent policy Ô¨Åelds,\narguably as a result of the journalists‚Äô intrinsic interest in them and due to the varying\nmobilization of political and civil society actors. But, to a large extent, campaign intensity\nis probably also exogenously determined by the uncertainty of the result of the ballot. Both\ncampaigners and voters are more likely to get involved in referendums when the margin of\nvictory is perceived to be small (e.g., Downs 1957; KirchgaÃàssner and Schulz 2005). Likewise,\nin our dataset the overall intensity of press coverage is substantially correlated with the\ncloseness of the voting results.18 The closer the (expected) outcome, the more journalists\nreport on issues.\n\nSource inclusiveness\nOne indicator of the fairness of the coverage of a ballot issue is how many diÔ¨Äerent\npolitical actors are involved in the deliberation process. Our standardized measure of\ninclusiveness points to a respectable diversity in the sources of issue statements in press\ncoverage (overall mean=0.62). It is highest for maternity issues, and lowest for public\nhealth issues, as well as for issues comprised in the ‚Äò‚Äòpopulist‚Äô‚Äô category. We thus assume\nthat inclusiveness depends on the nature of issues (see Pfetsch 2004: 87‚Äì93), as further\nsuggested by the fact that campaign intensity varies between policy Ô¨Åelds, as we have\nseen. Indeed, intensity was shown to depend strongly on inclusiveness, as far as advertisement campaigns are concerned (Marquis and Bergman 2009). Similarly, in press coverage, the correlation between our indicators of intensity and inclusiveness is fairly high\n(Pearson‚Äôs r = 0.76). In other words, the more political actors enter the Ô¨Åeld (and journalists‚Äô accounts presumably reÔ¨Çect this increasing diversity), the more likely the issue at\nhand is to receive general attention from the press ‚Äî whether because inclusiveness\ndetermines intensity or because both coverage features are determined by some higherlevel concept such as ‚Äò‚Äòissue importance‚Äô‚Äô.\n\n17\n\nPrior to the 1999 and 2004 votes, no less than three proposals to create a maternity insurance had already been\nrejected at the polls (Dec. 8, 1974; Dec. 2, 1984; and Dec. 6, 1987).\n18\nThe correlation coeÔ¨Écient is ‚Äì.54 for the number of articles and ‚Äì.48 for total surface. Closeness is measured as\nthe absolute diÔ¨Äerence between the actual result and a perfectly balanced result: CLOSENESS = | 50 ‚Äì RESULT |.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n142\n\n143\n\nLength of coverage\nCampaigns in Swiss direct democracy, whether through paid advertisements or in press\nreporting, usually unfold in two phases: there is Ô¨Årst an accelerating expansion of coverage\nand then a sharp decline in the last days before the vote (e.g., Marquis 2006: 429‚Äì438;\nTresch 2008: 147‚Äì149). Based on all articles published during all 24 campaigns, a thirdorder polynomial function modelling this typical development accounts for 67 percent of\nthe variance in the total daily surface of articles.19 Hence, at the aggregate level, the twophase pattern Ô¨Åts the data quite well: referendum campaigns on welfare state issues develop\nin a typical way, similar to what has been observed for other types of issues.20 In addition,\nall policy Ô¨Åelds follow roughly the same pattern ‚Äî the only notable diÔ¨Äerence is that campaigns on health matters (including maternity and disability) reach their peak earlier than\nother types of issues.\nThese Ô¨Åndings may dispel concerns that most media information on ballot issues is\nreleased too fast and too late for citizens to use it eÔ¨Éciently in their decision making. But\nactually how long is the press coverage of ballot issues? Drawing on our indicator of the\n‚Äò‚Äòaverage campaign day‚Äô‚Äô, the ‚Äò‚Äòaverage information‚Äô‚Äô is published some 24 days before the\nvoting date (i.e, it corresponds to the ‚Äò‚Äòmean average day‚Äô‚Äô for all 24 ballots). In the same\nperspective, the average median day is 21.6; this means that, in a typical campaign, half of\nthe total (weighted) sum of all information has been released three weeks before voting day,\nand the other half is to be released in the remaining weeks. In addition, there appears to be\nlittle diÔ¨Äerence between the various ballot issues ‚Äî even though ballot issues that draw\nmore intense coverage (pensions, maternity) also tend to be covered for a slightly longer\ntime. To be sure, actual exposure to the Ô¨Çow of information delivered during referendum\ncampaigns may greatly vary from one citizen to another, depending for example on which\nmedia outlet (if any) they use for their information (see below). But our Ô¨Åndings are hardly\ncompatible with the argument that citizens are too time-pressed to make up their minds\nand are not given a chance to learn what the ballot issues are all about.\n\nSource independence\nThe question of media independence and autonomy is important, both from the perspective\nof media practices and ethics and for the purposes of deliberative processes. For example,\nTresch (2008: 142‚Äì149) shows that ‚Äò‚Äòagenda-building‚Äô‚Äô by political actors through press conferences, party meetings, and other public relations activities, constitutes a substantial part\nof media content in referendum campaigns. Even though such coverage is certainly not\nwithout merit for citizens‚Äô information and orientation, an overly reliance on external\nagenda-building eÔ¨Äorts may lead to media instrumentalization beyond that which stems\nfrom patterns of media ownership (see Hallin and Mancini 2004).\n19\nThe following function was Ô¨Åtted to the data: Surface = 0.0015 time3 ‚Äì 0.1464 time2 + 3.7937 time + 4.3653,\nwith surface measured as a three-day moving average and time measured as the number of days remaining until\nvoting day. The proportion of explained variance rises to 80 percent when Sunday editions are removed. Because\nof their non-continuous time structure, such editions introduce ‚Äò‚Äònoise‚Äô‚Äô into the data. However, only Ô¨Åve outlets\nare weekly papers or are published on Sunday, and only 2 percent of articles were published on that weekday.\n20\nAt the level of each single ballot, the characteristic sigmoid shape can be found for all but four campaigns. With\nthe exception of ballots 572, 622, 781, and 782, all functions have positive values for time3 and time, and negative\nvalues for time2. Article size (rather than number) was used, and time was recoded in eight weekly periods to avoid\nhigh Ô¨Çuctuation in daily values. The average R2 for all 24 campaigns is 0.61 (SD=0.23).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nIf we Ô¨Årst consider journalists and partisan actors (i.e., parties and committees) in their\nrole of ‚Äò‚Äòspeakers‚Äô‚Äô at the level of articles, it comes as no surprise that journalists outweigh\npartisan actors (86 percent vs. 17 percent, on average). More remarkably, the diÔ¨Äerences\nbetween the various ballot proposals are quite limited. Journalists were identiÔ¨Åed as ‚Äò‚Äòspeakers‚Äô‚Äô in 80 to 88 percent of all articles in each of the six policy Ô¨Åelds, while the corresponding interval is 14 to 21 percent for partisan actors ‚Äî with the notable exception of labour\nmarket policies, where the parties‚Äô share is only 9 percent.21 As for governmental speakers,\nthey appear in less than 10 percent of articles in all policy Ô¨Åelds. (Note that the percentages\nfor the various categories add up to more than 100 percent, since any article can draw on\nseveral types of speakers.)\nAt the level of issue statements, recall that a total of 2859 issues were coded out of our\nsample of 1088 articles. Parties and committees account for about 44 percent of all coded\nissue statements, journalists and press agencies for 26 percent, governmental actors for 17\npercent, employers‚Äô and employees‚Äô organizations for 14 percent, and other types of actors\nfor 20 percent (similar to articles, percentages do not add to 100 percent because several\ncategories of actors can be involved as sources of one issue).22 Overall, then, journalists\nappear much less important as a source of issue statements than as a source of articles\n(i.e., as ‚Äò‚Äòspeakers‚Äô‚Äô), which makes perfect sense. Conversely, even though partisan actors\nare rarely directly involved as speakers (e.g., through interviews or op-eds), they largely\nsucceed in inÔ¨Çuencing campaign news by having their issue statements reported in the press\n(Bonfadelli and Blum 2000; Tresch 2008).\n\nBias in media coverage\nThe extent of bias in press coverage can also be investigated at two levels: at the level of\nwhole articles and at the level of issue statements. The analysis draws in both cases on the\nclassiÔ¨Åcation of newspapers‚Äô content into partial (pro or con), neutral, and controversial\ncategories. The resulting B scores theoretically vary between ‚Äì1 (all content is against ballot\nproposal) and +1 (all content is in favour of proposal). B scores are generally higher for\nissues than for articles, because, for one thing, there are far less ‚Äò‚Äòneutral‚Äô‚Äô and ‚Äò‚Äòcontroversial‚Äô‚Äô items (about 27 percent) in issue statements than at the level of whole articles (about\n68 percent).\nA striking feature of our results in Table 1 is the relative neutrality with which Swiss\njournalists report on the issues, at least taken collectively ‚Äî the question of diÔ¨Äerences\nbetween media outlets will be addressed below. The mean absolute B value is 0.09 for\narticles and 0.18 for issue statements. In fact, a good deal of this ‚Äò‚Äòdirectional thrust‚Äô‚Äô\nin media reporting is concentrated on ballot issues dealing with health matters (public\nhealth, maternity, disability). For example, the initiatives for ‚Äò‚Äòreduced hospital costs‚Äô‚Äô\n(2000) and ‚Äò‚Äòequal rights for disabled people‚Äô‚Äô (2003), as well as the referendum to\noppose paid maternity leaves (2004), stirred up considerable criticism or enthusiasm\nfrom journalists, leading them to take a clear position on these subjects. On closer\n21\n\nIn this domain, parties are secondary to other representative bodies with which they often have strong ties, in\nparticular employers‚Äô and employees‚Äô associations (15 percent).\n22\nThese shares expectedly vary across policy Ô¨Åelds. Journalists are most involved in unemployment, public health,\nand maternity issues (all 29 percent) and least involved with respect to disability (18 percent). Parties and committees are much quoted sources of statements on pensions and disability (48 and 47 percent) and less so on unemployment and labour regulation (36 percent).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n144\n\n145\n\ninspection, it appears that the general type of ballot proposals combines with their subject matter. As a category, the three populist proposals of the years 2000‚Äì2002 (including hospital costs) were treated in a far less even-handed manner than retrenchment or\nexpansion proposals, especially as concerns bias in issue statements.23 We may summarize these Ô¨Åndings by saying that journalists, most of the time, report about ballot\nissues in a quite balanced way.\nInterestingly, bias in press coverage is substantially related to several other features examined here (correlations of 0.4 or higher). To begin with, article bias decreases as coverage\nintensity and inclusiveness increase. In other words, imbalance in coverage looms large\nwhen journalists have little to report and rely on fewer sources. At the level of issue statements, a crucial link seems to be with the importance of partisan actors as sources of statements: the more parties and committees are referred to as a basis for issue analysis, the\nlesser the bias.\nUsing B* values we can also determine how media coverage is basically oriented\ntoward welfare state schemes (i.e., the extent to which campaign news systematically\nsupports welfare state expansion ‚ÅÑ protection rather than welfare state limitation ‚ÅÑ\nretrenchment). In so doing, we obtain a mean B* value of 0.01 for articles and 0.06\nfor issues ‚Äî the press thus displays a very slight pro-welfare bias. This strongly suggests that there is no overall systematic pro-welfare or anti-welfare bias in press coverage. However, diÔ¨Äerences exist between the various policy Ô¨Åelds. While neutral with\nrespect to pensions, labour market and unemployment, Swiss media outlets as a whole\nseem committed to more generous social protection programmes in the area of public\nhealth (B*=0.19 for issue statements), including maternity and invalidity (B*=0.35 and\n0.31, respectively).\nIt should also be noted that editorials and interviews are more critical of the welfare state\nthan other format types. B* scores (issue statements) for editorials and interviews are about\n‚Äì0.2 and ‚Äì0.1, respectively, as compared to +0.1 or higher for reports, letters to the editor,\nand campaign news. Journalists opposed to welfare policies, it would seem, rely heavily on\nwriting editorials and selecting anti-welfare interviewees. But this does not suÔ¨Éce to countervail the bulk of pro-welfare coverage that stems from ‚Äò‚Äòfactual reporting‚Äô‚Äô or coverage of\ncampaign events. Besides, the general thrust of media coverage is highly dependent on\nwhich types of actors get their messages across in the various newspapers, since more often\nthan not journalists are balanced in their own issue statements (B* = ‚Äì0.02). For instance,\nin the many cases where the parties‚Äô issues Ô¨Ånd their way into the media, center-left parties\nare much more likely to voice pro-welfare issues than are right parties (B* = 0.42 vs.\n‚Äì0.26). Similarly, the bias brought about by employees‚Äô organizations counterbalances that\nof employers‚Äô organizations (B* = 0.35 vs. ‚Äì0.29). Overall, referendum committees are relatively neutral toward the welfare system (B* = 0.04), but the organizations representing\nspeciÔ¨Åc population groups (retired people, disabled people, youth, women, families) are\noverwhelmingly pro-welfare. Interestingly, the bias exhibited by governmental sources is\nquite diÔ¨Äerent depending on the level of government. Institutions and civil servants at the\nnational level (e.g., federal councillors, senior oÔ¨Écials) are clearly less supportive of the\n\n23\n\nThe 2000 and 2001 initiatives (‚Äò‚Äòreduced hospital costs‚Äô‚Äô and ‚Äò‚Äòcheaper drugs‚Äô‚Äô) were fought by all parties, while\nthe 2002 initiative (‚Äò‚Äògold reserves to retirement pensions‚Äô‚Äô) was launched by the Swiss People‚Äôs Party and backed\nby other smaller populist right parties. Accordingly, the latter was supported by an important minority of 46% of\nthe popular votes, compared to 18% and 31% for the two earlier initiatives.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nwelfare system (or, at least, of welfare state expansion) than are their counterparts at the\ncantonal or local level (B* = ‚Äì0.15 vs. 0.48).24\n\nSubstantive coverage\nWe focus here on the three main formats of campaign coverage (i.e., ‚Äò‚Äòopinion articles‚Äô‚Äô,\n‚Äò‚Äòfactual reporting‚Äô‚Äô, and ‚Äò‚Äòhorserace information‚Äô‚Äô) to determine how ‚Äò‚Äòsubstantive‚Äô‚Äô campaign coverage is. Concerns are often expressed that media news that unduly revolves\naround the horserace and ‚Äò‚Äògame‚Äô‚Äô aspects of campaigns has a deleterious inÔ¨Çuence on public deliberation and citizens‚Äô decision-making. In fact, horserace information was present in\nall campaigns but it is quite weak (14 percent of the overall amount of news, on average)\ncompared to ‚Äò‚Äòopinion articles‚Äô‚Äô (35 percent) and ‚Äò‚Äòfactual articles‚Äô‚Äô (51 percent). Horserace\ncoverage varies between a minimum of 5 percent for unemployment ballot issues and a\nmaximum of 20 percent for labour regulation ballot issues. In comparison, the share of\nopinion articles varies between 29 and 37 percent depending on policy domains, while the\nshare of factual articles varies between 47 and 58 percent. Thus, unlike in other contexts,\nthe horserace is clearly not the leading theme in Swiss referendum campaigns.25\n\n5. A dynamic view of independence, inclusiveness, bias, and substance\nThe picture thus far supports the notion of rather ‚Äò‚Äòfair‚Äô‚Äô journalistic practices, as media\ncoverage appears to be relatively balanced, autonomous and substantive. We now examine\nthe hypothesis that journalists are however not immune to the pressure of the political environment and that they become increasingly dependent on external and ‚ÅÑ or biased sources of\ninformation over the course of campaigns. In other words, we ask whether the ‚Äò‚Äòfairness‚Äô‚Äô of\ncampaign coverage is aÔ¨Äected by agenda-building eÔ¨Äorts of political actors. We thus investigate the dynamics of campaign coverage, focusing on four aspects examined above: source\nindependence and inclusiveness, bias in coverage and substantive coverage. We believe that\nthe time dimension can add to our understanding of how much journalistic output is autonomous, inclusive, unbiased, and substantive ‚Äî and possibly also why it deviates from such\nnorms.\nBeginning with source independence, one interesting result is that journalists are the only\nactor category whose importance as a source of issue statements increases throughout the\n24\n\nThis diÔ¨Äerence is consistent across all types of issues, excepting maternity, and it may be explained in two ways.\nOn the one hand, the Swiss federal political system is largely based on the ‚Äò‚Äòprinciple of subsidiarity‚Äô‚Äô, which posits\nthat the federal state should assume only those tasks which cannot be performed eÔ¨Äectively at a more local level.\nHowever, the federal state assumes the greatest responsibility for managing social beneÔ¨Åts and Ô¨Ånancing pension\nand health insurances, while local governments may feel less under pressure. In addition, cantons and municipalities have to draw on their own resources to provide social assistance to needy people who fall through the cracks\nof the social safety net and are no longer eligible for national welfare beneÔ¨Åts. Accordingly, local authorities are\nless likely to endorse cutbacks in social beneÔ¨Åts and are more inclined to support their constituencies‚Äô demands for\nsocial services. On the other hand, the principle of collegiality implies that federal councillors from left parties are\ncompelled to advocate the view of the government as a collective body even when it contradicts the position of\ntheir party or their own opinion. For example, Federal Councillor Ruth Dreifuss, member of the Social Democratic Party and head of the Federal Department of Home AÔ¨Äairs (1994‚Äì2002), often had to oppose initiatives\nfrom left groups aiming at expanding or introducing new welfare programmes.\n25\nThis is all the more signiÔ¨Åcant as the deÔ¨Ånition of horserace information used in this study is rather broad. As a\nmatter of fact, voting cues by parties and major organizations account for the bulk of ‚Äò‚Äòhorserace information‚Äô‚Äô as\noperationalized here ‚Äî rather than opinion surveys or descriptions of campaign events.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n146\n\n147\n\n100\n\n10\n\n90\n\n9\n\n80\n\n8\n\n70\n\n7\n\n60\n\n6\n\n50\n\n5\n\n40\n\n4\n\n30\n\n3\n\n20\n\n2\n\n10\n\n1\n\n0\n\nNumber of source categories\n\nPercent of total sources\n\nFigure 1: Source independence and inclusiveness over time.\n\n% journalists (articles)\n% partisan (articles)\n% journalists (issues)\n% partisan (issues)\nNumber of source\ncategories (issues)\n\n0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\nwhole campaign period, even though their share as ‚Äò‚Äòspeakers‚Äô‚Äô actually declines (see Figure 1). In contrast, parties and committees become a bit less marginal as speakers (gaining\non average some 10 percent of the total share in the last seven weeks). But, most notably,\npartisan actors remain a major source of issue statements for press journalists during the\nwhole campaign period; their share varies between 33 and 61 percent, but without clear\nupward or downward trend over time.26 Just as signiÔ¨Åcant, however, is the fact that the\nsheer number of actor categories used as sources of issue statements grows almost linearly\nduring the campaign period ‚Äî except in the very last weeks ‚Äî and actually almost doubles\n(from 3 to 6) in the Ô¨Årst six weeks (see again Figure 1, right-hand axis). To use our terminology, this shows that press coverage becomes more inclusive as time goes by.27 For example, actors that may be regarded as ‚Äò‚Äòoutsiders‚Äô‚Äô (science and health professionals,\nassociations defending the rights of women ‚ÅÑ families ‚ÅÑ disabled people, non-proÔ¨Åt organizations, and other similar actors) rise from an average number of 0.7 (8th week before vote) to\nan average of 1.5 (4th week) and manage to keep their share of issue statements at just\nunder 20 percent throughout the campaign.\nTaken together, these results suggest that the dynamics of campaign coverage on welfare\nstate issues is hardly compatible with a radical understanding of the ‚Äò‚Äòdetermination theory‚Äô‚Äô. Our analysis reveals that journalists maintain their control over the newsgathering\nprocess and that no single source of campaign issue statements holds sway. As Figure 2\nshows, however, this does not mean that journalists downplay the inÔ¨Çuence of political\nactors ‚Äî or even try to do so in a collective sense. In fact, press coverage increasingly takes\nthe form of ‚Äò‚Äòopinion articles‚Äô‚Äô over time, while the share of ‚Äò‚Äòfactual reporting‚Äô‚Äô sharply\ndeclines. In the eight-week period, opinion articles become at least twice more frequent in\nrelative terms (from 22 to 52 percent), while the share of factual articles considerably\ndecreases (from 69 to 26 percent). With two exceptions, all campaigns exhibit this pattern,\n26\nThe same holds, albeit to a smaller extent, for governmental actors, who account for over one quarter of all\nissue statements in the Ô¨Årst four campaign weeks, but whose importance then declines to less than 15 percent. Yet,\nas compared to their tiny share of 5 percent of articles as ‚Äò‚Äòspeakers‚Äô‚Äô, governmental actors do succeed in getting\ntheir issues on the campaign agenda, especially at the earlier stage.\n27\nFor the sake of simplicity, Figure 1 displays only the number of issue source categories, because IQV values\nhardly vary (min: 0.85, max: 0.90) and thus the variations over time of the composite index INC boil down to variations in the number of source categories.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nFigure 2: Information format over time (substantive vs. non-substantive content).\n100\nPercent of total sources\n\n90\n80\n70\n% reporting\n\n60\n\n% opinion\n\n50\n40\n\n% horserace\n\n30\n20\n10\n0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\nwhereby opinions gain prominence at the expense of the presentation of facts as voting day\ndraws nearer. This may be related to another Ô¨Ånding stressed above, namely that ‚Äò‚Äòspeakers‚Äô‚Äô, i.e. those actors accountable for the content of an article, comprise less journalists and\nmore partisan actors as time goes by. As for horserace news, its salience Ô¨Çuctuates within a\nnarrow 9‚Äì16 percent range ‚Äì‚Äì with the understandable exception of the last campaign week,\ngiven the close proximity of the vote and mobilization eÔ¨Äorts by parties and other groups.28\nIn sum, there does not seem to be a strong focus or even focalization on the horserace during referendum campaigns in Switzerland. To a large extent, the overall evolution in the format of information is understandable, and some observers may Ô¨Ånd it comforting from a\nnormative perspective. It can be argued that, as a collective actor, journalists Ô¨Årst proceed\nto present the facts and main arguments (i.e., information function) and then provide citizens with particular opinions to help them take position on the issues (i.e., orientation function).\nLikewise, the ‚Äò‚Äòtone‚Äô‚Äô of media coverage changes over time. To begin with, articles become\nmore ‚Äò‚Äòpartial‚Äô‚Äô, i.e., they increasingly take sides for or against the various ballot proposals\n(see Figure 3). The share of partial articles amounts to slightly more than 20 percent in the\nÔ¨Årst three weeks and approaches 50 percent by the last two weeks.29 In contrast, the share\nof partial issue statements ‚Äî even though much higher than that of articles in overall level\n‚Äî slightly decreases over time. To a large extent this stems from the fact that issue statements get more ‚Äò‚Äòcontroversial‚Äô‚Äô (rather than more ‚Äò‚Äòneutral‚Äô‚Äô) as voting day draws closer,\nand this is probably reÔ¨Çective of the growing recognition by journalists of the complexity of\nballot issues. That the press becomes more committed to its opinion-giving and orientation\nfunction in the later stages of campaigns does not entail, however, that it provides an\nincreasingly biased picture of the ballot issues. As shown in Figure 3 (right-hand axis), it is\nstriking how little deviation there is from perfect neutrality (i.e., B*=0) throughout the\neight campaign weeks, based either on articles or on separate issue statements. In fact, 87\npercent of the weekly bias scores for articles are comprised in a range of ¬± 20 percent\n28\nWe may also add that most newspapers publish a summary list of all parties‚Äô and important organizations‚Äô voting cues in the last week before voting day (which we also included in the horserace category).\n29\nOne natural hypothesis is that journalists themselves become less impartial over time. There is strong evidence\nsupporting this assumption, as the share of partial items among journalists‚Äô articles rises from a low 16 percent\nseven weeks before voting day to a full 44 percent in the last campaign week.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n148\n\n149\n\n100\n\n1.0\n\n90\n\n0.8\n\n80\n\n0.6\n\n70\n\n0.4\n\n60\n\n0.2\n\n50\n\n0.0\n\n40\n\n‚Äì0.2\n\n30\n\n‚Äì0.4\n\n20\n\n‚Äì0.6\n\n10\n\n‚Äì0.8\n\n0\n\nArticle/issue bias (B* score)\n\nPercent of total\n\nFigure 3: Bias in media coverage over time.\n\nArticle partiality\n(pro+con/total)\nIssue partiality\n(pro+con/total)\nArticle bias\n(B* score)\nIssue bias\n(B* score)\n\n‚Äì1.0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\naround the neutral value.30 In sum, the fact that campaigns become more partisan over time\ndoes not necessarily imply that one side comes to prevail over the other. More often than\nnot media campaign coverage remains remarkably balanced until the end. As we have\nshown above, ballot campaigns usually heat up in the Ô¨Ånal weeks, as agenda-building\neÔ¨Äorts by partisan groups intensify. But even then there is very little to suggest that the\npress gives in to external pressure and leaves the ‚Äò‚Äòundecided‚Äô‚Äô citizens or ‚Äò‚Äòlate deciders‚Äô‚Äô\nexposed to the unchecked inÔ¨Çuence of partisan or special interests.\n\n6. A particularistic view of media fairness\nBased on a number of formal criteria, the press coverage of ballot issues on welfare state\nissues appears relatively ‚Äò‚Äòfair‚Äô‚Äô. However, such evidence may be somehow illusory if it stems\nfrom the aggregation of contradictory patterns from diÔ¨Äerent types of media outlets. For\nexample, a balanced, unbiased portray of ballot issues at the aggregate level may conceal\nmuch greater variation between individual papers, some of which may be slanted toward\nwelfare state expansion while others may be committed to welfare retrenchment. As most\ncitizens read only one newspaper on a regular basis, this would mean that a majority of\npotential voters are exposed to a one-sided communication Ô¨Çow. In addition, if the papers\non one side of the fence (e.g., the ‚Äò‚Äòpro-welfare camp‚Äô‚Äô) have a larger overall readership than\nthose on the other side, then the societal balance of information would no longer be guaranteed, despite indications to the contrary such as those provided in the preceding sections.\nTo investigate this question, we ask how the coverage of welfare state issues compares\nacross media outlets. Table 2 displays the whole range of indicators used thus far and shows\nhow they vary between the 28 media outlets included in this analysis.\n30\nThe same result is obtained if one takes absolute B scores (and hence all 24 campaigns are considered). However, when issue statements are considered instead of articles, the proportion of biased weekly values (|B|&gt;0.2) rises\nto 52 percent. To some extent this stems from our sampling procedure, because many weekly values are derived\nfrom a limited number of cases ‚Äî while the whole data is used for articles‚Äô bias. Accordingly, compared to statistics based on exhaustive data, there is a heightened probability that more extreme values of issue bias are produced\nby chance alone. Moreover, these frequent deviations from neutrality are in general temporary and unlikely to last\nfor longer than one week. In fact, the percent of adjacent weeks that exhibit a similar biased value (e.g., B scores\ngreater than 0.2 for both weeks) is only 19 percent.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n115.2\n\n97.6\n83.1\n80.1\n83.7\n77.7\n73.5\n58.4\n70.9\n68.0\n56.9\n42.6\n\n57.4\n35.2\n33.5\n37.7\n24.9\n26.8\n23.0\n\n19.9\n18.5\n\n18.9\n\n14.2\n8.6\n\n6.3\n\n5.7\n6.0\n\n321\n293\n286\n285\n263\n245\n222\n208\n201\n179\n170\n\n166\n165\n122\n104\n97\n90\n89\n\n70\n60\n\n38\n\n33\n21\n\n18\n\n17\n7\n\nSurfaceb\n\n528\n\nNumbera\n\n 2011 Swiss Political Science Association\n0.202\n0.194\n\n0.206\n\n0.143\n0.277\n\n0.222\n\n0.458\n0.752\n\n0.781\n0.750\n0.484\n0.745\n0.696\n0.409\n0.687\n\n0.873\n0.845\n0.865\n0.816\n0.664\n0.874\n0.866\n0.837\n0.783\n0.818\n0.840\n\n0.891\n\n22.8\n32.0\n\n16.3\n\n26.7\n38.7\n\n30.9\n\n27.4\n17.0\n\n26.1\n16.8\n14.6\n22.1\n22.5\n21.9\n20.6\n\n26.0\n27.2\n24.5\n26.0\n26.2\n28.0\n17.3\n26.4\n24.6\n28.7\n18.0\n\n27.3\n\nAverage\ncampaign\ndayd\n\n0.076\n0.000\n\n)0.200\n\n)0.026\n0.054\n0.106\n\n0.664\n0.051\n\n0.435\n\n0.142\n0.003\n\n0.164\n0.448\n)0.106\n0.206\n)0.007\n)0.124\n0.126\n\n0.675\n0.117\n\n0.425\n\n0.066\n)0.108\n\n0.038\n0.145\n)0.094\n0.012\n)0.026\n0.063\n0.046\n\n0.118\n)0.030\n0.153\n0.133\n0.023\n0.111\n)0.014\n0.057\n0.009\n)0.128\n0.040\n\n)0.279\n\n)0.127\n0.044\n)0.018\n0.011\n0.063\n)0.032\n)0.023\n)0.023\n0.006\n0.004\n)0.027\n)0.038\n\nIssue\nbiase\n\nArticle\nbiase\n\n87.3\n100.0\n\n100.0\n\n82.3\n81.2\n\n82.8\n\n84.9\n86.6\n\n91.0\n54.6\n72.3\n92.2\n90.2\n82.9\n91.9\n\n81.4\n93.6\n85.3\n96.4\n83.0\n98.8\n81.2\n91.4\n91.4\n90.0\n75.4\n\n81.0\n\n% Journalists\n(articles)f\n\n19.0\n34.2\n\n6.8\n\n7.6\n9.4\n\n11.2\n\n26.7\n14.6\n\n17.8\n35.6\n33.0\n11.8\n7.9\n24.1\n8.7\n\n20.9\n14.2\n16.7\n8.8\n25.1\n8.5\n25.7\n18.5\n10.8\n25.2\n20.0\n\n14.7\n\n% Parties\n(articles)f\n\n0.0\n77.6\n\n33.3\n\n57.4\n61.4\n\n67.4\n\n28.3\n24.5\n\n15.9\n10.5\n27.7\n25.7\n10.6\n16.8\n22.8\n\n23.1\n23.8\n26.0\n41.4\n18.2\n29.2\n23.8\n22.5\n16.7\n22.7\n34.7\n\n34.6\n\n% Journalists\n(issues)f\n\n91.3\n47.3\n\n66.7\n\n0.0\n24.5\n\n30.2\n\n36.7\n24.0\n\n56.3\n62.7\n43.9\n44.6\n58.8\n53.2\n58.1\n\n45.2\n38.7\n50.0\n25.5\n55.7\n44.7\n43.4\n45.6\n42.3\n47.1\n42.0\n\n35.3\n\n% Parties\n(issues)f\n\n47.6\n65.8\n\n55.9\n\n22.3\n44.1\n\n37.6\n\n48.1\n48.6\n\n55.0\n37.3\n32.1\n67.2\n65.6\n48.4\n59.7\n\n50.9\n53.7\n49.9\n54.0\n47.6\n64.5\n63.6\n57.1\n61.1\n47.3\n46.1\n\n35.9\n\n% Reportingg\n\n12.7\n34.2\n\n24.0\n\n69.7\n52.0\n\n51.6\n\n33.6\n34.1\n\n32.1\n56.5\n42.2\n21.6\n21.1\n46.5\n27.8\n\n34.6\n27.0\n30.8\n26.5\n39.3\n20.2\n30.9\n31.7\n29.3\n35.0\n51.3\n\n46.2\n\n% Opiniong\n\n39.7\n0.0\n\n20.1\n\n8.0\n3.9\n\n10.7\n\n18.3\n17.2\n\n12.9\n6.2\n25.7\n11.1\n13.2\n5.1\n12.5\n\n14.5\n19.3\n19.4\n19.5\n13.1\n15.2\n5.6\n11.2\n9.6\n17.6\n2.6\n\n17.9\n\n% Horseraceg\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNeue ZuÃàrcher Zeitung\n(NZZ)\nBasler Zeitung\nLe Temps (March 1998 ‚Äì)\nSt. Galler Tagblatt\nTages-Anzeiger\nAargauer Zeitung\nLa LiberteÃÅ\nCorriere del Ticino\nBund\n24 Heures\nNeue Luzerner Zeitung\nNouvelliste et Feuille\nd‚ÄôAvis du Valais\nBerner Zeitung\nLe Quotidien Jurassien\nSchaÔ¨Ähauser Nachrichten\nTribune de GeneÃÄve\nL‚ÄôExpress\nSolothurner Zeitung\nSuÃàdostschweiz ‚ÅÑ BuÃàndner\nZeitung\nBlick ‚ÅÑ Sonntags-Blick\nJournal de GeneÃÄve\n(1995 ‚Äì Feb. 1998)\nBerner Tagwacht\n(1995 ‚Äì 1997)\nWochenzeitung\nSchweizerische\nHandelszeitung\nLe Nouveau Quotidien\n(1995 ‚Äì Feb.1998)\nSonntags-Zeitung\nDie andere Zeitung (DAZ)\n(1995 ‚Äì 1997)\n\nNewspaper\n\nInclusivenessc\n\nTable 2: Indicators of fairness for all articles published in 28 daily and weekly newspapers\n\n150\n\n 2011 Swiss Political Science Association\n\n236.6\n(184.9)\n126.4\n(95.7)\n172.3\n(74.6)\n19.0\n(10.0)\n\n61.6\n(41.6)\n37.0\n(27.3)\n51.7\n(22.8)\n8.1\n(4.0)\n\nSurfaceb\n0.641\n(0.271)\n0.666\n(0.238)\n0.702\n(0.190)\n0.203\n(0.048)\n\nInclusivenessc\n\n0.138\n\n0.191\n0.749\n\nInclusivenessc\n\n28.0\n(2.1)\n21.4\n(4.7)\n22.9\n(4.6)\n26.0\n(8.4)\n\nAverage\ncampaign\ndayd\n\n5.5\n\n15.7\n24.0\n\nAverage\ncampaign\ndayd\n\n0.018\n(0.083)\n)0.021\n(0.051)\n0.036\n(0.121)\n0.125\n(0.364)\n\nArticle\nbiase\n\n0.062\n\n-0.347\n).001\n\nArticle\nbiase\n\n% Journalists\n(articles)f\n91.2\n(7.1)\n90.8\n(5.2)\n83.5\n(10.6)\n87.7\n(7.5)\n\n)0.007\n(0.153)\n)0.009\n(0.138)\n0.097\n(0.166)\n0.220\n(0.257)\n\n9.5\n\n100.0\n85.5\n\n% Journalists\n(articles)f\n\nIssue\nbiase\n\n0.146\n\n0.089\n.050\n\nIssue\nbiase\n\n19.7\n(9.3)\n14.4\n(6.5)\n19.4\n(8.5)\n9.0\n(6.8)\n\n% Parties\n(articles)f\n\n7.9\n\n0.0\n18.5\n\n% Parties\n(articles)f\n\n41.1\n(19.2)\n25.9\n(3.9)\n24.5\n(13.6)\n38.6\n(24.3)\n\n% Journalists\n(issues)f\n\n7.5\n\n35.7\n23.8\n\n% Journalists\n(issues)f\n\n36.7\n(7.0)\n49.2\n(14.3)\n47.8\n(8.2)\n29.0\n(37.4)\n\n% Parties\n(issues)f\n\n9.9\n\n0.0\n45.4\n\n% Parties\n(issues)f\n\n51.5\n(9.7)\n52.3\n(4.7)\n52.4\n(11.1)\n48.9\n(21.2)\n\n% Reportingg\n\n9.5\n\n81.5\n52.1\n\n% Reportingg\n\n33.5\n(7.1)\n30.4\n(4.1)\n36.4\n(11.5)\n38.2\n(23.6)\n\n% Opiniong\n\n9.5\n\n18.5\n34.2\n\n% Opiniong\n\n15.0\n(7.5)\n17.4\n(2.7)\n11.2\n(5.5)\n12.9\n(15.7)\n\n% Horseraceg\n\n5.6\n\n0.0\n13.7\n\n% Horseraceg\n\n151\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNotes: a: Number of articles. b: Surface in standard newspaper pages (one page=1247 cm2). c: Number of actor categories ¬∑ IQV (see text for calculation details). d: Mean number of days remaining before voting day. e: B* scores comprised between ‚Äì1 (all articles ‚ÅÑ issues against welfare state\npreservation ‚ÅÑ extension) and +1 (all articles ‚ÅÑ issues in favour of welfare state preservation ‚ÅÑ extension); populist ballots removed; see text for calculation details. f: Sum of categories ‚Äò‚Äòjournalists‚Äô‚Äô (including press agencies) and ‚Äò‚Äòparties‚Äô‚Äô (including referendum ‚ÅÑ initiative committees) may exceed\n100%, since several actors may be considered as the ‚Äò‚Äòsources‚Äô‚Äô of an article. g: Percentage of articles in each category (see text for deÔ¨Ånition). h:\nNewspapers with fewer than 50 articles are excluded; all papers retained (N = 28) for number, surface, and average campaign day. i: National\npapers: Blick, Le Temps, NZZ, Tages-Anzeiger, DAZ. Supraregional papers: Journal de GeneÃÄve, Neue Luzerner Zeitung, Le Nouveau Quotidien,\nSt. Galler Tagblatt, SuÃàdostschweiz. Cantonal papers: Aargauer Zeitung, Basler Zeitung, Bund, Berner Zeitung, Corriere del Ticino, L‚ÄôExpress, La\nLiberteÃÅ, Nouvelliste, Le Quotidien Jurassien, SchaÔ¨Ähauser Nachrichten, Solothurner Zeitung, Tribune de GeneÃÄve, 24 Heures, Berner Tagwacht.\nWeekly papers: Schweizerische Handelszeitung, Sonntags-Zeitung, Wochenzeitung, Weltwoche.\n\nWeeklyi\n\nCantonali\n\nSupraregionali\n\nNationali\n\nMeans for categories of\nnewspapers (standard\ndeviations in parentheses)\n\nb\n\n3.7\n44.6\n(R=1248.1)\n31.3\n\nSurface\n\nNumbera\n\n5\n153.7\n(R=4303)\n121.1\n\nDie Weltwoche\nMean (N = 21)h\n\nStandard deviation\n\nNumber\n\na\n\nNewspaper\n\nTable 2: (Continued)\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nWe will focus here on the three aspects of independence, bias, and substance. An inspection of individual values and standard deviations shows that there is indeed some variation\nbetween newspapers on these three criteria, but that it is rather limited. According to our\nbias measure B* for articles, the economy-oriented newspapers NZZ and Journal de Gene`ve\nmay qualify as ‚Äò‚Äòanti-welfare‚Äô‚Äô, as they were, on average, predominantly lopsided against\nwelfare state preservation ‚ÅÑ extension. In contrast, the left-wing paper Quotidien Jurassien\nappears as ‚Äò‚Äòpro-welfare‚Äô‚Äô.31 At the level of issue statements, there is greater variation in B*\nscores, but few papers stand outside a ¬± 20 percent range around the neutral value (antiwelfare: NZZ; pro-welfare: Quotidien Jurassien and Tribune de Gene`ve). In addition, few\nsingle ballots gave way to skewed information even in any separate outlet. Of all instances\nwith a suÔ¨Écient number of cases, 11 percent were rather pro-welfare and 8 percent were\nrather anti-welfare.32 Weekly (mostly Sunday) papers represent an exception to this overall\nmoderation in dealing with welfare issues, as they appear slanted toward pro-welfare positions (but self-evidently not the right-wing Weltwoche). In sum, the concern that our Ô¨Ånding\nof balanced coverage might be an artifact of aggregation is not substantiated by our data.\nOur Ô¨Åndings concerning the criteria of source independence and substantive coverage tell\na similar story. SigniÔ¨Åcant variation between media outlets is scarce, even though some\npeculiarities are worth pointing out. For example, journalists outweigh partisan sources in\nthe Tages-Anzeiger, while in other outlets (e.g., Quotidien Jurassien) these two categories are\nalmost equally present ‚Äî as speakers or sources of issue statements. In general, journalists\nplay a larger role in national papers than in regional and cantonal papers, which may have\nto do with the resources media organizations must invest to have their journalists closely\ncover ballot campaigns. Finally, the ‚Äò‚Äòformat‚Äô‚Äô of articles shows little diÔ¨Äerence between\nnewspapers. Some of them are more preoccupied with opinion formation than with factual\nreporting (NZZ, Nouvelliste, Quotidien Jurassien, SchaÔ¨Ähauser Nachrichten), while the\nopposite holds especially for a couple of French-speaking papers (La Liberte¬¥, Tribune de\nGene`ve, L‚ÄôExpress). With one single exception, horserace information account for less than\n20 percent of campaign coverage in all papers. In any account, then, the overall variation in\nsource independence and information format is limited. The existence of such variation cannot be taken to mean that the press coverage of ballot campaigns in Switzerland is a\nmere collection of disjoint ‚Äò‚ÄòspeciÔ¨Åc campaigns‚Äô‚Äô with potentially divergent consequences for\ndiÔ¨Äerent segments of the electorate.\n\n7. Spatial patterns of media coverage\nWe now turn to the issue of spatial homogeneity. Provided that the Swiss media system is\nhighly fragmented along linguistic lines, is this segmentation reÔ¨Çected in region-speciÔ¨Åc\n‚Äò‚Äòstyles‚Äô‚Äô of media coverage? More speciÔ¨Åcally, to what extent are the particular dimensions\nof media coverage that we analyzed thus far similar in the two main Swiss regions? As\n\n31\nIn the following, we will not comment on results for newspapers with a small number of published articles\n(N &lt; 50). Note that the indicators in this section are computed on the basis of all articles published in each newspaper, without distinction of the speciÔ¨Åc ballot measures.\n32\n292 campaigns in individual papers were analyzed and B* scores for articles were computed for each of them.\nOnly cases where a newspaper published more than 4 articles on a given campaign were considered. When the same\nprocedure is applied to B* scores for issue statements, the proportion of seemingly ‚Äò‚Äòbiased campaigns‚Äô‚Äô is much\nhigher, but also less reliable (see above note 30).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n152\n\n153\n\nbecomes clear from Table 3, diÔ¨Äerences are in general rather limited, and sizable diÔ¨Äerences\nare only found for particular types of ballot issues.\nCampaign intensity as reported in Table 3 is a composite measure derived from the surface of articles, from the circulation Ô¨Ågures of the newspapers, and from the number of people eligible to vote.33 The measure thus points out diÔ¨Äerences in the overall potential\nexposure of individual citizens and shows that campaigns are clearly more intense in the\nGerman-speaking region. The diÔ¨Äerence is particularly noticeable and systematic with\nrespect to pension and maternity issues. As concerns campaign length, the ‚Äò‚Äòaverage campaign day‚Äô‚Äô indicator suggests that overall diÔ¨Äerences are slight. Campaigns may last a bit\nlonger in the German-speaking press, but mainly for measures pertaining to unemployment,\nand in any case not for measures on disability. Further, as would be expected from these\ndiÔ¨Äerences in intensity and length, media campaigns are also somewhat more ‚Äò‚Äòinclusive‚Äô‚Äô in\nthe German-speaking press, where, on average, two additional actor categories are used as\nsources of issue statements.\nTurning to coverage bias, we again note that diÔ¨Äerences between the regions are marginal.\nHowever, as already pointed out above, bias is more conspicuous when measured at the level\nof issue statements rather than at the level of whole articles. Although the overall diÔ¨Äerence\nis negligible, this stems from the fact that the small diÔ¨Äerences that do exist cancel each other\nout across the various policy Ô¨Åelds. Thus coverage in the German-speaking press was more\nskewed on health and disability measures, while it was less skewed on maternity issues (most\nnotably, French- and Italian-speaking papers had been much more enthusiastically endorsing the 1999 maternity leave project than had their German-speaking counterparts).\nNext, we compared the independence of journalists from external sources of information\nin the two regions. On the whole, the diÔ¨Äerences are modest. As speakers, German-speaking\njournalists were less prominent than journalists from other regions on maternity and disability issues, but they were more ‚Äò‚Äòautonomous‚Äô‚Äô on unemployment. DiÔ¨Äerences were somewhat more pronounced as regards the source of issue statements. Journalists were more\nlikely to be the source of reported issues in the German-speaking press than in the Frenchand Italian-speaking press, especially for unemployment and labour regulation (but not for\nmaternity and disability issues). For example, French-speaking journalists sometimes draw\non scientiÔ¨Åc or educational sources (8 percent) for addressing labour and unemployment\nissues, while their German-speaking colleagues never do so (at least in our sample). These\nregional patterns may have at least two diÔ¨Äerent causes. On the one hand, turning to external sources may occur because journalists are less sure where they stand (or should stand)\non the issues and ‚ÅÑ or because they believe that public opinion on the issues is not crystallized\nyet and need orientating information from political sources. On the other hand, the\nobserved regional gaps may simply be reÔ¨Çective of more routinized relationships between\njournalists and political actors in some policy domains.\nThe ‚Äò‚Äòformat‚Äô‚Äô of information was then considered, with a focus on horserace information. Marginal regional gaps were observed, as the share of horserace items rarely exceeded\n20 percent in any region, but the diÔ¨Äerences were rather systematic. In general, information\nin German-speaking papers is more often of the ‚Äò‚Äòhorserace‚Äô‚Äô type than in French- or\nItalian-speaking papers (an overall 4 percent gap), and this diÔ¨Äerence holds for 17 of 24\n33\n\nLe Nouveau Quotidien, DAZ, and Berner Tagwacht are not taken into account in this analysis, due to unavailable circulation Ô¨Ågures, but they represent only about 2 percent of articles and surface. More consequential is the\nfact that the French-speaking tabloid Le Matin, which has the largest circulation in the western region, is not\nincluded in our data. The absence of this paper probably explains part of the diÔ¨Äerence between the two regions.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n 2011 Swiss Political Science Association\n\n0.5 (10.5)\n4.0 (9.5)\n\n2.0 (9.5)\n\n3.1 (8.8)\n\n9.3 (15.6)\n2.7 (5.5)\n\n2.0 (9.6)\n1.9 (9.7)\n1.3 (7.8)\n2.5 (10.8)\n\n4.2 (9.2)\n4.7 (10.3)\n2.5 (6.4)\n3.2 (8.3)\n\n2.2 (26.4)\n)4.1 (23.9)\n\n8.9 (27.0)\n\n1.6 (24.8)\n1.2 (25.3)\n0.3 (22.8)\n3.0 (23.8)\n\nAverage\ncampaign\nday\n\n)0.236 (0.297)\n0.178* (0.365)\n\n0.002 (0.120)\n\n)0.036 (0.053)\n)0.035 (0.065)\n0.047 (0.131)\n\n0.013 (0.207)\n0.011 (0.145)\n0.125 (0.420)\n)0.045 (0.071)\n\nIssue\nbias\n(|B| scores)\n\n0.009 (0.091)\n)0.010 (0.075)\n0.037 (0.157)\n0.052 (0.080)\n\nArticle\nbias\n(|B| scores)\n\n)4.0 (86.5)\n)11.3 (78.9)\n\n0.5 (28.7)\n)1.6 (16.0)\n\n10.2 (30.9)\n\n6.1** (28.1)\n5.1 (27.7)\n6.0 (33.0)\n13.1* (28.5)\n\n)0.7 (86.3)\n)1.5 (85.9)\n2.2 (89.1)\n1.3 (86.7)\n6.8 (89.2)\n\nSource\nof issues\n= journalists\n\nSource of\narticles\n= journalists\n\n)4.5 (14.2)\n)1.8 (14.0)\n\n3.9 (7.3)\n\n3.9 (15.7)\n5.7 (16.6)\n5.6 (14.2)\n4.6 (21.0)\n\nImportance of\nhorserace\ninformation\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n**: p&lt;.05; *: p&lt;.10 (two-tailed tests checking for diÔ¨Äerences between paired-sample means).\n\nNotes: The Ô¨Ågures show the diÔ¨Äerence between the two main linguistic areas (German-speaking vs. French- or Italian-speaking). A positive (negative) diÔ¨Äerence means that a given quantity is higher (lower) in the German-speaking area. In parentheses are the reference quantities, i.e., those\nmeasured in the German-speaking area.\nPk Pn\ncirci surfij\nj¬º1\na: Intensity = i¬º1 voters\n, with circi=circulation of newspaper i, surfij=surface of article j (in pages) in newspaper i, and voters=people eligible to vote (in thousands).\n\nTotal (N=24)\nPensions (N=10)\nHealth (N=4)\nLabour regulation\n(N=4)\nUnemployment\n(N=2)\nMaternity (N=2)\nDisability (N=2)\n\nIntensity a\n\nInclusiveness\n(# of source\ncategories)\n\nTable 3: Interregional diÔ¨Äerences with respect to eight indicators of media fairness and six policy Ô¨Åelds\n\n154\n\n155\n\nballot proposals. The largest between-region diÔ¨Äerences in the share of horserace articles\nare found for pension and health issues, but there was actually more horserace coverage in\nthe French ‚ÅÑ Italian-speaking area on maternity and disability issues.34\n\n8. Conclusion\nThe aim of this study was to assess the fairness of the press coverage of referendums on\nwelfare state issues in Switzerland. We distinguished seven dimensions of media coverage in\norder to determine how it compares to idealized notions of the media‚Äôs role in the democratic process. In this concluding section we summarize our analysis of media coverage\nquality and, whenever possible and sensible, we relate our results to those of other studies.\nFirst, as regards the intensity of press coverage in daily newspapers, we found about eight\narticles per proposal and newspaper, amounting to two or three full pages of coverage.\nWith only modest variation across votes (though variation is more pronounced across\nmedia outlets), such coverage might be considered as a ‚Äò‚Äòfair‚Äô‚Äô performance.35\nSecond, turning to the question of campaign duration, our results show that the press coverage peaked two to three weeks before the voting day, and that half of the total information had been released some 22 days before the poll. Although comparable studies of\nEuropean referendums are lacking (see Novik 2009: 13) we interpret this average duration\nas ‚Äò‚Äòappropriate‚Äô‚Äô, since press coverage was relatively gradual and did not surge in the last\ncampaign days.\nThird, we investigated the bias in media coverage. Overall, we Ô¨Ånd a minimal to nonexistent bias at the level of press articles (i.e., the general thrust of news stories) toward prowelfare state orientation. When looking at particular issue statements, the bias appeared\nlarger but still not overwhelming. In fact, bias was largely restricted to matters of public\nhealth in the larger sense (hospital costs, price of drugs, maternity, disability, etc.) and was\nvirtually absent from campaigns on such themes as pensions, labour regulation, and unemployment. The variation in balance among diÔ¨Äerent newspaper outlets is rather limited.\nConcerning articles in daily newspapers, only the Journal de Gene`ve and the NZZ adopted\na rather ‚Äò‚Äòanti-welfare‚Äô‚Äô position while the Quotidien Jurassien was lopsided toward the\n‚Äò‚Äòpro-welfare‚Äô‚Äô camp. However, compared to news balance in other referendum campaigns,\nsuch as Pilon‚Äôs (2009) report on the Ontario Provincial Referendum and Hobolt‚Äôs (2009:\n186‚Äì189) analysis of the Ô¨Årst Irish referendum on the Nice Treaty, we conclude that the\nreporting on welfare state issues in the Swiss print media generally provides little ammunition to those who suspect or condemn a systematic bias in media coverage.\n\n34\nIt may be that, due to a more skeptical opinion climate toward the latter issues in their region, German-speaking\njournalists had more incentives to engage in opinion formation rather than stick to hard facts and descriptions of\nthe situation. This is especially true for maternity issues, as welfare state support is 30 percent higher on average\namong French- and Italian-speaking voters than among German-speaking voters (our own calculations from the\nmunicipality-level data available in the ‚Äò‚ÄòPolitical Atlas of Switzerland‚Äô‚Äô, Swiss Federal Statistical OÔ¨Éce).\n35\nThis rather lenient judgment may be qualiÔ¨Åed by comparing our results with those of Hobolt (2009: 207)208),\nwho found more intense press coverage for the 2005 French and the Dutch referendum campaigns on the European\nConstitution, even if we restrict the analysis to the country‚Äôs two major broadsheet newspapers (NZZ and\nLe Temps, in the Swiss case) as Hobolt did. However, the Ô¨Ågures might not be fully comparable; the vote on the\nEuropean Constitution might have been of greater salience than single welfare state proposals. Moreover, the lower\nfrequency of popular votes in France and the Netherlands as compared to Switzerland may explain a more intense\ncoverage of those (rare) referendums. We should therefore await further research on news reporting in the Swiss\ncontext in order to compare our Ô¨Åndings.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nFourth, the relative independence of journalists from external (particularly partisan)\nsources was examined. Similar to coverage bias, the dimension of media autonomy was\ninvestigated at two levels: articles and issue statements. At the level of articles, it was found\nthat journalists are by far the most important ‚Äò‚Äòspeakers‚Äô‚Äô. Although they can delegate their\nagenda-setting role to other actors by soliciting their opinions through interviews, op-eds,\nor free columns, they rarely do so ‚Äî at least not until the last three or four campaign\nweeks. Hence, our analysis suggests that the Swiss newspapers‚Äô progressive loss of attachment to parties and other political groups (Meier and Schanne 1994) may have enhanced\ntheir ‚Äò‚Äòautonomy‚Äô‚Äô ‚Äî a concept not to be confused with that of journalistic ‚Äò‚Äòobjectivity‚Äô‚Äô,\nwhich is outside the scope of this study. However, when evaluated at the level of issue\nstatements, the press coverage of referendum campaigns appears in a somewhat diÔ¨Äerent\nlight. Without there being anything ‚Äò‚Äòunfair‚Äô‚Äô on a priori grounds, media coverage appears\nto largely reÔ¨Çect the issue agenda of the major political forces involved in campaigns (i.e.,\npolitical parties and committees, governmental agencies, professional associations, etc.).\nAltogether, these non-media sources account for about three times the number of journalistic issue items.36 In our view, there is no basic contradiction between the Ô¨Åndings from these\ndistinct levels of analysis; taken together, they are reÔ¨Çective of both main functions traditionally assigned to news media ‚Äî an information and an orientation function.\nThe dominance of journalists as sources of articles suggests that press journalists function\nas gatekeepers, selecting who may intervene directly in the news process, rather than as\nmere providers of a ‚Äò‚Äòfree forum‚Äô‚Äô to which any group or individual is granted equal and\nunlimited access. On the other hand, the press coverage of ballot issues is of course reÔ¨Çective ‚Äî and possibly ‚Äò‚ÄòreÔ¨Çexive‚Äô‚Äô in the Luhmannian sense (Neidhardt 1994) ‚Äî of what the\nmain political actors have to say. Therefore, media agenda-setting is not exogenous, but largely driven by the agenda of various political elites. As our measure of source inclusiveness\nsuggests, Swiss press journalists tend to rely on a broad array of diÔ¨Äerent actor categories,\nand media coverage may thus be said to be ‚Äò‚Äòinclusive‚Äô‚Äô. However, this substantial diversity\nin news coverage does not allow us to rule out the gatekeeping hypothesis: it is questionable\nwhether all actors who wanted to participate in the campaign debates Ô¨Ånally found their\nway in news reporting.\nNext, our data provided insight into the substance of media coverage. We found that the\noften-criticized ‚Äò‚Äòhorserace‚Äô‚Äô nature of election coverage is not prevalent in the context of\nSwiss referendum campaigns. For one thing, horserace information accounts for only about\n13 percent of all news items ‚Äî a tiny proportion compared, for instance, with U.S. presidential campaigns (StroÃàmbaÃàck and Dimitrova 2006), the 1995 Quebec secession referendum\n(see Pilon 2009), or even with more readily comparable campaigns such as the 2000 Danish\nreferendum on the adoption of the Euro (De Vreese and Semetko 2002). In addition,\nalthough the number of ‚Äò‚Äòfactual information‚Äô‚Äô items exceeds that of ‚Äò‚Äòopinion‚Äô‚Äô items, both\nare important categories of press coverage. This again suggests that information and orientation are important functions performed by the media, and that in assuming these functions the media go well beyond predicting which side is likely to win.\nLastly, spatial homogeneity was deÔ¨Åned as an additional norm of media coverage. This\nnorm is rooted in the perception that public opinion on welfare state issues frequently\ndiverges across the main linguistic areas. Accordingly, distinctive media coverage threatens\nto reinforce the pre-existing cleavages and to undermine national cohesion by promoting a\n36\n\nAs compared to Tresch‚Äôs (2008: 142‚Äì149) Ô¨Åndings on media coverage of European politics, state actors play a\nslightly less prominent role in debates on welfare state issues.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n156\n\n157\n\n‚Äò‚Äòtyranny of the majority‚Äô‚Äô. It was found that regional gaps in the press coverage of campaigns were minimal and largely restricted to three criteria: intensity of coverage, horserace\nreporting and source independence. In the German-speaking region, campaigns were somewhat more intense, more inclined toward horserace information, and journalists were more\noften the source of issues than was the case in the other linguistic areas. This may reÔ¨Çect\neither economic or cultural diÔ¨Äerences of media organizations between the regions. But\nagain, the hallmark of this analysis is similarity rather than discrepancy. Even when looking\nat speciÔ¨Åc welfare policy areas (pensions, health, etc.), press coverage appears ‚Äî with few\nexceptions ‚Äî strikingly similar across both regions, in line with the more detailed analysis\nof Swiss European policy by Tresch (2008).\nIn conclusion, the coverage of referendum campaigns on welfare state issues by the Swiss\npress appears reasonably fair when examined from a broad perspective. However, this\nappraisal of ‚Äò‚Äòsatisfactory‚Äô‚Äô (though certainly not ‚Äò‚Äòoptimal‚Äô‚Äô) media campaign coverage is\nbased on quantitative indicators that may fail to capture many intrinsic qualities of media\ncoverage. Admittedly, the standards used to assess the fairness of media coverage were not\nexcessively high, and the conclusions we draw from our analysis await conÔ¨Årmation from\nindependent datasets and studies, in particular from more qualitative-oriented research\n‚Äò‚Äòputting qualitative Ô¨Çesh on quantitative bones‚Äô‚Äô (Tarrow 2004: 176). Accordingly, we call\nfor further testing of the normative framework developed in the present study and for replications of our analysis in other settings. In addition, there is clearly a need of going beyond\nthe mere ‚Äò‚Äòprocedural‚Äô‚Äô approach to fairness developed here. Although they can be estimated by quantitative indicators, procedure-independent criteria of media fairness may be\nbest deÔ¨Åned through qualitative methods.\n\nReferences\nAlthaus, S. (1998). Information EÔ¨Äects in Collective Preferences. American Political Science Review\n92(3): 545‚Äì558.\nBaÃàchtiger, A., S. Niemeyer, M. Neblo, M. Steenbergen and J. Steiner (2010). Disentangling Diversity\nin Deliberative Democracy: Competing Theories, Their Blind Spots and Complementarities. Journal of Political Philosophy 18(1): 32‚Äì63.\nBaerns, B. (1979). OÃàÔ¨Äentlichkeitsarbeit als Determinante journalistischer Informationsleistungen. Publizistik 24(3): 301‚Äì316.\nBarrett, A. and L. Barrington (2005). Bias in Newspaper Photograph Selection. Political Research\nQuarterly 58(4): 609‚Äì618.\nBartels, L. (1988). Presidential Primaries and the Dynamics of Public Choice. Princeton: Princeton University Press.\n‚Äî‚Äî (1996). Uninformed Votes: Information EÔ¨Äects in Presidential Elections. American Journal of\nPolitical Science 40(1): 194‚Äì230.\nBennett, L., R. Lawrence and S. Livingston (2007). When the Press Fails. Political Power and the News\nMedia from Iraq to Katrina. Chicago: University of Chicago Press.\nBentele, G. (2003). Kommunikatorforschung: Public Relations. In Bentele, G., H.-B. Brosius and O.\nJarren (eds.), OÃàÔ¨Äentliche Kommunikation. Handbuch Kommunikations- und Medienwissenschaft.\nWiesbaden: Westdeutscher Verlag (54‚Äì78).\nBerelson, B. (1952). Democratic Theory and Public Opinion. Public Opinion Quarterly 16(3): 313‚Äì330.\nBerelson, B., P. Lazarsfeld and W. McPhee (1954). Voting. A Study of Opinion Formation in a Presidential Campaign. Chicago: The University of Chicago Press.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nBerkowitz, D.A. (2009). Reporters and Their Sources. In Wahl-Jorgensen, K. and T. Hanitzsch (eds.),\nThe Handbook of Journalism Studies. New York: Routledge (102‚Äì115).\nBlum, R. (2003). Medienstrukturen der Schweiz. In Bentele, G., H.-B. Brosius and O. Jarren (eds.),\nOÃàÔ¨Äentliche Kommunikation. Handbuch Kommunikations- und Medienwissenschaft. Wiesbaden: Westdeutscher Verlag (366‚Äì381).\nBonfadelli, H. and R. Blum (2000). Helvetisches Stiefkind: die Rolle der Massenmedien bei der Vermittlung schweizerischer Aussenpolitik. Bern, NFP 42 Synthesis n 28.\nBornschier, S. (2010). Cleavage Politics and the Populist Right: The New Cultural ConÔ¨Çict in Western\nEurope. Philadelphia: Temple University Press.\nBuÃàtzer, M. and L. Marquis (2002). Public Opinion Formation in Swiss Federal Referendums. In\nFarrell, D. and R. Schmitt-Beck (eds.), Do Political Campaigns Matter? Campaign EÔ¨Äects in Elections and Referendums. London and New York: Routledge (163‚Äì182).\nBunton, K. (1998). Social Responsibility in Covering Community: A Narrative Case Analysis. Journal\nof Mass Media Ethics 13(4): 232‚Äì246.\nChaÔ¨Äee, S. and S.Y. Choe (1980). Time of Decision and Media Use During the Ford-Carter\nCampaign. Public Opinion Quarterly 44(1): 53‚Äì69.\nChristians, C. and K. Nordenstreng (2004). Social Responsibility Worldwide. Journal of Mass Media\nEthics 19(1): 3‚Äì28.\nCohen, J. (1986). An Epistemic Conception of Democracy. Ethics 97(1): 26‚Äì38.\n‚Äî‚Äî (1989). Deliberation and Democratic Legitimacy. In Hamlin, A. and P. Pettit (eds.), The Good\nPolity. Oxford: Blackwell (17‚Äì34).\nConnolly, S. and S. Hargreaves Heap (2007). Cross Country DiÔ¨Äerences in Trust in Television and\nthe Governance of Public Broadcasters. Kyklos 60(1): 3‚Äì14.\nConnolly, W.E. 1991. Identity, DiÔ¨Äerence: Democratic Negotiations of Political Paradox. Ithaca:\nCornell University Press.\nDahl, R.A. 1989. Democracy and Its Critics. New Haven [etc.]: Yale University Press.\nDe Vreese, C. and H. Semetko (2002). Public Perception of Polls and Support for Restrictions on the\nPublication of Polls: Denmark‚Äôs 2000 Euro Referendum. International Journal of Public Opinion\nResearch 14(4): 367‚Äì390.\nDelli Carpini, M. and S. Keeter 1996. What Americans Know about Politics and Why It Matters. New\nHaven and London: Yale University Press.\nDiskin, A., A. Eschet-Schwarz and D. Felsenthal (2007). Homogeneity, Heterogeneity and Direct\nDemocracy: The Case of Swiss Referenda. Canadian Journal of Political Science 40(2): 317‚Äì342.\nDonovan, T. and S. Bowler (1998). An Overview of Direct Democracy in the American States. In\nBowler, S., T. Donovan and C. Tolbert (eds.), Citizens as Legislators. Direct Democracy in the\nUnited States. Columbus: Ohio State University Press (1‚Äì21).\nDonsbach, W. and A. Wenzel (2002). AktivitaÃàt und PassivitaÃàt von Journalisten gegenuÃàber parlamentarischer Pressearbeit. Publizistik 47(4): 373‚Äì387.\nDowns, A. (1957). An Economic Theory of Democracy. New York: Harper Collins.\nDryzek, J.S. (1990). Discursive Democracy: Politics, Policy, and Political Science. New York:\nCambridge University Press.\nDuVivier, K. (2006). The United States as a Democratic Ideal? International Lessons in Referendum\nDemocracy. Temple Law Review 79: 821‚Äì876.\nEntman, R. (2004). Projections of Power. Framing News, Public Opinion, and U.S. Foreign Policy.\nChicago: University of Chicago Press.\nEstlund, D. (1997). Beyond Fairness and Deliberation: The Epistemic Dimension of Democratic\nAuthority. In Bohman, J. and W. Rehg (eds.), Deliberative Democracy: Essays on Reason and\nPolitics. Cambridge: MIT Press (173‚Äì204).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n158\n\n159\n\nFoÃàrster, J. and N. Liberman (2007). Knowledge Activation. In Kruglanski, A. and E.T. Higgins\n(eds.), Social Psychology. Handbook of Basic Principles. New York: Guilford Press (201‚Äì231).\nFournier, P., R. Nadeau, A. Blais, E. Gidengil and N. Nevitte (2004). Time-of-Voting Decision and\nSusceptibility to Campaign EÔ¨Äects. Electoral Studies 23(4): 661‚Äì681.\nFroÃàhlich, R. and B. RuÃàdiger (2006). Framing Political Public Relations: Measuring Success of Political Communication Strategies in Germany. Public Relations Review 32: 18‚Äì25.\nGerhards, J. (1997). Diskursive versus liberale OÃàÔ¨Äentlichkeit. Eine empirische Auseinandersetzung mit\nJuÃàrgen Habermas. KoÃàlner Zeitschrift fuÃàr Soziologie und Sozialpsychologie 49(1): 1‚Äì34.\nGilens, M. (2001). Political Ignorance and Collective Policy Preferences. American Political Science\nReview 95(2): 379‚Äì396.\nGitlin, T. (1980). The Whole World is Watching. Mass Media in the Making and Unmaking of the New\nLeft. Berkeley: University of California Press.\nGollin, A. (1980). Exploring the Liaison between Polling and the Press. Public Opinion Quarterly\n44(4): 445‚Äì461.\nGraber, D. (2003). The Media and Democracy: Beyond Myths and Stereotypes. Annual Review of\nPolitical Science 6: 139‚Äì160.\n‚Äî‚Äî (2006). Mass Media and American Politics. Washington: CQ Press.\nGrossenbacher, R., T. Forsberg, M. Koch and M. BraÃàndli (2006). Politische OÃàÔ¨Äentlichkeitsarbeit in regionalen Medien. Kilchberg: Publicom AG.\nGurevitch, M. and J. Blumler (1977). Linkages between the Mass Media and Politics: A Model for\nthe Analysis of Political Communications Systems. In Curran, J., M. Gurevitch and J. Woollacott\n(eds.), Mass Communication and Society. London: Edward Arnold (270‚Äì290).\nGurevitch, M. and J. Blumler (1990). Political Communication Systems and Democratic Values. In\nLichtenberg, J. (ed.), Democracy and the Mass Media. New York: Cambridge University Press\n(269‚Äì289).\nHabermas, J. (1992). FaktizitaÃàt und Geltung. BeitraÃàge zur Diskurstheorie des Rechts und des demokratischen Rechtsstaats. Frankfurt am Main: Suhrkamp.\nHajnal, Z., E. Gerber and H. Louch (2002). Minorities and Direct Legislation: Evidence from\nCalifornia Ballot Proposition Elections. Journal of Politics 64(1): 154‚Äì177.\nHallin, D. (1984). The Media, the War in Vietnam, and Political Support: A Critique of the Thesis of\nan Oppositional Media. Journal of Politics 46(1): 2‚Äì24.\nHallin, D. and P. Mancini (2004). Comparing Media Systems. Three Models of Media and Politics.\nNew York: Cambridge University Press.\nHardmeier, S. (1999). Political Poll Reporting in Swiss Print Media: Analysis and Suggestions for\nQuality Improvement. International Journal of Public Opinion Research 11(3): 257‚Äì74.\n‚Äî‚Äî (2000). Meinungsumfragen im Journalismus: Nachrichtenwert, PraÃàzision und Publikum. Medien\nund Kommunikationswissenschaft 48(3): 371‚Äì395.\nHargreaves, I. and J. Thomas (2002). New News, Old News. An ITC and BSC Research Publication.\nLondon: ITC.\nHayes, A. (2008). Press Critics Are the Fifth Estate: Media Watchdogs in America. New York:\nPraeger.\nHertig, H.P. (1982). Sind Abstimmungserfolge kaÃàuÔ¨Çich? ‚Äî Elemente der Meinungsbildung bei\nEidgenoÃàssischen Abstimmungen. Annuaire Suisse de Science Politique 22: 35‚Äì57.\nHiggins, E. (1996). Knowledge Activation: Accessibility, Applicability, and Salience. In Higgins, E.\nand A. Kruglanski (eds.), Social Psychology. Handbook of Basic Principles. New York: The\nGuilford Press (133‚Äì168).\nHofstetter, C. et al. (1999). Information, Misinformation, and Political Talk Radio. Political Research\nQuarterly 52(2): 353‚Äì369.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nHobolt Binzer, S. (2009). Europe in Question: Referendums on European Integration. Oxford: Oxford\nUniversity Press.\nJerit, J., J. Barabas and T. Bolsen (2006). Citizens, Knowledge, and the Information Environment.\nAmerican Journal of Political Science 50(2): 266‚Äì282.\nKaufmann, B., G. Kreis and A. Gross (2005). Direkte Demokratie und europaÃàische Integration. Die\nHandlungsspielraÃàume der Schweiz. Basel: Europainstitut.\nKelley, S. (1960). Political Campaigning. Problems in Creating an Informed Electorate. Washington:\nThe Brookings Institution.\nKing, E. and M. Schudson (1995). The Press and the Illusion of Public Opinion: The Strange Case of\nRonald Reagan‚Äôs ‚ÄòPopularity‚Äô. In Glasser, T. and C. Salmon (eds.), Public Opinion and the Communication of Consent. New York: The Guilford Press (132‚Äì155).\nKirchgaÃàssner, G. and T. Schulz (2005). Was treibt die StimmbuÃàrger an die Urne? Eine empirische\nUntersuchung der Abstimmungsbeteiligung in der Schweiz, 1981‚Äì1999. Swiss Political Science\nReview 11(1): 1‚Äì56.\nKriesi, H. (1994). Le deÃÅÔ¨Å aÃÄ la deÃÅmocratie directe poseÃÅ par les transformations de l‚Äôespace public. In\nPapadopoulos, Y. (ed.), Pre¬¥sent et avenir de la de¬¥mocratie directe. Geneva: Georg (31‚Äì72).\n‚Äî‚Äî (1998). The Transformation of Cleavage Politics: The 1997 Stein Rokkan Lecture. European\nJournal of Political Research 33(2): 165‚Äì185.\n‚Äî‚Äî (2003). Strategische politische Kommunikation: Bedingungen und Chancen der Mobilisierung\noÃàÔ¨Äentlicher Meinung im internationalen Vergleich. In Esser, F. and B. Pfetsch (eds.), Politische\nKommunikation im internationalen Vergleich. Grundlagen, Anwendungen, Perspektiven. Wiesbaden:\nWestdeutscher Verlag (208‚Äì239).\n‚Äî‚Äî (2005). Direct Democratic Choice. The Swiss Experience. Lanham: Lexington Books.\nKriesi, H., B. Wernli, P. Sciarini and M. Gianni (1996). Le clivage linguistique. Proble`mes de compre¬¥hension entre les communaute¬¥s linguistiques en Suisse. Berne: OÔ¨Éce feÃÅdeÃÅral de la statistique.\nKrouse, R. and G. Marcus (1984). Electoral Studies and Democratic Theory Reconsidered. Political\nBehavior 6(1): 23‚Äì39.\nKuklinski, J. and P. Quirk (2000). Reconsidering the Rational Public: Cognition, Heuristics, and Mass\nOpinion. In Lupia, A., M. McCubbins and S. Popkin (eds.), Elements of Reason. Cambridge:\nCambridge University Press (153‚Äì182).\nLandis, J.R. and G. Koch (1977). The Measurement of Observer Agreement for Categorical Data.\nBiometrics 33(1): 159‚Äì174.\nLeuthold, H., M. Hermann and S. Fabrikant (2007). Making the Political Landscape Visible:\nMapping and Analyzing Voting Patterns in an Ideological Space. Environment and Planning B:\nPlanning and Design 34: 785‚Äì807.\nLinder, W., R. ZuÃàrcher and C. Bolliger (2008). Gespaltene Schweiz ‚Äì geeinte Schweiz. Gesellschaftliche\nSpaltungen und Konkordanz bei den Volksabstimmungen seit 1874. Baden: Hier und Jetzt.\nList, C. and R.E. Goodin (2001). Epistemic Democracy: Generalizing the Condorcet Jury Theorem.\nJournal of Political Philosophy 9(3): 277‚Äì306.\nLongchamp, C. (1998). Demoskopie: Seismograph oder Kompass? Ein UÃàberblick uÃàber die Ausbreitung\nund Verwendung der politischen Umfrageforschung in der Schweiz. Referat vor der ErdoÃàl-Vereinigung, 23.03.1998. Online: http://www.gfs.ch/publset.html [accessed: 29.04.2010].\nLuskin, R., J. Fishkin and R. Jowell (2002). Considered Opinions: Deliberative Polling in Britain.\nBritish Journal of Political Science 32(3): 455‚Äì487.\nMarquis, L. (2006). La formation de l‚Äôopinion publique en de¬¥mocratie directe. Les reÃÅfe¬¥rendums sur la\npolitique exte¬¥rieure suisse (1981‚Äì1995). Zurich: Seismo.\nMarquis, L. and M. Bergman (2009). Development and Consequences of Referendum Campaigns in\nSwitzerland, 1981‚Äì1999. Swiss Political Science Review 15(1): 63‚Äì97.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n160\n\n161\n\nMatthes, J. (2005). The Need for Orientation Towards News Media: Revising and Validating a Classic\nConcept. International Journal of Public Opinion Research 18(4): 422‚Äì444.\nMcDevitt, M. (2003). In Defense of Autonomy: A Critique of the Public Journalism Critique. Journal\nof Communication 53(1): 155‚Äì160.\nMcLeod, D., G. Kosicki and J. McLeod (2002). Resurveying the Boundaries of Political Communications EÔ¨Äects. In Bryant, J. and D. Zillmann (eds.), Media EÔ¨Äects. Advances in Theory and Research.\nMahwah: Lawrence Erlbaum (215‚Äì267).\nMeier, W. and M. Schanne (1994). Medien-‚Äò‚ÄòLandschaft‚Äô‚Äô Schweiz. Zurich: Pro Helvetia.\nMeier, W. and O. Jarren (2002). OÃàkonomisierung und Kommerzialisierung von Medien und Mediensystem. Bemerkungen zu einer (notwendigen) Debatte. In Haas, H. and O. Jarren (eds.), Mediensysteme im Wandel. Struktur, Organisation und Funktion der Massenmedien. Wien: BraumuÃàller\n(201‚Äì216).\nMerritt, D. (1995). Public Journalism and Public Life. Why Telling the News Is Not Enough. Mahwah:\nLawrence Erlbaum.\nNeidhardt, F. (1994). OÃàÔ¨Äentlichkeit, oÃàÔ¨Äentliche Meinung, soziale Bewegungen. In Neidhardt, F. (ed.),\nOÃàÔ¨Äentlichkeit, oÃàÔ¨Äentliche Meinung, soziale Bewegungen. KoÃàlner Zeitschrift fuÃàr Soziologie und\nSozialpsychologie, Sonderheft 34 (7‚Äì41).\nNeidhart, L. (1970). Plebiszit und pluralitaÃàre Demokratie. Eine Analyse der Funktion des schweizerischen Gesetzesreferendums. Berne: Francke.\nNeuman, W.R. (1990). The Threshold of Public Attention. Public Opinion Quarterly 54(2): 159‚Äì176.\nNovik, N. (2009). Do Campaigns Matter? The Contribution of European Union Campaigns to Broad\nPolitical Knowledge. Dissertation. Dublin: Trinity College.\nPage, B.I. (1996). Who Deliberates? Mass Media in Modern Democracy. Chicago: University of Chicago Press.\nPapadopoulos, Y. (1998). De¬¥mocratie directe. Paris: Economica.\nPateman, C. (1970). Participation and Democratic Theory. Cambridge: Cambridge University Press.\nPatterson, T. (1994). Out of Order. New York: Vintage.\n‚Äî‚Äî (1998). Political Roles of the Journalist. In Graber, D., D. McQuail and P. Norris (eds.), The\nPolitics of News. The News of Politics. Washington D.C.: Congressional Quarterly (17‚Äì32).\nPfetsch, B. (2004). Geschlossene Gesellschaft? Akteursensembles und Akteursbewertungen in Pressekommentaren. In Eilders, C., F. Neidhardt and B. Pfetsch (eds.), Die Stimme der Medien: Pressekommentare und politische OÃàÔ¨Äentlichkeit in der Bundesrepublik. Wiesbaden: VS Verlag (74‚Äì105).\nPilon, D. (2009). Investigating Media as a Deliberative Space: Newspaper Opinions about Voting Systems in the 2007 Ontario Provincial Referendum. Canadian Political Science Review 3(3): 1‚Äì23.\nPrice, V. and J. Zaller (1993). Who Gets the News? Alternative Measures of News Reception and their\nImplications for Research. Public Opinion Quarterly 57(2): 133‚Äì164.\nRobinson, G. (1995). Making News and Manufacturing Consent: The Journalistic Narrative and Its\nAudience. In Glasser, T. and C. Salmon (eds.), Public Opinion and the Communication of Consent.\nNew York: The Guilford Press (348‚Äì369).\nRothmayr, C. and S. Hardmeier (2002). Government and Polling: Use and Impact of Polls in the\nPolicy-Making Process in Switzerland. International Journal of Public Opinion Research 14(2):\n123‚Äì140.\nSallot, L. and E. Johnson (2006). Investigating Relationships between Journalists and Public Relations\nPractitioners: Working Together to Set, Frame and Build the Public Agenda, 1991-2004. Public\nRelations Review 32(2): 151‚Äì159.\nSchoÃànhagen, P. (2008). Ko-Evolution von Public Relations und Journalismus: Ein erster Beitrag zu\nihrer systematischen Aufarbeitung. Publizistik 53(1): 9‚Äì24.\nSchudson, M. (2001). The Objectivity Norm in American Journalism. Journalism 2(2): 149‚Äì170.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nShoemaker, P. and S. Reese (1995). Mediating the Message. Theories of InÔ¨Çuences on Mass Media\nContent. White Plains: Longman.\nSigal, L. (1973). Reporters and OÔ¨Écials. The Organization and Politics of Newsmaking. Lexington:\nHeath and Company.\nSinger, J. (2007). Contested Autonomy. Professional and Popular Claims on Journalistic Norms. Journalism Studies 8(1): 79‚Äì95.\nStatham, P. (2006). Political Journalism and Europeanization: Pressing Europe? European Political\nCommunication Working Paper No. 2006 ‚ÅÑ 13.\nStroÃàmbaÃàck, J. and D. Dimitrova (2006). Political and Media Systems Matter: A Comparison of\nElection News Coverage in Sweden and the United States. Harvard International Journal of Press ‚ÅÑ\nPolitics 11(4): 131‚Äì147.\nSturgis, P. (2003). Knowledge and Collective Preferences. A Comparison of Two Approaches to Estimating the Opinions of a Better Informed Public. Sociological Methods and Research 31(4): 453‚Äì485.\nTarrow, S. (2004). Bridging the Quantitative-Qualitative Divide. In Brady, H. and D. Collier (eds.),\nRethinking Social Inquiry: Diverse Tools, Shared Standards. Lanham: Rowman &amp; LittleÔ¨Åed (171‚Äì\n179).\nTrechsel, A. and P. Sciarini (1998). Direct Democracy in Switzerland: Do Elites Matter? European\nJournal of Political Research 33(1): 99‚Äì124.\nTresch, A. (2008). OÃàÔ¨Äentlichkeit und Sprachenvielfalt. Medienvermittelte Kommunikation zur Europapolitik in der Deutsch- und Westschweiz. Baden-Baden: Nomos.\nTuchman, G. (1972). Objectivity as Strategic Ritual: An Examination of Newsmen‚Äôs Notions of\nObjectivity. American Journal of Sociology 77(4): 660‚Äì679.\nVatter, A. (2002). Kantonale Demokratien im Vergleich. EntstehungsgruÃànde, Interaktionen und Wirkungen politischer Institutionen in den Schweizer Kantonen. Opladen: Leske und Budrich.\nWatts, M., D. Domke, D. Shah and D. Fan (1999). Elite Cues and Media Bias in Presidential Campaigns: Explaining Public Perceptions of a Liberal Press. Communication Research 26(2): 144‚Äì175.\nWuerth, A. (1999). Mediensystem und politische Kommunikation. In KloÃàti, U., P. Knoepfel,\nH. Kriesi, W. Linder and Y. Papadopoulos (eds.), Handbuch der Schweizer Politik. Zurich: NZZ\nVerlag (337‚Äì384).\nYankelovich, D. (1991). Coming to Public Judgment. Making Democracy Work in a Complex World.\nSyracuse: Syracuse University Press.\nYoung, I.M. (1990). Justice and the Politics of DiÔ¨Äerence. Princeton: Princeton University Press.\n‚Äî‚Äî (2000). Inclusion and Democracy. Oxford: Oxford University Press.\nZaller, J. and D. Chiu (1996). Government‚Äôs Little Helper: U.S. Press Coverage of Foreign Policy\nCrises, 1945‚Äì1991. Political Communication 13(4): 385‚Äì405.\n\nAppendix\nTable A1: List of all ballot measures analyzed in this study\nResult\n(share of yes\nvotes)\n\nBallot title\n571 10th amendment of retirement pension system (25.06.1995)\n572 Initiative on retirement pensions (25.06.1995)\n602 Law on labour: weekend and night work, maternity (01.12.1996)\n622 Financing of unemployment insurance (28.09.1997)\n\n 2011 Swiss Political Science Association\n\n60.7\n27.6\n33.0\n49.2\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n162\n\n163\n\nTable A1: (Continued).\nResult\n(share of yes\nvotes)\n\nBallot title\n643 10th amendment of pension system without increase of retirement age\n(27.09.1998)\n654 Law on labour: night work, maternity (29.11.1998)\n684 Law on disability insurance (13.06.1999)\n685 Law on maternity insurance (13.06.1999)\n721 Initiative against increase of retirement age for women (26.11.2000)\n722 Initiative for ‚Äò‚ÄòÔ¨Çexible retirement age from 62 years‚Äô‚Äô (26.11.2000)\n724 Initiative for ‚Äò‚Äòreduced hospital costs‚Äô‚Äô (26.11.2000)\n732 Initiative for ‚Äò‚Äòcheaper drugs‚Äô‚Äô (04.03.2001)\n752 Initiative to ‚Äò‚Äòsecure pension system ‚Äì tax energy instead of labour‚Äô‚Äô\n(02.12.2001)\n762 Reduction of work time (03.03.2002)\n781 Initiative about gold reserves to retirement pension (22.09.2002)\n782 Counter-proposal about gold reserves to retirement pension (22.09.2002)\n792 Law on unemployment insurance: unemployment beneÔ¨Åts (24.11.2002)\n802 Participation of cantons in Ô¨Ånancing of hospital treatments (09.02.2003)\n815 Initiative ‚Äò‚Äòhealth must remain aÔ¨Äordable‚Äô‚Äô (18.05.2003)\n816 Initiative ‚Äò‚Äòequal rights for disabled people‚Äô‚Äô (18.05.2003)\n819 Initiative for ‚Äò‚ÄòsuÔ¨Écient apprenticeship places‚Äô‚Äô (18.05.2003)\n831 11th amendment of pension system: increase of pension age for women\n(16.05.2004)\n832 Financing of retirement pension through VAT increase (16.05.2004)\n844 Maternity insurance (26.09.2004)\n\n41.5\n63.4\n30.3\n39.0\n39.5\n46.0\n17.9\n30.9\n22.9\n25.4\n46.4\n46.4\n56.1\n77.4\n27.1\n37.7\n31.6\n32.1\n31.4\n55.5\n\nSource: Swiss Federal Chancellery.\n\nLionel Marquis received his PhD from the University of Geneva in 2002. Since 2008 he has been a lecturer and\nresearcher in political science at the University of Lausanne. His research interests comprise Swiss foreign and\nsocial policy, political behaviour and political psychology. Address for correspondence: Lionel Marquis, University\nof Lausanne, Institut d‚ÄôEtudes Politiques, et Internationales, UNIL-Dorigny, Anthropole, 1015 Lausanne.\nPhone: +41 (0)21 692 31 56; Email: lionel.marquis@unil.ch\nHans-Peter Schaub is a PhD student at the University of Berne. He is working on the Swiss National Science Foundation project ‚Äò‚ÄòThe quality of democracy in the Swiss cantons‚Äô‚Äô and writing his doctoral thesis on democracy‚Äôs\nquality in cantons with a popular assembly (Landsgemeinde) as compared to cantons with a ballot box system.\nAddress for correspondence: Hans-Peter Schaub, University of Berne, Institut fuÃàr Politikwissenschaft, Lerchenweg\n36, 3000 Bern 9. Phone: +41 (0)31 631 48 49; Email: hans-peter.schaub@ipw.unibe.ch\nMarleÃÄne Gerber is a PhD student at the University of Berne. She is working on a project funded by the Swiss\nNational Science foundation that examines the potential for deliberation among EU-citizens. She writes her\ndoctoral thesis on deliberative quality in a European-wide deliberative poll on immigration. Address for correspondence: MarleÃÄne Gerber, University of Berne, Institut fuÃàr Politikwissenschaft, Lerchenweg 36, 3000 Bern 9. Phone:\n+41 (0)31 631 83 37; Email: marlene.gerber@ipw.unibe.ch\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128‚Äì163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n</td>
    </tr>
    <tr>
      <th>79</th>
      <td>news</td>
      <td>MEDIA BIAS, POLITICAL POLARIZATION,\nAND THE MERITS OF FAIRNESS‚ó¶\nRYAN Y. FANG‚ô¶\nAbstract. In this paper, we study the economic and social consequences of biased\nnews coverage in the public media and evaluate the merits of content regulations\ndesigned to curtail such bias. We present a general model of the market for news and\nshow that rational Bayesian consumers might prefer biased news to more balanced\nnews, even when the latter is significantly more informative. Consequently, media\noutlets motivated only by higher profits might produce news with significant bias in\nequilibrium. Our model is able to fit documented empirical relationships between\nmedia bias and consumer ideology. It also provides an explanation for the historical\nvariations of the average degree of bias in the U.S. news market based on changes\nin the cost of news to the consumers and the intensity of competition. Our policy\nanalysis shows that content regulations can never lead to Pareto superior outcomes\nbut can lead to Pareto dominated ones. Thus, they are poorly justified on the ground\nof protecting consumer welfare. However, we also find that media bias can lead to\npolitical polarization. While content regulations might help to mitigate such polarization, their effectiveness depends critically on market conditions.\nJEL Classification: D03; D83; L12; L13; L51; L52\nKey Words: Media Bias, Political Polarization, Content Regulation, Confirmation\nBias, Bayesian Rationality, Endogenous Information Acquisition\n\nDate: February 15, 2014.\n‚ó¶\nThis research was conducted under the direction of my advisers Roger Myerson, Philip Reny, and\nHugo Sonnenschein and have benefited immensely from their insightful suggestions. I am also grateful\nfor the valuable comments provided by Jesse Shapiro, Richard Van Weelden, and seminar participants\nat Brown University, the Pennsylvania State University, and the University of Chicago. All remaining\nerrors are, of course, my own.\n‚ô¶\nDepartment of Economics, University of Chicago. Email: ryfang@uchicago.edu.\n1\n\n1. Introduction\n‚ÄúWhere the press is free and every man able to read, all is safe.‚Äù - Thomas\nJefferson (to Colonel Charles Yancey 1816)\nIt is widely believed that a free, fair, and honest news media is one of the essential\npillars of a modern democracy. Because of its importance, scholars, politicians, and\nvarious watchdog groups have closely monitored the state of the media and have never\nbeen shy to voice their criticism.\nThus, allegations of failure by the media to meet public expectations and, in particular, allegations of bias in its coverage of political news have been plentiful in public\ndiscourse. However, in the past two decades, such allegations appeared to be growing more prevalent and impassioned in the United States. Numerous best-sellers have\nbeen written to warn the public of the pervasiveness and severity of media bias.1 Research scholars have identified and measured media bias in the U.S. news market (e.g.,\nGroseclose and Milyo (2005) and Gentzkow and Shapiro (2010)) and its impact on the\nviews of the general public and the outcomes of political processes (e.g., Gentzkow\nand Shapiro (2004), DellaVigna and Kaplan (2007), and Chiang and Knight (2011)).2\nRecent surveys by the Pew Research Center for the People and the Press (2011) show\nthat consumers‚Äô perception of media bias has deteriorated drastically since the mid\n1980s (see Figure 1.1).\nScholars, pundits, and politicians have expressed concerns over the apparent surge\nof media bias in the U.S. news market. It is the belief shared by many that media bias\nis the deliberate attempt by media outlets to misinform the public in pursuit of their\nown agendas. Moreover, biased news is less informative and thus inferior in value to\nconsumers. Thus, in order to protect consumer welfare, the government must intervene\nand impose fairness standards in the industry to curtail media bias.\nContent regulations that restrict the degree of bias in news coverage are popular tools\nfor such purposes. In the United Kingdom, the Office of Communications‚Äôs Broadcasting Codes require news to be reported with ‚Äúdue impartiality‚Äù.3 In the United States,\nthe Federal Communications Commission (FCC) enforced the Fairness Doctrine, which\nrequired TV and radio stations to present contrasting viewpoints on controversial issues of public interest. The FCC dissolved the doctrine during the deregulation sweep\n1\n\nFor example, Coulter (2003) and Goldberg (2002) claim that there is a significant liberal bias in\nthe American public media, while Alterman (2003) and Brock, Rabin-Havt, and Media Matters for\nAmerica (2012) claim that the bias is to the right.\n2\nNote that, while many studies find significant bias in the news media, Puglisi and Snyder (2012) find\nthe press to be largely balanced.\n3\nSection\nFive\nof\nthe\nOfcom\nBroadcasting\nCodes,\navailable\nat:\nhttp://stakeholders.ofcom.org.uk/broadcasting/broadcast-codes/broadcast-code/?a=0.\n2\n\nFigure 1.1. Percentage of Respondents Expressing Concerns for Media Bias\n\nof the Reagan Administration. But attempts to reintroduce the Fairness Doctrine and\neven to codify it have not stopped since.4\nIn this paper, we present a general model of the market for news and apply it to examining the economic and social consequences of media bias and evaluating the merits\nof these regulations on news content. Motivated by our goal to understand the impact\nof content regulations such as the Fairness Doctrine as well as the empirical measures\nof media bias in the literature, we define such bias in this paper as the unbalanced\npresentation of information (views, evidence, etc.) in favor of (i.e., inherently biased\nto) different sides of a controversial issue. The media outlets in our model can spend\na limited amount of resources on acquiring information regarding the unknown state\nof the world and can allocate these resources to collecting information with different\nbiases. They can produce balanced news reports by allocating resources evenly across\nthe collection of information favoring each side. Otherwise, their news reports will be\nbiased. Thus, media bias can be created in the process of collecting and synthesizing\n4\n\nSee Limburg (2013) for a brief account of the introduction and abolition of the Fairness Doctrine and\nsuggestions for further reading.\n3\n\ninformation. The media outlets can also garble the information they have collected\nbefore reporting them to the consumers. However, we show that if the media outlets‚Äô\ngoal is to maximize profits, garbling is suboptimal and is not part of their equilibrium\nstrategies.\nOur findings cast serious doubt on the common justification for content regulations\nthat hinges on protecting consumers from misinformation. Although there is evidence\nsuggesting that consumers exposed to unbalanced news sources appear to be relatively\npoorly informed (e.g., Gentzkow and Shapiro (2004)), this does not necessarily imply\nthat consumer welfare is lower. Our results show that rational Bayesian consumers who\nconsume news only to help themselves make informed individual decisions may strictly\nprefer biased news to more balanced news, even if the latter provides significantly\nmore information. The reason is that, while more information always improves the\naccuracy of the consumers‚Äô beliefs and can never hurt a rational Bayesian consumer\nmaking non-strategic decisions (Blackwell (1951)), its value depends on the nature of\nthe consumers‚Äô decision problem and the nature of other information the consumers\nhave.5\nIn particular, acquiring information with opposite biases can be inefficient. Contrasting viewpoints or conflicting evidence prevents rational consumers from becoming\ncertain of the underlying state and making resolute decisions that bring higher expected\nutilities. Thus, when information are costly to gather and there is tradeoff between\ninformation with different biases, learning only one-sided information can be more efficient to the consumers. This may be the case even when there is significant decreasing\nreturn to scale associated with producing information biased to one side, and allocating\nall resources to collecting one-sided information results in less information gathered in\ntotal.\nWe show that media outlets may choose to produce news with significant bias in\nequilibrium even when they are only motivated by higher profits. Moreover, content\nregulations not only cannot lead to Pareto improvements from market outcomes, they\ncan in fact result in Pareto dominated outcomes. Thus, these regulations are poorly\njustified on the ground of protecting consumer welfare. On the other hand, we also\nfind that media bias can lead to political polarization, which is behaviorally defined by\nconsumers taking more extreme actions in opposite directions. We show that content\n5\n\nNote that, in this paper, a news report providing ‚Äúmore information‚Äù is one that presents a larger\nnumber of facts (pieces of evidence) and does not necessarily dominate a news report providing less\ninformation according to the Blackwell order, which already takes into account of the nature of the\ndecision problem. In fact, pairs of news reports often cannot be ordered by the Blackwell order, which,\nof course, is not complete.\n4\n\nregulations can help mitigate such polarization under some market conditions, but can\nalso exacerbate polarization under other circumstances.\nA fast growing literature on media economics has produced many insightful explanations for the perceived biases in the news media.6 Baron (2006), Besley and Prat\n(2006), Duggan and Martinelli (2011), and Anderson and McLaren (2012) show that\nmedia bias may originate from the supply side, when media outlets or their employees\nhave incentives to deliberately distort the consumers‚Äô beliefs with biased news. On\nthe other hand, other papers have modeled media bias as originating from the demand\nside. The consumers may demand bias in their news because they appreciate the entertainment value in such news (e.g. Mullainathan and Shleifer (2005), Bernhardt, Krasa,\nand Polborn (2008)) or find such news more useful in helping them determining their\noptimal course of action (e.g. Chan and Suen (2008), Oliveros and Vardy (2012), and\nSobbrio (2013)). Gentzkow and Shapiro (2006) and Stone (2011) show that media bias\ncan arise if media outlets have the incentive to mislead consumers unsure of the media\noutlets‚Äô capabilities into believing that they are of the superior type or if consumers\nand reporters misinterpret their information (i.e., they are affected by confirmation\nbiases in the spirit of Rabin and Schrag (1999)).\nIn this paper, our consumers only care about making optimal individual choices and\nconsume news only to assist their decision making as in Chan and Suen (2008) and\nOliveros and Vardy (2012). The media outlets in our model only aim to maximize\nprofits as in Mullainathan and Shleifer (2005) and Sobbrio (2013). This is not to say\nthat we do not think that the entertainment value in news and the media outlets‚Äô\nincentives to influence their consumers are not important aspects of the problem. But\nwe believe that, to better understand these other aspects, it is important to learn how\nfar a more basic model can take us to understand the phenomenon of media bias.\nIn contrast to the fruitful research on the cause of media bias and its impact on\ndemocratic processes, little has been done to develop a theoretical understanding of\nthe industrial organization of the market for news, which is essential for the evaluation\nof media industry regulations. Earlier models that study the commercial aspects of\nmedia bias (e.g., Mullainathan and Shleifer (2005), Anderson and McLaren (2012),\nand Sobbrio (2013)) are too restrictive to match the rich body of empirical evidence\naccumulated by recent studies (e.g. Hamilton (2006), Gentzkow, Glaeser, and Goldin\n(2006), Gentzkow and Shapiro (2010), and Gentzkow, Shapiro, and Sinkinson (2012)).\nFor example, consumers are generally restricted to consuming only one news report, and\nmost of the models have difficulties analyzing oligopolistic competition involving more\n6\n\nSee Prat and Stromberg (2011) for a survey of the literature on the political economy of public media.\n5\n\nthan two media outlets. Consequently, these models cannot match known consumption\npatterns, according to which consumers often consume multiple number of news reports\nwith distinct biases, and media outlets attract consumers from distinct ideological\ngroups (the Pew Research Center for the People and the Press (2012) and Mitchell,\nJurkowitz, Enda, and Olmstead (2013)).\nIn this paper, media outlets have more freedom in deciding the amount of information\nto report and the manner in which they report, while consumers are able to consume\nmultiple news reports. At the same time, our model remains tractable and is able to\naccommodate any finite number of media outlets. The generality of our model leads to\nnew predictions. In addition to matching the above mentioned consumption patterns,\nthe flexibility to handle large number of competitors allows us to examine the joint\neffect of the cost incurred by consumers from consuming news and the intensity of\ncompetition on the average degree of bias in the news supplied in equilibrium. We\nare thus able to explain the historical variations of the degree of media bias in the US\nmarket based on the changes in those factors.\nLast, this paper presents a new model of rational demand for biased information.\nAs in Calvert (1985) and Suen (2004), the preference for biased information by our\nconsumers is attributable to the non-concavity in the value of information (Radner\nand Stiglitz (1984)). However, the ways bias is conceptualized differ across these models, which lead to different behavioral predictions.7 The type of preference for biased\ninformation in our model is an example of the concept generally termed ‚Äúconfirmation\nbias‚Äù in the Psychology literature (See Klayman (1995) and Nickerson (1998)), which\nhas been introduced to the economics literature by Rabin and Schrag (1999).\nThe rest of the paper is organized as follows: the next section introduces the formal\nmodel. In Section 3, we characterize the optimal news report from an individual\nconsumer‚Äôs perspective and show that it often is biased. Section 4 studies the industrial\norganization of the market for news and analyzes the relationship between average\nequilibrium media bias and other market conditions. Towards the end of the section,\nwe lay out the empirical implications of our model and evaluate the effect of imposing\ncontent regulations on consumers‚Äô well-being. In Section 5, we show that media bias can\nlead to political polarization. We demonstrate that content regulations can mitigate\nsuch polarization and discuss their limits. Section 6 concludes with a discussion on\npossible extensions. All proofs are relegated to the appendix.\n\n7\n\nFor example, in Chan and Suen (2008), which shares the same basic model as Suen (2004), the\nconsumers are never willing to pay for more than one news reports.\n6\n\n2. The Model\nConsider a market for news with a continuum of consumers and a finite number\nof producers. The producers will be referred to as media outlets. The mass of the\nconsumers is normalized to unity and N ‚àà N denotes the number of media outlets.\nThe consumers each, independently, face a choice under uncertainty and the media\noutlets provide information that can potentially assist the consumers in making better\ndecisions.\n2.1. The Consumers‚Äô Decision. Let i denote a typical consumer who faces a choice\nbetween three actions: the left action, denoted by l, the right action, denoted by r,\nand abstention, denoted by a. As summarized in Table 2.1, i‚Äôs utilities associated with\nactions l and r depend on the unknown state of the world, which can be either left,\ndenoted by L, or right, denoted by R, while her utility associated with action a is\ncertain and is normalized to 0. The parameters Œ±i , Œ≤i , Œ¥i , Œ≥i are positive real numbers.\nŒ¥i\ni\n&lt; Œ¥i +Œ≥\n, so that action a is not dominated.\nWe assume that Œ±iŒ±+Œ≤\ni\ni\nTable 2.1. Consumer i0 s Decision Problem\nL\nR\nl Œ±i ‚àíŒ≤i\nr ‚àíŒ¥i Œ≥i\na 0\n0\nConsumer i is assumed to be a subjective expected utility (SEU) maximizer. Let\nher subjective prior belief over the possible states, {L, R}, be given by the vector\n(1 ‚àí œÄi , œÄi ), that is, she believes that state R obtains with probability œÄi .8 Let upi (d)\ndenote her expected utility when her belief over {L, R} is given by the vector of probabilities (1 ‚àí p, p) and she decides to take action d ‚àà {l, r, a}. Define dbi (p) as her\noptimal decision given her belief p, i.e., dbi (p) ‚â° arg maxd‚àà{l,r,a} upi (d). Ex ante, her\noptimal decision depends on her utility function and prior belief as follows:\nÔ£±\ni\nÔ£¥\n{l},\nœÄi ‚àà [0, Œ±iŒ±+Œ≤\n)\nÔ£¥\ni\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥{l, a}, œÄi = Œ±i\nÔ£¥\nÔ£¥\nÔ£≤\nŒ±i +Œ≤i\n\nŒ±i\nŒ¥i\nb\ndi (œÄi ) =\n{a},\nœÄi ‚àà Œ±i +Œ≤i , Œ¥i +Œ≥i .\nÔ£¥\nÔ£¥\nÔ£¥\nŒ¥i\nÔ£¥\nÔ£¥\n{a, r}, œÄi = Œ¥i +Œ≥\nÔ£¥\ni\nÔ£¥\nÔ£¥\nÔ£≥\nŒ¥i\n{r},\nœÄi ‚àà ( Œ¥i +Œ≥i , 1]\n8Note that the consumers are not forced to have heterogeneous priors. The subjective prior beliefs of\n\nall of the consumers may very well agree.\n7\n\nIn the rest of the paper, members of dbi (œÄi ) are referred to as consumer i‚Äôs ‚Äúdefault\nactions‚Äù.\nDifferent consumers can have different utility functions and beliefs, hence the dependence of (Œ±i , Œ≤i , Œ¥i , Œ≥i , œÄi ) on i. Consequently, they might have different default\nactions.\nFor example, imagine that two candidates are vying for a political office. The consumers at a positive utility cost can either vote for the left candidate (action l) or vote\nfor the right candidate (action r). Otherwise, she can choose to abstain (a). One of\nthe two candidates has higher valence than the other. The better candidate could be\nthe left one (state L) or the right one (state R). Consumer i always wants to vote for\nthe candidate with the higher valence.\nAlternatively, imagine that there is contention over the optimal strategy to prevent\na hostile foreign country from developing nuclear weapons. All consumers agree that\nif the foreign country‚Äôs nuclear program is still in its early stage (state L), sanctions\nare the most appropriate policy. However, if the nuclear program has passed a certain\npoint (state R), preemptive military actions are necessary. Consumer i can, again at\na cost, choose to advocate for either choice (actions l or r) or she can refrain from\nchoosing sides at all (action a).\nIn either case, if i is sufficiently certain that the true state is L (R), or, more precisely,\nŒ¥i\ni\nif œÄi &lt; Œ±iŒ±+Œ≤\n(respectively, if œÄi &gt; Œ¥i +Œ≥\n), her optimal choice is l (r). Otherwise, she is\ni\ni\nbetter off choosing a, which is both less costly and less risky than the other choices.\nNote that how certain consumer i needs to be to choose l or r depends on her utility\nfunction. Two consumers with the same belief might choose different actions because\nof their different preferences. For example, given the same belief about the candidates‚Äô\nvalence, one consumer might choose to vote for the left candidate and the other for\nthe right candidate because they each find their chosen candidates‚Äô personal traits\nmore likable. Alternatively, given the same belief about the success of the foreign\ncountry‚Äôs nuclear program, one consumer might support sanctions while the other\nsupports military action, because the former disapproves of the use of violence in\ngeneral and the latter is more lax about it.\nFor expositional convenience, the consumers with default action l, i.e. all i with\ndbi (œÄi ) = {l}, are referred to as ‚Äúliberals‚Äù, and those with default actions r and a are\nreferred to as ‚Äúconservatives‚Äù and ‚Äúmoderates‚Äù, respectively.9\n2.2. The News Reports.\n9Those consumers who are indifferent between two actions can be categorized into either group.\n\nIn\nthe following analysis, they will generally form a subset of measure zero. Consequently, their behavior\ndoes not affect our analysis.\n8\n\n2.2.1. Investigations and Signals. To produce a news report, the media outlets need\nto investigate into various matters pertaining to the unknown state. Conceptually, we\ncan think of this as the media outlets asking a number of questions, each with an ‚Äúyes‚Äù\nor ‚Äúno‚Äù answer, on behalf of their readers / viewers. Formally, these investigations can\nbe modeled as binary signals that send a message of ‚Äúleft‚Äù or ‚Äúright‚Äù in each state.\nWe recognize that investigations conducted by media outlets to ascertain the truth\nof an uncertain issue can in fact favor one side or the other. For example, when\ninvestigating the valence of a political candidate, the media outlets can elicit opinions\nfrom a supporter of the candidate or a member of the same political party. These people\nare more likely to endorse the candidate, and might even endorse him or her knowing\nthat he or she in fact has lower valence. Thus, opinions elicited from supporters or\nparty members are inherently biased towards their favored candidate.\nTo capture this idea, we assume that there are two types of binary signals the media\noutlets can acquire: signals that are biased to the left (in short, ‚Äúleft signal s‚Äù) and\nsignals that are biased to the right (‚Äúright signals‚Äù). As illustrated in Table 2.2, when\nthe true state is L, a left signal always identifies the state, correctly, as left. On the\nother hand, if the true state is R, a left signal only correctly identifies the state as right\nwith probability œÉL ‚àà (0, 1) and, with the remaining probability, the signal makes a\nmistake (or ‚Äúlies‚Äù) and identify the state as left. A right signal is defined symmetrically,\nand is characterized by some œÉR ‚àà (0, 1) (see Table 2.3).\nGiven her prior belief (1 ‚àí œÄi , œÄi ), consumer i expects a left signal to report ‚Äúleft‚Äù\nwith a probability strictly higher than 1 ‚àí œÄi , and, upon receiving a ‚Äúleft‚Äù report from\nthe signal, the consumer updates her belief to (1 ‚àí œÄ 0 , œÄ 0 ), where œÄ 0 &lt; œÄ. The opposite\nis true for a right signal. This is the sense in which the signals are biased: ex ante,\na left (right) signal is more likely to cause the consumer to have a stronger belief in\nstate L (respectively, R).10 In the previous example, the opinion from a supporter of\nthe left candidate amounts to a left signal, while the opinion from a supporter of the\nright candidate is a right signal.\nTable 2.2. A Left Signal\n‚Äúlef t‚Äù\n‚Äúright‚Äù\n\nL\nR\n1 1 ‚àí œÉL\n0\nœÉL\n\n10In precise terms, ‚Äúmore likely‚Äù here means ‚Äúwith higher probability than actuarially fair according\n\nto the consumer‚Äôs prior belief‚Äù.\n9\n\nTable 2.3. A Right Signal\nL\nR\n‚Äúlef t‚Äù\nœÉR\n0\n‚Äúright‚Äù 1 ‚àí œÉR 1\nHowever, bias does not have to result from misrepresentation of facts. It can equally\nbe due to the uneven type I and type II errors associated with the particular investigation. For example, when investigating the foreign nuclear program, the media outlets\ncan attempt to find out whether or not the foreign country has developed the capacity\nto enrich uranium, which must occur before the milestone of development, or they can\nattempt to find out if that country has already conducted nuclear tests, which occurs\nafter the critical stage. The former amounts to a right signal, since it will fail to recognize that the milestone has not been reached, if the foreign country has acquired\nthe capacity to enrich uranium. The latter, on the other hand, is equivalent to a left\nsignal.\nRealistically, even a left (right) signal may not be perfectly accurate in identifying\nthe left (right) state. There may very well be small chances that the signals can err in\ntheir favored states. Such small chances are ignored here in order to gain tractability.\nHowever, one needs not to be too concerned by this simplification. As it will become\nclearer below, the consumers‚Äô expected utilities are continuous in the conditional probabilities characterizing our signals. Thus, so long as the probability that left and right\nsignals misidentify their favored states is small, the predictions of consumers‚Äô behavior\nin our model remain good approximations.\n2.2.2. News Reports and News Consumption Bundles. Each media outlet can produce\none news report, which is based on the findings of the various investigations conducted.\nTracking all the possible combinations of findings from those investigations and compute the probabilities they each obtain is potentially a very tedious task. However,\nnote that a collection of left signals can be identified with a single (composite) left\nsignal.\nFor example, consider a collection of two left signals characterized by conditional\nprobabilities œÉL and œÉL0 , respectively. In state L, both signals are going to identify the\nstate as L. In state R, there are four distinct possible outcomes in which zero, one,\nor two of the signals identifies the state correctly as R. However, if any of the two\nleft signals identifies the state as R, we can conclude that the state must indeed be R.\nThus, for all intents and purposes, we can simply identify the two left signals with a\nsingle left signal characterized by conditional probability œÉL00 , which is the probability\n10\n\nthat any of the two original left signals correctly identifies the state in R. Note that\nœÉL00 &gt; max{œÉL , œÉL0 } as long as the two original signals are not perfectly correlated.\nSimilarly, any collection of left (right) signals can be identified with a single (composite)\nleft (right) signal.\nOn the other hand, a collection of signals of both types can be identified to a composite signal that sends a message mL (respectively, mR ) when any of the right (left)\nsignals reports ‚Äúleft‚Äù (‚Äúright‚Äù), and sends a message mN when all of the left signals\nreport ‚Äúleft‚Äù and all of the right signals report ‚Äúright‚Äù. Thus, a news report that reports\ntruthfully the findings from all the investigations conducted can be identified as a composite signal characterized by a pair of conditional probabilities (œÉL , œÉR ) ‚àà [0, 1]2 , where\nœÉL (respectively, œÉR ) is the probability that any left (right) signal correctly identifies\nthe state as R (L) (see Table 2.4).\nIf such a news report sends a message mL (mR ), consumer i knows that the true state\nmust be L (R). Thus, mL (mR ) can be interpreted as ‚Äúconclusive evidence‚Äù presented\nby the media outlet in support of state L (R). By contrast, message mN represents\n‚Äúinconclusive evidence‚Äù presented by the media outlet. There may be two types of\ninconclusive evidence: if either œÉL or œÉR equals to zero, the evidence is ‚Äúone-sided ‚Äù,\nwhile, if both œÉL and œÉR are positive, the evidence is ‚Äúconflicting‚Äù.\nTable 2.4. A News Report\nsL\nsN\nsR\n\nL\nR\nœÉR\n0\n1 ‚àí œÉR 1 ‚àí œÉL\n0\nœÉL\n\nNote that the media outlet is assumed to be reporting its findings truthfully here.\nIf, instead, the media outlet chooses to garble its signals, its news report is no longer\nequivalent to the composite signal presented in Table 2.4. However, as we shall see\nin our analysis below, we do not expect this to happen in equilibrium if the media\noutlets maximize their profits. This is because that, in equilibrium, where consumers\nhave rational expectations of the media outlets‚Äô strategies, garbling its signals can only\nreduce a media outlet‚Äôs profit and is therefore dominated by truthful reporting.\nFinally, as alluded to earlier, the consumers in our model have the freedom to consume news reports produced by multiple media outlets. For any set of media outlets\nJ ‚äÜ {1, 2, . . . , N }, a ‚Äúnews consumption bundle‚Äù consisting of the news reports produced (faithfully) by members of J is equivalent to the collection of all the left signals\nand all the right signals acquired by those media outlets and can be identified again with\n\na (richer) composite signal characterized by conditional probabilities œÉLJ , œÉRJ ‚àà [0, 1]2 ,\n11\n\n\nwhere œÉLJ , œÉRJ depend on the conditional probabilities characterizing each of the media outlet‚Äôs reports, which, in turn, depend on the amount of resources devoted by the\nmedia outlets to acquire their signals.\n2.2.3. News Production Technology. Each media outlet is endowed with q units of\nresources that can be spent on conducting investigations (i.e., acquiring signals). q\nis normalized so that it falls in (0, 1). A media outlet can allocate these resources\nbetween acquiring left signals and right signals. Specifically, media outlet j chooses a\n\n‚Äúreporting strategy‚Äù, characterized by a pair of non-negative real numbers qLj , qRj such\nthat qLj + qRj ‚â§ q, where qLj (respectively, qRj ) is the amount of resources allocated to\nacquiring left (right) signals.11\nSpending qLj and qRj on acquiring left and right signals gives media outlet j a compos\n\n\nite signal characterized by œÉLj , œÉRj = œÉ qLj , œÉ qRj . The function œÉ : [0, 1] ‚Üí [0, 1]\nspecifies the news production technology available to the media outlet. We assume\nthat œÉ is strictly increasing and that œÉ (0) = 0. The strict monotonicity of œÉ reflects\nthe idea that, as a media outlet spends more resources on collecting information, its\ninformation becomes better.12\nFor any subset of media outlets J, a news consumption bundle consisting reports\n\nfrom these outlets is characterized by œÉLJ , œÉRJ , where œÉbJ , b = L, R, should depend on\nthe statistical interdependence between all of the b-biased\nsignals contained in all of\n \nj\nJ\nthe news reports. We assume that œÉb = œÑJ œÉb j‚ààJ , where œÑJ : [0, 1]|J| ‚Üí [0, 1] is\n  \n\nQ\ndefined by œÑJ œÉbj j‚ààJ ‚â° 1 ‚àí j‚ààJ 1 ‚àí œÉbj . That is, the composite signals generated\nby the news reports are, in effect, statistically independent conditional on the state.13\nIn what follows, we refer to (q, 0) and (0, q) as ‚Äúextreme reporting strategies‚Äù and\nany other feasible (qL , qR ) as an ‚Äúinterior reporting strategy‚Äù. We shall from time to\n11The fact that media outlets only choose the allocation of resources to acquiring signals reflects our\n\nrestriction of attention to the undominated truthful reporting strategies.\n12For example, if the media outlet acquires more left signals, the probability that at least one of these\nsignals will correctly identify the state R increases as long as those signals are not perfectly correlated.\nNo additional restrictions on œÉ (e.g., on its curvature) is imposed. While it is reasonable to expect\nthat œÉL and œÉR should be concave in the number of signals the media outlet acquires, they need not\nto be concave in the amount of resources the media outlet spends. There may very well be significant\nscale economies in acquiring signals of the same type and the resulting œÉ may be linear or even convex.\n13This assumption is in fact more restrictive than what is needed for our results and is made for\nexpositional brevity only. However, we do need œÑJ to be strictly monotone and concave. As discussed\nearlier, the curvature of œÉ is not restricted. In particular, it can be convex. Thus, the fact that œÑJ is\nstrictly concave reflects the assumption that by pooling their resources, two media outlets can produce\na single news report that is more accurate than the news consumption bundle containing news reports\nproduced independently by these outlets. This could be due to repetitions in investigations conducted\nby the outlets.\n12\n\n\n\n\ntime abuse notation and write œÉ (qj ) for œÉ qLj , œÉ qRj\nand œÑ œÉ (qj ) , œÉ qk for\n\n\n\n\nœÑ œÉ qLj , œÉ qLk , œÑ œÉ qRj , œÉ qRk\n.\n\n2.2.4. Defining Bias. A media outlet is considered ‚Äúbiased to the left (right)‚Äù if it allocates more resources to acquiring left (right) signals. Formally, a news report (qL , qR )\nR\nis biased to the left (right) if œÅ ‚â° qLq+q\n&lt; 12 (&gt; 12 ), where | œÅ ‚àí 12 | measures the degree\nR\nof bias in the report.\nThus, media bias is created in the process of acquiring and synthesizing information.\nBy choosing different experts or institutions to consult, questions to ask, or matters\nto investigate, the media outlets can make their reports favor one state over the other.\nIn our previous example, a media outlet that only elicits opinions from a candidate‚Äôs\nsupporters is considered to be biased towards that candidate. On the other hand,\na media outlet that elicits opinions from supporters of both candidates is considered\nbalanced.\nOur definition of media bias is tailored to representing the kind of bias policies like\nthe Fairness Doctrine are intended to curtail. Moreover, it corresponds directly to the\nmeasures of media bias in the empirical literature adopted by scholars like Groseclose\nand Milyo (2005), who measure the bias of a media outlet by the relative frequencies\nthe latter quotes ‚Äúliberal think tanks‚Äù versus ‚Äúconservative ones‚Äù, and Gentzkow and\nShapiro (2010), who measure bias by the relative frequencies media outlets use phrases\nthat are more commonly used by Democrats versus those used by Republicans.14\nSimilarly, a news consumption bundle is said to be ‚Äúbiased to the left‚Äù or ‚Äúbiased to\nR\n&lt; 12 or œâ &gt; 12 respectively. | œâ ‚àí 21 | measures the degree of\nthe right‚Äù if œâ ‚â° œÉLœÉ+œÉ\nR\nbias in the news consumption bundle.\n\n2.3. The Value of Information to Consumers. The consumers are assumed to\nhave rational expectations about the media outlets‚Äô reporting strategies and update\ntheir beliefs according to Bayes‚Äô rule. Given consumer i‚Äôs prior belief, œÄi , and her\nnews consumption, œÉ ‚â° (œÉL , œÉR ), we can calculate i‚Äôs posterior belief upon receiving\nmessages mL , mR , and mN , respectively, as well as her prior belief for the likelihood\n\n14The correspondence to the Gentzkow and Shapiro (2010) measure might appear less obvious at first.\n\nHowever, if we recognize that phrases used by politicians are likely related to the issues they raise,\nthe questions they ask, and the arguments they make, all of which are presumably in favor of their\nown causes; then more frequent usage of the same phrases as a politician may well indicate that the\nmedia outlet takes the same stance as that politician on the underlying issues.\n13\n\nof receiving them. Abusing notation a little, these can be written as:\np (mL ) = (1 ‚àí œÄi ) œÉR\np (mR ) = œÄi œÉL\np (mN ) = 1 ‚àí œÄi œÉL ‚àí (1 ‚àí œÄi ) œÉR\np (R | mL ) = 0\np (R | mR ) = 1\np (R | mN ) =\n\nœÄi [1 ‚àí œÉL ]\n.\n1 ‚àí œÄi œÉL ‚àí (1 ‚àí œÄi ) œÉR\n\nNote that the bias in consumer i‚Äôs news consumption bundle determines how the report\naffects her posterior belief. After receiving conclusive evidence mL (mR ), the consumer\nknows that the state is L (R). However, her posterior belief, and hence optimal choice,\nupon receiving inconclusive evidence mN depends on œâ. For any œÄi ‚àà (0, 1), holding\nœÉL + œÉR constant, p (R | sN ) is strictly increasing in œâ, and p (R | sN ) &lt; œÄi (&gt; œÄi ) if\nand only if œâ &lt; 12 (&gt; 12 ).\nDefine u‚àói (p) ‚â° max{upi (l) , upi (r) , upi (a)}. Thus, u‚àói (p) is the maximum expected\nutility consumer i can achieve without additional information given her belief (1 ‚àí p, p).\nConsumer i‚Äôs ‚Äúdefault utility‚Äù is u‚àói (œÄi ). Having access to a bundle of news reports allows\nthe consumer to make her decision contingent on the message she receives. Thus, with\nconsumption bundle (œÉL , œÉR ), the maximum expected utility consumer i can achieve,\nex ante, becomes:\nUi‚àó (œÉL , œÉR , œÄi )\n‚â° p (mR ) u‚àói (p (R | mR )) + p (mL ) u‚àói (p (R | mL )) + p (mN ) u‚àói (p (R | mN ))\n= œÄi œÉL Œ≥i + (1 ‚àí œÄi ) œÉR Œ±i + [1 ‚àí œÄi œÉL ‚àí (1 ‚àí œÄi ) œÉR ] u‚àói (p (R | sN )) .\n\n(2.1)\n\nThe difference between Ui‚àó (œÉL , œÉR , œÄi ) and u‚àói (œÄi ) is the net gain in expected utility\nbrought by the news consumption bundle œÉ and, hence, is how much the news consumption bundle is valued to the consumer.\n\n14\n\nSince [1 ‚àí œÄi œÉL ‚àí (1 ‚àí œÄi ) œÉR ] is non-negative for all (œÉL , œÉR ) ‚àà [0, 1]2 , we can rewrite\n(2.1) as:\nUi‚àó (œÉL , œÉR , œÄi ) = max{œÄi œÉL Œ≥i + (1 ‚àí œÄi ) œÉR Œ±i\n+œÄi (1 ‚àí œÉL ) Œ±i + (1 ‚àí œÄi ) (1 ‚àí œÉR ) (‚àíŒ≤i ) ,\nœÄi œÉL Œ≥i + (1 ‚àí œÄi ) œÉR Œ±i\n+œÄi (1 ‚àí œÉL ) (‚àíŒ¥i ) + (1 ‚àí œÄi ) (1 ‚àí œÉR ) Œ≥i ,\nœÄi œÉL Œ≥i + (1 ‚àí œÄi ) œÉR Œ±i }.\nThe expressions in the brackets are the consumer‚Äôs expected utility if she commits\nto choosing l, r, and a, respectively, after receiving inconclusive evidence. Viewed as\nfunctions of (œÉL , œÉR ) or functions of œÄi , all of these expressions are linear. Thus, Ui‚àó is\nthe maximum of linear functions and is therefore convex in (œÉL , œÉR ) and in œÄi .\n3. Utility Maximizing News Reports\nWe are interested in the consumers‚Äô welfare in various market outcomes with or\nwithout government intervention. This comes down to understanding the consumers‚Äô\npreference over news consumption bundles. In this section, we ask the following question: fixing a media outlet‚Äôs resources and production technology, what is the most\nvaluable news report it can produce for an individual consumer, given the consumer‚Äôs\npreference and prior belief? Formally, let (Œ±, Œ≤, Œ¥, Œ≥) be any member of R4++ that satŒ±\nŒ¥\n&lt; Œ¥+Œ≥\n, we want to solve, for each q ‚àà (0, 1) and each œÄ ‚àà (0, 1), the following\nisfy Œ±+Œ≤\nproblem:\nmax(qL ,qR ) U ‚àó (œÉ (qL ) , œÉ (qR ) , œÄ)\ns.t.\n\n(3.1)\n\nqL , qR ‚â• 0\nqL + qR ‚â§ q,\n\nwhere the dependence of U ‚àó on the utility vector (Œ±, Œ≤, Œ¥, Œ≥) is suppressed in the notation.\nŒ±\nAs it turns out, if the consumer is a liberal or a conservative, i.e., if œÄ &lt; Œ±+Œ≤\nor\nŒ¥\nœÄ &gt; Œ¥+Œ≥\n, the solution to this problem is remarkably simple.\nProposition 1. The unique solution to problem (3.1) is q‚àó = (q, 0), if the consumer\nis a liberal, and is q‚àó = (0, q), if she is a conservative.\nThus, a liberal prefers her news report to be extremely biased towards the left, while\na conservative prefers her news report to be extremely biased to the right. These consumers‚Äô preference for biased news is rational and consistent with SEU maximization.\n15\n\nNote that, when œÉ is concave, acquiring more left (right) signals or producing such\nsignals with higher accuracy may lead to larger reductions in the number or accuracy\nof of right (left) signals that can be produced. That is, the extremely biased news\nreport may be significantly less informative than a more balanced one. Nevertheless,\nthe partisan consumers always prefer the former.\nTo understand the intuition behind Proposition 1, let us explore some properties of\nthe function U ‚àó . The following lemma establishes that U ‚àó is monotone in (œÉL , œÉR ).\nLemma 1. For any œÄ ‚àà (0, 1) and any œÉL , œÉL0 , œÉR , œÉR0 ‚àà [0, 1], such that œÉL &lt; œÉL0 and\nœÉR &lt; œÉR0 :\na) U ‚àó (œÉL , œÉR , œÄ) ‚â§ U ‚àó (œÉL0 , œÉR , œÄ) and U ‚àó (œÉL , œÉR , œÄ) ‚â§ U ‚àó (œÉL , œÉR0 , œÄ);\nb) U ‚àó (œÉL , œÉR , œÄ) &lt; U ‚àó (œÉL0 , œÉR0 , œÄ) ‚â§ U ‚àó (1, œÉR0 , œÄ) = U ‚àó (œÉL0 , 1, œÄ).\nA short algebraic proof of Lemma 1 is given in the appendix. However, note that,\nfor b = L, R, reducing œÉb can be viewed as randomly misreporting the realization of\nb-biased signals. Thus, Lemma 1 a) is essentially a special case of Blackwell‚Äôs (1951)\nwell-known theorem on comparing experiments. It re-iterates the well-known fact that,\nto an individual facing a non-strategic decision problem, more information is never a\nbad thing.\nLemma 1 b) implies that the marginal utility value of resources spent on collecting\none of the two types of information must always be strictly positive. Thus, it is\nnever optimal for the consumers if a media outlet underutilizes its resources, hence\nthe solution to (3.1), (qL‚àó , qR‚àó ), must satisfy qL‚àó + qR‚àó = q.\nThe next lemma identifies the conditions in which additional information of a particular kind is not valuable. If the consumer‚Äôs news consumption bundle is œÉ, let\npœÉœÄ (L | mN ) denote her posterior belief after she is presented with inconclusive evidence. Recall that db(p) is the consumer‚Äôs optimal choice(s) of action when her belief\nis given by p.\nLemma 2. For any œÄ ‚àà (0, 1) andany œÉL , œÉL0 , œÉR , œÉR0 ‚àà [0, 1]:\n\n\n(œÉ0 ,œÉR )\n(œÉ ,œÉ )\na) If db pœÄ L R (L | mN ) = db pœÄ L\n(L | mN ) = {r}, then U ‚àó (œÉL , œÉR , œÄ) =\nU ‚àó (œÉ 0 L , œÉ R , œÄ); and,\n\n\n\n\n(œÉL ,œÉR0 )\n(œÉL ,œÉR )\nb\nb\nb) If d pœÄ\n(L | mN ) = d pœÄ\n(L | mN ) = {l}, then U ‚àó (œÉL , œÉR , œÄ) =\nU ‚àó (œÉ L , œÉ 0 R , œÄ).\nLemma 2 says that if, upon receiving inconclusive evidence (mN ), the consumer‚Äôs\noptimal choice is l (r), then additional information (signals) biased to the right (left)\nadds no value to her unless it can persuade her to change action.\n16\n\nBecause the consumer is a Bayesian, a news report that directly sends her a message\nfrom the set {mL , mR , mN } is equivalent to two reports that inform her, in turn, about\nwhich message she can rule out. For example, telling the consumer mL is equivalent to\nfirst telling her not mR and then not mN . However, if her choice after receiving mN is\nl, then, after receiving the report ‚Äúnot mR ‚Äù, the consumer can just go ahead and choose\nl. This is simply Savage‚Äôs (1972) ‚ÄúSure-thing Principle‚Äù, which our SEU maximizing\nconsumer respects. Consequently, the second report is useless to her. Moreover, even\nif the second report is made more informative (i.e., œÉR increases), it still does not help\nthe consumer as long as it is not informative enough to persuade her to change her\nchoice after receiving mN .\n(œÉ ,œÉ )\nRecall that pœÄ L R (L | mN ) ‚â§ œÄ, if and only if œÉL ‚â• œÉR . Therefore, for a liberal,\nthere exists Œµ &gt; 0, such that any news report (œÉL , œÉR + Œµ) with œÉL ‚â• œÉR is as valuable to\nher as the extremely biased news report (œÉL , 0). The opposite is true for a conservative.\nOn the other hand, Lemma 1 and the strict monotonicity of œÉ imply that\nU ‚àó (œÉ (qL ) , œÉ (qR ) , œÄ) ‚â§ U ‚àó (œÉ (q) , œÉ (q) , œÄ)\nfor all interior reporting strategies (qL , qR ). Proposition 1 follows immediately.\nWe can also visualize Proposition 1 in Figure 3.1, which depicts the consumers‚Äô\nindifference curves. The set of feasible reporting strategies is the area bounded by\nthe black dotted curve that represents the production possibility frontier (PPF) of the\nmedia outlet. The PPF is determined by œÉ and q and can be concave, linear or convex,\nif œÉ is concave, linear or convex respectively.\nLemma 1 implies that there can be no ‚Äúthick‚Äù indifference curves and that indifference curves lying to the North-East represent higher values to the consumer. Lemma\n2 implies that, when the difference between œÉL and œÉR is sufficiently large, the indifference curves are either horizontal (œÉL &lt; œÉR ) or vertical (œÉL &gt; œÉR ). Moreover, the\nvertical part of a liberal‚Äôs indifference curves must cross the 45-degree line. So does\nthe horizontal part of a conservative‚Äôs indifference curves. Therefore, a liberal‚Äôs utility\nmust be maximized at the corner (œÉ (q) , 0), while a conservative‚Äôs utility is maximized\nat (0, œÉ (q)).\nHowever, note that Proposition 1 relies on our implicit assumption that the media\noutlet is equally efficient in acquiring information biased to the left and right, which\nimplies that the PPF is symmetrical about the 45-degree line. If, instead, we assume\nthat the media outlet is more efficient in acquiring information biased to the left,\nthen the PPF looks like the grey dotted curve in Figure 3.1. In that case, while a\nconservative still prefers an extremely biased news report, her utility maximizing news\nreport may very well be (q, 0).\n17\n\nFigure 3.1. Indifference Curves of Liberals and Conservatives\n\nThe argument for Proposition 1 given above does not apply to the moderates. Unlike\nthe case with liberals and conservatives, the horizontal and vertical parts of a moderate‚Äôs indifference curves do not cross the 45-degree line (See Figure 3.2). Therefore,\na moderate consumer‚Äôs utility may very well be maximized by an interior reporting\nstrategy. However, the next proposition shows that, if œÉ is convex, the solution to (3.1)\nis still at a corner. Thus, when increasing the accuracy of the left (right) signals does\nnot cost strictly more in terms of the accuracy of the right (left) signals, a moderate\nalso prefers her news report to be extremely biased.\nProposition 2. If œÉ : [0, 1] ‚Üí [0, 1] is convex, the solution to problem (3.1) is either\n(q, 0) or (0, q) for all consumers.\nProposition 2 follows from the fact that U ‚àó is convex in (œÉL , œÉR ) and that œÉ is strictly\nincreasing. If œÉ is also convex, U ‚àó is convex in (qL , qR ) and the solution to (3.1) must\nbe an extreme point of the set of feasible reporting strategies. Lemma 1 rules out the\nextreme point (0, 0). Proposition 2 can also be visualized in Figure 3.2.\n3.1. Discussion.\n18\n\nFigure 3.2. Indifference Curves of Moderates\n\n3.1.1. Contrasting Viewpoints. The conventional wisdom professes that, to make an\ninformed decision, one should consider arguments both for and against any particular\ncourse of action; and that truth will emerge from competition in the marketplace of\nideas. Such beliefs are behind industry regulations that obligate media outlets to\npresent diversified viewpoints on controversial affairs of public interest. However, our\nanalysis above suggests that the conventional wisdom may have been misapplied in\nthis case.\nWhile learning additional information that might challenge one‚Äôs current belief can\nnever hurt if such information is readily available, this is not necessarily true when\nsuch information can only be acquired at a cost and one has to trade off information\nfrom different sources. In order to present contrasting viewpoints, a media outlet has\nto acquire both information biased to the left and to the right. However, Lemma 2\nidentifies circumstances under which acquiring information biased in a particular direction adds no value to the consumer. By contrast, Lemma 1 guarantees that resources\ncan be better spent on acquiring information biased in the other direction. This is\ntrue regardless of the efficiency with which the media outlet can acquire information.\n19\n\nThus, the consumer prefers her evidence to be more one-sided, even if that evidence is\nless accurate in identifying the true state. Regulations restricting the degree of bias in\nnews reporting can therefore hurt the consumers.\nHowever, this is not to say that such regulations cannot be justified at all. As we\nshow in Section 5, content regulations like the Fairness Doctrine may serve the society\nas a whole by preventing political polarization and correcting distortions created by\nmisalignment between individual and societal interests.\n3.1.2. More Choices Available to Consumers. We can extend the model to include any\nfinite number of choices by the consumers. In this case, Proposition 2 goes through\nwithout any modification. That is, so long as œÉ is convex, the utility maximizing news\nreport for a consumer is always extremely biased, regardless of how many actions she\ncan choose from.\nIn the general model, the consumers can still be divided into groups according to\ntheir default actions. In particular, we can identify the ‚Äúmost liberal consumers‚Äù, whose\ndefault action is the ‚Äúmost liberal action‚Äù, that is, db(0). Similarly, the ‚Äúmost conservative consumers‚Äù are those with default action db(1). Lemma 2 and Proposition 1 still\nhold in the general model for the most liberal action and the most liberal consumers\nas well as the most conservative ones.\n\n4. The Industrial Organization of the Market for News\nIn this section, we analyze the industrial organization of the market for news and\nexamine how equilibrium demand and supply respond to changes in market conditions.\nWe then relate our results to empirical observations made by other researchers.\n4.1. The Consumers. Recall that there is a continuum of consumers with unit mass.\nEach consumer is described by a five-dimensional vector, (Œ±, Œ≤, Œ¥, Œ≥, œÄ) that specifies\nher utility function and prior belief. In the rest of the paper, we consider the aggregate\ndemand by these consumers for news reports offered by an array of media outlets. In\norder to keep track of the demand of all the consumers, we restrict attention to the\ncase in which all of the consumers share the same utility function as summarized in\nTable 4.1. Here, c ‚àà (0, 1) represents the cost associated with taking action l or r. For\nexpositional brevity, we shall identify a consumer with her prior belief.\nThe consumers may still differ in their prior beliefs and, hence, default optimal\n), a conservative has prior belief in\nactions. A liberal now has prior belief in [0, 1‚àíc\n2\n\n1+c\n1+c\n( 2 , 1], and a moderate‚Äôs prior belief falls in the interval 1‚àíc\n,\n. Let the distribution\n2\n2\n20\n\nTable 4.1. Consumers‚Äô Utility Function\nL\nR\nl 1 ‚àí c ‚àí1 ‚àí c\nr ‚àí1 ‚àí c 1 ‚àí c\na\n0\n0\nof the consumers‚Äô prior beliefs be summarized by the distribution function F , which\nhas a continuous density f and support [0, 1].15\n4.2. The Producers. The producers in the market for news are N ‚àà N profitmaximizing media outlets. The media outlets‚Äô profits, denoted Œ†j , for j = 1, 2, . . . N ,\nare assumed to be an increasing affine function of the measure of consumers they\nattract. Thus, maximizing expected profits is the same as maximizing expected readership / viewership. This assumption is common in the literature and is appropriate\nwhen the majority of the media outlets‚Äô profits come from advertising.\nRealistically, a media outlet‚Äôs advertising income should also depend on the demographic characteristics of its readers / viewers. In particular, advertisers might pay\ndifferent rates for consumers who only consume news from one media outlet from\nthose who consume news from multiple sources (Gentzkow, Shapiro, and Sinkinson (2012), Ambrus, Calvano, and Reisinger (2013)). As we show below, this\ncan be easily accommodated in our model by adjusting the weight on the measures of\ndifferent groups of consumers.\n4.3. The Market Demand for News. Recall that, the value of news consumption\nbundle œÉ ‚â° (œÉL , œÉR ) to the consumer is the difference between U ‚àó (œÉL , œÉR , œÄ) and u‚àó (œÄ).\nWe denote this value by V (œÉL , œÉR , œÄ). Define œÄ‚àó (œÉL , œÉR ) implicitly by pœÉœÄ‚àó (R | sN ) =\n1‚àíc\nand œÄ ‚àó (œÉL , œÉR ) by pœÉœÄ‚àó (R | sN ) = 1+c\n.16 U ‚àó (œÉL , œÉR , œÄ) and u‚àó (œÄ) are given by:\n2\n2\nÔ£±\nÔ£¥\nœÄ ‚àà [0, œÄ‚àó (œÉL , œÉR )]\nÔ£¥\nÔ£≤1 ‚àí 2œÄ ‚àí c + 2œÉL œÄ\nU ‚àó (œÉL , œÉR , œÄ) =\n[œÉL œÄ + œÉR (1 ‚àí œÄ)] (1 ‚àí c) œÄ ‚àà (œÄ‚àó (œÉL , œÉR ) , œÄ ‚àó (œÉL , œÉR )) ,\nÔ£¥\nÔ£¥\nÔ£≥\n2œÄ ‚àí 1 ‚àí c + 2œÉR (1 ‚àí œÄ) œÄ ‚àà [œÄ ‚àó (œÉL , œÉR ) , 1]\n15Some readers may be concerned by the assumed combination of homogeneous utility functions and\n\nheterogeneous priors. However, as demonstrated by the analysis so far, the behavior characteristics\nof the consumers and, in particular, their preferences for biased news reports, are not driven by\nany restrictions on their utilities or beliefs. Moreover, this is also only a choice of representation:\nthe consumers described above behave identically as a set of consumers with a common prior and\nheterogeneous utility functions. Detailed discussion is given in Appendix 7.3.\n16Thus, fixing a news consumption bundle œÉ, œÄ (œÉ , œÉ ) is the prior belief of a consumer who is\n‚àó\nL\nR\nindifferent between actions l and a after learning inconclusive evidence sN . Similarly, consumer\nœÄ ‚àó (œÉL , œÉR ) is indifferent between actions a and r after learning sN .\n21\n\nand\nu‚àó (œÄ) =\n\nÔ£±\n 1‚àíc \nÔ£¥\n1\n‚àí\n2œÄ\n‚àí\nc\nœÄ\n‚àà\n0, 2\nÔ£¥\nÔ£≤\n\n1‚àíc 1+c\n, 2\n2\n 1+c \nœÄ ‚àà 2 ,1\n\nœÄ‚àà\n\n0\n\nÔ£¥\nÔ£¥\nÔ£≥\n2œÄ ‚àí 1 ‚àí c\n\n\n\n.\n\nRecall that, œÄ‚àó &lt; 1‚àíc\nand œÄ ‚àó &lt; 1+c\n, if œÉL &lt; œÉR , while the opposite is true, if œÉL &gt; œÉR .\n2\n2\nThe consumers can acquire any number of news reports offered in the market at\na constant cost (in terms of money, time, effort and other resources) of Œ∫ &gt; 0 per\n\n‚â° Œ∫, where\nnews report.17 To avoid triviality, Œ∫ needs to satisfy Œ∫ &lt; V œÉ (q) , 0, 1‚àíc\n2\n\n\n1+c\n1‚àíc\nV œÉ (q) , 0, 2 = V 0, œÉ (q) , 2 is the highest possible value of a single news report\nto any consumer.\nThe consumers each choose a set of news reports that maximizes their expected\nutilities. We assume that when a consumer is indifferent between consuming a news\nreport or not, she always chooses to consume it.18 Moreover, when a consumer is\nindifferent between a number of news consumption bundles, she randomly chooses one\nof them and all news consumption bundles are chosen with equal probabilities.\nTo illustrate how market demand is determined, suppose there are two media outlets\noperating in the market, namely, media outlets j and k. They each offer a news report,\n\n\ncharacterized by qj = qLj , qRj and qk = qLk , qRk respectively. A consumer with\n \nprior belief œÄ values these reports at V (œÉ (qj ) , œÄ) and V œÉ qk , œÄ , and values the\n \nbundle of these two reports at V œÑ œÉ (qj ) , œÉ qk , œÄ . Without loss of generality, let\n \nV (œÉ (qj ) , œÄ) ‚â• V œÉ qk , œÄ . Thus the consumer will consume qj , if V (œÉ (qj ) , œÄ) ‚â•\n \nŒ∫. She will choose to consume both qj and qk if V œÑ œÉ (qj ) , œÉ qk , œÄ ‚â• 2Œ∫ and\n \nV œÑ œÉ (qj ) , œÉ qk , œÄ ‚àí V (œÉ (qj ) , œÄ) ‚â• Œ∫.\n4.4. Model Specialization. We have defined all of the necessary components of our\nformal model. However, this setup is quite general. While all of the qualitative results\nin the following sections are stated and proved within this general setting, sharper\ncharacterizations can be given if the model is further specialized. Thus, in addition\nto the general model, we consider a specialized model with the following additional\nassumptions.\n2c\nAssumption 1. c, q, and œÉ satisfy: œÉ (q) &gt; 1+c\n.\n17The assumption of a constant marginal consumption cost is made for convenience only.\n\nLetting\nthe marginal consumption cost depend on the number of news reports received does not qualitatively\nchange our results.\n18This implies that the sum of the media outlets‚Äô readership / viewership is upper semi-continuous in\ntheir reporting strategies.\n22\n\nAssumption 1 ensures that any moderate consumer can potentially be persuaded to\ntake a partisan action even when the evidence is not conclusive.\nAssumption 2. œÉ (x) ‚â° x\nThe following analyses focus on market forces that drive media bias, and not on the\nmedia outlets‚Äô considerations for production efficiency. Therefore, in the specialized\nmodel, œÉ is assumed to be linear. Since œÉ (0) = 0, letting the slope of œÉ be unity, i.e.,\nœÉ (x) ‚â° x, is without loss of generality.\nAssumption 3. F is given by the truncated normal distribution with mean ¬µ ‚àà\n 1‚àíc 1+c \n, 2 and variance œÉ 2 , i.e.,\n2\nÔ£Æ\nÔ£π\n(x‚àí¬µ)2\n1\n1\n‚àí\nÔ£ª\n2œÉ 2\n‚àö\nf (x) = Ô£∞ ¬¥\ne\n(y‚àí¬µ)2\n1\n‚àí\nœÉ 2œÄ\n‚àö1 e\n2œÉ 2 dy\n0 œÉ 2œÄ\n\nfor all x ‚àà [0, 1] and is equal to 0 otherwise.19\nWhile most of the results stated in the following sections only require the distribution\nF to be uni-modal, some of them do depend on its shape. Instead of imposing a number\nof conditions on F , we simply assume that it takes the form of a truncated normal\ndistribution.\n4.5. Monopoly. When there is only one media outlet in the market, the consumers\ncan consume at most one news report. Therefore, given the monopolist j‚Äôs reporting\nstrategy qj , consumer œÄ chooses to consume j‚Äôs news report if and only if V (œÉ (qj ) , œÄ) ‚â•\nŒ∫. Thus, j faces the following problem:\nÀÜ\n\nj\nj\nmax\nŒ†j qL , qR ; Œ∫\n= max\nf dœÄ\n(4.1)\nj j\nj j\nj\nqL\n,qR\nqL\n,qR {œÄ‚àà[0,1]|V (œÉ (qL\n),œÉ(qRj ),œÄ)‚â•Œ∫}\ns.t. qLj , qRj ‚â• 0\nqLj + qRj ‚â§ q.\n\n\nLemma 1 implies that, for any Œ∫ &gt; 0 and any qeLj , qeRj &gt;&gt; qLj , qRj , {œÄ ‚àà [0, 1] |\n\n\nV qLj , qRj , œÄ ‚â• Œ∫} ( {œÄ ‚àà [0, 1] | V qeLj , qeRj , œÄ ‚â• Œ∫}. Since F has full support on\n[0, 1], this implies that j can strictly increase its profit by increasing both qLj and qRj .\n\nTherefore, any solution to (4.1), qj‚àó ‚â° qLj‚àó , qRj‚àó , must satisfy: qLj‚àó + qRj‚àó = q.\nThe same holds for a duopolist, a triopolist, or, in general, any producer in the\nmarket. Since f is supported on [0, 1], there are always marginal consumers that\nare indifferent between distinct news reports or indifferent between consuming a news\n19œÄ in this expression is the familiar mathematical constant.\n\n23\n\nreport or not. Therefore, it is always suboptimal for a profit maximizing media outlet\nto underutilize its resources.20 Moreover, a media outlet has no incentive to garble its\nsignals, that is, mis-reporting the findings from its investigation. Blackwell‚Äôs (1951)\ntheorem implies that any garbling by the media outlet can only reduce the value of its\nnews report to all of the consumers and, consequently, leads to lower profits.\nj\nqL\nFixing qLj + qRj , changing the bias œÅj = qj +q\nj , makes a news report more valuable to\nL\nR\nsome consumers and less valuable to others. Thus, in general, the monopolist‚Äôs choice\nof bias in its report involves a tradeoff between one group of consumers and another.\nHowever, there are exceptions, as illustrated by the next lemma.\nLemma 3. There exists Œ∫‚àó ‚àà (0, Œ∫) such that, if Œ∫ ‚àà (Œ∫‚àó , Œ∫), then the monopolist‚Äôs\nproblem (4.1) has only extreme solutions (i.e., either (q, 0) or (0, q)).\nThat is, when the news consumption costs borne by the consumers are sufficiently\nhigh, the only profit maximizing reporting strategies of the monopolist are extremely\nbiased.\nWhen the monopolist increases the bias of its news report in a particular direction,\nthe consumers whose initial position lies opposite to that direction are alienated. However, when the cost of consuming news is high, these consumers would not consume the\nmonopolist‚Äôs news report even without the increase in bias. Therefore, the monopolist\nfaces no real tradeoff and is better off choosing an extreme position. However, the next\nobservation shows that, when the cost of consuming news is low, the opposite is true.\n\n\nLemma 4. For any interior qLj , qRj , there exists Œ∫\nb qLj , qRj &gt; 0 such that, if Œ∫ ‚àà\n\n\n0, Œ∫\nb qLj , qRj , Œ†j qLj , qRj is strictly higher than both Œ†j (q, 0) and Œ†j (0, q).\nThus, if the news consumption costs are sufficiently low, the extremely biased reporting strategies are suboptimal, and Problem (4.1) has only interior solutions.\nLemmas 3 and 4 lead to the following Proposition.\nProposition 3. The solution to the monopolist‚Äôs problem (4.1) exists for all Œ∫. Moreover, there exist Œ∫‚àó1 and Œ∫\nb1 in (0, Œ∫), such that, when Œ∫ ‚àà (Œ∫‚àó1 , Œ∫), the monopolist‚Äôs\nprofit maximizing reporting strategies must be extreme (i.e. (q, 0) or (0, q)), and, when\nŒ∫ ‚àà (0, Œ∫\nb1 ), the monopolist‚Äôs profit maximizing reporting strategies must be interior.\nCompared with a more balanced news report, an extremely biased news report provides strictly higher value to some consumers. On the other hand, Lemma 2 implies\n20Note that œÑ is a strictly increasing function, so the consumers‚Äô valuation of their second (third, etc)\n\nnews report is also increasing in the resources devoted by the media out.\n24\n\nthat an extremely biased news report provides no value to consumers with strong positions contrary to the direction of its bias, while a more balanced news report provides\npositive value to all consumers. When the consumption costs are high, only high value\nnews reports are consumed. Consequently, the monopolist is better off focusing on a\nsegment of the market and attracting as many consumers in that segment as possible.\nThis is achieved by producing an extremely biased news report. On the other hand,\nwhen the consumption costs are low, a monopolist can capture the whole market by\noffering a more balanced news report.\nWe can further characterize the monopolist‚Äôs optimal reporting strategy, by focusing\non the specialized model.\nProposition 4. Under Assumptions 1 to 3, the monopolist‚Äôs profit maximizing reporting strategies are biased to the left (right) if and only if ¬µ &lt; 12 (¬µ &gt; 12 ). Moreover,\nwhen Œ∫ &lt; Œ∫\nb1 , the monopolist‚Äôs profit maximization strategy is unique and it becomes\nless biased (i.e. | œÅj‚àó ‚àí 21 | decreases) as Œ∫ falls.\nIn the specialized model, when consumption costs are low, the monopolist‚Äôs problem\nessentially becomes a tradeoff between marginal liberal consumers and conservative\nones. This comes down to comparing the population density of the marginal consumers,\nj‚àó\nqL\nand hence the dependence of œÅ‚àó = qj‚àó +q\nj‚àó on ¬µ.\nL\n\nR\n\n4.6. Duopoly. Now suppose there are two media outlets, j and k. The oligopolistic\ncompetition amongst media outlets is modeled as a strategic game, in which the media outlets independently and simultaneously choose their reporting strategies. The\npayoff to a player is the profits it makes. In the following sections, we study the Nash\nEquilibria of this game.\nThe duopolists each offer a news report. Thus, the consumers can consume up to two\nnews reports at a cost of Œ∫ per report. Fixing the reporting strategy of its competitor,\nk, and that of itself, the consumers attracted to media outlet j can be broken down to\ntwo groups. One group of the consumers have a unique optimal consumption bundle\nthat includes j‚Äôs news report. The other group of consumers have multiple optimal\nconsumption bundles, and j‚Äôs news report is included in some of them. The first group\nof consumers, denoted by Aj ‚äÜ [0, 1], choose to consume j‚Äôs report with probability one.\nOn the other hand, the second group of consumers randomly choose from their optimal\nconsumption bundles, and thus may only choose to consume j‚Äôs report with positive\nm\nprobability. Let AjM denote the set of consumers who have M optimal consumption\nbundles, m of which include j‚Äôs report.\n25\n\nIn a duopoly, j‚Äôs profit can be written as:\nÀÜ\nÀÜ\n\n1\nj\nk\nf dœÄ.\nŒ†j q ; q , Œ∫ =\nf dœÄ +\n2 Aj12\nAj\nThe duopolists‚Äô game and, more generally, any oligopolists‚Äô game are not continuous,\nthat is, the media outlets‚Äô payoffs are not continuous in their strategies, and pure\nstrategy Nash equilibria do not exist in general. However, as the next proposition\nshows, there always exists at least one Nash equilibrium in mixed strategies. In fact,\nthere exists at least one symmetric equilibrium. Moreover, the mixed strategy equilibria\nhave to satisfy certain properties:\nProposition 5. The duopolists‚Äô game has at least one symmetric Nash equilibrium\n(in mixed strategies) for any Œ∫ ‚àà (0, Œ∫). Moreover, there exist Œ∫‚àó2 and Œ∫\nb2 in (0, Œ∫),\n‚àó\nsuch that, if Œ∫ ‚àà (Œ∫2 , Œ∫), only (q, 0) and (0, q) can be in the support of any equilibrium\nstrategy, while, if Œ∫ ‚àà (0, Œ∫\nb2 ), then, in any equilibrium, the probability that some interior\nreporting strategy is chosen must be strictly positive.\nThat is, when the news consumption costs are sufficiently high, only extremely biased news reports are produced with positive probability. However, when the news\nconsumption costs are sufficiently low, more balanced news reports are produced with\npositive probability. Thus, similar to the monopolist‚Äôs case, as the costs of consuming news fall, the news reports offered in equilibrium become more balanced, albeit in\na probabilistic sense.21 Note that, when news consumption costs are low, all media\noutlets choose interior reporting strategies with positive probability in the symmetric\nequilibrium.\nThe logic behind Proposition 5 is also similar to the logic behind the monopolist‚Äôs\nproblem. Even though the consumers have the freedom to choose two news reports,\nwhen consumption costs are high, doing so is not economical. Thus, an oligopolist‚Äôs\nproblem is similar to that of a monopolist when consumption costs are high. Thus, its\noptimal strategy is to focus on a segment of the market.\nOn the other hand, when the consumption costs are low, then it is possible for some\nconsumers to consume two news reports. However, just like before, an extremely biased\nnews report is not valuable to consumers with strong positions opposite to the direction\nof the report‚Äôs bias even as a second choice. On the other hand, like in the monopolist‚Äôs\ncase, any media outlet can serve the whole market with a more balanced news report.\nConsequently, the media outlets have incentives to reduce biases in their news reports.\nWith the specialized model, we can further characterize the equilibria of this game.\n21Note that, in general, Œ∫\ne\n\ne2 and Œ∫\nb1 6= Œ∫\nb2 .\n1 6= Œ∫\n26\n\nProposition 6. Under Assumptions 1 to 3, there exists Œ∫Ãå2 ‚àà (0, Œ∫‚àó2 ], such that, when\n¬µ = 21 and Œ∫ ‚àà (0, Œ∫Ãå2 ), the game has a symmetric Pure Strategy Nash Equilibrium\n\n\n(PSNE) at 2q , 2q , 2q , 2q . Moreover, if | ¬µ ‚àí 21 | is sufficiently small, then there is a\nPSNE ((x‚àó q, (1 ‚àí x‚àó ) q) , (x‚àó q, (1 ‚àí x‚àó ) q)), where x‚àó ‚àà [0, 1] and x‚àó ‚âà 12 .\nThus, in the specialized model with enough symmetry and low consumption costs,\nthe duopolists each choose a (almost) perfectly balanced news report with probability\none in equilibrium.\nNote that, the consumers‚Äô ability to choose any number of news reports is essential\nfor these results. The reason a media outlet offers a less biased news report, when\nnews consumption costs are low, is to attract consumers initially located at the other\nend of the ideological spectrum, who might consume the less biased report as a second\nnews source. For that reason, Propositions 5 and 6 may not hold if the consumers are\nrestricted to consuming only one news report, as illustrated by the next example.\nExample 1. In addition to Assumptions 1 and 3, assume that the consumers are\nrestricted to consuming no more than one news report. Then, for any Œ∫ &gt; 0, only\n(q, 0) and (0, q) can be chosen with positive probability in any equilibrium.\n4.7. Multiple Competitors. When there are N &gt; 2 media outlets competing in the\nmarket, results analogous to Propositions 5 and 6 still hold. That is, fixing the number\nof media outlets operating in the market, when news consumption costs are sufficiently\nhigh, we can only expect to see extremely biased news reports in equilibrium. As the\nconsumption costs fall, extreme reporting strategies become less profitable to media\noutlets compared to more balanced ones. Indeed, in some cases, all media outlets end\nup offering perfectly balanced news reports with probability one.\nThe next result shows that, for any level of consumption costs, increase in competition eventually makes the extreme reporting strategies profitable. Thus, the trend\nof decreasing biases brought about by falling consumption costs can be reversed by\nintensifying competition.\ne (Œ∫), such that,\nProposition 7. For each Œ∫ ‚àà (0, Œ∫), there exists a positive integer N\ne (Œ∫) media outlets and news consumption\nin any equilibrium of the game with N &gt; N\ncost Œ∫, (q, 0) must be chosen with positive probability, and so is (0, q).\nWith low consumption costs, the reason that a media outlet produces a less biased\nnews report in equilibrium is so that it can attract more consumers from the other\nend of the ideological spectrum. However, this becomes difficult when there are more\nmedia outlets producing news with biases that are preferred by those consumers. On\nthe other hand, by reducing the bias in its news report, a media outlet risks losing\n27\n\nconsumers who favor such biases, when there are other media outlets targeting those\nconsumers and are willing to produce news with more bias. Consequently, increasing\nbiases eventually becomes more profitable to the media outlets.\n4.8. Empirical Implications. As argued above, when news consumption costs are\nlow, there must be (symmetric) Nash equilibria in which all media outlets choose interior reporting strategies with positive probability. In particular, we may observe\noutcomes in which news reports are produced with biases across the ideological spectrum. The next example illustrates such a scenario.\nExample 2. Let œÉ (x) ‚â° x and let F be uniform over [0, 1]. Consider a market with\nthree media outlets. Suppose that Œ∫ is sufficiently low and the following strategy profile\nis in the support of the equilibrium strategies: ((xq, (1 ‚àí x) q) , (yq, (1 ‚àí y) q) , ((1 ‚àí x) q, xq)),\nwhere 0 &lt; x &lt; y &lt; 1‚àíx. When Œ∫ is sufficiently low, all three media outlets can attract\nconsumers from\nall three ideological groups.\nh\ni Specifically, all consumers whose prior beŒ∫\nŒ∫\nlief falls in 2xq , 1 ‚àí 2(1‚àíxq)[1‚àí(1‚àíy)q](1‚àíx)q consume the news report (xq, (1 ‚àí x) q), all\ni\nh\nŒ∫\nŒ∫\n, 1 ‚àí 2(1‚àíxq)(1‚àíy)q\nconsume the news report (yq, (1 ‚àí y) q), and all\nconsumers 2(1‚àíxq)yq\ni\nh\nŒ∫\nŒ∫\nconsume the report ((1 ‚àí x) q, xq).\nconsumers 2(1‚àíxq)(1‚àíyq)(1‚àíx)q\n, 1 ‚àí 2xq\n\n\nŒ∫\nIn this example, the media outlet most biased to the left attracts 1‚àíc\n‚àí\nliberals\n2\n2xq\n\n\nŒ∫\nconservatives. Similarly, the most right-biased media\nand 1‚àíc\n‚àí 2(1‚àíxq)[1‚àí(1‚àíy)q](1‚àíx)q\n2\n\n\n\n\n1‚àíc\n1‚àíc\nŒ∫\nŒ∫\noutlet attracts 2 ‚àí 2(1‚àíxq)(1‚àíyq)(1‚àíx)q liberals and 2 ‚àí 2xq conservatives. The\n\n\n\n\nŒ∫\n1‚àíc\nŒ∫\nmost balanced news report attracts 1‚àíc\n‚àí\nliberals\nand\n‚àí\n2\n2(1‚àíxq)yq\n2\n2(1‚àíxq)(1‚àíy)q\nconservatives. Thus, the ratio of liberals to conservative consumers decreases as the\nR\nmedia outlet‚Äôs bias œÅ = qLq+q\nincreases. The average ideological position of a media\nR\noutlet‚Äôs consumers is correlated with the bias in its news report. This matches the\nfindings by the Pew Research Center for the People and the Press (2012) in a recent\nsurvey of news consumption patterns (see Figure 4.1).\nMoreover, there are overlaps between the\nouth readership / viewership of the media\ni\nŒ∫\nŒ∫\nlets. The consumers with prior beliefs in 2(1‚àíxq)yq , 1 ‚àí 2(1‚àíxq)[1‚àí(1‚àíy)q](1‚àíx)q consume\nboth the most\nleft biased news report and the\nh\ni most balanced news report. The conŒ∫\nŒ∫\nsumers in 2(1‚àíxq)(1‚àíyq)(1‚àíx)q , 1 ‚àí 2(1‚àíxq)(1‚àíy)q consume both the balanced report and\nthe most right biased\nreport. The two media outlets with strong\nopposite biases share\nh\ni\nŒ∫\nŒ∫\nthe consumers in 2(1‚àíxq)(1‚àíyq)(1‚àíx)q , 1 ‚àí 2(1‚àíxq)[1‚àí(1‚àíy)q](1‚àíx)q . Thus, the media outlets\nwith similar biases share larger overlapping readership / viewership. This pattern of\noverlapping readership / viewership is consistent with the findings by a Nielson survey\n28\n\nFigure 4.1. Pew Research Center Survey on Audience Ideology\n\nconducted on behalf of Pew Research Center (Mitchell, Jurkowitz, Enda, and Olmstead (2013)), which shows a similar pattern of cross viewership between cable news\nprograms in the U.S. market (See Figure 4.2).\nHamilton (2006) documents historical changes of media bias in the U.S. market for\nnews. There was first a trend of decreasing media bias occurred in the late 19th century.\nBefore then, most U.S. newspapers are openly affiliated with political parties. However,\nsince the 1870s, ‚Äúnonpartisan reporting emerged as a commercial product.‚Äù 22 Gentzkow,\nGlaeser, and Goldin (2006) provided a similar account for this change. According to\nthem, in 1870, only 11 percent of all political newspapers claimed to be independent.\n22Hamilton (2006) P. 3\n\n29\n\nFigure 4.2. Nielson Survey on Cross-Viewership\n\nBy 1920, this number had risen to 62 percent. An opposite trend occurred since the\n1990s, when ‚Äúelements of partisanship reemerged in television.‚Äù 23\nBoth of these historical trends can be explained by the present model. As noted\nby Hamilton (2006), the first trend of decreasing media bias corresponded with the\ninvention of rotary printing press. Mass printing and other technological innovation\ndrastically reduced the cost of newspapers to the consumers. Thus, as predicted by\nProposition 5 and 6, the papers had the incentive to reduce bias in their reporting in\norder to capture a larger share of the market.\nWhile news consumption costs did not rise in the 1990s, new technologies such as\ncable and satellite provided consumers with easy access to a wider range of programs.\nThus, as predicted by Proposition 7, increase in competition among media outlets gave\nthem incentives to bias their news reports. The late 1990s saw the establishment of the\nFox News Channel and MSNBC, which over the years have established strong branding\nas conservative and progressive news stations. Moreover, it has been argued that ‚Äúthe\nrise of the conservative Fox News Channel caused CNN to shift to the left. ‚Äù 24 Chiang\n23Hamilton (2006) P.3\n24Posner (2005)\n\n30\n\n(2010) provides further evidence that competition induces media outlets to increase\ntheir bias.\n4.9. The Merits of Fairness. Content regulations such as the FCC‚Äôs Fairness Doctrine and the Ofcom‚Äôs Due Impartiality rules can be modeled in our framework as\nconstraints on the degree of bias with which the media outlets can produce their\n \nnews reports. Formally, such regulations can be represented by a number b ‚àà 0, 12\nsuch that all media outlets can only choose reporting strategies (qL , qR ) that satisfy\nL\n| qLq+q\n‚àí 12 |‚â§ b. Such regulations are said to be binding, if, without these conR\nstraints, the media outlets‚Äô equilibrium strategies assign positive probabilities to reporting strategies that violate these constraints. The next proposition shows that such\nregulations, if binding, will always make some consumers worse off. Moreover, there\nare conditions under which they can make all consumers worse off.\nProposition 8. Content regulations, if binding, can never result in Pareto improvements but can result in Pareto dominated outcomes.\nThus, contrary to widely held beliefs, content regulations like the Fairness Doctrine\nare poorly justified on the ground of protecting consumer welfare. However, as we\nshow in the next section, they may help to mitigate other potentially harmful social\nconsequences of media bias, such as political polarization.\n5. Political Polarization\nThe consumers‚Äô preferences for the biases in their news consumption are not continuous, that is, two consumers with very similar utility functions and prior beliefs may\nprefer their news consumption to contain very different biases. On the other hand,\nhaving received news reports containing different biases, the posterior beliefs of two\nalmost identical consumers may end up being quite far apart. Thus, as we show in\nthe following example, media bias can cause political polarization, which is defined\nbehaviorally as consumers choosing more extreme actions in opposite directions.\nSuppose there are two media outlets operating in the market, and the market conditions are such that in equilibrium, all consumers consume at most one news report\nand the two media outlets offer news reports that are extremely biased in opposite\ndirections, i.e., (q, 0) and (0, q).25 Moreover, suppose that Assumptions 1 and 2 hold.\nThus, all consumers with prior beliefs smaller than 21 strictly prefer the news report\n(q, 0), while the report (0, q) is strictly preferred by consumers with prior beliefs greater\nthan 21 .26\n25By virtue of Proposition 5, such an equilibrium exists when Œ∫ is sufficiently high.\n26These assumptions are not essential for this analysis but are made for expositional brevity.\n\n31\n\nConsider two moderates with prior beliefs œÄ 0 and œÄ 00 respectively, where œÄ 0 &lt; 21 &lt; œÄ 00 .\nFurther, let œÄ 0 and œÄ 00 be such that the two moderates each consume one news report.27 The two media outlets are expected to both report message œÉN with probability 1 ‚àí œÉ (q). In that event, consumers œÄ 0 and œÄ 00 learn the inconclusive evidence\n(œÉ(q),0)\npresented by their news reports of choice and update their beliefs to pœÄ0\n(R | sN )\n(0,œÉ(q))\nand pœÄ00\n(R | sN ) respectively. By virtue of Assumption 1, both moderates abandon\ntheir default action after seeing the evidence. However, while consumer œÄ 0 chooses\naction l, consumer œÄ 00 goes in the other direction and chooses action r.\nThus, media bias leads to political polarization. Given the choice, both moderate consumers consume a biased news report. However, due to the difference in the\nconsumers‚Äô prior beliefs, the biases in their chosen news reports are in the opposite\ndirections. This difference in their beliefs is not significant enough for the consumers\nto choose different actions without additional information. However, in some event, the\nconsumers learn inconclusive evidence that point to opposite directions. As a result,\nthe two moderates end up choosing opposite partisan actions.\nThe two consumers in this example each represent a positive measure of other moderates whose choices agree with theirs. Thus, in the absence of conclusive evidence,\nthere can be a significant reduction in the population of moderate consumers, while\nthe populations of both partisan groups increase.\nThe extent of political polarization depends on the level of news consumption costs\nand the degree of competition. In the previous example, when Œ∫ is high, the news\nreports produced are extremely biased. However, polarization is not severe, since very\nfew consumers consume any news. As Œ∫ falls, the news reports remain extremely biased,\nand more moderates choose to consume one of the two news reports. Consequently,\npolarization becomes more severe, that is, in the event that no conclusive evidence is\nfound, more moderates become partisans. However, as Œ∫ continues to fall, some moderates find it worthwhile to consume both news reports, which gives them a perfectly\nbalanced news consumption bundle. When presented with inconclusive evidence, these\nconsumers do not change their action, since the evidence in the news reports balance\nout. Thus, polarization is mitigated. It is further mitigated if Œ∫ falls even more, as the\nmedia outlets produce more balanced news in response.\nOn the other hand, when news consumption costs are low such that political polarization is not severe to begin with, it can be exacerbated by increase in competition. As\nmore media outlets enter the market, the news reported in equilibrium becomes more\nbiased again. Moreover, the moderates that used to consume two news reports with\n27Such œÄ 0 and œÄ 00 exist for any Œ∫ &lt; Œ∫.\n\n32\n\nopposite biases end up consuming news reports biased in the same direction. Thus,\npolarization becomes more severe again. However, with more media outlets acquiring\ninformation, the probability that conclusive evidence is produced increases. So does\nconsumer surplus.\n5.1. Political Polarization and Social Inefficiency. The reason why a consumer\nprefers her news to be biased is because that, in the absence of any conclusive evidence,\nevidence that is more one-sided can make her more certain of what the true state is.\nIndeed, such evidence can be strong enough to convince her to take a more extreme\naction. However, her decision to change action may not be justifiable if all the social\ncosts associated with her action are taken into account. Higher social costs means that\nstronger evidence is needed to justify the consumer‚Äôs new action. In other words, the\nconsumer‚Äôs choice in light of the evidence presented by her choice of news consumption\nmay be premature from the society‚Äôs perspective.\nLet us consider a simple scenario where, in addition to costing c to the consumers,\nthe partisan actions l and r also impose an externality on the society, which makes\nthe social cost of these actions equal to c0 &gt; c. As illustrated in the previous example,\nmedia bias can lead to political polarization. The two moderates in the earlier example\nend up choosing partisan actions after learning inconclusive evidence presented by their\nnews reports.\n0\n&lt;\nConsider consumer œÄ 0 . Suppose that the externalities are significant so that 1‚àíc\n2\n(œÉ(q),0)\n1‚àíc\n0\npœÄ 0\n(R | sN ) &lt; 2 . Thus, if consumer œÄ takes into account the costs her action\nimposes on the society, she would not change her action after learning sN . In the\nabsence of any means to ensure that the consumer internalize all the social costs, she\nends up choosing l, and expected social welfare is brought down.\n5.2. Mitigating Political Polarization. Now suppose a content regulation, b, is imposed. For expositional convenience, let b = 0. Then, the only reporting strategies the\n\n\nmedia outlets can choose is 2q , 2q . The inconclusive evidence reported by 2q , 2q is not\nstrong enough to persuade the consumer to change her action, so political polarization\nis mitigated. Moreover, it is easy to verify that, the ex ante expected social welfare\n\nis higher when consumer œÄ 0 chooses news report 2q , 2q instead of (q, 0), as long as\n(œÉ(q),0)\n1‚àíc0\n&lt; pœÄ0\n(R | sN ) &lt; 1‚àíc\n. Therefore, the content regulation helps to correct the\n2\n2\ndistortions caused by the externalities.\nHowever, the effectiveness of such regulations in mitigating political polarization depends crucially on market conditions. In fact, there are circumstances under which\ncontent regulations can exacerbate political polarization, rather than mitigate it. Suppose that, in the previous example, the consumption costs are lower so that some\n33\n\nmoderates choose to consume both news reports. However, suppose that the media\noutlets still produce extremely biased news.28 Now suppose that a content regulation,\ncharacterized by 0 &lt; b &lt; 12 , is introduced and is binding in equilibrium.29\nAfter the media outlets reduce their bias to satisfy the regulations, the moderate\nconsumers who were close to being indifferent between consuming one and two news\nreports before the regulation is introduced end up consuming only one news report.\nComparing with their initial consumption bundle, which was completely balanced, the\nnews report they consume now is more biased. Consequently, in addition to reducing\nconsumer surplus, the content regulation can also aggravate polarization, because some\nof those moderates that end up consuming more biased news might end up choosing a\npartisan action in the absence of conclusive evidence.30\n\n6. Conclusion\nWe present a theory of media bias where preference for biased news is consistent\nwith Bayesian rationality. To an individual consumer, consuming biased news may be\na more efficient means to acquire information than consuming more balanced news.\nConsequently, profit maximizing media outlets have the incentive to bias their news\nreports in order to attract more consumers.\nOur model offers theoretical explanations for a number of empirical findings pertaining to consumer and supplier behaviors in the news market uncovered in recent\nstudies. We find that falling costs of consuming news encourages the media outlets to\noffer more balanced news in equilibrium, while the opposite happens when competition\nheightens. The biases in the news reports are correlated with the prior positions of the\nconsumers they attract. The consumer bases of different media outlets may overlap,\nand the overlap is larger if the biases in their news reports are closer.\nMoreover, this new formal framework sheds some light on the social impact of media\nbias and the regulations designed to curtail it. We show that media bias may lead\nto political polarization, which can be socially inefficient when there are externalities.\nContent regulations such as the FCC‚Äôs Fairness Doctrine can help to mitigate polarization and correct distortions. However, the severity of political polarization and the\n28In general, without strong efficiency gains, to make the media outlets choose an interior strategy, the\n\nconsumption costs need to be sufficiently low so that balanced reports can potentially attract sizable\npopulations of partisan consumers.\n29Otherwise, it would be unnecessary to introduce this regulation.\n30Because the consumers‚Äô posterior beliefs p(œÉL ,œÉR ) (s ) and their valuation of information\nœÄ\nN\n\nV (œÉL , œÉR , œÄ) are both continuous, the set of parameters œÉ (q) , Œ∫, b that can give rise to such scenarios\nis non-empty.\n34\n\neffectiveness of content regulations both depend critically on market conditions. Under some circumstances, content regulations might exacerbate polarization rather than\nmitigate it.\nOur model can be extended in a number of directions. As discussed in Section 3, an\nimplicit assumption we make is that the media outlets are equally efficient in acquiring\ninformation biased to both directions. If, instead, the media outlets are more efficient\nin producing news reports biased to the left, then even a conservative might prefer left\nbiased news reports to right biased ones.\nMany scholars as well as political commentators have argued that the American\npublic media is biased to the left (e.g., Goldberg (2002), Groseclose and Milyo (2005),\nand Groseclose (2011)). One explanation they give for why a liberal bias exists is that\nthe members of the media elite themselves have liberal views that, in turn, make them\nmore open to liberal arguments. As a consequence, they are more efficient in acquiring\ninformation biased to the left.\nFor example, Groseclose and Milyo (2005) quote the following from Sutter (2001):\nIf the majority of journalists have left-of-center views, liberal news might\ncost less to supply than unbiased news.31\nArguments like these are supported by our model. If the media outlets‚Äô production\ntechnology is sufficiently asymmetrical, both liberals and conservatives prefer news\nreports biased to the left. Consequently, the media outlets produce mostly left biased\nnews in the equilibrium.\nHowever, if the liberal bias results from taking advantage of more efficient production\ntechnology, then such biases are beneficial to all consumers, including the conservatives.\nThe conservatives would be better off if the media outlets could produce right biased\nnews more efficiently. However, when this is not feasible, consuming left biased news\nis optimal for them.\nWe can also let consumers‚Äô well-being depend on each other‚Äôs actions (as in an election). Then a consumer‚Äôs choice of news consumption imposes an externality on others\nthrough her expected choice of action. Consequently, an individual consumer might\nprefer regulations that affect the variety of news reports other consumers can consume.\nGiven the heterogeneity among the consumers, their preferred policy interventions are\nalso going to differ.\n\n31\n\nSutter (2001) P. 444. Quoted by Groseclose and Milyo (2005) P. 1227\n35\n\nReferences\nAlterman, E. (2003): What Liberal Media? : The Truth about Bias and the News.\nBasic Books, New York, paperback edition edn.\nAmbrus, A., E. Calvano, and M. Reisinger (2013): ‚ÄúEither or Both Competition:\nA "Two-sided" Theory of Advertising with Overlapping Viewerships,‚Äù .\nAnderson, S. P., and J. McLaren (2012): ‚ÄúMedia Mergers and Media Bias with\nRational Consumers,‚Äù Journal of the European Economic Association, 10(4), 831‚Äì\n859.\nBaron, D. P. (2006): ‚ÄúPersistent Media Bias,‚Äù Journal of Public Economics, pp. 1‚Äì36.\nBernhardt, D., S. Krasa, and M. Polborn (2008): ‚ÄúPolitical Polarization and\nthe Electoral Effects of Media Bias,‚Äù Jounal of Public Economics, 92, 1092‚Äì1104.\nBesley, T., and A. Prat (2006): ‚ÄúHandcuffs for the Grabbing Hand? Media Capture\nand Government Accountability,‚Äù American Economic Review, 96(3), 720‚Äì736.\nBlackwell, D. (1951): ‚ÄúComparison of Experiments,‚Äù in Proceedings of the Second\nBerkeley Symposium on Mathematical Statistics and Probability, pp. 93‚Äì102. University of California Press.\nBrock, D., A. Rabin-Havt, and Media Matters for America (2012): The\nFox Effect: How Roger Ailes Turned a Network into a Propaganda Machine. Anchor\nBooks.\nCalvert, R. L. (1985): ‚ÄúThe Value of Biased Information: A Rational Choice Model\nof Political Advice,‚Äù Journal of Politics, 47, 530‚Äì55.\nChan, J., and W. Suen (2008): ‚ÄúA Spatial Theory of News Consumption and Electoral Competition,‚Äù The Review of Economic Studies, 75, 699‚Äì728.\nChiang, C.-F. (2010): ‚ÄúPolitical Differentiation in Newspaper Markets,‚Äù .\nChiang, C.-F., and B. Knight (2011): ‚ÄúMedia Bias and Influence: Evidence from\nNewspaper Endorsements,‚Äù The Review of Economic Studies, 78, 795‚Äì820.\nCoulter, A. (2003): Slander: Liberal Lies about the American Right. Three Rivers\nPress, 1 st edition edn.\nDellaVigna, S., and E. Kaplan (2007): ‚ÄúThe Fox News Effect: Media Bias and\nVoting,‚Äù Quarterly Journal of Economics, pp. 1187‚Äì1234.\nDuggan, J., and C. Martinelli (2011): ‚ÄúA Spatial Theory of Media Slant and\nVoter Choice,‚Äù The Review of Economic Studies, 78(2), 640‚Äì666.\nGentzkow, M. A., E. L. Glaeser, and C. Goldin (2006): ‚ÄúThe Rise of the Fourth\nEstate: How Newspapers Became Informative and Why It Mattered,‚Äù in Corruption\nand Reform: Lessons from America‚Äôs Economic History, ed. by E. L. Glaeser, and\nC. Goldin. University of Chicago Press.\n36\n\nGentzkow, M. A., and J. M. Shapiro (2004): ‚ÄúMedia, Education and AntiAmericanism in the Muslim World,‚Äù Journal of Economic Perspectives, 18(3), 117‚Äì\n133.\n(2006): ‚ÄúMedia Bias and Reputation,‚Äù Journal of Political Economy, 114(2),\n280‚Äì316.\n(2010): ‚ÄúWhat Drives Media Slant? Evidence from U.S. Daily Newspapers,‚Äù\nEconometrica, pp. 35‚Äì71.\nGentzkow, M. A., J. M. Shapiro, and M. Sinkinson (2012): ‚ÄúCompetition and\nIdeological Diversity: Historical Evidence from US Newspapers,‚Äù .\nGoldberg, B. (2002): Bias: A CBS Insider Exposes How the Media Distort the\nNews. Originally Published by Regnery Publishing, Inc. and Reprinted by Perennial,\nWashington.\nGroseclose, T. (2011): Left Turn: How Liberal Media Bias Distorts the American\nMind. St. Martin‚Äôs Press, New York.\nGroseclose, T., and J. Milyo (2005): ‚ÄúA Measure of Media Bias,‚Äù Quarterly Journal of Economics, 120(4), 1191‚Äì1237.\nHamilton, J. T. (2006): All the News That‚Äôs Fit to Sell: How the Market Transforms\nInformation into News. Princeton University Press, Princeton, New Jersey.\nKlayman, J. (1995): ‚ÄúVarieties of Confirmation Bias,‚Äù Psychology of Learning and\nMotivation, 32, 385‚Äì418.\nLimburg, V. E. (2013): ‚ÄúFairness Doctrine - U.S. Broadcasting Policy,‚Äù .\nMitchell, A., M. Jurkowitz, J. Enda, and K. Olmstead (2013): ‚ÄúHow Americans Get TV News at Home,‚Äù .\nMullainathan, S., and A. Shleifer (2005): ‚ÄúThe Market for News,‚Äù American\nEconomic Review, 95(4), 1031‚Äì1053.\nNickerson, R. S. (1998): ‚ÄúConfirmation Bias: A Ubiquitous Phenomenon in Many\nGuises,‚Äù Review of General Psychology, 2(2), 175‚Äì220.\nOliveros, S., and F. Vardy (2012): ‚ÄúDemand for Slant: How Abstention Shapes\nVoters‚Äô Choices of News Media,‚Äù .\nPosner, R. A. (2005): ‚ÄúBad News,‚Äù .\nPrat, A., and D. Stromberg (2011): ‚ÄúThe Political Economy of Mass Media,‚Äù .\nPuglisi, R., and James M. Snyder Jr. (2012): ‚ÄúThe Balanced U.S. Press,‚Äù .\nRabin, M., and J. L. Schrag (1999): ‚ÄúFirst Impressions Matter: A Model of Confirmatory Bias,‚Äù The Quarterly Journal of Economics, 114(1), 37‚Äì82.\nRadner, R., and J. E. Stiglitz (1984): ‚ÄúA Nonconcavity in the Value of Information,‚Äù in Bayesian Models of Economic Theory, ed. by M. Boyer, and R. E. Kihlstrom.\nElsevier, Amsterdam.\n37\n\nReny, P. J. (1999): ‚ÄúOn the Existence of Pure and Mixed Strategy Nash Equilibria\nin Discontinous Games,‚Äù Econometrica, 67(5), 1029‚Äì1056.\nSavage, L. J. (1972): The Foundations of Statistics. 1954. Dover Publications, Inc.,\nNew York, second edn.\nSobbrio, F. (2013): ‚ÄúCitizen-Editors‚Äô Endogenous Information Acquisition and News\nAccuracy,‚Äù .\nStone, D. F. (2011): ‚ÄúIdeological Media Bias,‚Äù Journal of Economic Behavior and\nOrganization, 78, 256‚Äì271.\nSuen, W. (2004): ‚ÄúThe Self-Perpetuation of Biased Beliefs,‚Äù The Economic Journal,\n114, 377‚Äì396.\nSutter, D. (2001): ‚ÄúCan the Media Be So Liberal? The Economics of Media Bias,‚Äù\nThe Cato Journal, pp. 431‚Äì451.\nthe Pew Research Center for the People and the Press (2011): ‚ÄúPress\nWidely Criticized, But Trusted More than Other Information Sources: Views of the\nNews Media: 1985 - 2011,‚Äù .\n(2012): ‚ÄúIn Changing News Landscape, Even Television is Vulnerable: Trends\nin News Consumption: 1991-2012,‚Äù .\n7. Appendix\n7.1. Proofs of Lemmas 1 and 2.\nProof. Let Œ£ = œÉL + œÉR and recall that œâ = œÉŒ£R and up (d) is the consumers expected\nutility when her belief is given by p and she chooses d ‚àà {l, r, a}. It is easy to verify\nthat, when Œ£ ‚â§ 1:\nU ‚àó (Œ£, 0, œÄ) = max{uœÄ (l) + (Œ≥ + Œ≤) œÄŒ£, uœÄ (r) , Œ≥œÄŒ£},\n\n(7.1)\n\nU ‚àó (0, Œ£, œÄ) = max{uœÄ (l) , uœÄ (r) + (Œ± + Œ¥) (1 ‚àí œÄ) Œ£, Œ± (1 ‚àí œÄ) Œ£},\n\n(7.2)\n\nand,\nU ‚àó (œÉL , œÉR , œÄ) = max{(1 ‚àí œâ) [uœÄ (l) + (Œ≥ + Œ≤) œÄŒ£] + œâuœÄ (l) ,\n(1 ‚àí œâ) uœÄ (r) + œâ [uœÄ (r) + (Œ± + Œ¥) (1 ‚àí œÄ) Œ£] ,\n(1 ‚àí œâ) [Œ≥œÄŒ£] + œâ [Œ± (1 ‚àí œÄ) Œ£]}.\n\n(7.3)\n\nWhen Œ£ &gt; 1, (7.1) and (7.2) no longer hold, but (7.3) still holds so long as (œÉL , œÉR ) ‚àà\n[0, 1]2 .\n38\n\nThe monotonicity of U ‚àó stated in Lemma 1 follows from the fact that each of the linear functions supporting U ‚àó (œÉL , œÉR , œÄ) is non-decreasing in œÉL = (1 ‚àí œâ) Œ£ or œÉR = œâŒ£\nand strictly increasing in Œ£. Now if either œÉL or œÉR is 1, the news reports are perfectly\ninformative and the consumer can achieve the highest expected utility\npossible. \n\n(œÉL ,œÉR )\nb\nLemma 2 follows from the fact that for any (œÉL , œÉR ) such that d pœÄ\n(R | sN ) =\n‚àó\nœÄ\nr, U (œÉL, œÉR , œÄ) = u (r)+(Œ±\n + Œ¥) œÄœÉR , which clearly does not depend on œÉL . Similarly,\n(œÉL ,œÉR )\nb\nwhen d pœÄ\n(R | sN ) = l, U ‚àó (œÉL , œÉR , œÄ) = uœÄ (l) + (Œ≥ + Œ≤) œÄœÉL , which does not\ndepend on œÉR .\n\n7.2. Proofs of Proposition 2.\nProof. Recall that U ‚àó (œÉL , œÉR , œÄ) is convex in (œÉL , œÉR ). Therefore, given the monotonicity of U ‚àó and œÉ, if œÉ is convex, then U ‚àó (œÉ (qL ) , œÉ (qR ) , œÄ) is also convex in (qL , qR ).\nThe set of feasible (qL , qR ) is a polyhedron, thus U ‚àó is maximized at an extreme point.\nClearly, (0, 0) cannot be a solution. Therefore, we must have:\nU ‚àó (œÉ (qL ) , œÉ (qR ) , œÄ) ‚â§ max{U ‚àó (œÉ (q) , 0, œÄ) , U ‚àó (0, œÉ (q) , œÄ)}.\n\n7.3. Isomorphic Representation. In Section 4, we suggested that our restriction\nof the consumer‚Äôs utility function to that defined in Table 4.1 is only a matter of\nrepresentation. The consumers in our simplified model behave identically as a set of\nconsumers with a common prior and heterogeneous utility functions.\nFormally, for any œÄ, œÄ 0 ‚àà (0, 1), there exists a vector (Œ±, Œ≤, Œ¥, Œ≥) such that, Œ±, Œ≤, Œ¥, Œ≥ &gt;\nŒ≥\nŒ≤\n0 and Œ¥+Œ≥\n&lt; Œ±+Œ≤\n, and, if consumer i‚Äôs utility function is that given in Table 4.1 and\nher prior belief is œÄ, and if consumer j‚Äôs utility function and prior belief is given by the\nvector (Œ±, Œ≤, Œ¥, Œ≥, œÄ 0 ), the following statements hold:\n(1) dbi (œÄ) = dbj (œÄ 0 );\n(2) forany œÉ ‚â° (œÉL , œÉR) ‚àà [0, 1]2 , Vi (œÉL , œÉR ) =Vj (œÉL , œÉR ); and,\n(œÉ ,œÉ )\n(œÉ ,œÉ )\n(3) dbi pœÄ L R (L | sN ) = dbj p 0 L R (L | sN ) .\nœÄ\n\nProof. It suffices to show that, we can find (Œ±, Œ≤, Œ¥, Œ≥), such that, for any œÉ ‚â° (œÉL , œÉR ) ‚àà\n0\n[0, 1]2 : i) uœÄi (d) = uœÄj (d), for d ‚àà {l, r, a}; ii) Vi (œÉL , œÉR ) = Vj (œÉL , œÉR ); and, iii) for all\n(œÉ ,œÉ )\n(œÉ ,œÉ )\n(œÉ ,œÉ )\npœÄ0 L R (R|sN )\npœÄ L R (R|sN )\npœÄ L R (R|sN )\n0\nd, d ‚àà {l, r, a}, ui\n(d) ‚â• ui\n(d ) if and only if uj\n(d) ‚â•\n(œÉL ,œÉR )\np\n(R|sN )\nuj œÄ0\n(d0 ).\n0\n\n39\n\nBy definition, ii) holds if i) holds and Ui‚àó (œÉL , œÉR , œÄ) = Uj‚àó (œÉL , œÉR , œÄ 0 ). (7.1) to (7.3)\nguarantee that both i) and Ui‚àó (œÉL , œÉR , œÄ) = Uj‚àó (œÉL , œÉR , œÄ 0 ) hold if:\nÔ£±\nÔ£¥\n[(1 ‚àí œÄ 0 ) Œ± ‚àí œÄ 0 Œ≤ + (Œ≥ + Œ≤) œÄ 0 Œ£] = [1 ‚àí 2œÄ ‚àí c + 2œÄŒ£]\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\n[(1 ‚àí œÄ 0 ) Œ± ‚àí œÄ 0 Œ≤] = [1 ‚àí 2œÄ ‚àí c]\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≤[‚àí (1 ‚àí œÄ 0 ) Œ¥ + œÄ 0 Œ≥] = [2œÄ ‚àí 1 ‚àí c]\nÔ£¥\nÔ£¥[‚àí (1 ‚àí œÄ 0 ) Œ¥ + œÄ 0 Œ≥ + (Œ± + Œ¥) (1 ‚àí œÄ 0 ) Œ£] = [2œÄ ‚àí 1 ‚àí c + 2 (1 ‚àí œÄ) Œ£]\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\n[Œ≥œÄ 0 Œ£] = [(1 ‚àí c) œÄŒ£]\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£¥\nÔ£≥[Œ± (1 ‚àí œÄ 0 ) Œ£] = [(1 ‚àí c) (1 ‚àí œÄ) Œ£]\n.\nThus, there exists (Œ±, Œ≤, Œ¥, Œ≥) such that both i) and ii) hold if the system of linear\nequations above has a solution.\n\n1‚àíœÄ\nœÄ\n1‚àíœÄ\nœÄ\nIt is easy to verify that (Œ±, Œ≤, Œ¥, Œ≥) = (1 ‚àí c) 1‚àíœÄ\n0 , (1 + c) œÄ 0 , (1 + c) 1‚àíœÄ 0 , (1 ‚àí c) œÄ 0\nis a solution to the system. It is, in fact, the unique solution.\nNote that, when the system of equations hold, we also have:\np\n\n(œÉL ,œÉR )\n\np\n\n(œÉL ,œÉR )\n\nui œÄ\n\n= uj œÄ0\n\n(œÉ ,œÉ )\np L R (R|sN )\n\n(R|sN )\n\n(d) ‚àí ui œÄ\n\n(R|sN )\n\n(d) ‚àí uj œÄ0\n\n(œÉ ,œÉ )\np L R (R|sN )\n\nfor all d, d0 ‚àà {l, r, a}. Thus, iii) also holds.\n\n(d0 )\n(d0 )\n\n\n7.4. Proof of Lemma 3.\nProof. For any qL0 ‚àà ( 2q , q], we have œÉ (qL0 ) &gt; œÉ (q ‚àí qL0 ) and hence 1‚àíc\n&lt; œÄ‚àó (œÉ (qL0 ) , œÉ (q ‚àí qL0 )).\n2\nSuppose œÄ‚àó (œÉ (qL0 ) , œÉ (q ‚àí qL0 )) &lt; 1+c\n, then V (œÉ (qL0 ) , œÉ (q ‚àí qL0 ) , œÄ) is strictly increas2\n\n\n 1+c \n, 1 . That\ning in œÄ over œÄ‚àó (œÉ (qL0 ) , œÉ (q ‚àí qL0 )) , 1+c\nand\nstrictly\ndecreasing\nover\n2\n2\nis to say\n1+c\n} = arg\nmax\nV (œÉ (qL0 ) , œÉ (q ‚àí qL0 ) , œÄ) .\nœÄ‚àà[œÄ‚àó (œÉ(qL ),œÉ(qR )),1]\n2\n\nNow let Œ∫‚àó = maxqL ‚àà[ q ,q] V œÉ (qL ) , œÉ (qR ) , 1+c\n. The maximum is attained given\n2\n2\n\nthe continuity of V in (qL , qR ). By Lemma 1, Œ∫‚àó &lt; V œÉ (q) , œÉ (q) , 1+c\n= Œ∫. It\n2\nq\n‚àó\n0\n0\n0\nfollows that, for any Œ∫ &gt; Œ∫ and qL ‚àà ( 2 , q], V (œÉ (qL ) , œÉ (q ‚àí qL ) , œÄ) &gt; Œ∫ implies\nœÄ ‚àà [0, œÄ‚àó (œÉ (qL0 ) , œÉ (q ‚àí qL0 ))], which, in turn, implies that V (œÉ (qL0 ) , œÉ (q ‚àí qL0 ) , œÄ) is\n.\nstrictly increasing in qL0 . The same clearly holds when œÄ‚àó (œÉ (qL0 ) , œÉ (q ‚àí qL0 )) ‚â• 1+c\n2\n‚àó\nTherefore, when Œ∫ ‚àà (Œ∫ , Œ∫), {(q, 0)} = arg maxqL ‚àà[ q ,q] Œ† (qL , qR ).\n2\nA symmetrical argument establishes that {(0, q)} = arg maxqR ‚àà[ q ,q] Œ† (qL , qR ). We\n2\nhave thus proved Lemma 3.\n\n{\n\n40\n\n7.5. Proof of Lemma 4 and Proposition 3.\nProof. Lemma 4 follows from the fact that Œ† (qL , qR ; Œ∫) is continuous in Œ∫ over\n\n\n \n\n\n1+c\n1‚àíc\n, V œÉ (qL ) , œÉ (qR ) ,\n}\n,\n0, max{V œÉ (qL ) , œÉ (qR ) ,\n2\n2\nand hence for any interior (qL , qR ), limŒ∫‚Üí0 Œ† (qL , qR ; Œ∫) = 1 and limŒ∫‚Üí0 Œ† (q, 0; Œ∫) , limŒ∫‚Üí0 Œ† (0, q; Œ∫) &lt;\n1.\nContinuity of Œ† (qL , qR ; Œ∫) in (qL , qR ) over {(qL , qR ) | qL , qR ‚â• 0, qL + qR ‚â§ q} guarantees that the solution set is non-empty. The rest of Proposition 3 follows from Lemmas\n3 and 4.\n\n7.6. Proof of Proposition 4.\nProof. Under Assumption 2, V (œÉ (qL ) , œÉ (qR ) , œÄ) = V (qL , qR , œÄ). Suppose, qL &gt; qR &gt;\n0, we have: 1‚àíc\n&lt; œÄ‚àó (qL , qR ) &lt; œÄ‚àó (q, 0). Moreover, Assumption 1 implies that\n2\n1\nœÄ‚àó (q, 0) &gt; 2 .\nIt is obvious that for all œÄ ‚àà [0, œÄ‚àó (qL , qR )], U ‚àó (q, 0, œÄ) &gt; U ‚àó (qL , qR , œÄ) and hence\nV (q, 0, œÄ) &gt; V (qL , qR , œÄ). Now, for all œÄ ‚àà (max{ 21 , œÄ‚àó (qL , qR )}, œÄ‚àó (q, 0)], we have:\nU ‚àó (q, 0, œÄ) = 1 ‚àí 2œÄ ‚àí c + 2qœÄ\n‚â• œÄq (1 ‚àí c)\n&gt; [œÉ (qL ) œÄ + œÉ (qR ) (1 ‚àí œÄ)] (1 ‚àí c)\n= U ‚àó (qL , qR , œÄ) ,\n\n\nand for all œÄ ‚àà min{ 12 , œÄ‚àó (qL , qR )}, 12 , we have:\nU ‚àó (q, 0, œÄ) &gt; U ‚àó (q, 0, œÄ‚àó (q, 0))\n= œÄ‚àó (q, 0) q (1 ‚àí c)\nq\n(1 ‚àí c)\n&gt;\n2\n‚â• [œÉ (qL ) œÄ + œÉ (qR ) (1 ‚àí œÄ)] (1 ‚àí c)\n= U ‚àó (qL , qR , œÄ) .\nFinally, if œÄ‚àó (q, 0) &lt; œÄ ‚àó (qL , qR ), it is obvious that U ‚àó (q, 0, œÄ) &gt; U ‚àó (qL , qR , œÄ) for all\n[œÄ‚àó (q, 0) , œÄ ‚àó (qL , qR )].\nTherefore, for all interior q = (qL , qR ) such that qL &gt; qR and all œÄ ‚àà [0, œÄ ‚àó (qL , qR )],\nwe have V (q, 0, œÄ) &gt; V (qL , qR , œÄ). Similarly, one can show that, for all interior q =\n(qL , qR ) such that qL &lt; qR and all œÄ ‚àà [œÄ‚àó (qL , qR ) , 1], we have V (0, q, œÄ) &gt; V (qL , qR , œÄ).\nDefine œÄ (œÉL , œÉR , Œ∫) ‚â° inf{œÄ | V (œÉL , œÉR , œÄ) ‚â• Œ∫} and œÄ (œÉL , œÉR , Œ∫) ‚â° sup{œÄ |\nV (œÉL , œÉR , œÄ) ‚â• Œ∫}.\n41\n\nConsider qL &gt; qR &gt; 0. If Œ∫ ‚â• V (qL , qR , œÄ ‚àó (qL , qR )), then œÄ (qL , qR , Œ∫) ‚â• œÄ ‚àó (qL , qR ).\nThus, V (q, 0, œÄ) &gt; V (qL , qR , œÄ) implies that Œ† (q, 0; Œ∫) &gt; Œ† (qL , qR ; Œ∫). Similarly, if\n0 &lt; qL &lt; qR and Œ∫ ‚â• V (qL , qR , œÄ‚àó (qL , qR )), then Œ† (0, q; Œ∫) &gt; Œ† (qL , qR ; Œ∫).\nSuppose there is an interior solution to (4.1), denoted (qL‚àó , qR‚àó ). Then if qL‚àó &gt; qR‚àó ,\nit must be that Œ∫ &lt; V (qL‚àó , qR‚àó , œÄ ‚àó (qL‚àó , qR‚àó )) (or, equivalently, qR‚àó &gt; 2œÄ‚àó qŒ∫‚àó ,q‚àó ), while\n( L R)\nqL‚àó &lt; qR‚àó implies Œ∫ &lt; V (qL‚àó , qR‚àó , œÄ‚àó (qL‚àó , qR‚àó )) (or, equivalently, qL‚àó &gt; 2œÄ qŒ∫‚àó ,q‚àó ). In either\n‚àó( L R)\ncase, the monopolist‚Äôs profit is given by:\nÀÜ œÄ(qL‚àó ,qR‚àó ,Œ∫)\n‚àó\n‚àó\nŒ† (qL , qR ; Œ∫) =\nf dœÄ,\n‚àó ,q ‚àó ,Œ∫\nœÄ (qL\nR )\nwhere œÄ (qL‚àó , qR‚àó , Œ∫) = 2qŒ∫‚àó and œÄ (qL‚àó , qR‚àó , Œ∫) = 2qŒ∫‚àó . Hence, the FOC is given by:\nL\nR\n\n\n ‚àó 2\nf 1 ‚àí 2œÉ Œ∫q‚àó\n( L)\nqL\n\n\n.\n=\nqR‚àó\nŒ∫\nf 2œÉ qj\n( R)\n\n(7.4)\n\nUnder Assumption 3, (7.4) can only be satisfied by one interior reporting strategy\nand qL‚àó &gt; qR‚àó (respectively, qL‚àó &lt; qR‚àó ) if and only if ¬µ &lt; 21 (respectively, ¬µ &gt; 12 ). It is\n1\nobvious that Œ† (q, 0; Œ∫) &gt; Œ† (0, q; Œ∫)\nFinally, it is easy to verify\n if and only\n if ¬µ &lt; 2 . \nthat when ¬µ &lt; 12 and qL‚àó &gt; qR‚àó , f\n\n1 ‚àí 2œÉ Œ∫q‚àó\n( L)\n1\n‚àó\nthe opposite is true when ¬µ &gt; 2 and qL &lt; qR‚àó .\n\n/f\n\nŒ∫\nj\n2œÉ (qR\n)\n\nis increasing in Œ∫, while\n\n\n7.7. Proof of Proposition 5.\nProof. We apply Corollary 5.2 of Reny (1999) to prove the existence of mixed strategy\nNash equilibria for the dupololists‚Äô game. To apply the corollary, we want to show that\nthe mixed extension of the duopolists‚Äô game is both ‚Äúreciprocally upper semicontinuous‚Äù\nand ‚Äúpayoff secure‚Äù 32.\nThe sum of the duopolists‚Äô payoffs always equals the total news consumption by all\nthe consumers, and is hence upper semicontinuous in qj and qk for all Œ∫. Proposition\n5.1 of Reny (1999) then ensures that the mixed extension of the duopolists‚Äô game is\nalways ‚Äúreciprocally upper semicontinuous‚Äù.\n\nLet EŒ†j œëj , œëk ; Œ∫ denote player j‚Äôs expected payoff when j and k play mixed strate\ngies œëj and œëk , respectively. Since Œ†j qj , qk ; Œ∫ is only discontinuous at points where\n\nqj = qk , EŒ†j œëj , œëk ; Œ∫ can only be discontinuous at points where œëj and œëk have mass\npoints at qj and qk , respectively, for some qj = qk . Moreover, for any q = (qL , qR ) and\n\n‚àÜ ‚àà R, let q + ‚àÜ denote (qL + ‚àÜ, qR ‚àí ‚àÜ), then Œ†j qj , qk ; Œ∫ is only discontinuous\n32See Reny (1999) for the relevant definitions\n\n42\n\nat (q, q) if Œ†j (q + Œµ‚àÜ, q; Œ∫) &gt; Œ†j (q + (‚àíŒµ‚àÜ) , q; Œ∫) for all Œµ &gt; 0 sufficiently small.\n\nTherefore at those points where EŒ†j œëj , œëk ; Œ∫ is discontinuous, player j can ‚Äúsecure‚Äù\n\na payoff EŒ†j œëj , œëk ; Œ∫ by moving the mass point at qj to qj +Œµ‚àÜ for some Œµ arbitrarily\nsmall. Thus the mixed extension of the duopolists‚Äô game is ‚Äúpayoff secure‚Äù.\nTherefore the duopolists‚Äô game has at least one Nash equilibrium in mixed strategies.\nMoreover, the duopolist‚Äôs game is clearly symmetrical. Therefore, Corollary 5.3 of Reny\n(1999) implies that there exists at least one symmetric Nash equilibrium in mixed\nstrategies of this game. The same argument can be applied to proving the existence of\nsymmetric mixed strategy Nash equilibria for the media outlets‚Äô game with any number\nof players.\n\nRecall from the proof of Lemma 3 that if Œ∫ &gt; maxqL ‚àà[ q ,q] V œÉ (qL ) , œÉ (qR ) , 1+c\nand\n2\n2\nif V (œÉ (q L ) , œÉ (q ‚àí q L ) , œÄ) ‚â• Œ∫, then V (œÉ (q L ) , œÉ (q ‚àí q L ) , œÄ) is either strictly increasing in qL or strictly decreasing in qL . On the other hand, the bundle of news reports con\nsisting one from each media outlet can be valued at most at V œÑ (œÉ (q) , œÉ (q)) , 0, 1‚àíc\n.\n2\n\n1‚àíc\n1\nThus, if Œ∫ &gt; 2 V œÑ (œÉ (q) , œÉ (q)) , 0, 2 , no consumer would purchase more than one\n\nnews report. Moreover, V œÑ (œÉ (q) , œÉ (q)) , 0, 1‚àíc\n&lt; 2œÉ (q) (1 ‚àí c) = 2Œ∫.\n2\n‚àó\nNow let Œ∫2 be defined by:\n\n\n\n\n1‚àíc\n1+c\n1\n‚àó\nŒ∫2 = max{ max V œÉ (qL ) , œÉ (qR ) ,\n, V œÑ (œÉ (q) , œÉ (q)) , 0,\n}.\n2\n2\n2\nqL ‚àà[ 2q ,q ]\nIt follows that, when Œ∫ &gt; Œ∫‚àó2 , at least one extreme reporting strategy (i.e. (q, 0) or\n(0, q) or both) strictly dominates all interior strategies for either media outlet.\nFinally, let qk = (q, 0). For Œ∫ sufficiently small, j‚Äôs payoff when choosing strategy\n(q, 0) is:\nÀÜ\nÀÜ\n\n1\nk\nf dœÄ\nf dœÄ +\nŒ†j (q, 0) , q ; Œ∫ =\n2 Aj12\nAj\n1+c‚àí2Œ∫\nŒ∫\nÀÜ\nÀÜ\n2‚àí(1‚àíc)œÑ (œÉ(q),œÉ(q))\n1 2[œÑ (œÉ(q),œÉ(q))‚àíœÉ(q)]\n=\nf dœÄ +\nf dœÄ,\nŒ∫\nŒ∫\n2 2œÑ (œÉ(q),œÉ(q))\n2[œÑ (œÉ(q),œÉ(q))‚àíœÉ(q)]\nwhile its payoff when choosing strategy (0, q) is:\nÀÜ\n\nk\nŒ†j (0, q) , q ; Œ∫ =\nf dœÄ\nAj\n\nÀÜ 1‚àí Œ∫\n\n2œÉ(q)\n\n=\n\nf dœÄ.\nŒ∫+(1‚àíc)[1‚àíœÉ(q)]\n2[1‚àíœÉ(q)]\n\n43\n\nNow pick any interior strategy (qL , qR ), j‚Äôs payoff when choosing (qL , qR ) is:\nÀÜ\n\nk\nŒ†j (qL , qR ) , q ; Œ∫ =\nf dœÄ\nAj\n\nÀÜ 1‚àí\n=\n\nŒ∫\n2œÉ (qR )\n\nf dœÄ.\n\nŒ∫\n2[œÑ (œÉ(q),œÉ (qL ))‚àíœÉ(q)]\n\nAll of these payoffs are continuous in Œ∫ when Œ∫ is sufficiently small. Thus, we have\n\n\n\nlimŒ∫‚Üí0 Œ†j (qL , qR ) , qk ; Œ∫ = 1 while limŒ∫‚Üí0 Œ†j (q, 0) , qk ; Œ∫ , limŒ∫‚Üí0 Œ†j (0, q) , qk ; Œ∫ &lt;\n\n1. Therefore, there exists a Œ∫0 &gt; 0 such that Œ†j (qL , qR ) , qk ; Œ∫ is strictly higher than\n\n\nboth Œ†j (q, 0) , qk ; Œ∫ and Œ†j (0, q) , qk ; Œ∫ for all Œ∫ &lt; Œ∫0 .\nSimilarly, we can prove that, when qk = (0, q), there exists a Œ∫00 &gt; 0 such that\n\n\n\nŒ†j (qL , qR ) , qk ; Œ∫ is strictly higher than both Œ†j (q, 0) , qk ; Œ∫ and Œ†j (0, q) , qk ; Œ∫\nfor all Œ∫ &lt; Œ∫00 . In fact, the analogous statement can be proved by the same argument\nfor any reporting strategy qk .\nNow let Œ∫\nb2 = min{Œ∫0 , Œ∫00 }. Then, when Œ∫ &lt; Œ∫\nb2 , an interior strategy (qL , qR ) strictly\ndominates both (q, 0) and (0, q) for media outlet j when k is restricted to randomizing\nover only {(q, 0) , (0, q)}. Therefore, there cannot be any Nash equilibria where both\nplayers only randomize over {(q, 0) , (0, q)}.\nWe have thus proved Proposition 5.\n\n7.8. Proof of Proposition 6.\n\n\nProof. When both media outlets choose q = 2q , 2q and Œ∫ &lt; 1 ‚àí 2q q 1‚àíc\n, each receives\n2\na payoff equal to:\nŒ∫\nÀÜ Œ∫\nÀÜ\n1 1‚àí q\n1 1‚àí (1‚àí 2q )q\nŒ† (q, q; Œ∫) =\nf dœÄ +\nf dœÄ.\nŒ∫\n2 Œ∫q\n2\nq\n(1‚àí 2 )q\n\nOn the other hand, if media outlet j deviate to some other interior reporting strategy\n(qL , qR ) with qL &gt; qR its payoff is equal to:\nÀÜ œÄÃÉ\nŒ† ((qL , qR ) , q; Œ∫) =\nf dœÄ,\nŒ∫\n2qL\n\nwhere œÄ\ne is the prior belief of the most conservative consumer who is willing to choose\nj‚Äôs news report as her second choice, which, depending on Œ∫, has to satisfy one of the\nfollowing equations:\nÔ£±\n\nq q\nÔ£≤ 1 V (œÉ , œÉ , œÄ\ne\n)\n=\nŒ∫\nif\nV\n(œÉ\n,\nœÉ\n,\nœÄ\ne\n)\n‚â•\n2V\n,\n,\nœÄ\ne\nL\nR\nL\nR\n2\n2 2\n,\n\nq q\nÔ£≥V (œÉL , œÉR , œÄ\ne) ‚àí V , , œÄ\ne = Œ∫ Otherwise\n2 2\n\n44\n\n\n\n\nL\nR\nwhere œÉL = œÑ 2q , qL and œÉR = œÑ 2q , qR . Note that, ‚àÇœÉ\n= ‚àÇœÉ\n= 1 ‚àí 2q , which\n‚àÇqL\n‚àÇqR\n\nimplies that V (œÉL , œÉR , œÄ\ne) is strictly increasing in qL over 12 , œÄ ‚àó (œÉL , œÉR ) . It follows\nthat, if œÄ\ne &lt; œÄ ‚àó (œÉL , œÉR ), then it is strictly increasing in qL , and Œ† ((qL , qR ) , q; Œ∫) &lt;\n\nŒ† ((q, 0) , q; Œ∫). When œÄ\ne ‚â• œÄ ‚àó (œÉL , œÉR ), which implies that Œ∫ ‚â§ 2œÄ ‚àó (œÉL , œÉR ) œÉR ‚àí 2q ,\nwe have œÄ\ne = 1 ‚àí 2 œÉ Œ∫‚àí q = 1 ‚àí 2 1‚àíŒ∫q q , which is strictly increasing in qR . 2qŒ∫L , on the\n( R 2)\n( 2) R\nother hand, is strictly decreasing in qL . Thus any (qL , qR ) with qL + qR &lt; q cannot be\nprofit maximizing for j. Therefore, we can, without loss generality, focus on reporting\nstrategies satisfying qL + qR = q, and can identify j‚Äôs strategy with x = qqL . j‚Äôs payoff\nthen becomes:\nŒ∫\nÀÜ 1‚àí\nq\n2(1‚àí 2 )(1‚àíx)q\nŒ† (x, q; Œ∫) =\nf dœÄ.\nŒ∫\n2xq\n\nDifferentiating with respect to x yields:\n!\n\n\nŒ∫\nŒ∫\nŒ∫\nŒ∫\n\n\n‚àíf 1‚àí\nf\nq\nq\n2\n2xq 2qx\n2 1 ‚àí 2 (1 ‚àí x) q 2 1 ‚àí 2 q (1 ‚àí x)2\n\n,\n\n(7.5)\n\nwhich, when ¬µ = 12 , is negative for x &gt; 12 . The case when qL &lt; qR is symmetrical\nis positive for x &lt; 12 . Finally, it is easy to verify that, when\nand, when ¬µ = 12 , ‚àÇŒ†(x,q;Œ∫)\n‚àÇx\n\n\n\n¬µ = 21 , limx‚Üí 1 Œ† (x, q; Œ∫) = Œ† 12 , q; Œ∫ . Therefore, at 2q , 2q , 2q , 2q , if a media outlet\n2\nhas a profitable deviation, then its payoff must be maximized by either (q, 0) or (0, q).\nHowever, an argument similar to that applied towards the end of the previous proof\n\n, Œ∫‚àó2 }, such that for all Œ∫ ‚àà (0, Œ∫Ãå2 ),\nshows that we can find a Œ∫Ãå2 ‚â§ min{ 1 ‚àí 2q q 1‚àíc\n2\n\nŒ† x = 21 , q; Œ∫ is strictly higher than both Œ† (0, q; Œ∫) and Œ† (1, q; Œ∫).\n\n\nTherefore, when ¬µ = 12 and Œ∫ ‚àà (0, Œ∫Ãå2 ), 2q , 2q , 2q , 2q is a Nash equilibrium.\nMoreover, it is easy to show that, for all Œµ &gt; 0, if ¬µ is sufficiently close to 21 , there\n\nexists an x‚àó in 12 ‚àí Œµ, 21 + Œµ , such that limx‚Üíx‚àó Œ† (x, x‚àó ; Œ∫) = Œ† (x‚àó , x‚àó ; Œ∫).\n\nOn the other hand, when Œ∫ &lt; 1 ‚àí 2q q 1‚àíc\n, Œ† (x, q; Œ∫) is continuous in (x, q, ¬µ) at\n2\n 1\nq q\n1\n, 2 , 2 , 2 , so is its derivative with respect to x. Therefore, for x‚àó and ¬µ sufficiently\n2\nclose to 12 , we can simply replace 12 by x‚àó in the above argument, and continuity ensures\nthat all the strict inequalities still hold. Then, (x‚àó , x‚àó ) is a Nash equilibrium if we also\nhave limx‚Üíx‚àó Œ† (x, x‚àó ; Œ∫) = Œ† (x‚àó , x‚àó ; Œ∫).\nTherefore, for the same Œ∫, if ¬µ is sufficiently close to 21 , the game has a Nash equi\n\n\nlibrium at some ((x‚àó q, (1 ‚àí x‚àó ) q) , (x‚àó q, (1 ‚àí x‚àó ) q)) close to 2q , 2q , 2q , 2q .\n\n7.9. Proof of Proposition 7.\n45\n\nProof. If no media outlet chooses (q, 0) (respectively, (0, q)) with positive probability,\n¬¥1\n¬¥ 1‚àíc\nthen a player can secure a payoff of at least 0 2 f dœÄ (respectively, 1+c f dœÄ) by choos2\ning (q, 0) (respectively, (0, q)) with probability one. On the other hand, fixing Œ∫, the\n\nnumber of news report a consumer will consume is bounded above by V 1, 0, 12 /Œ∫.\nThus, when there are N media outlets, the average payoff of a media outlet is bounded\n\nby V 1, 0, 12 / (Œ∫N ). Therefore, for N sufficiently large, some player must find it more\nprofitable to play (q, 0) (respectively, (0, q)) than any other interior reporting strategy if none of the other media outlets chooses (q, 0) (respectively, (0, q)) with positive\nprobability.\n\n7.10. Proof of Proposition 8.\nProof. First, by inspecting V , the difference between functions U ‚àó and u‚àó , we see\nthat for any news consumption bundle (œÉL , œÉR ) and any œÄ ‚àà [0, 1], we must have\n\n\nV (œÉL , œÉR , œÄ) ‚â§ max{V œÉL , œÉR , 1‚àíc\n, V œÉL , œÉR , 1+c\n}. That is, either the consumers\n2\n2\n1‚àíc\nwith prior belief given by œÄ = 2 or those with prior œÄ = 1+c\nmust value (œÉL , œÉR )\n2\nhigher than any other consumers. It follows that if any news report is consumed at\nor 1+c\n. Since V\nall, it must be consumed by some consumers with prior beliefs 1‚àíc\n2\n2\nis continuous in œÄ, this implies that the news report is also consumed by either some\nliberals or some conservatives.\n \nNow let b ‚àà 0, 12 be a set of binding content regulations. Let Œ£j0 and Œ£j1 denote the\nsupports of media outlet j‚Äôs pre-regulation equilibrium strategy and its post-regulation\nequilibrium strategy, respectively. Then, there must be some media outlet j, for whom\nj\n\nqL\n1\nthe set Œ£j‚àó ‚â° { qLj , qRj ‚àà Œ£j0 \ Œ£j1 || qj +q\nj ‚àí 2 |&gt; b} is non-empty. Moreover, either\nL\nR\n\n\nthe set { qLj , qRj ‚àà Œ£j‚àó | qLj &lt; qRj } or the set { qLj , qRj ‚àà Œ£j‚àó | qLj &lt; qRj } is non-empty.\n\nWithout loss of generality, let { qLj , qRj ‚àà Œ£j‚àó | qLj &lt; qRj } be non-empty. Note that,\n\nby definition, the reporting strategies in { qLj , qRj ‚àà Œ£j‚àó | qLj &lt; qRj } are played with\npositive probability before the regulations were imposed.\nNow let (qL0 , qR0 ) denote the news report in the set ‚à™j Œ£j1 that is most biased to the\nleft. By the above argument, there must be some liberal consumer who are willing\nto consume (qL0 , qR0 ). Moreover, concavity of œÑ implies that a liberal who is willing to\nconsume (qL0 , qR0 ) in a bundle must be willing to consume it on its own. On the other\nhand, we know that a liberal with prior belief given by œÄ = 0 is not willing to consume\n(qL0 , qR0 ) at any positive Œ∫. Thus, by continuity of V , there exists œÄ 0 ‚àà (0, 1) such that\nconsumers with prior belief œÄ 0 are indifferent between consuming (qL0 , qR0 ) on its own\nand not consuming any news. Fixing Œ∫, consumers with prior belief œÄ &lt; œÄ 0 are not\nwilling to consume (qL0 , qR0 ) and are therefore not willing to consume any news with\npositive probability. On the other hand, continuity of V implies that some of these\n46\n\n\nconsumers are willing to consume news reports in { qLj , qRj ‚àà Œ£j‚àó | qLj &lt; qRj } at Œ∫.\nThus, these consumers enjoy positive expected surplus in the equilibrium before the\ncontent regulations are imposed and are made strictly worse-off by the introduction of\nsuch regulations. We have thus proved the first half of the proposition.\nConsider a game with two media outlets. Let œÉ be convex and suppose that, in\nthe equilibrium before content regulations are introduced, one of the two media outlet produces news report (q, 0) with probability one and the other produce (0, q) with\nprobability one. Then Proposition 2 and the concavity of œÑ implies that the introduction of binding content regulations must make all consumers worse-off. This proves the\nsecond half of the proposition.\n\n\n47\n\n</td>
    </tr>
  </tbody>
</table>