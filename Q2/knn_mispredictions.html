<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13</th>
      <td>poli</td>
      <td>royalsocietypublishing.org/journal/rsif Research Cite this article: Coscia M, Rossi L. 2020 Distortions of political bias in crowdsourcedmisinformation flagging. J. R. Soc. Interface 17: 20200020.http://dx.doi.org/10.1098/rsif.2020.0020 Received: 8 January 2020 Accepted: 13 May 2020 Subject Category: Life Sciences –Mathematics interface Subject Areas: computational biology, biotechnology Keywords: social media, social networks, content policing,flagging, fake news, echo chambers Author for correspondence: Michele Cosciae-mail: mcos@itu.dkDistortions of political bias in crowdsourced misinformation flagging Michele Coscia and Luca Rossi IT University of Copenhagen, Kobenhavn, Denmark MC, 0000-0001-5984-5137; LR, 0000-0002-3629-2039 Many people view news on social media, yet the production of news items online has come under fire because of the common spreading of misinforma- tion. Social media platforms police their content in various ways. Primarily they rely on crowdsourced ‘flags ’: users signal to the platform that a specific news item might be misleading and, if they raise enough of them, the item will be fact-checked. However, real-world data show that the most flagged news sources are also the most popular and —supposedly —reliable ones. In this paper, we show that this phenomenon can be explained by the unrea- sonable assumptions that current content policing strategies make about how the online social media environment is shaped. The most realistic assumptionis that confirmation bias will prevent a user from flagging a news item if they share the same political bias as the news source producing it. We show, via agent-based simulations, that a model reproducing our current understandingof the social media environment will necessarily result in the most neutral and accurate sources receiving most flags. 1. Introduction Social media have a central role to play in the dissemination of news [1]. There is a general concern about the low quality and reliability of information viewed online:researchers have dedicated increasing amounts of attention to the problem of so- called fake news [2 –4]. Given the current ecosystem of news consumption and pro- duction, misinformation should be understood within the complex set of social andtechnical phenomena underlying online news propagation, such as echo chambers [5–10], platform-induced polarization [11,12] and selective exposure [13,14]. Over the years two main approaches have emerged to try to address the problem of fake news by limiting its circulation: a technical approach and an expert-based approach. The technical approach aims at building predictive models able to detect misinformation [15,16]. This is often done using one ormore features associated with the message, such as content (through natural language processing (NLP) approaches [17]), source reliability [18] or network structure [19]. While these approaches have often produced promising results,the limited availability of training data as well as the unavoidable subjectivity involved in labelling a news item as fake [20,21] constitute a major obstacle to wider development. The alternative expert-based approach consists of a fact-checker on the specific topic that investigates and evaluates each claim. While this could be the most accurate way to deal with misinformation, given the amount ofnews that circulates on social media every second, it is hard to imagine how this could scale to the point of being effective. For this reason, the dominant approach, which has recently also been adopted by Facebook, 1is based on a combination of methods that first use computationally detected crowd signals, often constituted by users flagging what they consider fake or misleading infor- mation, and then assigning selected news items to external professional fact-checkers for further investigation [22,23]. Although flagging-based systems remain, to the best of our knowledge, widely used, many authors have ques- tioned their reliability, showing how users can flag news items for reasons © 2020 The Authors. Published by the Royal Society under the terms of the Creative Commons AttributionLicense http:/ /creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the originalauthor and source are credited.  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  other than the ones intended [24,25]. Recently, researchers proposed methods to identify reliable users and improve, in that way, the quality of the crowd signal [20,23]. Regardless of the ongoing efforts, fake news and mislead- ing information still pollute online communications and no immediate solution seems to be available. In 2018, Facebook released, through the Social Science One initiative, theFacebook URL Shares dataset [26], a preview of the larger dataset released recently. 2The dataset contains the web page addresses (URLs) shared by at least 20 unique accountson Facebook between January 2017 and June 2018. Together with the URLs, the dataset also details whether the specific link had been sent to the third-party fact-checkers thatcollaborate with Facebook. We accessed the most shared links in the Italian subset, which revealed some curious patterns and inspired the pre-sent work. We exclusively use this dataset for the motivation and validation of our analysis, leaving the use of the newer full dataset for future work. Table 1 shows the top 10 most reported domains, which are exclusively major national newspapers, news sites and a satirical website. A further analysis of the data reveals, as figure 1 shows,a positive correlation ( y¼ bxafit, with slope α= 0.2, scale β= 1.22 and p&lt; 0.0013) between a source ’sp o p u l a r i t ya n dt h e number of times a domain has been checked by Facebook ’s third-party fact-checkers. We measure the popularity of the source through Alexa ’s (https://www.alexa.com) page views per million users (PVPM). It is worth observing that all the news reported in the top 10 most reported domains have been fact-checked astrue legitimate news (with the obvious exception of the satirical website, which was fact-checked as satire).These observations create the background for the present paper. Our hypothesis is that users are polarized and that polarization is an important driver of the decision of whetherto flag or not a news item: a user will only flag it if it is not perceived truthful enough andif it has a significantly differ- ent bias from that of the user (polarity). Sharing the samebias would act against the user ’s flagging action. Thus, we introduce a model of online news flagging that we call the ‘bipolar ’model, since we assume for simplicity that there are only two poles —roughly corresponding to ‘liberal ’and ‘conservative ’in the US political system. The bipolar model of news-flagging attempts to capture the main ingredients thatwe observe in empirical research on fake news and disinforma- tion—echo chambers, confirmation bias, platform-induced polarization and selective exposure. We show how the proposedmodel provides a reasonable explanation of the patterns that we observe in Facebook data. The current crowdsourced flagging systems seem to assume a simpler flag-generating model. Despite being some- how similar to the bipolar model we propose, in this simple case the model does not account for users ’polarization, thus we will call it the ‘monopolar ’model. In the monopolar model, users do not gravitate around two poles and perceived truthfulness constitutes the only parameter. Users flagnews items only if they perceive an excessive ‘fakeness ’of the news item, depending of their degree of scepticism. We show how the monopolar model relies on unrealistic expectationsand that it is unable to reproduce the observed flag-generating patterns. Lastly, we test the robustness of the bipolar model against various configurations of the underlying network structure and the actors ’behaviour. We show, on the one hand, how the model is always able to explain the observed flaggingphenomenon and, on the other hand, that a complex social network structure is a core element of the system. 2. Methods In this section, we present the main model on which we base the results of this paper. It is possible to understand the bipolar andmonopolar models as a single model with or without users ’ polarization. However, a user ’s polarization has a significant impact on the results, and it seriously affects the social networkunderlying the flagging and propagation processes. For theseTable 1. The top 10 most ﬂagged domains among the Italian links shared on the Facebook URL Shares dataset. domain reported PVPM type 1 repubblica.it 270.00 54.00 national newspaper 2 ilfattoquotidiano.it 85.00 21.00 national newspaper 3 corriere.it 83.00 30.00 national newspaper 4 fanpage.it 49.00 5.00 national news site 5 ansa.it 47.00 12.00 national news site 6 huf ﬁngtonpost.it 40.00 7.20 national news site 7 ilmessaggero.it 34.00 2.00 national newspaper 8 ilsole24ore.com 32.00 4.00 national newspaper 9 lercio.it 29.00 3.00 satire10 tgcom24.mediaset.it 28.00 28.00 national news site110102103 10–210–11 10 102no. flags PVPM Figure 1. The relationship between the web traffic of a website ( x-axis) and the number of flags it received on Facebook ( y-axis). Traffic is expressed in PPVM, which indicates what fraction of all the page views by Alexa toolbar users go to a particular site.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000202  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  reasons, in the paper, we will refer to them as two different models with two different names, which makes the comparisoneasier to grasp. In the following, we start by giving a general overview of the bipolar model (§2.1). In the subsequent sections, we provide themodel details, motivating each choice on the basis of real-worlddata. We conclude by showing the crucial differences betweenthe bipolar and monopolar models (§2.5). We note that our model shares some commonalities with the bounded confidence model [27]. 2.1. Model overview Figure 2 shows a general depiction of the bipolar model. In the bipo-lar model, we have two kinds of agents: news sources and users. News sources are characterized by three values: popularity, polarity and truthfulness. The popularity distributes broadly:there are a few big players with a large following while themajority of sources are followed by only a few users. The polaritydistributes quasi-normally. Most sources are neutral and there areprogressively fewer and fewer sources that are more polarized.Truthfulness is linked to polarity, with more polarized sourcestending to be less truthful. This implies that most news sourcesare truthful, and less trustworthy sources are more and morerare. Each news item has the same polarity and truthfulnessvalues as the news source publishing it. Users only have polarity. The polarity of the users distributes in the same way as that of the news sources. Most users aremoderate and extremists are progressively more rare. Usersfollow news sources, preferentially those of similar polarity(selective exposure). Users embed in a social network, preferen- tially being friends of other users of similar polarity (homophily). A user can see a news item if the item is either published by a source the user is following or reshared by one of their friends. Ineither case, the user can do one of three things: 1. reshare —if the polarity of the item is sufficiently close to their own andthe item is sufficiently truthful; 2. flag —if the polarity of the item is sufficiently different from their own orthe item is not truthful enough; 3. consume —in all other cases, meaning that the item does not propagate and nor is it flagged. We expect the bipolar model to produce mostly flags in the moderate and truthful part of the spectrum. We base this expec-tation on the following reasoning. Since most news sources aremoderate and truthful, the few very popular sources are over- whelmingly more likely to be moderate and truthful. Thus wewill see more moderate and truthful news items, which aremore likely to be reshared. This resharing activity will causethe news items published by the moderate and truthful newssources to be shared to the polarized parts of the network.Here, given that the difference between the polarization of theuser and the polarization of the source plays a role in flaggingeven relatively truthful items, moderate and truthful newsitems are likely to be flagged. Polarized and untruthful items, on the other hand, are unli- kely to be reshared. Because of the polarization homophily thatcharacterizes the network structure, they are unlikely to reachthe more moderate parts of the network. If polarized itemsare not shared, they cannot be flagged. A neutral item is morelikely to be shared, and thus could reach a polarized user, whowould flag it. Thus, most flags will hit moderate and truthfulnews items, rendering the whole flagging mechanism unsuitablefor discovering untruthful items. 2.2. Agents In this section, we detail how we build the main agents in ourmodel: the news sources and the users. As mentioned previously, news sources have a certain popu- larity. The popularity of a news source is the number of usersfollowing it. We generate the source popularity distribution asa power law. This means that the vast majority of news sourceshave a single follower, while the most popular sources have thousands of followers. This is supported by real-world data. Figure 3 ashows the complement cumulative distribution of the number of followersof Facebook pages. These data come from CrowdTangle. 4As we can see, the distribution has a long tail: two out of three Face-book pages have 10 000 followers or fewer. The most popularpages are followed by more than 60 million users. As for the user and source polarities ( p uand pi), we assume that they distribute quasi-normally. We create a normal distributionwith average equal to zero and standard deviation equal to 1.Then we divide it by its maximum absolute value to ensure thatthe distribution fully lies between −1 and 1. In this way we ensure that most users are moderates; more extreme users/sourcesare progressively more rare, at both ends of the spectrum. This is also supported by the literature [28] and by real-world data. Figure 3 bshows the distribution of political leaning in the USA across time [29], collected online. 5These data were collectedsourcespopularity polarity truth userspolarit ypublish reshare degreefrom friend flagfi,u =ti |pi – pu| consumefi,u = 1 –fi,u fi,u + 1 fi,u &lt; r fi,u &gt; f Figure 2. The overview of the bipolar model. From left to right, we show: the characteristics of the agents (source ’s polarities, popularity and truthfulness; and user ’s polarity); the model ’s structures (the bipartite source –user follower network and the unipartite user –user social network); and the agents ’actions (source publishing and users resharing, consuming and flagging news items).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000203  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  by surveying a representative sample of the US electorate via phone and face-to-face interviews. While not perfectly normally distributed, the data show that the majority of Americans either feel they are moderate or do notknow to which side they lean. ‘Moderate ’or‘don’t know ’is always the mode of the distribution, and their combinationis always the plurality option. Finally, sources have a degree of truthfulness t i. Here, we make the assumption that this is correlated with the newssource ’s polarity. The more a source is polarized, the less it is interested in the actual truth. A polarized source wants tobring readers onto their side, and their ideology clouds theirbest judgement of truthfulness. This reasonable assumption isalso supported by the literature [30]. Mathematically , this means that t i=1−|pi|+ϵ, with −0.05≤ ϵ≤0.05 being extracted uniformly at random, ensuring then that ti remains between 0 and 1 by capping it to these values. 2.3. Structures There are two structures in the model: the user –source bipartite network and the user –user social network. 2.3.1. User –source network The user –source network connects users to the news sources they are following. This is the primary channel through which usersare exposed to news items. We fix the degree distribution of the sources to be a power law, as we detailed in the previous section. The degree distribution ofthe user depends on the other rules of the model. There is a certainnumber of users with degree zero in this network. These users donot follow any news source and only react to what is shared bytheir circle of friends. We think this is reasonably realistic. We connect users to sources to maximize polarity homophily. The assumption is that users will follow news organizationssharing their polarity. This assumption is supported by theliterature [31,32]. For each source with a given polarity and popularity, we pick the required number of individuals with polarity values in aninterval around the source polarity. For instance, if a sourcehas popularity of 24 and polarity of 0.5, we will pick the 24users whose polarity is closest to 0.5 and we will connect themto the source. 2.3.2. Social network Users connect to each other in a social network. The social net-work is the channel through which users are exposed to newsitems from sources they are not following.We aim at creating a social network with realistic character- istics. For this reason, we generate it via an Lancichinetti – Fortunato –Radicchi (LFR) benchmark 6[33]. The LFR benchmark ensures that the social network has a community structure, abroad degree distribution, and communities are overlapping,i.e. they can share nodes. All these characteristics are typical ofreal-world social networks. We fix the number of nodes to≈16 000, while the number of communities is variable and not fixed by the LFR ’s parameters. We need an additional feature in the social network: polarity homophily. People are more likely to be friends with like-mindedindividuals. This is supported by studies of politics on socialmedia [34]. We ensure homophily by iterating over all communitiesgenerated by the LFR benchmark and assigning to users grouped inthe same community a portion of the polarity distribution. For instance, if a community includes 12 nodes, we take 12 con- secutive values in the polarity distribution and we assign themto the users. This procedure generates extremely high polarityassortativity. The Pearson correlation of the polarity values at thetwo endpoints of each edge is ≈0.89. 2.4. Actions A news source publishes to all the users following it an item i carrying the source ’s polarity piand truthfulness ti. Every time a user sees an item i, it calculates how acceptable the item is, using the function fi,u. An item is acceptable if it is (i) truthful and (ii) it is not far from the user in the polarity spectrum — experiments [35] show how this is a reasonable mechanics:users tend to trust more sources with a similar polarity to theirown. Mathematically, (i) means that f i,uis directly proportional toti; while (ii) means that fi,uis inversely proportional to the difference between piand pu fi,u¼ti jpi/C0puj: The acceptability function fi,uhas two issues: first, its domain spans from 0 (if ti=0 )t o+ ∞(ifpi=pu). This can be solved by the standard transformation x/(x+ 1), which is always between 0 and 1 if x≥0. Second, for the discussion of our parameters and results, it is more convenient to estimate a degree of ‘unacceptability ’, which is the opposite of the acceptability fi,u. This can be achieved by the standard transformation 1 −x. Putting the two transformations together, the unacceptability fi,uof item ifor user uis fi,u¼1/C0fi,u fi,uþ1:10–410–310–210–11 1 10 102103p (followers ≥ x) followers (×10 k)0100200300400500600700 EL L SL M DK SC C ECcount polarit y(b)(a) Figure 3. (a) The cumulative distribution of source popularity on Facebook in our dataset: the probability ( y-axis) of a page to have a given number of followers or more ( x-axis). ( b) The polarity distribution in the USA from 1994 (light) to 2016 (dark). Biannual observation, except for missing years 2006, 2010 and 2014. EL, extremely liberal; L, liberal; SL, slightly liberal; M, moderate; DK, don ’t know; SC, slightly conservative; C, conservative; EC, extremely conservative.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000204  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  Users have a finite tolerance for how unacceptable a news item can be. If the item exceeds this threshold, meaning fi,u.f, the user will flag the item. On the other hand, if the news item has low to zero unacceptability, meaning fi,u,r, the user will reshare it to their friends. If r/C20fi,u/C20f, the user will neither flag nor reshare the item. The parameters ϕand ρregulate which and how many news items are flagged, and thus we need to tune them to generaterealistic results —as we do in the Results section. 2.5. Monopolar model The monopolar model is the result of removing everything related to polarity from the bipolar model. The sharing and flag-ging criteria are the same as in the bipolar model —testing fi,u against the ρand ϕparameters, with the difference being in how fi,uis calculated. The unacceptability of a news item is now simply the opposite of its truthfulness, i.e. fi,u¼1/C0ti. Moreover, in the monopolar model users connect to random news sources and there is no polarity homophily in thesocial network. The monopolar model attempts to reproduce the assumption of real-world crowdsourced flagging systems: only the least truthfularticles are flagged. However, we argue that it is not a good rep-resentation of reality because truthfulness assessment is not anobjective process: it is a subjective judgement and it includes pre-existing polarization of both sources and users. The bipolar modelcan capture such polarization while the monopolar model cannot. 2.6. Example To understand what happens in the bipolar and monopolarmodels, consider figure 4 as a toy example. Table 2 a,bcalculates fi,ufor all user –source pairs in the bipolar and monopolar models, respectively. Table 3 a,bcounts the number of flags received by each source for different combinations of the ρand ϕparameters in the bipolar and monopolar models, respectively. A few interesting differences between the bipolar and monopolarmodels appear. In the monopolar model, only the direct audience of a source can flag its news items and, if one member of the direct audienceflags, so will all of them. This is because fi,uis equal for all nodes, thus either fi,u.fand the entire audience will flag the item (and no one will reshare it) or fi,u,rand the entire network —not just the audience —will reshare the item, and no one will ever flag it. This is not true for the bipolar model. S1 (figure 4) can be either flagged by its entire audience ( ϕ= 0.14); by part of its audi- ence ( ϕ= 0.3); or by nodes who are not in its audience at all (users U5 and U6 for ϕ= 0.44; or user U7 for ϕ= 0.6). On the other hand, in our examples, S2 is never flagged by its audience (U7). WhenS2 is flagged, it is always because it percolated to a user for which fi,u.f, via a chain of users for which fi,u,r, because fi,uis not constant across users any longer. 3. Results 3.1. Parameter tuning Before looking at the results of the model, we need to identify the range of parameter values that can support robust andU5S2 S1 U3 U1 U7 U2 U4 U6pi = 0.5 ti = 0.55 pu = 0.8 pu = 0.6 pu = 0.4 pu = 0.2 pu = –0.2 pu = –0.45 pu = 0pi = –0.5 ti = 0.45 Figure 4. Two simple structures with sources (squares) and users (circles). Edges connect sources to the users following them and users to their friends. Each s ource has an associated tiand pivalue and each user has an associated puvalue next to their respective nodes. Table 2. The fi,uvalue for each user –source pair from ﬁgure 4 in the ( a) bipolar and ( b) monopolar models. (a) bipolar ’sfi,u (b) monopolar ’sfi,u user S1 S2 user S1 S2 U1 0.35 0.74 U1 0.45 0.55 U2 0.15 0.71 U2 0.45 0.55 U3 0.15 0.66 U3 0.45 0.55 U4 0.35 0.61 U4 0.45 0.55U5 0.48 0.52 U5 0.45 0.55 U6 0.56 0.40 U6 0.45 0.55 U7 0.62 0.10 U7 0.45 0.55 Table 3. The number of ﬂags each source in ﬁgure 4 gets in the ( a) bipolar and ( b) monopolar models, for varying values of ρandϕ. (a) bipolar ( b) monopolar ρϕ S1 S2 ρϕ S1 S2 0.67 0.7 0 2 0.67 0.7 0 0 0.57 0.6 1 1 0.57 0.6 0 0 0.49 0.54 1 1 0.49 0.54 0 1 0.36 0.44 2 0 0.36 0.44 4 10.2 0.3 2 1 0.2 0.3 4 1 0.1 0.6 0 0 0.1 0.6 0 0 0.1 0.5 0 0 0.1 0.5 0 1 0.1 0.14 4 0 0.1 0.14 4 1royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000205  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  realistic results. The most important of the two parameters isϕ, because it determines the number of flags generated in the system. Figure 5 ashows the total number of flags generated per value of ϕ. As expected, the higher the ϕ, the fewer the flags, as the user finds more news items acceptable. The sharp drop means that, for ϕ&gt; 0.6, we do not have a sufficient number of flags to support our observation of the model ’s be- haviour. Thus, hereafter, we will only investigate the behaviour of the model for ϕ≤0.6. ρis linked to ϕ; specifically , its value is capped by ϕ. Aworld with ρ≥ϕis unreasonable, because it would be a scenario where a user feels enough indignation by an item that theywill flag it, but then they will also reshare it to their social network. Thus, we only test scenarios in which ρ&lt;ϕ. Another important question is what combination of ϕand ρvalues generates flags that can reproduce the observed relation between source popularity and the number of flagswe see in figure 1. To do so, we perform a grid search, testing many combinations of ϕ–ρvalues. Our quality criterion is the absolute difference in the slope of the power fit betweenpopularity and the number of flags. The lower the difference, the better the model is able to approximate reality. Figure 5 bshows such a relationship. We can see that there is an area of high performance at all levels of ϕ. 3.2. Bipolar model Figure 6 shows the distribution of the polarity of the flagged news items, for different values of ϕand setting ρ= 0.08, an interval including the widest spectrum of goodness of fit asshown in figure 5 b. We run the model 50 times and take the average of the results, to smooth out random fluctuations. We can see that our hypothesis is supported: in a polarized environment the vast majorityofflagged news items are neutral. This happens for ϕ≤0.3, which, as we saw in figure 5 b,i st h e most realistic scenario. For ϕ≥0.4, our hypothesis would not be supported, but, as we can see in figure 5 b, this is the area in red, where the model is a bad fit for the observations anyway —since here we are looking at ρ= 0.08 results. Figure 7 shows the distribution of truthfulness of the flagged items. These distributions show that, by flagging following their individual polarization, users in the bipolarmodel end up flagging the most truthful item they can —if ϕis high enough, items with t i∼1 cannot be flagged almost regardless of the polarity difference.The two observations put together mean that, in the bipolar model, the vast majority of flags come from extremists who are exposed to popular neutral and truthful news. The extremists do not follow the neutral and truthful news sources, but getin contact with neutral and truthful viewpoints because of their social network. The bipolar model results —in accordance with the obser- vation from figure 1 —suggest that more popular items are s h a r e dm o r ea n dt h u sf l a g g e dm o r e .O n ec o u l db et e m p t e dt o identify and remove fake news items by taking the ones receivingmore than their fair shares of flags given their popularity. How- ever, such a simple system would not work in reality. Figure 1 is based on data coming after Facebook ’s machine learning pre- processor, the aim of which is to minimize false positives. 7 Thus, even after controlling for a number of factors —source popularity, reputation, etc. —most reported flags still end up attached to high-popularity, high-reputability sources. 3.3. Monopolar model In the monopolar model, we remove all aspects related topolarity, thus we cannot show the polarity distribution of the flags. Moreover, as we have shown in §2.6, the effect ofρand ϕis marginal. Thus we only show in figure 8 the truth- fulness distribution of the flags, for only ϕ= 0.1 and ρ= 0.08, noting that all other parameter combinations result in apractically identical distribution. The monopolar results show the flag truthfulness distribution as the ideal result. The distribution shows a dispro-portionate number of flags going to low truthfulness news items, as they should —the drop for the lowest truthfulness value is due to the fact that there are few items at that lowlevel of truthfulness, and that they are not reshared. Is this ideal result realistic? If we use the same criterion as we used for the bipolar model to evaluate the quality of themonopolar model, the answer is no. The absolute slope difference in the popularity –flag regression between obser- vation and the monopolar model is ≈0.798 for all ϕ–ρ combinations. This is a significantly worse performance than the worst-performing versions of the bipolar model — figure 5 bshows that no bipolar version goes beyond a slope difference of 0.5. Thus we can conclude that the monopolar model is not a realistic representation of reality, even if we would expect it tocorrectly flag the untruthful news items. The bipolar model is a better approximation, and results in flagging truthful news items. 0.1 0.2 0.3 0.4 0.5 0.6 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45r 00.050.100.150.200.250.300.350.400.450.50 abs slo pe difference 02.0 × 1054.0 × 1056.0 × 1058.0 × 1051.0 × 1061.2 × 1061.4 × 1061.6 × 1061.8 × 1062.0 × 106 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9no. flags ff(b) (a) Figure 5. (a) The number of flags ( y-axis) in the bipolar model for different values of ϕ(x-axis). ( b) The slope difference (colour; red = high, green = low) between the real world and the bipolar fit between the source popularity and the number of flags received, per combination of ϕandρvalues ( x–yaxis).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000206  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  3.4. Robustness Our bipolar model makes a number of simplifying assumptions that we need to test. First, we are showing results for a model in which all news sources have the same degree of activity ,meaning that each source will publish exactly one news item. This is not realistic: data from Facebook pages show that there is a huge degree of activity heterogeneity (figure 9 a). There is a mild positive correlation between the popular- ity of a page and its degree of activity (log-log Pearson correlation of ≈0.12; figure 9 b). For this reason, we use the real-world distribution of page popularity and we lock it in with its real-world activity level. This is the weighted bipolar model, in which each synthetic news source is the model ’s equivalent of a real page, with its popularity and activity. A second simplifying assumption of the bipolar model is that the reshareability and flaggability parameters ρand ϕarethe same for every individual in the social network. However, people might have different trigger levels. Thus we create thevariable bipolar model, where each user has its own ρ uand ϕu. These values are distributed normally, with their average /C22r¼0:08 (and standard deviation 0.01) and /C22fdepending on which average value of ϕwe are interested in studying (with the standard deviation set to one-eighth of /C22f). Figure 10 shows the result of the weighted and variable variants against the original bipolar model. In figure 10 a, we report the dispersion (standard deviation) of the polariz- ation values of the flags. A low dispersion means that flagscluster in the neutral portion of the polarity spectrum, mean- ing that most flags signal neutral news items. In figure 10 b, we report the average truthfulness of flagged items. We can see that taking into account the pages ’activities increases the dispersion by a negligible amount and only020406080100120140no. flags polarity010203040506070no. flags polarity 0510152025 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0no. flags polarity012345678no. flags polarity 00.20.40.60.81.01.21.4 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0–1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0–1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0 –1.0–0.9–0.8–0.7–0.6–0.5–0.4–0.3–0.2–0.100.10.20.30.40.50.60.70.80.91.0no. flags polarity00.010.020.030.040.050.060.070.080.090.10no. flags polarity(e)( f)(b) (a) (c) (d) Figure 6. Flag count per polarity of items at different flaggability thresholds ϕfor the bipolar model. Reshareability parameter ρ= 0.08. Average of 50 runs. (a)ϕ= 0.1, ( b)ϕ= 0.2, ( c)ϕ= 0.3, ( d)ϕ= 0.4, ( e)ϕ= 0.5 and ( f)ϕ= 0.6.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000207  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  for high values of ϕ. This happens because there could be some extremely active fringe pages spamming fake content, which increases the likelihood of extreme flags. There is no difference in the average truthfulness of flagged items. Having variable ϕandρvalues, instead, actually decreases dispersion, making the problem worse —although only for larger values of ϕ. In this configuration, a very tolerant society with high (average) ϕwould end up flagging mostly neutral reporting —as witnessed by the higher average truthfulness of the reported items. This is because lower-than-average ρu users will be even less likely to reshare the most extreme news items. So far we have kept the reshareability parameter constant atρ= 0.08. If we change ρ(figure 11) the dispersion of a flag ’s polarity (figure 11 a) and its average truthfulness value (figure 11 b) do not significantly change. The changes are050100150200250 00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0 00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0 0.00.10.20.30.40.50.60.70.80.91.000.10.20.30.40.50.60.70.80.91.0no. flags truthfulness020406080100120140no. flags truthfulness 05101520253035404550no. flags truthfulness0246810121416no. flags truthfulness 00.51.01.52.02.53.0no. flags truthfulness00.020.040.060.080.100.120.140.160.180.20no. flags truthfulness(e)( f)(b) (a) (c) (d) Figure 7. Flag count per truthfulness of items at different flaggability thresholds ϕfor the bipolar model. Reshareability parameter ρ= 0.08. Average of 50 runs. (a)ϕ= 0.1, ( b)ϕ= 0.2, ( c)ϕ= 0.3, ( d)ϕ= 0.4, ( e)ϕ= 0.5 and ( f)ϕ= 0.6. 00.51.01.52.02.53.03.54.0 00.10.20.30.40.50.60.70.80.91.0no. flags truthfulness Figure 8. Flag count per truthfulness of items for the monopolar model for ϕ= 0.6. Average of 50 runs.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000208  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  10–410–310–210–11 1 10 102103p (shares ≥x) shares01234567 00.5 1.0 1.5 2.0 2.5 3.0 3.5log (followers) log (shares) 110102 no. sources(b) (a) Figure 9. (a) The cumulative distribution of source activity in Facebook in our dataset: the probability ( y-axis) of a news source sharing a given number of items or more ( x-axis). ( b) The relationship between activity ( x-axis) and popularity ( y-axis) in our Facebook dataset. 00.10.20.30.40.50.6s(pi)bipolar weighted variable 00.10.20.30.40.50.60.70.80.9 0.1 0.2 0.3 0.4 0.5 0.6m(ti) f0.1 0.2 0.3 0.4 0.5 0.6 fbipolar weighted variable(b) (a) Figure 10. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items in the bipolar model and its weighted and variable variants.s(pi) 0.1 0.2 0.3 0.4 0.5 0.6m(ti) f0.1 0.2 0.3 0.4 0.5 0.6 f(b) (a) 00.10.20.30.40.50.6 r = 0.03 r = 0.04 r = 0.05 r = 0.06 r = 0.07 r = 0.08 00.10.20.30.40.50.60.70.80.9 r = 0.03 r = 0.04 r = 0.05 r = 0.06 r = 0.07 r = 0.08 Figure 11. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items for different values of reshareability ρ.s(pi) m(ti) 0.1 0.2 0.3 0.4 0.5 0.6 f0.1 0.2 0.3 0.4 0.5 0.6 f(b) (a) 00.10.20.30.40.50.60.7 bipolar no-homophily no-community 00.10.20.30.40.50.60.70.80.91.0 bipolar no-homophily no-community Figure 12. Dispersion of polarization ( a) and average truthfulness ( b) of the flagged items in the bipolar and alternative models.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 202000209  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  due to the fact that ρsimply affects the number of flags: a higher ρmeans that users are more likely to share news items. More shares imply more news items percolating through the social network and thus more flags. The bipolar model contains many elements besides the ρ and ϕparameters. For instance, it imposes that the social net- work has several communities and that social relationshipsare driven by homophily. These two elements are based on existing literature, yet we should test their impact on the model. First, keeping everything else constant, the no-homophily variant allows users to connect to friends ignoring their polarity value. In other words, polarity is randomly distribu- ted in the network. Second, keeping everything else constant,the no-community variant uses an Erdo ̋s–Rényi random graph as the social network instead of an LFR benchmark. The Erdo ̋s–Rényi graph extracts connections between nodes uniformly at random and thus it has, by definition, no com- munity structure. Figure 12 shows the impact on flag polarity dispersion (figure 12 a) and average truthfulness (figure 12 b). The no-homophily variant of the bipolar model has a significantly higher dispersion in the flag polarity distribution, and lowertruthfulness average, and the difference is stable (though stronger for values of ρabove 0.3). This means that polarity homophily is playing a key role in ensuring that flags are pre-dominantly assigned to neutral news items: if we remove it, the accuracy in spotting fake news increases. In contrast, removing the community structure from the net- work will result in a slightly smaller dispersion of flag ’s polarity and higher average flag truthfulness. The lack of communities might cause truthful items to spread more easily, and thus beflagged, increasing the average flag truthfulness. 4. Discussion In this paper, we show how the assumption of traditionalcrowdsourced content policing systems is unreasonable. Expecting users to flag content carries the problematic assump- tion that a user will genuinely attempt to estimate the veracityof a news item to the best of their capacity. Even if that was a reasonable expectation to have, a user ’s estimation of veracity will be made within their individual view of the world andvariable polarization. This will result in assessments that will give an easier pass to biased content if they share such bias. This hypothesis is supported by our bipolar agent-basedmodel. The model shows that even contexts that are extremely tolerant towards different opinions, represented by our flagg- ability parameter ϕ, would still mostly flag neutral content, and produce results that fit well with observed real-world data. Moreover, by testing the robustness of our model, we show how our results hold both for the amount of heterogen-eity of source activity and for individual differences in both tolerance and propagation attitudes. Removing polarization from the model, and thus testing what we defined as the monopolar model, attempts to repro- duce the assumptions that would make a classical content policy system work. The monopolar model, while seeminglybased on reasonable assumptions, is not largely supported by established literature in the area of online behaviour and social interaction, differently from the bipolar model.Moreover, it is not able to deliver on its promises in terms of ability to represent real-world data.Our paper has a number of weaknesses and possible future directions. First, our main results are based on a simu- lated agent-based model. The results hold as long as the assumptions and the dynamics of the models are an accurateapproximation of reality. We provided evidence to motivate the bipolar model ’s assumptions, but there could still be fac- tors unaccounted for, such as the role of originality [36] or ofspreaders ’effort [37] in making content go viral. Second, many aspects of the model were fixed and should be investi- gated. For instance, there is a strong polarity homophilybetween users and news sources, and in user –user connec- tions in the social network. We should investigate whether such strong homophily is really supported in real-world scen-arios. Third, the model has an essentially static structure. The users will never start/stop following news sources, nor befriend/unfriend fellow users. Such actions are commonin real-world social systems and should be taken into account. Fourth the model only assumes news stories worth interacting with. This is clearly different from the realitywhere, in a context of overabundant information, most stories are barely read and collect few reshares or flags. Including those news stories in the model could certainly affect theoverall visibility of other items. Finally, the model does not take into account reward and cost functions for both users and news sources. What are the repercussions for a newssource of having its content flagged? Should news sources attempt to become mainstream and gather following? Such reward/cost mechanisms are likely to greatly influence ouroutcomes. We plan to address the last two points in future expansions of our model. Ethics. No individual-level data have been accessed in the develop- ment of this paper. The paper ’s experiments rely on synthetic simulations. Motivating data provided by the Social Science Research Council fulfil the ethical criteria required by Social Science One. Data accessibility. The archive containing the data and code necessary for the replication of our results can be found at http://www.michelec-oscia.com/wp-content/uploads/2020/03/20200304_ffff.zip Authors ’contributions. L.R. collected the data. M.C. performed the exper- iments. M.C. and L.R. jointly designed the study, analysed the data, prepared the figures, and wrote and approved the manuscript. Competing interests. We declare we have no competing interest. Funding. No funding has been received for this article. Acknowledgements. This study was supported in part by a dataset from the Social Science Research Council within the Social Data Initiative. CrowdTangle data access has been provided by Facebook in collabor- ation with Social Science One. The authors also thank Fabio Gigliettoand the LaRiCA, University of Urbino Carlo Bo, for data access, and Clara Vandeweerdt for insightful comments. Endnotes 1https://www.facebook.com/facebookmedia/blog/working-to- stop-misinformation-and-false-news (April 2017, date of access 3 March 2020). 2https://socialscience.one/blog/unprecedented-facebook-urls-data- set-now-available-research-through-social-science-one (February 2020, date of access 3 March 2020). 3From a least-squares fit in a log-log space. Alternative hypotheses such as linear relationship or exponential relationship are discarded, with p-values approximately 0.98 and 0.34, respectively. 4https://www.crowdtangle.com/ 5https://electionstudies.org/resources/anes-guide/top-tables/?id= 29 (date of access 11 November 2019). 6https://sites.google.com/site/andrealancichinetti/files 7https://about.fb.com/news/2018/06/increasing-our-efforts-to- fight-false-news/ (date of access 7 January 2020).royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 2020002010  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022  References 1. Newman N, Fletcher R, Kalogeropoulos A, Nielsen R. 2019 Reuters institute digital news report 2019 , vol. 2019. Oxford, UK: Reuters Institute for the Study of Journalism. 2. Allcott H, Gentzkow M. 2017 Social media and fake news in the 2016 election. J. Econ. Perspect. 31, 211 –36. (doi:10.1257/jep.31.2.211) 3. Lazer DMJ et al. 2018 The science of fake news. Science 359, 1094 –1096. (doi:10.1126/science. aao2998) 4. Vosoughi S, Roy D, Aral S. 2018 The spread of true and false news online. Science 359, 1146 –1151. (doi:10.1126/science.aap9559) 5. Adamic LA, Glance N. 2005 The political blogosphere and the 2004 US election: divided they blog. In Proc. of the 3rd Int. Workshop on Link Discovery, Chicago, IL, 21 –24 August 2005 , pp. 36 –43. New York, NY: ACM. 6. Garrett RK. 2009 Echo chambers online? Politically motivated selective exposure among internet news users. J. Comput.-Mediated Commun. 14, 265 –285. (doi:10.1111/j.1083-6101.2009.01440.x) 7. Nikolov D, Oliveira DFM, Flammini A, Menczer F. 2015 Measuring online social bubbles. PeerJ Comput. Sci. 1, e38. (doi:10.7717/peerj-cs.38) 8. Quattrociocchi W, Scala A, Sunstein CR. 2016 Echo chambers on Facebook. See https://papers.ssrn.com/ sol3/papers.cfm?abstract_id=2795110. 9. Flaxman S, Goel S, Rao JM. 2016 Filter bubbles, echo chambers, and online news consumption. Public Opin. Q. 80, 298 –320. (doi:10.1093/poq/ nfw006) 10. Dubois E, Blank G. 2018 The echo chamber is overstated: the moderating effect of politicalinterest and diverse media. Inf. Commun. Soc. 21, 729 –745. (doi:10.1080/1369118X.2018.1428656) 11. Del Vicario M, Vivaldo G, Bessi A, Zollo F, Scala A, Caldarelli G, Quattrociocchi W. 2016 Echo chambers: emotional contagion and group polarization on Facebook. Sci. Rep. 6, 37825. (doi:10.1038/ srep37825) 12. Garimella K, De Francisci Morales G, Gionis A, Mathioudakis M. 2018 Political discourse on socialmedia: echo chambers, gatekeepers, and the price of bipartisanship. In Proc. of the 2018 World Wide Web Conference, Lyon, France, 23 –27 April 2018 , pp. 913 –922. Geneva, Switzerland: International World Wide Web Conferences Steering Committee. 13. An J, Quercia D, Crowcroft J. 2013 Fragmented social media: a look into selective exposure to political news. In Proc. of the 22nd Int. Conf. on World Wide Web, Rio de Janeiro, Brazil, 13 –17 May 2013 , pp. 51 –52. New York, NY: ACM.14. Bakshy E, Messing S, Adamic LA. 2015 Exposure to ideologically diverse news and opinion on Facebook. Science 348, 1130 –1132. (doi:10.1126/science. aaa1160) 15. Conroy NJ, Rubin VL, Chen Y. 2015 Automatic deception detection: methods for finding fake news. Proc. Assoc. Inf. Sci. Technol. 52,1–4. (doi:10.1002/ pra2.2015.145052010082) 16. Shu K, Sliva A, Wang S, Tang J, Liu H. 2017 Fake news detection on social media: a data miningperspective. ACM SIGKDD Explor. Newsl. 19,2 2 –36. (doi:10.1145/3137597.3137600) 17. Wei W, Wan X. 2017 Learning to identify ambiguous and misleading news headlines. In Proc. of the 26th Int. Joint Conf. on Artificial Intelligence, Melbourne, Australia, 19 –25 August 2017 , pp. 4172 –4178. Palo Alto, CA: AAAI Press. 18. Li Y, Li Q, Gao J, Su L, Zhao B, Fan W, Han J. 2015 On the discovery of evolving truth. In Proc. of the 21th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, Sydney, Australia, 10 –13 August 2015 , pp. 675 –684. New York, NY: ACM. 19. Wu L, Liu H. 2018 Tracing fake-news footprints: characterizing social media messages by how they propagate. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, CA, 5 –9 February 2018 , pp. 637 –645. New York, NY: ACM. 20. Tschiatschek S, Singla A, Gomez Rodriguez M, Merchant A, Krause A. 2018 Fake news detection in social networks via crowd signals. In Companion Proc. of the Web Conf. 2018, Lyon, France, 23 –27 April 2018 , pp. 517 –524. Geneva, Switzerland: International World Wide Web Conferences Steering Committee. 21. Giglietto F, Iannelli L, Valeriani A, Rossi L. 2019 ‘Fake news ’is the invention of a liar: how false information circulates within the hybrid news system. Curr. Sociol. 67, 625 –642. 22. Myslinski LJ. 2013 Social media fact checking method and system, 4 June 2013. US Patent 8,458,046. 23. Kim J, Tabibian B, Oh A, Schölkopf B, Gomez- Rodriguez M. 2018 Leveraging the crowd to detect and reduce the spread of fake news and misinformation. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, 5 –9 February 2018 , pp. 324 –332. New York, NY: ACM. 24. Crawford K, Gillespie T. 2016 What is a flag for? Social media reporting tools and the vocabulary of complaint. New Media Soc. 18, 410 –428. (doi:10. 1177/1461444814543163) 25. Gillespie T. 2018 Custodians of the Internet: platforms, content moderation, and the hidden decisions that shape social media . New Haven, CT: Yale University Press.26. Messing S, State B, Nayak C, King G, Persily N. 2018 Facebook URL Shares. See https://doi.org/10.7910/ DVN/EIAACS. 27. Mathias J-D, Huet S, Deffuant G. 2016 Bounded confidence model with fixed uncertainties and extremists: the opinions can keep fluctuating indefinitely. J. Artif. Soc. Soc. Simul. 19, 6. (doi:10. 18564/jasss.2967) 28. Giglietto F, Iannelli L, Rossi L, Valeriani A, Righetti N, Carabini F, Marino G, Usai S, Zurovac E. 2018Mapping italian news media political coverage in the lead-up to 2018 general election. See https:// papers.ssrn.com/sol3/papers.cfm?abstract_id=3179930. 29. American National Election Studies. 2008 The ANES guide to public opinion and electoral behavior. Seehttps://electionstudies.org/resources/anes-guide/ top-tables/?id=29. 30. Lewandowsky S, Ecker UKH, Cook J. 2017 Beyond misinformation: understanding and coping with the ‘post-truth ’era. J. Appl. Res. Memory Cogn. 6, 353 –369. (doi:10.1016/j.jarmac.2017.07.008) 31. Iyengar S, Hahn KS, Krosnick JA, Walker J. 2008 Selective exposure to campaign communication: the role of anticipated agreement and issue publicmembership. J. Politics 70, 186 –200. (doi:10.1017/ S0022381607080139) 32. Stroud NJ. 2008 Media use and political predispositions: revisiting the concept of selective exposure. Pol. Behav. 30, 341 –366. (doi:10.1007/ s11109-007-9050-9) 33. Lancichinetti A, Fortunato S, Radicchi F. 2008 Benchmark graphs for testing community detection algorithms. Phys. Rev. E 78, 046110. (doi:10.1103/ PhysRevE.78.046110) 34. Conover MD, Ratkiewicz J, Francisco M, Gonçalves B, Menczer F, Flammini A. 2011 Political polarizationon twitter. In Proc. 5th Int. AAAI Conf. on Weblogs and Social Media, Barcelona, Spain, 17 –21 July 2011. Palo Alto: AAAI Press. 35. Swire B, Berinsky AJ, Lewandowsky S, Ecker UKH. 2017 Processing political misinformation: comprehending the Trump phenomenon. R. Soc. open sci. 4, 160802. (doi:10.1098/rsos.160802) 36. Coscia M. 2017 Popularity spikes hurt future chances for viral propagation of protomemes. Commun. ACM 61,7 0 –77. (doi:10.1145/3158227) 37. Pennacchioli D, Rossetti G, Pappalardo L, Pedreschi D, Giannotti F, Coscia M. 2013 The threedimensions of social prominence. In Proc. Int. Conf. on Social Informatics, Kyoto, Japan, 25 –27 November 2013 , pp. 319 – 332. New York, NY: Springer.royalsocietypublishing.org/journal/rsif J. R. Soc. Interface 17: 2020002011  Downloaded from https://royalsocietypublishing.org/ on 27 November 2022</td>
    </tr>
    <tr>
      <th>9</th>
      <td>poli</td>
      <td>© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.A reprint from American Scientist the magazine of Sigma Xi, The Scientific Research Society This reprint is provided for personal and noncommercial use. For any other use, please send a request to Permissions,  American Scientist, P .O. Box 13975, Research Triangle Park, NC, 27709, U.S.A., or by electronic mail to perms@amsci. org. ©Sigma Xi, The Scientific Research Society and other rightsholders 542     American Scientist, Volume 94© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.The summer of 1994 was our first season to - gether in the Chernobyl Exclusion Zone, a  region within a 30-kilometer radius of the Cher - nobyl Nuclear Power Plant. We were there to  investigate the long-term biological effects of  ionizing radiation following the catastrophic ex - plosion and fire at reactor number four on April  26, 1986, which released plumes of radionu - clides that spread across Europe. We were only  2 kilometers from the defunct power plant, and  the area was still so radioactive that our Geiger  counters were perpetually abuzz. Although the  “Zone” was now nearly deserted—more than  135,000 people had been evacuated from the  region—we were amazed by the diversity of  mammals living in the shadow of the ruined  reactor only eight years after the meltdown. The  odd juxtaposition was eerily reminiscent of one  of the creepier Twilight Zone  episodes. We were in an area known as the “red for - est,” so named from the predominant hue of  the trees, which had been discolored in death  by the radiation. All the pine trees were dead;  only birches remained. During our excursion  through the woods, we trapped some of the local  mice for examination in a makeshift laboratory .  We were surprised to find that although each  mouse registered unprecedented levels of ra - diation in its bones and muscles, all the animals  seemed physically normal, and many of the fe - males were carrying normal-looking embryos.  This was true for pretty much every creature we  examined—highly radioactive, but physically  normal. It was the first of many revelations.  We have now spent 12 years trying to sort  out the effects of a radioactive environment on  the local wildlife. We have performed a variety  of experiments in the Zone. In one of our earli - est studies, we found that the resident mouse  population did not have any obvious chromo - somal damage. We wondered whether the ab - sence of injury could be explained by some sort  of adaptive change, perhaps a more efficient  DNA -repair mechanism, after many prior gen - erations of exposure to radiation. But when we  transplanted wild mice from uncontaminated regions into cages in the red forest and then  examined their chromosomes, they were like - wise unaffected by the radiation. In at least this  respect, the mice seemed to have a natural “im - munity” to harm from radiation. We repeated  the cage experiments with Big Blue transgenic  mice—which carry a gene that glows “blue” if it  undergoes a mutation—and radiosensitive mice  to look for evidence of chromosome breakage,  genetic aberrations and changes in gene expres - sion. The genetic impacts proved to be subtle  and not likely to threaten the rodent’s repro - ductive success or longevity . We also compared  the genetic variations of populations inside the  Zone with those from relatively uncontaminat - ed areas, and we found no evidence of increased  mutation rates from exposure to radioactivity . It turns out that the nascent field of radioecol - ogy is much more complicated than we had ex - pected. Radioactive fallout from the Chernobyl  accident was not deposited uniformly around  the reactor. Distinct “excursions,” known as the  northern and western traces, carried the ash  in plumes across the countryside and through  the city of Pripyat, a mere 3 kilometers from the  power plant. This produced a mosaic of radio - active habitats that are separated by relatively  unaffected areas. Such heterogeneity makes it  difficult to evaluate the effects on animal popu - lations because animals from “clean” habitats  might migrate into the contaminated areas. The  complexity of the habitats is exacerbated by  the presence of non-radioactive pollutants. Vin - cent Bahryaktor, vice president of the Ukrainian  Academy of Sciences, has said that “Northern  Ukraine is the cleanest part of our country; it has  only radiation.” Unfortunately , this isn’t quite  true. Decades of uncontrolled waste manage - ment have contaminated the region with heavy  metals, petrochemicals and pesticides. Radiation doses have declined precipitously  since the accident—less than 3 percent of the  initial radioactivity remains. Nevertheless, the  Chernobyl Exclusion Zone still offers a unique  outdoor laboratory to examine the fate and the  effects of a radioactive environment. The aban -Growing Up with Chernobyl  Working in a radioactive zone, two scientists learn tough lessons   about politics, bias and the challenges of doing good science Ronald K. Chesser and Robert J. Baker Ronald K. Chesser is a profes - sor of biological sciences and  director of the Center for Envi - ronmental Radiation Studies at  T exas T ech University. Much  of his current research is in  reverse-engineering radioac - tive releases from nuclear ac - cidents. He continues to work  at Chernobyl and is currently  examining radioactive con - tamination and human health  issues surrounding nuclear  facilities near Baghdad, Iraq.  Robert J. Baker is Horn Profes - sor of Biological Sciences and  director of the Natural Sciences  Research Laboratory at T exas  T ech. His research program  evalulates molecular variations  in organisms exposed to Cher - nobyl radiation. He is one of  the world’s leading authorities  on the genetic variation and  phylogenetics of bat species. Ad - dress: Department of Biological  Sciences, T exas T ech University,  Lubbock, T exas 79409–3131.  Internet: ron.chesser@ttu.edu,   robert.baker@ttu.edu 2006    November–December      543 www.americanscientist.org© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.doned city of Pripyat is now largely a forest with  buildings poking above the treetops. After the  initial decline of the animal populations, which  were decimated by radioactive fallout, wildlife  is now thriving. The region has become a refuge  for released populations of Przewalski’s horse  and European bison. The population densities of  Russian wild boar are 10 to 15 times greater in the  Zone than in adjacent areas inhabited by people.  Endangered black storks and white-tailed eagles  are also more common in the Zone. The “Exclu - sion Zone” has effectively become a preserve. We were completely taken aback by what  we saw that first summer in Chernobyl, and  we continue to be challenged by what we en - counter in that strangely beautiful environ - ment. Our endeavors have led to some of the  happiest and bleakest moments in our profes - sional lives. We now recognize that we were  terribly naive about radioecology and the poli - tics of scientific research when we first started  this work. But we’ve gained some wisdom  along the way, and here we’d like to share  what we’ve learned from our experiences in  the form of brief lessons. Lesson 1:   Beautiful  theories  are often  destroyed  by ugly  facts. It may be a cliché, but it seems that nearly  everyone must learn this lesson at some point  in their scientific careers. In our case, the beau - tiful theory involved little rodents, voles of  the genus Microtus . We found a great deal of  genetic variation when we first examined the  voles within the Exclusion Zone, and because  the genetic differences were linked to different  sites within the Zone, we naturally assumed  that the variations were caused by diverse  exposures to radiation. To our chagrin, a chro - mosomal analysis revealed that we were ac - tually studying the natural variation of four  species of Microtus , not a single species, as we  had believed. It was evolutionary time, not  mutagenic radiation, that accounted for the  genetic differences we observed. What had promised to be a quick exposé of  the radiation effects from the Chernobyl fallout  proved to be a lesson in taxonomy . It also re - vealed a prejudice we had about the potential ef - fects of radiation. W e caught the error early in our  investigations, but we were still disappointed.  Figure 1. Destruction of the Chernobyl nuclear Power Plant by an explosion in reactor IV on April 26, 1986 released plumes of radioactive  particles across the countryside. The ionizing radiation resulted in a few dozen deaths within a few months, along with cancers implicated in  thousands of premature deaths. More than 135,000 people were evacuated from the zone around the plant, leaving behind the local wildlife.  The long-term effects of a radioactive environment on these inhabitants are still under investigation. The authors discuss some of the difficul - ties of assessing these effects after more than 12 years of research in the region surrounding the defunct nuclear complex.Igor Kostin/Sygma/Corbis 544     American Scientist, Volume 94© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.W e hadn’t traveled halfway across the globe and  hiked through radiation-contaminated forests  to conduct studies in species classification, but  that was exactly what we had to do if we were to  move onto the meaningful phase of our work. Lesson 2:  Real  progress  often  requires  a  change  in direction. Before we worked at Chernobyl, our expertise  was limited to evolutionary genetics. Our un -derstanding of radiation dose rates, especially  in rodents, was almost zero. When we entered  Chernobyl, most animal studies assumed that  individuals from the same location would  have similar dose rates and that the rates were  proportional to the animal’s distance from the  source, in this case a damaged reactor. Neither  of these assumptions proved to be correct.  Mice living in the same habitat vary consider - ably in how much radiation they are exposed  to externally from the soils and the vegetation,  and internally from things they have ingested.  Our analyses showed that we must examine  the internal and external doses for each indi - vidual, rather than relying on population aver - ages or the animal’s proximity to the reactor. So we immersed ourselves in the study of  radioisotopes. The predominant radionuclides  remaining in Chernobyl are strontium-90  and cesium-137. These isotopes emit differ - ent amounts of energy, through particles and  photons, so the radiation an animal receives  depends on its relative exposure to these ra - dioisotopes. Also, it turns out that cesium ac - cumulates in muscle and other soft tissues,  whereas strontium is deposited in teeth and  bones. We studied the energies of the particles  and photons emitted by these radioisotopes,  and we learned how to estimate the probabili - ties that these energies will be absorbed by  air, soil and biological tissues. These are non - Figure 2. Two radioactive plumes—the northern and Western T races—skirted the edges of Pripyat, a city in northern Ukraine inhabited by 50,000  people at the time of the accident. It’s been estimated that 4,000 people died of cancer because of direct exposure to the radiation. The death toll  would have been much greater had the prevailing winds directed the plumes through the city. Distribution of the isotope cesium-137 serves as a  marker of radioactive contamination in the Chernobyl exclusion Zone  (map) . Most of the authors’ studies on the local wildlife took place in the  “Red Forest,” named after pine trees that were killed and discolored by the radiation. ( satellite image courtesy of Google/T erraMetrics.)10 kilometers BELARUSRed Forest Chernobyl nuclear power plant Pripyat City Ukraine/Belarus border Exclusion Zone boundaryremediated 1,000 500 200 100 50 20 10 5 1 &lt;1curies per square kilometer UKRAINE Chernobyl reactor IVChernobyl reactor IVPripyat, UkrainePripyat, Ukraine Western TraceNorthern Trace 2006    November–December      545 www.americanscientist.org© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.trivial tasks, and even today we are still refin - ing some of the mathematical formulations to  improve our estimates. We failed to anticipate that such intricacies  would force us to become familiar with other  branches of science. Indeed, it’s been said that  science advances so quickly that its practitio - ners must run as hard as they can—like the Red  Queen in Lewis Carroll’s Through the Looking- Glass —just to stay in the same place. We learned  that sometimes you also have to change your  course just to stay on top of things. Lesson 3:   Don’t  forget  about  history. Animal populations have natural variations  in both gene frequency and physical traits as  a normal product of their evolutionary histo - ries. Populations experience growths, declines,  dispersals and local extinctions that may be  completely independent of the event that is  being investigated—here, an explosive release  of lethal radiation. The trick is to come up  with a way to distinguish the natural variation  from that caused by the agent of interest. This  is difficult because we don’t have samples of  populations in the contaminated zone before  the radiation was released.  One approach is to assume that nearby popu - lations of the same species that have not been  exposed to appreciable amounts of radioactivity  will display levels of variations that are similar to  those that would have been found in the original  population within the contaminated zone before  the accident. We use this approach, but not with - out recognizing its limitations. The “reference”  samples are merely pseudo-controls because we  cannot be sure that we have accounted for all the  factors that might have influenced genetic varia - tion. For example, geographical features—rivers,  forests and farmlands—that differ between the  regions may affect gene frequencies in unexpect - ed ways. Ecotoxicologists must consider these  historical influences if we are to identify the true  effects of a contaminating agent. Lesson 4:   It’s  always  wise  to maintain  some  humility. There’s a broad range of opinions on the biolog - ical consequences of being exposed to the con - taminated environment near Chernobyl. Vari - ous studies on wheat, mice, birds and humans  have concluded that mutation rates are greatly  elevated and that the evolutionary fitness of the  organisms is reduced. Other studies have failed  to find any increase in the rate of genetic muta - tions or any evidence that the survival of the  animals living near Chernobyl differs from that  of those living in clean environments.  We have spent a considerable amount of time  trying to understand how applications of the  scientific method can produce results that are  so contradictory . We could offer a few explana - tions, including the possibility that some studies simply lack the data to justify the authors’ con - clusions, but it might be best to offer an example  from our own experiences of tasting humble  pie. (We should add that human error may not  explain all the differences between the studies.) The April 25, 1996 issue of Nature  featured on  its cover our article concluding that voles living  in the Chernobyl environment had an elevated  rate of genetic mutation. Our experimental de - sign included double-blind analyses of DNA  sequences, the long strings of nucleotides that  make up the genetic code. We had determined  the genetic sequences manually , a process which  involves laborious alignments of genes and even  a few judgment calls. Nevertheless, we were  confident in our results.  Figure 3. Pripyat, now abandoned, lies a mere 3 kilometers from the Chernobyl nucle- ar Complex, which is visible on the horizon. Brenda Rodgers of T exas T ech University  and author Chesser measured the radiation levels of every building in Pripyat, and the  city is now the basis of a digital, three-dimensional reconstruction that models the flow  of radiation in urban environments. (Photograph courtesy of the authors.) Figure 4. The Red Forest was bathed in the ionizing radiation of the Western Trace,  which passed through the region in the wake of the accident at reactor IV . Pine trees  were killed by the plume, but birches survived. Wildlife now thrives in the area.  (Photograph courtesy of the authors.) 546     American Scientist, Volume 94© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.Soon after the paper was published, we ac - quired an automated sequencer that was more  accurate than the manual methods used to se - quence DNA. We had archived the tissues from  all the animals used in our Nature  study , so we  decided to re-sequence the genes to compare  the methods. To our horror, the automated se - quencer failed to replicate the result we reported  in Nature . The more accurate method failed to  find an elevated mutation rate, even though we  repeated the sequencing several times. We agonized over our options for a few  weeks while we were on an expedition to an - other radioactive site in Chelyabinsk, Russia.  After we returned, we knew we had to retract  our report. Not all of our seven coauthors  agreed. Some thought that we should allow  the paper to fade from public scrutiny . Another  suggested that our future work would eluci - date the true mutation rate. However, Nature  is  a publication with a high profile, and our origi - nal report may well attract more attention than  potential reports in other publications. In the  end, we all agreed that we had an obligation to  the scientific community to come clean, and we  published a brief retraction in the November 6, 1997 issue of Nature . It was an important lesson  in admitting error and coming to terms with  our mistakes. Lesson 5:   Scientists  must  have  a single  agenda:  the truth. One day a graduate student brought her labo - ratory notebook to one of our group meetings.  She looked at us, almost in tears, and blurted,  “I couldn’t find any differences between the  experimentals and the controls. What did I do  wrong?” We were grateful for her honesty . Our  retraction of the Nature  paper had shown us  that problems in quality control can arise even  with the best intentions. Our scrutiny of the  published literature reveals that many scientists  are less than careful about such matters. Professors, graduate students and techni - cians all have preconceived ideas of where  their data may lead them. We recognized that  we weren’t immune to such prejudices either,  so we had to find a way to prevent our bi - ases from influencing our results. The best ap - proach is a blind analysis, with no knowledge  of whether the samples come from the experi - mental or the control groups. (We now have  inhalation of airborne particles ingestion of food and particles beta particles gamma raysairborne particles egestion and urinationsoil and vegetationexternal exposure internal exposure Figure 5. Mice brought into the Red Forest from uncontaminated regions serve  as experimental models to ascertain the effects of a radioactive environment. The  animals are exposed to radioactive particles, primarily cesium-137 and strontium- 90 (purple  and yellow  dots),  in the contaminated forest from internal and external  sources. some of the ionizing radiation (gamma rays and beta particles) is not  absorbed by the animal, and some of the particles are excreted. each mouse wears  a collar (photograph),  which contains dosimeters that absorb radiation at the same  rate as soft biological tissues. The collar provides an accurate measure of the radia - tion dose the animal receives from outside sources. such experiments reveal that  the mice appear unaffected by the residual radiation in the Chernobyl environ - ment. (Photograph courtesy of the authors.) 2006    November–December      547 www.americanscientist.org© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.a secretary codify all the sample tubes.) After  we complete the analysis, we then decode and  classify our data.  Right or wrong, at least we know that the  results were not affected by our personal prej - udices. A scientist should always be ready to  change his mind. Once a scientist resists alterna - tive explanations, he is no longer a useful deci - sion maker. Blind studies are the antithesis of  blind ambition.  Lesson 6:   Incredible  results  require  incredible  evidence. Some reports on the biological impacts of the  fallout from Chernobyl seem to lie outside the  bounds of reasonable expectations. One study  reported that barn swallows, collected from  northern Ukraine, were experiencing partial al - binism and increased germline mutation rates,  with a concomitant loss of evolutionary fitness.  Unfortunately , the authors did not identify ex - actly where the birds were collected, they did  not evaluate the radiation doses to the birds and  they provided little information on the level of  soil contamination. In contrast, our own inves - tigations of swallows collected in a 10-kilometer  zone surrounding the reactor reveals that the  internal radiation doses are negligible—less  than 10 microsieverts per day . That dose rate  is less than one-tenth of a typical chest x ray ,  or about the same for three hours of flight at  35,000 feet. It would be astonishing if that dose were responsible for the elevated mutation rates  reported by the authors.  It’s also the case that local genetic variations  are common in natural animal populations. It  would be surprising to find populations with - out geographic variations. The authors of the  barn-swallow article inferred that the variation  among the birds was the result of radiation-in - duced mutations, but they did not provide any  evidence for their assertion. They did not elimi - nate the possibility that the geographic varia - tions were natural, or that the mutations might  have been caused by something else. Moreover,  some of the same barn-swallow variants have  been found in regions not affected by Chernob - yl, suggesting that they may not be uncommon.  In our opinion, their incredible conclusions were  supported only by circumstantial evidence. Lesson 7:   A good  idea doesn’t  always  attract  funding. Chernobyl is known the world over as the  worst nuclear power plant disaster in history .  We naively assumed that this name recognition,  and a good scientific plan, would quickly yield  financial support for our research. On one of  our funding forays to Washington we present - ed what we thought was a well-designed plan  on the scientific merits of our proposed research  at Chernobyl. Afterward, one of the politicians  said, “Okay , that was fine ... now, how do I sell  this to my fellow congressmen?” We exchanged  Figure 6. Wildlife flourishes in the Chernobyl exclusion Zone. Many species are more plentiful in the exclusion Zone than they are in neigh - boring habitats (clockwise  from  upper  left: red fox, nesting  Northern  shrikes,  elk and Russian  wild  boar).  (Photographs courtesy of the authors.) 548     American Scientist, Volume 94© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.glances with each other that said, “didn’t we  just answer that question?” Later we realized that we hadn’t provided  him with anything useful for his agenda. Good  science is a beautiful thing, but it must fit within  an existing framework of policy and strategic  plans or it will be very difficult to finance. Our  great scientific proposal floated away like a he - lium-filled balloon with no string tying it down  to political reality .  Policy makers want concrete conclusions and  results, not probability estimates on the relative  dangers of radiation exposure, which turns out  to be less hazardous than generally believed. Many public servants do not share the scientist’s  enthusiasm for the scientific process. They make  laws that distinguish right from wrong, while we  spend 95 percent of our time trying to explain 5  percent of the variation of a phenomenon. Ultimately, we were successful in securing  funds for several years of research, and we have  since built the International Radioecology Labo - ratory in Slavutych, Ukraine. But it hasn’t been  easy, and most prospects for future funding  look bleak. Lesson 8:   Be prepared  to be unpopular  and uncomfortable. In this year’s 20th-anniversary reports on the  Chernobyl accident, news outlets various - ly claimed that the disaster had resulted in  93,500, 70,000, 4,000, hundreds or just 31 hu - man deaths. We couldn’t find a single story  that tried to explain the enormous difficulties  of determining an accurate number for the  excess cancer deaths caused by the radiation  fallout from Chernobyl. The press did not at - tempt to explain the differences in opinions  between scientists or the contradictory results  of research on animals exposed to radiation.  Instead, advocacy groups pointed their fingers  at scientists and asked why they were trying  to cover up the “real” impact of radiation on  people and the environment.  Scientists often find themselves in unpopular  and uncomfortable positions. That’s just part  of the job when you have to report the truth.  A scientist’s conclusions help to guide public  policy , write regulations and develop new tech - nologies. The results of good science are simply  Figure 7. some people have returned to the Chernobyl exclusion Zone, hoping to  reclaim the land and livelihoods they lost to the accident in 1986. scientists continue  to monitor the environment. Viktor Drachev/AFP/Getty Images 548     American Scientist, Volume 94Research on the effects of radiation should be held to  the highest scientific standards. In our opinion, the  standards have been lax. Many of the studies showing  an elevated rate of mutations among the animals in the  Chernobyl environment need to be replicated, often with  improved experimental designs. Funding agencies should  encourage independent laboratories to undertake simulta - neous studies of the same samples.  We would be negligent in our mission to improve the re - search at Chernobyl if we did not also provide some positive  recommendations for future investigations. Here we offer a  short list of the minimum requirements necessary for a valid  study of the consequences of environmental radioactivity . 1. Investigators should archive tissue, DNA and any other  material that would permit other scientists to replicate their  results. Archiving would also allow scientists to employ other  experimental designs to corroborate, refute or enhance the  results. To that end, we have archived over 3,000 specimens  from mammals native to Chernobyl and the surrounding  areas at the Museum of Texas Tech University . We have also  archived tissue from laboratory mice with recombinant DNA  (Big Blue), and mice exposed to low-dose radiation. These  samples allow scientists to confirm our results, and the tissue can be used to identify biomarkers that can resolve the effects  of radiation. Scientists interested in obtaining tissue or bor - rowing samples from the Chernobyl region may contact us by  e-mail: robert.baker@ttu.edu 2. Samples should be analyzed using double-blind ex - perimental methods. This removes any suspicion that an  investigator’s bias may be affecting the results. 3. Radiation levels and expected dose rates from external  sources in an animal’s normal activity area should be identi - fied for all known radionuclides. There is too much variation  in radiation levels to assign dose rates for an animal based on  a few measures from soil samples.  4. Investigators need to acquire accurate measures of an  animal’s dose rate from inhaled or ingested radionuclides.  Dose rates from internal sources are often higher than those  from the outside. If dose rates are unknown, then measures of  radioactivity in tissues will suffice. 5. The provenance of a sample must be provided. Other  scientists should have the opportunity to collect samples from  the same location. 6. Scientists should report positive and negative results.  The omission of negative results gives the impression that the  effects of radiation are ubiquitous. Setting Standards for Radioecology 2006    November–December      549 www.americanscientist.org© 2006 Sigma Xi, The Scientific Research Society. Reproduction  with permission only. Contact perms@amsci.org.too important to be swayed by emotional ap - peals. Unfortunately, poor science often gets  great publicity , especially if it stirs controversy  or implies that governments are recklessly en - dangering the lives of their citizens. In the long  run, poor science will beget poor policy . Lessons for science Twenty years have passed since the accident at  Chernobyl, yet the extent to which people, ani - mals and the environment have been harmed  is hotly debated. The conflicting reports on the  genetic and biological impacts of environmental  radiation make it difficult for even the most  seasoned scientist to make sense of all the data.  Remarkably , there is still no accurate account  of the number of deaths or birth defects caused  by the disaster. Investigations into the effects of  ionizing radiation on living organisms should  be based on sound scientific principles for the  simple reason that risk assessments, regulatory  statutes and the effectiveness of remediation  measures are often based on these reports. The  public and scientific communities need to recog - nize that ecological studies on Chernobyl that do  not include accurate information on animal ex - posure do not qualify as radiological research. The proper null hypothesis should be that  the effects of the Chernobyl environment on  an organism do not differ from effects outside  the environment. Falsification of the null hy - pothesis has profound implications for society .  If there is an elevated mutation rate and loss of  health, then appropriate measures should be  taken to protect ourselves. No one would argue  with that. But we must be mindful that the costs  of over-regulation can be extreme. Zbigniew  Jaworowski, former chairman of the United  Nations Scientific Committee on the Effects of  Atomic Radiation, has estimated that enforcing  the radiation-safety regulations in the U.S. costs  about three billion dollars for each life saved  from accidental exposure. By comparison, the  measles vaccine costs $99 per life saved. We believe the problem requires a coordinat - ed effort that enforces standards of data gather - ing and assessment. This effort would establish  protocols for collegial verification of results and  preserve samples for future studies. Without  such coordination, we will fritter away meager  resources on disconnected and unrepeatable  studies. We should endeavor now, while the sig - natures of released radiation remain on the land - scape and in the affected organisms, to solve the  issues of environmental health and safety . Bibliography Baker, R. J., R. A. Van Den Bussche, A. J. Wright, L. E.  Wiggins, M. J. Hamilton, E. P . Reat, M. H. Smith, M. D.  Lomakin and R. Chesser. 1996. High levels of genetic  change in rodents of Chernobyl. Nature  380:707–708. Baker, R. J., R. A. Van Den Bussche, A. J. Wright, L. E.  Wiggins, M. J. Hamilton, E. P. Reat, M. H. Smith,  M. D. Lomakin and R. Chesser. 1997. Retraction. High levels of genetic change in rodents of Cher - nobyl. Nature  390:100. Baker, R. J., and R. K. Chesser. 2000. The Chornobyl  nuclear disaster and subsequent creation of a wild - life preserve. Environmental Toxicology and Chemistry  19:1231–1232 . Baker, R. J., A. M. Bickham, M. Bondarkov, S. P . Gas - chak, C. W. Matson, B. E. Rodgers, J. K. Wickliffe and  R. K. Chesser. 2001. Consequences of polluted en - vironments on population structure: The bank vole  (Clethrionomys glareolus ) at Chornobyl. Ecotoxicology   10:211–216. Chesser, R. K., and R. J. Baker. 1996 . Life continues at  Chernobyl. La Recherche  286:30–31. Chesser, R. K., D. W. Sugg, A. J. DeWoody, C. H. Jagoe,  M. H. Smith, M. D. Lomakin, R. A. Van Den Bussche,  C. E. Dallas, K. Holloman, F. W. Whicker, S. P . Gas - chak, I. V . Chizhevsky, V . V . Lyabik, E. G. Buntova  and R. J. Baker. 2000. Concentrations and dose rate  estimates of 134,  137cesium and 90strontium in small  mammals at Chornobyl, Ukraine. Environmental Toxi - cology and Chemistry 19:305–312. Chesser, R. K., M. Bondarkov , R. J. Baker, J. K. Wickliffe  and B. E. Rodgers. 2004. Reconstruction of radioactive  plume characteristics along Chernobyl’s western trace.  Journal of Environmental Radioactivity  71:147–157. Chesser, R. K., B. E. Rodgers, J. K. Wickliffe, S. Gaschak,  I. Chizhevsky, C. J. Phillips and R. J. Baker. 2001. Ac - cumulation of 137cesium and 90strontium from abiotic  and biotic sources in rodents at Chornobyl, Ukraine.  Environmental Toxicology and Chemistry  20:1927–1935. Dubrova, Y. E., V . N. Nesterov, N. G. Krouchinsky, V . A.  Ostapenko, R. Neumann, D. L. Nell and A. J. Jeffreys.  1996. Human minisatellite mutation rate after the  Chernobyl accident. Nature  380:683–686. Ellegren, H., G. Lindgren, C. R. Primmer and A.P.  Møller. 1997. Fitness loss and germline mutations  in barn swallows breeding in Chernobyl. Nature   389:593–596. Goncharova, R. I., and N. I. Ryabokon. 1995. Dynamics  of cytogenetic injuries in natural populations of bank  vole in the republic of Belarus. Radiation Protection  Dosimetry  62:37–40. Jacob, P .,  et al . 1998. Thyroid cancer risk to children cal - culated. Nature  392:31–32.  Jaworowski, Z. 1995. Beneficial radiation. Nukleonika   40:3–12. Kovalchuk, O., Y. E. Dubrova, A. Arkhipov, B. Hohn  and I. Kovalchuk. 2000. Wheat mutation rate after  Chernobyl. Nature  407:583. Medvedev, Z. A. 1994. Chernobyl: Eight years after.  Trends in Ecology &amp; Evolution  9:369–371. Meeks, H. N., J. K. Wickliffe, S. R. Hoofer, R. K. Chesser,  B. E. Rodgers and R. J. Baker. Accepted. Evidence  that variation in the mitochondrial control region  is not related to radiation exposure. Environmental  Toxicology and Chemistry. Rodgers, B. E., R. K. Chesser, J. K. Wickliffe, C. J. Phillips  and R. J. Baker. 2001. Sub-chronic exposure of BALB  and C57BL strains of Mus musculus to the radioactive  environment of the Chornobyl exclusion zone. Envi - ronmental Toxicology and Chemistry  20:2830–2835. Rodgers, B. E., J. K. Wickliffe, C. J. Phillips, R. K. Chesser  and R. J. Baker. 2001. Experimental exposure of naïve  bank voles, Clethrionomys glareolus , to the Chornobyl,  Ukraine, environment: A test of radioresistance. Envi - ronmental Toxicology and Chemistry  20:1936–1941. Wickliffe, J. K., B. E. Rodgers, R. K. Chesser, C. J. Phil - lips, S. P . Gaschak and R. J. Baker. In press. Mito - chondrial DNA heteroplasmy in laboratory mice ex - perimentally enclosed in the radioactive Chornobyl  environment. Radiation Research .For relevant Web links,  consult this issue of  American Scientist  Online : http://www.american   scientist.org/   IssueTOC/issue/902</td>
    </tr>
    <tr>
      <th>75</th>
      <td>news</td>
      <td>Google’s Top Stories and the Fairness Doctrine: Unbalanced Amplification of\nFar-Right News Sources\nEni Mustafaraj\neni.mustafaraj@wellesley.edu\nDepartment of Computer Science\nWellesley College, Wellesley, MA\n\nAbstract\nGoogle’s Top stories is a component of Google Search\nthat frequently surfaces current news when a user performs a search. Our one-year long audit of Google’s\nsearch results for the candidates of the 2020 US Presidential Elections indicated that the composition of the\nTop stories panel shows an unbalanced amplification of\nfar-right news publishers.\n\nIntroduction\nIn their book “Network Propaganda” (Benkler, Faris, and\nRoberts 2018), the authors consider a set of actors and technological drivers that have been identified as causing the\npresent state of information disorder, among others, “fake\nnews” entrepreneurs, political clickbait fabricators; Russian hackers, bots, and sockpuppets; the Facebook Newsfeed algorithm and online echochambers; Cambridge Analytica; and white supremacists and alt-right trolls. Ultimately, they settle on the right-wing media ecosystem as\n“the primary culprit in sowing confusion and distrust in the\nbroader American media ecosystem.” Their analysis is based\non three sources of data: the open web, Facebook news sharing, and Twitter news sharing. Although the book doesn’t\naddress the question of how people access news on the Web,\nit appears to suggest the primacy of social media in this respect. In the aftermath of the 2016 US Election, Facebook\nmade changes to its news feed algorithm that reduced the\namount of referral traffic to other websites. Thus, since 2017,\nsearch engines have directed more traffic to news websites\nthan social media.1\nAs the amount of search engine referrals to news sources\nincreases, it is worth investigating what news is shown by\nsearch engines. Since 2016, Google, the most used search\nengine, has modified its search results page (SERP) interface\nto show Top stories, a panel of up to 10 headlines accompanied by images, near the top of the SERP. When the search\nterm concerns events or people in the news, Top stories is\nthe first element of the page shown on mobile and desktop\ndevices. Given that thousands of stories from thousands of\nCopyright c 2020, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\n1\nhttps://www.businessinsider.com/search-engines-more-trafficpublishers-social-media-2017-2018-2\n\nnews sources are written daily, by selecting only a few of\nthem at a time, Google’s Top stories is engaging in what is\nknown as “algorithmic news curation” (Diakopoulos 2019).\nIf algorithms are curating news, what choices are they\nmaking, especially with respect to news sources with problematic credibility? Concretely, are the right-wing publications identified in (Benkler, Faris, and Roberts 2018) as the\ncause of our current information disorder (pre- and post2016 US Election) being promoted by Google Top stories?\nDoes that apply to left-wing publications?\n\nFigure 1: Google’s Top stories panel for Joe Biden on Oct 2,\n2019. All three stories are from news sources considered as\n“right-wing” or “far-right” (partisan audience bias &gt; 0.5).\nThis line of research, which falls under the umbrella of algorithm auditing (Sandvig et al. 2014), is important for two\nreasons: 1) more people use search engines than social media on a daily basis. If they are being exposed to news in this\nway, we need to understand how algorithms are curating the\nnews; 2) there is evidence that as many as half of all search\nqueries don’t lead to clicks,2 because a user’s information\nneed is fulfilled by the SERP content. Thus, the news headlines that a user sees in Top stories might be all they remember about a news event. Taken together, these headlines can\nframe issues in a partisan way and help with media agenda\nsetting. To exemplify, Google’s Top news panel on Figure 1\n2\nhttps://searchengineland.com/49-of-all-google-searches-areno-click-study-finds-318426\n\nshows an occasion in which all three headlines are from farright news sources, and critical of candidate Joe Biden.\n\nData\nWe have been auditing Google’s Top stories for the coverage\nof the 2020 US Presidential Elections since December 2018\n(Kawakami, Umarova, and Mustafaraj 2020). Although we\nhave data for 30 candidates, we focus here only on the top\nfive Democratic candidates and the incumbent president,\nDonald Trump. Our auditing system has captured the list\n(and ordering) of ten top stories multiple times a day. Approximately, we collected 80,000 news articles from 2,168\nnews sources. We then use the Partisan Audience Bias scores\ndataset (Robertson et al. 2018) to assign a partisanship score\nto news sources. The scores are between -1 (far left) to +1\n(far right). For example, Breitbart News has a score of 0.74\nand LGTBQ Nation a score of -0.77. To simplify our analysis, sources with scores (-1, -0.5) are labeled as “far left”,\nthose in (-0.5, 0.0) as “center left”, those in (0.0, +0.5) as\n“center right”, and those in (+0.5, +1) as “far right”. These\nnumbers reflect the partisanship of their audience and might\nnot be an objective measure of the news sources bias.\n\nResults\nFor each of the four categories above, we calculated the proportion of occurrences of news articles from corresponding\nnews outlets. The results are summarized in Table 1. What is\nimportant to notice here is the dominance of the “center left”\nsources (which is known as mainstream media) especially\nfor Donald Trump, as well as the disproportionate amount\nof far-right media coverage, especially for the front-runner\nDemocratic candidate, Joe Biden.\nCandidate\nDonald Trump\nJoe Biden\nBernie Sanders\nElizabeth Warren\nAmy Klobuchar\nPete Buttigieg\n\nFL\n8.7%\n9.0%\n15.2%\n11.5%\n8.8%\n10.7%\n\nCL\n64.9%\n51.9%\n50.4%\n53.5%\n57.2%\n52.9%\n\nCR\n17.6%\n16.1%\n18.0%\n19.3%\n17.2%\n21.1%\n\nFR\n8.3%\n22.1%\n14.3%\n14.6%\n12.7%\n11.6%\n\nTable 1: The proportion of Top stories’ news articles for four\ngroups of partisan audience bias: FL - Far Left, CL - Center\nLeft, CR - Center Right, FR - Far Right.\nThis unbalanced coverage of Joe Biden is captured better\nin Figure 2, which shows the stark contrast between all four\ngroups of media. There was a reason for this: Joe Biden was\nseen as the candidate who was most likely to beat President\nTrump in the election. Thus, news outlets who support the\npresident focused on aggressively covering Biden’s candidacy. Meanwhile, far-left sources focused more on Bernie\nSanders, given his political ageenda.\n\nDiscussion\nIs Google’s Top stories algorithm reflecting user’s demand\nfor news; the uneven supply from the news publishers; or\ntrying to impose the so-called “fairness doctrine” (Simmons\n\nFigure 2: Distribution of articles volume by various news\noutlets in the partisan audience bias spectrum for Joe Biden’s\nGoogle searches. Notice the disproportionate far-right coverage by 28 news sources.\n1978), which was a policy implemented in the United States\nfrom 1949-1987, demanding from broadcasters the coverage\nof opposing views. Since overall there are fewer far-right\nnews sources compared to the rest of the field, they are disproportionately represented in Top stories. Should that be\nconsidered fair? Given the findings from (Benkler, Faris, and\nRoberts 2018) on the role that the Breitbart-led right-wing\nnews ecosystem played in the 2016 US election, setting the\nnews agenda, by focusing on immigration fears and alleged\nClinton’s corruption, our results indicate a possible scenario\nrepetition. Thus, we invite discussion on the principles that\nshould underlie algorithmic news curation.\n\nAcknowledgments\nI am grateful to my students Emma Lurie, Khonzoda\nUmarova, and Anna Kawakami for their contributions to this\nproject and the Wellesley Cred Lab members for their continuous support. This project was partially funded by the National Science Foundation, through grant IIS 1751087.\n\nReferences\nBenkler, Y.; Faris, R.; and Roberts, H. 2018. Network propaganda: Manipulation, disinformation, and radicalization\nin American politics. Oxford University Press.\nDiakopoulos, N. 2019. Automating the news: How algorithms are rewriting the media. Harvard University Press.\nKawakami, A.; Umarova, K.; and Mustafaraj, E. 2020. The\nmedia coverage of the 2020 us presidential election candidates through the lens of google’s top stories. Proceedings of\nthe International AAAI Conference on Web and Social Media 14(1):868–877.\nRobertson, R. E.; Jiang, S.; Joseph, K.; Friedland, L.; Lazer,\nD.; and Wilson, C. 2018. Auditing partisan audience bias\nwithin google search.\nSandvig, C.; Hamilton, K.; Karahalios, K.; and Langbort, C.\n2014. Auditing algorithms: Research methods for detecting\ndiscrimination on internet platforms.\nSimmons, S. J. 1978. The fairness doctrine and the media.\nUniv of California Press.\n\n</td>
    </tr>
    <tr>
      <th>29</th>
      <td>poli</td>
      <td>Political Bias Analysis Arkajyoti Misra Target Corporation Stanford University arkajyot@stanford.eduSanjib Basak Digital River Inc. Stanford University sbasak@stanford.edu Abstract The two major political parties in US are polarized between either the liberal and conservative point of view on a multitude of socio-economical and environmental issues. An algorithmic approach towards detection of such bias is both intellectu- ally challenging and useful in areas like election prediction. There exists very few studies in the literature where modern deep learning techniques are applied to de- tect the personal opinion or bias of an individual. In this work, we have developed an LSTM network that achieved an F1 score of 0.718 on a data set consisting of statements made in the recent past by US election candidates. 1 Introduction The political atmosphere in the US is deeply polarized between two predominant ideologies: liberal and conservative. The twp major parties maintain differences in opinion in different issues like global warming, gay rights, abortions, foreign policies and immigration, to name a few. While the liberals encourage active role for government in society and believe in environmental regulations, conservatives like to have a limited role for government in the society and argue against imposing environmental regulations. In the age of big data, with the help modern technology, this information is being captured in both structured and unstructured form at an unprecedented scale. Particularly, the year of 2016 being a US presidential election year, there is no shortage of active and engaging political discussions in the media fed by the plethora of public debates, interviews and speeches. The sudden eruption of activity in the area of opinion mining and sentiment analysis, which deals with the computational treatment of opinion, sentiment, and subjectivity in text, has generated increased interest in building new applications that deal directly with opinion [1]. The agenda of the political parties are obviously biased over the different issues, but the bias in the different forms of public communication like news media, journals, news channels are at times quite difﬁcult to comprehend from a cursory look. In many cases, it is certainly challenging, if not impossible, to manually decipher every bit of such information available in the public domain that can be quite useful in predicting the outcome of an election, for example. Our hypothesis is that a sophisticated deep learning algorithm can be trained to detect such bias auto- matically. Natural Language Processing (NLP) and Information Retrieval are becoming increasingly popular in detecting private states such as opinions, sentiment, and beliefs [2], [3] from text. How- ever, the task of detecting political bias is quite non trivial and provided a unique challenge to the NLP community over years. The goal of our project is to build an analyzer capable of detecting political bias from a given body of text. Previous work on bias or ideology detection from a textual document is relatively rare in literature. Most prior work on the topic are based on a bag-of-words representations of the document together with a multitude of hand crafted rule based on deep understanding of the structure of the language. For example, Gerrish and Blei [4] predicted the voting patterns of Congress members based on 1 bag-of-words representations of bills and inferred political leanings of those members; whereas Gentzkow and Shapiro [5] derived a slant index to rate the ideological leaning of newspapers. With the recent success of deep neural network models in the ﬁeld of natural language processing, researchers have started to apply the state of the art models in the ﬁeld of abstract theme or opinion detection [6] and achieved higher accuracy (an F1 score of close to 70.) Models like Recurrent neural network deploy deep architecture with multiple hidden layers and perform well for sequential prediction of tasks. Within the NLP ﬁeld, sentences are viewed as constructed sequence of tokens that need to carry forward the meaning from the beginning of the sentences to the end. With this view, those models have been successfully applied to tasks such as language modeling [7], and spoken language understanding [8] Recursive neural networks is another class of deep neural net architecture within that has been applied to parsing [9], sentence-level sentiment analysis [10], and paraphrase detection [11]. The major inspiration of the present work comes from the recent work by Iyyer et al [12] where the authors applied a Recursive Neural Network (RvNN) based on the Stanford tree parser and achieved a 69% accuracy on a binomial classiﬁcation of the two prominent political ideologies in the US. 2 Data The data set we used for the project is called the Ideological Books Corpus (IBC), which was com- piled by a group of researchers from the University of Maryland [12]. The data set was based on publicly available US congressional ﬂoor debate transcripts from 2005 [13]. The ﬁnal data set [14] was a compilation of sentences hand picked to be most expressive of political sentiment and man- ually labeled by a majority voting scheme. We are using the entire data set for this project that consists of 2025 liberal and 1701 conservative biased sentences. A typical example of a conservative biased sentence is ”Even he would have been in complete shock over Al Gore ’s ability to scare billions of people into believing humans are killing themselves and suffocating all life on the planet by driving their carbon-emitting cars back and forth to work instead of riding bicycles .” The example highlights the difﬁculty of the task at hand. It would be easy for a real human to categorize the sentence as anti-liberal based on prior knowledge of Al Gore’s political position or that carbon emitting cars are bad for the environment is a predominantly progressive point of view. However, any classiﬁer that needs to effectively identify the political bias of an example like this must have (a) the ability to capture long distance correlation between words and (b) knowledge of proper context. A typical liberal biased example - ”Though the practice can be defended as generating revenue used to improve the college ’s academic program , the effect is to favor middle-class and less needy applicants .” - also supports the fact that political bias may not be explicitly expressed through one or many words and knowledge of the general perception about the middle class of the major US political institutions is of paramount importance in classifying the sentence correctly. We also collected data from ontheissues [15] (OTI) that collects political speeches, dialogues and debate transcripts, from candidates of both the major parties, on a multitude of issues. A majority of the content of the data set being statements from the political candidates on an election campaign, the texts consist of generally smaller sentences and are more expressive of the bias of the speaker compared to the previous data set. For each of the issues we created two documents - one with liberal views and another with conservative views. We did not assign a label to a text based on the political afﬁliation of the speaker; instead we carefully labeled them based on the actual bias expressed in the text. This is a departure from the IBC data set where the text was labeled based on the political afﬁliation of the speaker. In the OTI data set, a typical conservative biased example on the issue of gun control is: ’Restrictive gun laws don’t stop culture of violence’; while a liberal biased statement on environment is: ’Adopt the Clean Cars Act to ﬁght global warming’. 2 Figure 1: A rolled out RNN network used in binary classiﬁcation. 3 Model Recurrent neural networks (RNN) have completely revolutionized the world of Natural Language Processing (NLP) in the last few years. In extremely difﬁcult NLP challenges like machine trans- lation, question answering and text generation to name a few, RNN have recently outperformed the conventional techniques based on a deep understanding of the structure of the language. Conven- tional RNNs are generative model where the network is built to always predict the next word in a sequence, thereby learning the semantic structure of the language. For the task at hand, we are using the network as a classiﬁer where the network is tasked with predicting the label at the end of a sequence, at shown in Fig. 1. The task at hand demands that the model capture long range correlation between words in the text. That is because the data loss does not get contribution from every word in the network and is calculated only at the very last time step and the gradient of the loss has to backpropagate to the beginning of the sentence. However, conventional RNNs stuggle to back propagate the gradient over many time steps because of the well known problems of vanishing or exploding gradients [16]. More recently, RNN variants like GRU and LSTM have solved the problem and therefore, an LSTM network was chosen for the task at hand. An LSTM unit is described by the set of activations in Eqs. (1), where htis the hidden state at time stept;i,fandostand for the input, forget and the output gate respectively. The network learns the variousWandUmatrices and ctcontrols how much of the past information has to be retained in the network. The symbol denotes the Hadamard product. i=(xtUi+ht 1Wi) f=(xtUf+ht 1Wf) o=(xtUo+ht 1Wo) g= tanh(xtUg+ht 1Wg) o=(xtUo+ht 1Wo) ct=ct 1f+gi st= tanh(ct)o (1) The binary cross entropy loss is calculated at the last time step ( tend) of the network as follows: lossCE(y;^y) = X iyilog( ^yi); whereyis the true label and the predicted label is calculated using a sigmoid function applied on the hidden state at tend: ^y=(htendU+b) (2) 4 Results and Discussion In a binary classiﬁcation framework, both the ROC-AUC number and the F1-score are widely ac- cepted to be robust measures. The AUC is the Area Under the Curve of a plot of the true positive rate (TPR) vs the false positive rate (FPR). The metric varies between 0.5 for a completely random prediction and 1 for a perfect prediction. For data sets having highly imbalanced classes present in 3 it, the AUC is a good measure as it properly weights the correct prediction of the minority class too. The F1-score, on the other hand, is deﬁned as the geometric mean of the precision and recall [17] F1 =2precision recall precision +recall; (3) where precision is the fraction of retrieved instances that are relevant, while recall is the fraction of relevant instances that are retrieved [18]. The F1 score varies between 0 and 1 and the standard goal in a classiﬁcation project is to maximize the score. Figure 2: Performance of the Naive Bayes model measured by both F1 and AUC metrics on both the data sets used in the study. In our experiment we shall focus on the F1 score as it is most common in the literature but will also track the AUC score as a guide against the model predicting completely random outcomes. Although the F1 score is more frequently reported in classiﬁcation tasks similar to the present one, the AUC actually looks at all possible prediction thresholds instead of the best possible one. The IBC data set being so challenging, we felt it is important to track both metrics for higher conﬁdence in the prediction. The previous work [12] on the IBC data set consistently used accuracy as the measure of their model prediction. However, we have experimented with another data set (OTI) that tends to have a larger imbalance between the labels on some topics. So we decided to focus on the F1 and AUC metrics instead. A baseline was established for both sets of data using a Naive Bayes bag of words model that works on the frequency of the unigram and bigrams present in the text. Fig. 2 shows the performance of both the IBC and the OTI data set in terms of F1 and AUC. The basic model performed very poorly with the F1 metric on the IBC data set. Both the metrics perform in a similar fashion for the OTI data set. The F1 score on the IBC data sets a very low baseline clearly illustrating the challenges with the content of the data set. We used a single layer LSTM model for our classiﬁcation task, where each hidden unit in ﬁg. 1 is replaced by an LSTM unit governed by the set of activations described in eqn. 1. The binary cross entropy loss described in eqn. 2 was minimized by ’Adam’ optimizer. We let the optimizer run for an unlimited number of epochs and used a 10 step early stopping scheme to terminate each individual model run. We kept our batch size ﬁxed at 32 for all our experiments. We stuck to a ﬁve fold cross validation scheme for all our experiments, where in each fold the model was trained on 80% of the data and a validation score was calculated on the remaining 20%. Exploratory runs with the IBC data revealed that for learning rates larger than 0.001 the model ﬁts nicely to the training data, while the validation loss kept increasing slowly over hundreds of epochs. We believe the reason for the model’s failure to decrease the validation loss lies in the very nature 4 Figure 3: Model performance on the IBC Dataset: Variation of F1 and AUC measures as a function of the dropout rate for a range of hidden layer sizes. of the data set as in every run the training data looks quite different from that of the validation data. The poor F1 score of the bag of words model shown in Fig. 2 supports this claim. Fig. 3 shows the performance of the model on the IBC data set. We were careful not to overﬁt the training data and hence kept the size of the hidden layer at a maximum of 80. The dropout rate had to be pushed to quite extreme limits for the model to start ﬁtting. Again, the extreme low values of dropout, namely 0.1, where the model performs best on both the F1 and AUC metrics suggests the extreme risk of overﬁtting as discussed before. However, such a large amount of regularization leads to a poor model that cannot even ﬁt the training data well. The best F1 score of 0.568 was obtained by a model with a hidden size of 40 and a dropout rate of 0.05. However poor the F1 scores appear for the model trained on the IBC data set, it must be noted that this is not unprecedented. Using a combination of bi-directional RNN and a bidirectional RvNN Isroy et al [19] obtained a best F1 score in the range of 0.5-0.6 on an opinion extraction task. Figure 4: Model performance on the OTI Dataset: Variation of F1 and AUC measures as a function of the dropout rate for a range of hidden layer sizes. Nonetheless, the results presented in ﬁg. 3 does not show beyond any reasonable doubts, that a state of the art LSTM network is up to the task of capturing implicit meaning of a text. As mentioned before, we strongly believe it is not a shortcoming of the model, rather a combination of complexity and lack of volume of the data led to the results. It should be noted that Iyyer et al [12] extracted better performance from the data set because it was manually labeled to the node level of the parse tree associated with every sentence that was used in building their RvNN model. We argue that this method is not scalable to newer data sets and we wanted to test further on our hypothesis that an LSTM network should be able to extract hidden meaning of a text with just an overall label for the text. To test out hypothesis, we collected and manually cleaned data publicly available on the web to create the OTI dataset. The advantage of the OTI data set over the IBC data set was that almost all the sentences showed a bias that could be detected by a normal human, thereby reducing the 5 possibility of ’confusing’ the model. Moreover, the average length of a sentence was 11 in the OTI data set, compared to 37 for the IBC data set, which made the training the model a lot easier. The ﬁrst indication of learning by the model became obvious when we did not have to resort un- reasonably strong regularization (very low dropout number). Fig. 4 shows a fundamental change in behavior of the inﬂuence of dropout on the F1 score. The best performing models had a dropout of 0.9 beyond which overﬁtting started and the score dropped rather dramatically. There was not a big inﬂuence coming from the hidden layer size of the network, another clear sign that the model was truly learning from the data without a need of becoming too complex. The AUC score, on the other hand, showed a nearly opposite trend. The model could obtain the best AUC value of 0.642 at a dropout of 0.3. It must be reiterated that the two metrics do not capture the same sensitivity from a model and we kept the AUC as an extra metric to look at. Figure 5: Effect of learning rate of the Adam optimizer as a function of dropout rate for the minimum and maximum hidden layer sizes used in the study. We also looked at the sensitivity of our result as a function of the learning rate in the model. Fig. 5 shows that the peak performance does not suffer from doubling the learning rate from 0.0002 to 0.0004, but a smaller hidden layer size with a faster learning rate lead to poor performance. The RNN and its variants can also be used in a bi-directional network. Meaning of a particular word in context does not always depend on the preceding words, sometimes the meaning of a word gets fully expressed from trailing words. Bi-directional networks try to capture this effect. We experimented with a bi-directional network where we concatenated the the hidden layers from the forward and backward direction. Fig. 6 shows that the network did not learn any extra information from the text. The bi-directional model performed nearly at par with its regular counterpart and the best bi-directional model also had a dropout rate of 0.9 and a hidden layer size of 80. 5 Conclusions In this work we have showed how a state of the art model like LSTM can be used to predict the implicit political bias present in a text even if there are no speciﬁc words present in the text that obviously relates to one of the two major political ideologies. We have explored two data sets with very different content - one is extracted from speeches of US congressional ﬂoor debates while the other is a collection of statements on multiple socio-political issues by US presidential candidates in most recent history. The model performed poorly on the former data set because of two main reasons: There is very little overlap of contents in the data that led to severe training challenges but more importantly a good portion of the data did not actually show any clear political bias that can be detected by a normal human being. We argue that the work by Iyyer et al [12] on the same data set performed better, although it is not a straight comparison because we used the F1 score instead of accuracy, with a RvNN because it was manually labeled at the node level of the parse tree, none of which we used in our model. Our goal was to build a model that is robust enough so that it can be applied to a variety of different contexts without the need of any detailed manual labeling, which is always difﬁcult to obtain. 6 Figure 6: A bi-directional LSTM network performs very similarly as that of a uni-directional net- work on the OTI data set. To test our hypothesis, we created a curated data set based on publicly available statements made by political candidates. We were able to obtain an F1 score of 0.718 with a single layer uni-directional LSTM network. This is at par with the best results on bias or opinion detection available in the literature [19]. We want to emphasize the fact that a model performs well only when there exists useful information present in the data. We would also like to point out that the method we developed is general in nature in the sense that the same model can be applied to extract bias or opinion in a different ﬁeld of study without any major modiﬁcation. The LSTM model we developed works only marginally better than a bag of words based approach on the OTI data set. It is already extensively reported in the literature that deep learning based models need substantially larger amount of data to outperform the traditional methods of the domain. We, therefore, strongly believe the model will outperform the bag of words model substantially if we have more training data at our disposal. References [1] URL:http://www.cs.cornell.edu/home/llee/omsa/omsa.pdf . [2] J. Wiebe T. Wilson and P. Hoffmann. “Recognizing contextual polarity in phrase-level senti- ment analysis”. In: (2005). [3] B. Pang and L. Lee. “Opinion mining and sentiment analysis. Foundations and trends in information retrieval”. In: (2008). [4] Sean Gerrish and David Blei. “ Predicting legislative roll calls from text”. In: 28th Interna- tional Conference on Machine Learning ().URL:http://www.cs.columbia.edu/ ˜blei/papers/GerrishBlei2011.pdf . [5] Matthew Gentzkow and Jesse M Shapiro. “What drives media slant? evidence from us daily newspapers”. In: Econometrica 78(1) (2010), pp. 35–71. [6] URL:http://www.cs.cornell.edu/ ˜oirsoy/files/emnlp14drnt.pdf . [7] Tomas Mikolov et al. “Extensions of recurrent neural network language model. In Acoustics, Speech and Signal Processing (ICASSP)”. In: 2011 IEEE International Conference (2011), 55285531. [8] Yoshua Bengio Deng. “Investigation of recurrent- neural-network architectures and learning methods for spoken language understanding”. In: Interspeech (2013). [9] Cliff C and Lin, Andrew Ng, and Chris Manning. “Parsing natural scenes and natural language with recursive neural networks”. In: Proceedings of the 28th International Conference on Machine Learning (ICML-11) (2011), 129136. [10] Richard Socher et al. “Semi-supervised recursive autoencoders for predicting sentiment dis- tributions”. In: In Proceedings of the Conference on Empirical Methods in Natural Language Processing (2011), 151161. 7 [11] Richard Socher et al. “Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Advances in Neural Information Processing Systems”. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (2011), 801809. [12] Mohit Iyyer et al. “Political Ideology Detection Using Recursive Neural Networks”. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (2014), pp. 1113–1122. [13] URL:http://www.cs.cornell.edu/home/llee/data/convote.html . [14] URL:http://cs.umd.edu/miyyer/ibc . [15] URL:http://www.ontheissues.org/default.htm . [16] Bengio et all. “Learning Long-Term Dependencies with Gradient Descent is difﬁcult”. In: IEEE Transactions on Neural Network Vol 5 No. 2 (1994). [17] URL:https://en.wikipedia.org/wiki/F1_score . [18] URL:https://en.wikipedia.org/wiki/Precision_and_recall . [19] URL:https://arxiv.org/pdf/1312.0493.pdf . 8</td>
    </tr>
    <tr>
      <th>28</th>
      <td>poli</td>
      <td>See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/249809418 Perceptions of Political Bias in the Headlines of T wo Major News Organizations Article    in  The Int ernational Journal of Pr ess/P olitics  · April 2007 DOI: 10.1177/1081180X07299804 CITATIONS 28READS 3,257 4 author s: Jeffr ey N We atherly Univ ersity of North Dak ota 169 PUBLICA TIONS    2,159  CITATIONS     SEE PROFILE Tom P etros Univ ersity of North Dak ota 69 PUBLICA TIONS    1,945  CITATIONS     SEE PROFILE Kimberly Christ opher son Morningside Colle ge 11 PUBLICA TIONS    617 CITATIONS     SEE PROFILE Erin Haug en Univ ersity of North Dak ota 5 PUBLICA TIONS    550 CITATIONS     SEE PROFILE All c ontent f ollo wing this p age was uplo aded b y Jeffr ey N We atherly  on 25 Mar ch 2016. The user has r equest ed enhanc ement of the do wnlo aded file. 91Press/Politics 12(2):91-104 DOI: 10.1177/1081180X07299804© 2007 by the President and the Fellows of Harvard CollegePerceptions of Political Bias in the Headlines of T wo Major NewsOrganizations Jeffrey N.Weatherly,Thomas V . Petros, Kimberly M. Christopherson, and Erin N. Haugen Although claims of media bias are abundant, systematic and scientific investigations of potential biases are rare. The present study was an attempt to determinewhether a perception of bias would be found in the headlines of lead or major sto-ries taken from the Web sites of two major American news organizations, CNN andFOX News, during the final two months of the 2004 presidential campaign.Significant perceptions of bias were found. Overall, headlines taken from CNN wererated as significantly more liberal than those taken from FOX News. Headlinestaken from FOX News were rated as slightly on the liberal side of neutral. WithCNN’s headlines slightly to the left of FOX News’, instructing participants that theheadlines came from a particular source did not influence the results.Although thestudy by no means provides the definitive answer to whether major news organi-zations have biases, it indicates that perceptions of bias exist. Keywords: media bias; perceptions; CNN; FOX News Bias in the media has been widely discussed in recent years.The idea that major American news organizations may have political biases or agendas was raised byGoldberg (2002). Goldberg, a former employee of CBS News, argued that theorganization had a liberal bias. He asserted that the vast majority of employeesat CBS News, including those in decision-making positions, held liberal viewsthat indirectly biased the news coverage of stories because the views played a rolein what stories were deemed newsworthy. Others, like news personality BillO’Reilly, have gone a step further and accused most major news organizations ofintentionally conspiring to forward a liberal agenda under the disguise of unbi-ased reporting (e.g., O’Reilly 2004). For example, some have coined CNN theClinton News Network because of its supposed favorable treatment of PresidentClinton while he was in office (e.g., Ponti 2004).  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  Still others have challenged these claims by saying that there is a conservative bias in the media. Franken (2003) satirically attacked the views and statements of Goldberg and others (e.g., O’Reilly) primarily affiliated with one newsorganization—FOX News. Indeed, the Internet is scattered with Web sites pur-portedly providing documentation of a conservative bias at FOX News (e.g.,Senti 2005). Although not claiming a conservative bias in the media, someresearchers have suggested that those with conservative viewpoints have wageda campaign of sorts to build perception among the populace that the media is lib-erally biased (Watts et al. 1999). According to these researchers, this campaignhas been accomplished largely through media stories on the topic of bias ratherthan on documented instances of biased news coverage. For better or worse, most claims of bias consist of anecdotal evidence and are forwarded by individuals with their own biases. Little in the way of sys-tematic, scientific inquiries into bias has been conducted, especially usingexperimental methods (but see Brescoll and LaFrance 2004). Furthermore, itis unclear as to how the rampant claims of media bias have influenced thepublic’s perception of bias in the media (Watts et al. 1999). It is possible thatclaims of media bias have actually created a situation in which people may per-ceive bias from a particular news source even if no real bias exists. It is alsopossible that people’s own political leanings may buffer them from perceivingbias even when bias does exist. When dealing with bias in the media, there are many different forms it can take. Some are indirect. Goldberg (2002) accused CBS News of bias, not nec-essarily in how a story was presented, but rather, in what stories were chosento be reported. Other forms are more direct. Taking a nonneutral stance onthe issues being covered once a story is chosen would be an example.Arguably,both of these forms of bias can be intentional or unintentional. For instance,news directors may be keenly aware that their political views are guiding theirchoice of what is newsworthy. Then again, such choices may be made in theabsence of overt knowledge of a bias.The complexity of interpreting “bias” fur-ther increases when one considers that the recipients of supposedly biasednews have their own biases of which they may or may not be aware. Thus, any single study on political bias in the media will likely be incom- plete.The present attempt was to determine whether a certain aspect of newsreporting (i.e., headlines posted on the Web sites of two major American newssources) would be perceived as biased. Headlines were chosen for several rea-sons. First, it was possible, in a relatively brief period of time, to expose par-ticipants to a number of different headlines from a particular source. Second,and perhaps more importantly, many of the news stories found on the Webpages of major news outlets come from the same source, the Associated Press.Thus, the text of the story is largely, if not entirely, identical when read fromthe different news agencies.What differs, however, is how those agencies pitchthe story.92 Press/Politics 12(2) Spring 2007  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  During approximately the final two months of the 2004 presidential campaign, we collected headlines from the CNN (http://www .cnn.com) and FOX News (http://www .foxnews.com) Web sites. The sites were checked atleast once daily, and headlines were chosen according to two criteria. First, thestory had to have a reasonable relation, directly or indirectly, to a political issue(e.g., a story about a mudslide would not be considered political, whereas cover-age of a presidential campaign function would be). Second, coverage of the samestory had to simultaneously be available on the Web sites of both news agencies. Participants then ranked each headline along a liberal-neutral-conservative continuum. Some participants were accurately informed that the headlineswere drawn from two different news agencies. Others were informed that allthe headlines were drawn from one news source, either CNN or FOX News. The hypothesized outcome depended on which of the lead authors was queried. One predicted that the headlines taken from FOX News would be per-ceived as more conservative than those taken from CNN, with CNN headlines’being perceived as neutral. Another predicted that headlines taken from CNNwould be perceived as more liberal than those taken from FOX News, with FOXNews headlines’ being perceived as neutral. Similar predictions were madeabout informing participants of the source of the headlines. One researcher pre-dicted the ratings of the headlines would be skewed toward the conservative endof the continuum when participants were told that all the headlines were fromFOX News.The other predicted the ratings would be skewed toward the liberalend when participants were told that all the headlines were from CNN. Method Participants Participants were 225 (seventy-four males, 149 females, and two who failed to identify their sex) individuals recruited through the University of NorthDakota psychology department and its subject pool.The mean age of the par-ticipants was 19.71 years ( SD=5.41). Participants received research credit in their psychology course(s) for their participation (if applicable). Materials Participants completed two measures. The first was the General Social Survey (Davis et al. 2002). It consisted of nineteen questions that assessedpolitical party affiliation, general political views, and certain behavioral char-acteristics. This measure was used for two reasons. First, it was used to pro-vide some assessment of how the current sample compared with the “average”citizen. Second, it is possible that individuals’ perceptions of political bias bythe news organizations could themselves be influenced by the views held bythe participants. This measure was thus used to help identify those views sothey could be controlled for statistically if necessary.Weatherly et al. / Political Bias in Headlines 93  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  The second measure was a list of twenty-eight pairs of headlines taken from the CNN and FOX News Web sites between September 13, 2004, and November 3, 2004.T o be chosen, the headlines needed to have a political topicand needed to appear as either the lead story or under the “More News”section on the CNN Web site, and simultaneously, as the lead story or underthe “Latest Headlines” section on the FOX News Web site. Also included withthe real headlines were two pairs of fabricated headlines that were intention-ally biased.Two of the headlines were biased toward a conservative viewpoint.The other two were biased toward a liberal viewpoint. A list of the real andfake headlines can be found in the appendix. Procedure On entering the room, participants went through the process of providing informed consent. Once consent was obtained, the researchers distributedpackets that contained the General Social Survey followed by the headlines.For the first group (paired-headlines group; n=60), the headlines were paired together such that the two headlines from CNN and FOX News on the samenews story were adjacent to one another. These participants read the follow-ing instructions before rating the headlines: The following represent headlines that appeared on two major news Web sites dur- ing the recent national campaign period.We are interested in determining whetherthe headlines were biased toward one political party or another.T o do so, we wouldlike you to rate each headline with a percentage from 0 percent to 100 percent,with 0 percent’s being liberally biased (i.e., pro-Kerry, pro-Democrat; anti-Bush,anti-Republican) and 100 percent’s being conservatively biased (i.e., pro-Bush,pro-Republican; anti-Kerry, anti-Democrat). If a headline showed no favoritism toone side or another (i.e., totally neutral), you would rate it 50 percent. Remaining participants were randomly divided into three groups (nonpaired groups). These groups rated the headlines presented in random order. One of these groups read the identical instructions as those that appear above.A secondgroup read the identical instructions with the exception that they were informedthat all of the headlines were from CNN’s Web site.The third group of partici-pants read that all of the headlines were from FOX News’Web site. After participants completed the General Social Survey and rated the head- lines, they were debriefed.They then received documentation of their partic-ipation (for purposes of earning course credit) and were dismissed. Results Examination of the data from the General Social Survey suggests that the composition of the paired-headlines and nonpaired-headlines groups was94 Press/Politics 12(2) Spring 2007  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  similar. In the paired-headlines group, twenty-four participants (40 percent) identified themselves as affiliated with the Democratic party, twenty-three(38.3 percent) claimed affiliation with the Republican party, five (8.3 percent)claimed to be Independents, and eight individuals (13.3 percent) marked the“don’t know” option. As for political leanings, nineteen individuals (31.7 per-cent) identified themselves as being extremely liberal, liberal, or slightly lib-eral. Twenty-six people (43.3 percent) identified themselves as moderate.Fifteen people (25 percent) identified themselves as slightly conservative, con-servative, or extremely conservative. For the nonpaired-headlines groups,fifty-four (32.7 percent) identified themselves as Democrats, seventy-three(44.2 percent) identified themselves as Republicans, and thirty-seven (22.4percent) identified themselves as Independents. As for political leanings, fifty-six (33.9 percent), sixty-two (37.6 percent), and forty-five (27.3 percent)individuals identified themselves as liberal, moderate, and conservative,respectively. A significant correlation was found between party affiliation andpolitical leanings (r s[177] =.509; p&lt;.01). Results for this analysis and all that follow were considered significant at p&lt;.05. The rationale of including fake headlines was to ensure that participants could identify bias. Participants, however, had difficulty discerning the bias inone pair of fake headlines.The headlines “Bush Defends Ill-conceived Health-Care Policy” versus “Kerry Evades His Lackluster Senate Record” generatedmean ratings of 58.5 percent (median =60 percent) and 56.0 percent (median =60), respectively. Bias in the second set of fake headlines, on the other hand, was well discerned by the participants.The headline “Bush on Correct Side ofMoral Issues” had a mean rating of 87.6 percent (median =100), while the headline “Kerry’s Morals Superior” had a mean rating of 11.9 percent (median=0). The second pair of fake headlines was therefore used to screen partici- pants. Participants’ ratings were eliminated from further analysis if the ratingof these latter fake headlines was beyond two standard deviations from theoverall mean for that headline. For the paired-headlines group ( n=51), this criterion removed nine participants from the following analyses. For the non-paired-headline groups ( n=137), it removed twenty-eight participants (group informed that headlines came from two news agencies, n =44; group informed that headlines came from FOX News, n=49; group informed that headlines came from CNN, n=44). Ratings for the paired-headlines group were analyzed by conducting a two- way (News Agency × Headline T opic) repeated-measures analysis of variance(ANOVA). 1 This analysis yielded a significant main effect of news agency ( F[1, 50] =14.54, p&lt;.001), indicating that participants rated the headlines taken from CNN as more liberal ( M=46.31) than those taken from FOX News (M=49.17). The main effect of headline topic was significant ( F[27, 1,350] = 23.61, p&lt;.001), indicating that ratings varied across the twenty-eight differentWeatherly et al. / Political Bias in Headlines 95  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  topics. Finally, the interaction between news agency and headline topic was also significant (F[27, 1,350] =6.86, p&lt;.001). T o follow up the significant interaction, a post hoc Tukey HSD was calcu- lated. Results demonstrated that within-pair differences existed for nine of thetwenty-eight headlines. The mean ratings for each headline by participants inthe paired-headlines group can be found in table 1. Ratings for the nonpaired-headline groups were analyzed by conducting a three-way (Instructions × News Agency × Headline T opic) mixed-modelANOVA. 2The instruction as to the news source of the headlines was the group- ing factor, while news agency and headline topic were repeated measures . This analysis yielded a nonsignificant main effect of instructions ( F[2, 134] =1.62),96 Press/Politics 12(2) Spring 2007 T able 1 Mean ratings (with standard deviations) of each headline by participants in the paired- headlines group and whether the ratings differed significantly Headline Pair CNN FOX News Significant 1 37.31 (31.27) 28.39 (32.65) X 2 63.24 (21.72) 62.75 (19.55) 3 27.16 (27.34) 35.29 (28.08) 4 43.78 (19.22) 46.08 (13.69) 5 73.83 (27.31) 62.45 (21.53) X 6 35.10 (29.42) 48.04 (23.11) X 7 30.35 (32.56) 33.18 (22.75) 8 37.96 (21.40) 49.31 (32.79) X 9 64.41 (22.77) 75.00 (26.17) X 10 29.47 (28.72) 33.43 (25.66) 11 55.00 (14.59) 47.55 (16.32) 12 17.94 (22.96) 52.45 (10.88) X 13 43.33 (23.21) 44.61 (20.27) 14 48.63 (19.32) 72.25 (28.02) X 15 55.98 (18.79) 53.92 (19.58) 16 45.10 (22.81) 51.76 (16.70) 17 44.12 (19.69) 48.33 (20.14) 18 47.88 (22.68) 39.76 (21.87) 19 48.73 (11.78) 51.37 (9.39) 20 45.59 (15.83) 49.71 (14.57) 21 35.78 (25.64) 39.90 (21.55) 22 37.06 (25.54) 37.65 (23.82) 23 37.53 (28.21) 42.35 (25.50) 24 41.37 (25.04) 42.45 (23.27) 25 49.51 (24.03) 48.53 (20.35) 26 73.31 (31.38) 82.45 (20.94) X 27 50.47 (28.74) 46.59 (26.78) 28 76.67 (27.42) 51.08 (30.57) X  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  indicating that ratings of the headlines did not vary as a function of the sup- posed source. The main effect of news agency was significant ( F[1, 134] = 29.46, p&lt;.001). Again, participants rated the headlines taken from CNN as more liberal (M =46.69) than those taken from FOX News (M =49.12).The main effect of headline topic was also significant ( F[27, 134] =119.39, p&lt;.001), as was the news-agency-by-headline-topic interaction ( F[27, 134] = 33.78, p&lt;.001). All remaining effects were not significant. Because of the significant interaction, a post hoc Tukey HSD was again calcu- lated to determine differences in ratings within each pair of headlines. Thatanalysis indicated that differences in ratings were present in fifteen of thetwenty-eight pairs. The mean ratings for each headline by participants in thenonpaired-headlines groups can be found in table 2. Discussion The present study assessed whether headlines for the same news story posted on the Web sites of CNN and FOX News would be perceived as biasedtoward one particular political perspective and whether any potential biaswould differ between news agencies. Results indicate that perceptions of theheadlines varied as a function of agency. Participants who read the competingheadlines side by side (i.e., the paired-headlines group) rated nine of thetwenty-eight headlines to differ between news agencies. Participants who readthe headlines in random order (i.e., the nonpaired-headlines groups) rated fif-teen of the twenty-eight headlines from the same story differently. Overall,participants in both groups rated the headlines from CNN as significantly moreliberal than those from FOX News.The absolute difference in the mean eval-uations was relatively small (3 percentage points), and the evaluations of bothFOX News and CNN were close to the 50 percent mark—the neutral point.Nevertheless, CNN tilted more to the left than did FOX News. The conclusion that CNN’s headlines were perceived as more liberal than FOX News’, rather than FOX News’ headlines’ being perceived as more con-servative than CNN’s, is supported by the finding that overall, the headlinesfrom FOX News were rated slightly on the liberal side of neutral. If FOXNews’ headlines had been perceived as biased toward the conservative view-point, then the overall ratings should have exceeded 50 percent (i.e., the con-servative side of neutral). The present study was also designed to determine whether information about the news agencies themselves would alter perceptions of bias. Theresults failed to support this idea. Participants who were not told the sourceof the headlines, were told CNN was the source, or were told FOX News wasthe source did not differ in their ratings of the headlines.Thus, despite accusa-tions that certain media outlets are biased (e.g., Franken 2003; Ponti 2004),Weatherly et al. / Political Bias in Headlines 97  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  either being informed of the source of the headlines had no influence on the participants’ perceptions of bias, the participants were not aware of such accu-sations, or both. Before labeling CNN’s headlines as liberally biased and claiming FOX News to be bias free, there are numerous aspects of the present procedure and resultsto be addressed. First, the sample used in the present study was a conveniencesample of college students from the University of North Dakota.Although polit-ical party affiliations and political leanings of participants tended to mirror thenational statistics, it is undisputable that the participants were younger than theaverage voter.Their education background also differed from a large number ofvoters, given that many voters have never attended a university.98 Press/Politics 12(2) Spring 2007 T able 2 Mean ratings (with standard deviations) of each headline by participants in the nonpaired- headlines groups and whether the ratings differed significantly Headline Pair CNN FOX News Significant 1 35.11 (36.49) 18.95 (29.02) X 2 78.66 (21.41) 80.83 (21.51) 3 15.46 (25.26) 30.21 (35.35) X 4 41.09 (23.01) 43.53 (21.08) 5 83.57 (24.28) 81.65 (21.29) 6 33.95 (35.66) 56.52 (31.45) X 7 36.62 (37.19) 24.17 (24.50) X 8 31.87 (31.00) 35.80 (35.51) 9 72.48 (24.65) 86.48 (20.28) X 10 24.13 (29.90) 15.43 (19.29) X 11 52.81 (11.52) 47.89 (10.74) X 12 9.07 (18.29) 49.58 (12.15) X 13 38.37 (23.21) 43.04 (20.27) 14 44.88 (22.20) 78.18 (27.40) X 15 60.75 (23.57) 61.61 (21.36) 16 49.04 (14.75) 51.15 (10.73) 17 47.02 (20.82) 46.12 (21.02) 18 46.91 (25.81) 36.43 (25.88) X 19 47.48 (18.31) 51.12 (7.25) 20 46.41 (14.42) 52.68 (14.22) X 21 31.48 (24.22) 34.21 (27.15) 22 50.26 (24.51) 35.82 (24.00) X 23 32.02 (27.91) 31.79 (27.33) 24 37.45 (27.25) 34.99 (28.24) 25 39.55 (24.52) 52.33 (20.13) X 26 81.07 (26.03) 85.83 (22.30)  27 55.97 (21.26) 50.97 (20.11) X 28 83.91 (23.96) 57.95 (34.19) X  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  One could also argue that because the study was conducted in a “red” state (i.e., a state that voted Republican in the 2004 presidential election), you would expect favoritism toward the supposedly conservative news agency(FOX News) and bias against the supposedly liberal agency (CNN).This argu-ment cannot be completely refuted. However, it can be questioned on anumber of levels. For one, the sample included more people who self-identi-fied as liberal than as conservative. Second, there were instances in which par-ticipants ranked the headlines from CNN as significantly more conservativethan those from FOX News (e.g., headline pairs five and twenty-eight).Third,participants ranked several of the headlines from FOX News as beingextremely conservative (e.g., headline pairs nine and twenty-six). Finally,information about the source of the headlines did not alter participants’ rank-ings, which you would expect if a preexisting bias was at work. Another potential argument is that participants could not properly perceive bias (or mistakenly perceived it). The fact that participants had difficulty dis-cerning the bias in one of the fake headline pairs supports this argument.Furthermore, some ratings were in the opposite direction than one mightexpect. For instance, the CNN headline “Bush Pushing Health Care Message”was rated on the conservative end of the spectrum by the average participant.However, one could reasonably rate this headline as liberal inasmuch as the termpushing carries a negative connotation. The argument that participants poorly perceived bias cannot be completely refuted. However, it can be said that par-ticipants very accurately identified the bias in the second pair of fake headlines.More importantly, perceptions of bias are determined by the perceiver. Thus,although it may be the case that participants in the present sample perceived biasdifferently than others might, we were specifically interested in reported per-ceptions of bias. According to the present participants, a bias was perceived. A related argument would be that because of the youth of the participants, they were relatively naive to political issues, and thus, insensitive to politicalnuances present or absent in the headlines. A different sample of people whowere experts on political issues may have produced vastly different results.Because the General Social Survey administered in the present study cannotdetermine the extent of someone’s political knowledge, it is not possible tofully assess or refute this argument.Then again, if this argument were correct,it would suggest that the present results actually represent a “pure” measure ofbias in that the participants may not have been “reading into” the headlines. Yet another argument against the finding of bias is that although headlines from CNN were rated as significantly more liberal than those from FOXNews, the actual difference was not large. Indeed, as noted above, there wereseveral instances in which headlines from CNN were reported to be signifi-cantly more conservative than those from FOX News. Certainly, the smalldifference and the instances of being more conservative can be used to argueWeatherly et al. / Political Bias in Headlines 99  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  that the headlines from CNN were not liberally biased.The one point that can- not be argued, however, is that across these twenty-eight pairs of headlines,participants reported a systematic difference in the political leaning in theheadlines from CNN versus from FOX News. That leaning may have beensmall, but it was systematic. One could, then, legitimately argue that the results of the present study were determined not by the participants but by the researchers who chosewhich headlines to use. It seems reasonable to suspect that if an entirely dif-ferent set of headlines would have been chosen, less bias, more bias, or bias ina different direction may have been reported. As with other arguments, thisone cannot be completely refuted. However, the present study was designedto try to guard against the potential biases of the researchers. For one, the rat-ings of bias were not the only dependent measure. Rather, headlines from bothnews agencies on the same story were rated so that even if there was a selec-tion bias, the difference between the sources could serve as a second depen-dent measure. Second, the researchers were aware of this potential confoundand tried to ensure that stories covered the spectrum.The fact that some of theheadlines from both sources were rated as very liberal (e.g., headline pairsthree and ten) while others were rated as very conservative (e.g., headlinepairs nine and twenty-six) suggests that this effort was successful. In guarding against this confound, however, the present study likely created another one. One selection criterion for the headlines was that both newsagencies had to be covering the same story as the lead or major story at thesame time. There were numerous instances in which potentially biased (orunbiased) headlines were not used because the opposing news agency was notcovering that particular story simultaneously. One such example was the cov-erage of CBS and its reporting of documents, now considered by many to beforgeries, that supposedly indicated that President Bush did not properly servehis time in the military (e.g., Associated Press 2004). Coverage of the CBSscandal could be found almost daily on FOX News. It appeared less frequently,at least as a major story, on CNN. The present study is silent as to potentialbiases represented by excessive coverage or omissions. The present data do not indicate that the reporting of the different news agencies is or is not biased. As noted above, headlines were chosen becausearticles are often similar on different Web sites because the sites get the arti-cles from the same source (e.g., the Associated Press).Thus, in the instances inwhich the same story ran under a different headline, there was no differencein reporting between CNN and FOX News.A different type of study would benecessary to determine whether biases exist between the two agencies interms of actual news reporting. Although accusations of bias in the media are commonly heard, relatively little in terms of systematic research has been done on the topic.The present100 Press/Politics 12(2) Spring 2007  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  study represents one such attempt. It looked at one potential source of bias between two (of many) news agencies on a sample of twenty-eight pairs ofheadlines for news stories. Admittedly, the results of the present study do notprovide the definitive answer as to whether bias exists in the media, who maybe biased, and how much they may be biased. However, the results do indicatethat participants perceived a bias in the headlines that were rated.That bias wasthat the headlines taken from CNN were rated as more liberal than those takenfrom FOX News. It must be noted, however, that the mean difference in evaluation of the two sources’ headlines was relatively small and that headlines are likely a weakertest of bias than the stories themselves.The last point—extending this type ofexperimental study to the full stories—is clearly an area for future research. Appendix Pairs of headlines in the order seen by the paired-headlines group. The parenthe- ses represent the pair number (see tables 1 and 2).The news agency is indicated after each headline, and the date the headlines appeared is also presented. Participants didnot see the pair number, agency, or date. (1) __________“Kerry Blasts Loss of Weapons Ban,” CNN, 9/13/2004 __________ “Kerry Slams Bush over Ban,” FOX (2) __________“Bush Addressing National Guard,” FOX, 9/14/2004 __________ “Bush to Talk to National Guard Convention,” CNN (3) __________“Kerry T outs Health-care Plan,” FOX, 9/14/2004 __________ “Kerry Woos Wisconsin Seniors,” CNN (4) __________“Americans Convicted in Kabul,” FOX, 9/15/2004 __________ “3 Americans Guilty in Afghan T orture Case,” CNN__________ “Bush on Correct Side of Moral Issues,” FAKE__________ “Kerry’s Morals Superior,” FAKE (5) __________“Bush Pushing Health Care Message,” CNN, 9/16/2004 __________ “Bush to Talk Health Care,” FOX (6) __________ “Laura Bush Speech Disrupted,” FOX, 9/17/2004 __________ “Laura Bush Heckled by Mom of Soldier Killed in Iraq,” CNN (7) __________ “Kerry Challenges Bush,” FOX, 9/20/2004 __________ “Kerry Attacks Bush’s Iraq Plans,” CNN (8) __________“Kerry Advisor Spoke with CBS Document Source,” CNN, 9/21/2004 __________ “Kerry Aide Linked to CBS Docs,” FOX (9) __________ “Iraqi PM:‘Thank You, America, ’” CNN, 9/23/2004 __________ “Allawi Thanks Bush for Iraq Effort,” FOX (10) __________ “Kerry Outlines Anti-terror Plans,” FOX, 9/24/2004 __________ “Kerry Unveiling Plan for T error War,” CNN (11) __________ “Kerry, Bush Plan for Debates,” FOX, 9/27/2004 __________ “Bush, Kerry Gear Up for First Debate,” CNN (12) __________“Candidates Downplay Poll,” FOX, 10/3/2004 __________ “Polls: Kerry Won Debate,” CNNWeatherly et al. / Political Bias in Headlines 101  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  (13)__________ “Report: No Iraq WMDs,” FOX, 10/6/2004 __________ “Official: No WMD Stockpiles in Iraq,” CNN (14)__________ “Bush:WMD Report Justifies Iraq War,” FOX, 10/7/2004 __________ “Iraq WMD Report Enters Political Battlefield,” CNN __________ “Bush Defends Ill-conceived Health-care Policy,” FAKE__________ “Kerry Evades His Lackluster Senate Record,” FAKE (15)__________ “Weapons Handover Begins in Sadr City,” CNN, 10/11/2004 __________ “Al-Sadr Militia Disarms,” FOX (16) __________ “108th Congress Wraps Up,” FOX, 10/12/2004 __________ “Congress Wraps up Rancorous Session,” CNN (17) __________ “Insurgents under Attack,” FOX, 10/12/2004 __________ “Iraqi Forces Raid Ramadi Mosques,” CNN (18)__________ “Source: U.S.Tried Twice to Rescue Hostages,” CNN, 10/13/2004 __________ “Iraq Hostage Rescue Failed,” FOX (19)__________ “Candidates Duel in Final Face-off,” FOX, 10/14/2004 __________ “Domestic Issues Dominate Debate,” CNN (20) __________ “Swing-state Stumping,” FOX, 10/15/2004 __________ “Kerry, Bush Search for Persuadable Voters,” CNN (21)__________ “Poll: Military Has Iraq Doubts,” FOX, 10/16/2004 __________ “Poll:Troops, Families Question Iraq Strategy,” CNN (22)__________  “Study:White Disproportionately Wealthier in U.S.,” CNN, 10/18/2004 __________ “Study: Income Gap Grows,” FOX (23) __________ “Dozens of Unarmed Iraqi GIs Killed in Ambush,” FOX, 10/24/2004 __________ “Dozens of Iraqi Soldiers Killed ‘Execution Style, ’” CNN (24)__________ “Explosives Missing in Iraq,” FOX, 10/25/2004 __________ “380 T ons of Iraq Explosives Vanish,” CNN (25) __________ “GI Answers on Al Qaqaa,” FOX, 10/29/2004 __________ “Pentagon Seeking Answers for Missing Explosives,” CNN (26) __________ “Bush Camp Claims Victory,” FOX, 11/3/2004 __________ “Bush Camp Certain of Win; Election Still up in the Air,” CNN (27)__________ “Senate: Daschle Loses, GOP Gains,” CNN, 11/3/2004 __________ “Daschle Loses Senate Seat,” FOX (28) __________ “Kerry Concedes to Bush,” FOX, 11/3/2004 __________ “Bush Wins: Kerry Calls to Concede,” CNN Notes 1. There is debate as to whether a covariate analysis should be used when dealing with com- pletely within-subject designs.Without taking sides in that debate, an analysis of covari- ance, with political leanings (i.e., liberal, moderate, conservative) and party affiliation(Democrat, Independent, Republican, and Don’t Know) as the covariates, was conductedseparately for the paired-headlines group. Similar results were obtained. Furthermore,both of these factors pulled out nonsignificant portions of the variance ( Fs &lt;1).Thus, we report results from the analysis conducted without covariates.102 Press/Politics 12(2) Spring 2007  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  2. Separate one-way ANOVAs of political party affiliation and political leanings by group yielded nonsignificant effects ( Fs &lt;1), indicating that a covariate analysis was not neces- sary. However, as a safeguard, an analysis of covariance was conducted for the nonpaired- headlines group using political leanings and party affiliation as covariates. The effect ofthese factors was not significant. Thus, we report results from the ANOVA conductedwithout covariates. References Associated Press. 2004. “CBS News Admits Bush Documents Can’t Be Verified.” Internet. &lt;http://www .msnbc.msn.com/id/6055248/&gt;. Brescoll, V ., and M. LaFrance. 2004. “The Correlates and Consequences of Newspaper Reports of Research on Sex Differences.” Psychological Science 15:515-20. Davis, J.A., T .W . Smith, and P .V . Marsden. 2002. “General Social Survey 2000.” Chicago: National Opinion Research Center (producer); Storrs, CT: The Roper Center for PublicOpinion Research, University of Connecticut (distributor). Franken, A. 2003. Lies and the Lying Liars Who T ell Them . Penguin: New York. Goldberg, B. 2002. Bias:A CBS Insider Exposes How the Media Distort the News.Washington, D.C.: Regnery. O’Reilly, B. 2004. The Media Strategy to Elect Kerry . Internet. &lt;http://www .billoreilly.com/pg/ jsp/general/genericpageblue.jsp?pageID =474#a&gt; . Ponti, L. 2004. “MSNBC, the New Clinton News Network?” Internet. Feb. 18. &lt;http://www .frontpagemag.com/Articles/ReadArticle.asp?ID =12234&gt; . Senti, S., ed. 2005. &lt;http://www .oreilly-sucks.com/ &gt;. Watts, M.D., D. Domke, D.V . Shah, and D.P . Fan. 1999. “Elite Cues and Media Bias in Presidential Campaigns: Explaining Public Perceptions of a Liberal Press.” Communication Research 26:144-75. Biographical Notes Jeffrey N.Weatherly is a professor of psychology and currently serves as the chairperson of the psychology department at the University of North Dakota. His research expertise is in theexperimental analysis of behavior. Address: Department of Psychology, University of North Dakota, Grand Forks, ND 58202-8380; phone: (701) 777-3470; fax: (701) 777-3454; e-mail: jeffrey_weatherly@ und.nodak.edu. Thomas V . Petros is a Chester Fritz Distinguished Professor of Psychology at the University of North Dakota. His research expertise is in developmental and cognitive psychology. Address: Department of Psychology, University of North Dakota, Grand Forks, ND 58202-8380.Kimberly M. Christopherson is a doctoral student in general/experimental psychology at the University of North Dakota. Her research expertise is in psychological issues in educationalsettings.Weatherly et al. / Political Bias in Headlines 103  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  Address: Department of Psychology, University of North Dakota, Grand Forks, ND 58202- 8380. Erin N. Haugen is a graduate of the clinical psychology PhD program at the University of North Dakota and is currently a psychology fellow at the UC Davis Medical Center inSacramento, California. Her research expertise is in anxiety disorders, especially as they relateto postpartum issues. Address: University of California, Davis Medical Center, 2230 Stockton Boulevard, Sacramento, CA 95817.104 Press/Politics 12(2) Spring 2007  at UNIV OF NORTH DAKOTA on March 25, 2016 hij.sagepub.com Downloaded from  View publication stats</td>
    </tr>
    <tr>
      <th>93</th>
      <td>news</td>
      <td>doi:10.1111/j.1662-6370.2011.02015.x\n\nThe Fairness of Media Coverage in Question:\nAn Analysis of Referendum Campaigns on\nWelfare State Issues in Switzerland\nLionel Marquis, Hans-Peter Schaub &amp; Marlène Gerber\nUniversity of Lausanne and University of Berne\n\nAbstract: The mass media are assigned an important role in political campaigns on popular votes.\nThis article asks how the press communicates political issues to citizens during referendum campaigns, and whether some minimal criteria for successful public deliberation are met. The press coverage of all 24 ballot votes on welfare state issues from 1995 to 2004 in Switzerland is examined,\ndistinguishing seven criteria to judge how news coverage compares to idealized notions of the media’s role in the democratic process: coverage intensity, time for public deliberation, balance in media\ncoverage, source independence and inclusiveness, substantive coverage, and spatial homogeneity.\nThe results of our quantitative analysis suggest that the press does fulﬁl these normative requirements to a reasonable extent and that fears about biased or deceitful media treatment of ballot\nissues are not well-founded. However, some potential for optimizing the coverage of referendum\ncampaigns by the Swiss press does exist.\n\nKeywords: Referendum campaigns, media fairness, press coverage, welfare state, Switzerland\n\n1. Introduction1\nInstruments of direct democracy are at the heart of the Swiss political system. They are\nwidely used, so much in fact that Switzerland alone accounts for half of all referendums\nheld at the national level all over the world (Kaufmann et al. 2005; DuVivier 2006). Quite\nexpectedly, this unequalled degree of direct democratic practice has triggered research to\nexplore the determinants, conditions, and outcomes of the use of initiatives and referendums, as well as research to ﬁnd out the causes of their success or failure. For example,\nSwiss scholars have directed their attention to the institutional eﬀects of the referendum on\nthe integration of political forces and to its role in shaping the Swiss concordance system\n(e.g., Neidhart 1970; Papadopoulos 1998; Vatter 2002). Another important area of inquiry\nfocused on individual and aggregate citizen behaviour in referendum votes, relating voting\npatterns to the level of elite support or to structural properties of campaign propaganda\n(e.g., Hertig 1982; Trechsel and Sciarini 1998; Bützer and Marquis 2002).\n1\n\nThis research was carried out at the University of Berne in the framework of a project on the ‘‘Political Consequences of Attitudes Toward the Welfare State’’ funded by the Swiss National Science Foundation, whose ﬁnancial\nsupport is gratefully acknowledged (grant #100012–108274). The authors would like to thank Klaus Armingeon\nand Nathalie Giger for their support, as well as Hans Hirter, head of the Anne´e Politique Suisse series, for giving\nus access to its invaluable archive of Swiss press releases. We also thank two anonymous reviewers for their extremely helpful comments on an earlier draft of our manuscript.\n\n 2011 Swiss Political Science Association\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nSwiss Political Science Review 17(2): 128–163\n\n129\n\nIn this study, we follow a complementary approach. Speciﬁcally, we ask how political\nissues are communicated to citizens during referendum campaigns, and whether some minimal criteria for successful public deliberation are met. Our analysis is based on the press\ncoverage of twenty-four ballot votes on welfare issues, spanning more than two legislative\nperiods (1995–2004) of highest importance for the development of the Swiss welfare state.\nAccordingly, our aim is to shed light on the journalistic perception of ballot campaigns.\nHowever, the views of political actors directly involved in partisan campaigns (e.g., parties,\nbusiness associations) are also reﬂected in their agenda-building eﬀorts to capture and manage media attention. It is from the interplay between these two perspectives on the news\nprocess — the journalists’ gatekeeping role and the elites’ agenda-building role — that the\nfocal questions of this study arise. What is the degree of media autonomy? How inclusive\nare journalists’ accounts of the political actors involved in campaigns? How biased are their\nportrayals of issues?\nIn the next section of the paper we present some current ideas about public deliberation\nand provide theoretical insights into the structure and functions of referendum campaigns.\nWe thus set a number of criteria for assessing whether media campaigns may be regarded as\nwise guides to sound decision-making. Section 3 then presents the empirical data collected\nand the methods used for measuring the quality of media campaign coverage. Sections 4 to\n7 oﬀer evidence of how journalists report on welfare state issues. We show that the press\ntreatment of these issues does not fall short of expectations as concerns seven distinct criteria\nof ‘‘fair coverage’’. On this overall basis, we conclude in Section 8 that some fears about\nskewed or deceitful media treatment of ballot issues are not justiﬁed, but also that the\ncommunication and framing of issues does not meet all conceivable normative requirements.\n\n2. Theoretical background: Criteria of fair media coverage\nThis article focuses on the ‘‘supply side’’ of referendum campaigns. Speciﬁcally, we attempt\nto deﬁne a number of dimensions on which to judge the fairness and democratic utility of\nthe coverage of referendum issues in the Swiss media. The importance of articulating ‘‘democratic expectations of media performance’’ has been emphasized in several contributions\n(e.g., Gurevitch and Blumler 1990; McLeod et al. 2002). In particular, the ‘‘social responsibility’’ of the media has attracted much attention, leading scholars to deﬁne a number of\ndesirable qualities of media content –– some of which may be properly regarded as ‘‘ethical’’, but others are more directly related to the functioning of democratic systems (e.g.,\nBunton 1998; Christians and Nordenstreng 2004).\nOur questioning in this article takes place in the interplay of several disciplines — including media ethics and the theory of deliberative democracy. These are broad and currently\nexpanding disciplinary areas rather than formalized theories coupled with established methods and ﬁeldwork, as the example of deliberative theory suggests (see Bächtiger et al. 2010).\nThese theoretical accounts do not provide a clear and agreed-upon indication of what\nmedia fairness should be conceived of, let alone how to measure fairness. However, to the\nextent that the media are an important arena where democratic deliberation may occur, one\nmajor conceptual distinction from deliberative theory is helpful for framing our approach\nto media fairness.\nScholars in the deliberative framework usually advance that democratic decision-making\nand deliberation may be appraised (and purportedly justiﬁed) either from an epistemic or\nfrom a procedural standpoint (see Cohen 1986; Estlund 1997; List and Goodin 2001). The\ndistinction is captured in the question of ‘‘whether we want our political outcomes to be\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nright or whether we want them to be fair’’ (List and Goodin 2001: 277). To be sure, democratic processes oriented toward the search for ‘‘truth’’ or toward the observance of procedures may often bring about similar outcomes. It is nevertheless easy to imagine cases\nwhere ‘‘correctness’’ lacks procedural fairness (e.g., one individual ‘‘rightly’’ chooses for all\nothers) and other cases where procedural rigidity is misplaced from procedure-independent\nstandards (e.g., it violates some notion of the ‘‘common good’’).\nThe ﬁeld of media ethics is concerned with the same kind of questions, asking whether\nand how the ‘‘fairness’’ goal of media coverage can put up with the sometimes dissonant\nideal of the ‘‘correctness’’ of the views being presented — beyond the mere question of\ninformation ‘‘accuracy’’. In this article we adopt a procedural stance and examine how media\ncoverage fulﬁls a number of formal rules regarding the form, provenance, and diﬀusion of\ninformation.2 Even though correctness criteria may appear to involve considerations of a\nmore normative nature, it is however obvious that any set of formal-procedural rules is\nitself not ‘‘given’’. As will become clear, some of the procedural criteria described below\nhave been the subject of considerable speculation and debate. Moreover, ‘‘fairness’’, as the\npivotal concept of procedural approaches, is to be taken here in a generic sense, as it\nextends beyond the notions of fairness developed in careful theoretical analyses of ‘‘democratic proceduralism’’ (Cohen 1989; Estlund 1997).3 This enlarged concept of media fairness\nposits that, whatever the media induce citizens to think and choose, they must do so within\ncertain procedural boundaries.\nIn this article we will focus on seven criteria that appear particularly relevant to evaluating the fairness of the media coverage of referendum campaigns in Switzerland. In this and\nthe following sections we identify these criteria at a fairly abstract level, based on the available literature, and we show how each of them provides an appropriate dimension for\nassessing the achievements of campaign coverage from a normative perspective. Our goal in\nthis contribution is primarily comparative, as we aim at showing how fairness varies across\nissue domains, across media outlets, over time, and across geographical units. Therefore,\nwe deliberately avoid setting precise boundaries between ‘‘fair’’ and ‘‘unfair’’ coverage. On\nthe other hand, the measurement of relevant criteria should be as precise and abstracted\nfrom context as possible, in order to allow for valid and meaningful comparisons. Besides,\nin order to avoid conceptual ambiguities, let us make clear that the term ‘‘fairness’’ is used\nhere to denote the ‘‘positive side’’ on each dimension of media coverage. Thus we do not\nwish to imply, for instance, that a short, two-week campaign coverage is deliberately\n‘‘unfair’’ or intended to fool voters, but only that a longer time period is more desirable\naccording to some formal-procedural normative standard.\nBased on this broad deﬁnition, we now delineate seven speciﬁc criteria for appraising the\nfairness of media campaign coverage.\n2\nBy choosing a procedural rather than epistemic perspective, we do not mean to imply any superiority or higher\ndesirability of the former perspective in dealing with our subject.\n3\nNevertheless, the fact that the elaboration and selection of procedural criteria is no less subjective than that of\nepistemic principles does not mean that the fundamental distinction between the two types of considerations is\nblurred. Generally speaking, our approach to media fairness is blind to information which may be of uttermost\nimportance from an epistemic perspective — the speciﬁc opinions and origins of information purveyed in media\ncoverage. We do not say that journalists are not (or should not be) driven by an orientation toward the common\ngood, as when they downplay opinions that are disruptive and threatening for the democratic order — for example,\nBritish and German journalists have totally ignored extreme right parties in their coverage of election campaigns in\nthe 1980s and 1990s (Bornschier 2010: 174-5). We simply say that this reference to the explicit content and implicit\nintent of media coverage is not relevant for our present purposes.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n130\n\n131\n\n1. Suﬃcient media coverage of issues. We ﬁrst consider the information function of the\nmass media and the public knowledge of political issues that is expected to stem from media\ninformation. Learning eﬀects are extremely important from a normative perspective, since\nthey attest to the capacity of the people to understand politics and to exert inﬂuence on\npolicies, as emphasized by classical democratic theory (e.g., Berelson 1952; Kelley 1960;\nKrouse and Marcus 1984; but see Pateman 1970). As a matter of fact, it has long been\nshown that media exposure generates knowledge about issues and candidates, and enhances\nopinion strength and attitude integration (e.g., Berelson et al. 1954: chap. 11; Delli Carpini\nand Keeter 1996: chap. 5; Jerit et al. 2006). These eﬀects are usually not overwhelming, but\nthey are quite robust across a wide range of contexts. Accordingly, learning eﬀects have\nbeen observed in the Swiss direct democratic context as well (Kriesi 1994; Kriesi 2005: chap.\n4; Marquis 2006). Information holding, in turn, matters for political judgments and voting\ndecisions (Bartels 1996; Sturgis 2003). For example, a lack of knowledge causes citizens to\nbe more conservative on some issues and more liberal on others (Althaus 1998; Gilens\n2001), and it usually prompts reliance on heuristic cues that can lead to serious misﬁts\nbetween the people’s actual choices and their own values and interests (e.g., Kuklinski and\nQuirk 2000). Therefore, the overall intensity of media campaign coverage probably matters\nboth for the public knowledge of issues and for the ﬁnal outcome of the ballots. In fact,\nfew would question that a suﬃcient amount of information is necessary for the proper functioning of democratic institutions. However, as argued below, the content of information\nalso deserves attention, especially as concerns value-laden information (e.g., Hofstetter\net al. 1999).\n2. Suﬃcient time for public deliberation. Time is needed for the public to become\ninformed about the issues and to ponder the pros and cons of a ballot proposal. If all campaign coverage takes place in a last-minute avalanche, then it is unlikely to beneﬁt citizens,\nhowever extensive it may be in terms of sheer volume. Quite logically, the inﬂuence of a\ncampaign usually concentrates on citizens who make up their minds during that campaign,\nthat is, for people whose voting decision was neither clear from the outset nor delayed until\nthe very last campaign days (e.g., Chaﬀee and Choe 1980; Fournier et al. 2004; Marquis\n2006). Were campaigns so short-lived as to be virtually nonexistent for the purpose of\ndeliberation, the collective decision-making process would be essentially reduced to the use\nof last-minute shortcuts (e.g., status quo bias) or of long-standing attitudes and prejudices\n(e.g., a personal bias against ‘‘big government’’). The longer the referendum campaigns, the\nmore likely it is that the same issues will be tackled and thus the same arguments will be\nrepeated. In turn, this cumulative exposure may be expected to facilitate information acquisition by citizens (see Marquis and Bergman 2009). In other words, frequent exposure to\ncampaign information enhances the accessibility of the relevant concepts (e.g., Higgins\n1996; Förster and Liberman 2007) and heightens the likelihood that they will permeate the\ncitizens’ voting considerations.\n3. No outright bias in media coverage. A relatively unbiased media coverage of issues may\nbe stressed as a prerequisite for sound collective deliberation. This ‘‘impartiality’’ or ‘‘balance’’ assumption is more or less explicitly present in the writings of political philosophers\nsuch as Arendt, Elster, and Habermas, but also in concrete experiments designed to mimic\nideal deliberative procedures (e.g., Yankelovich 1991: chap. 12; Luskin et al. 2002). Likewise, the norm of balance is deeply enmeshed in Western (primarily Anglo-American) culture and values (Schudson 2001). It looms large in the self-descriptions and perceived\nprofessional standards of journalists (e.g., Tuchman 1972; Patterson 1998) and in academic\nstudies of media coverage unveiling their structural biases (e.g., Gitlin 1980; Hallin 1984;\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nEntman 2004; Bennett et al. 2007).4 In addition, the development of ‘‘media watchdog journalism’’ monitoring media bias is, in part, reﬂective of the increasingly acute perception of\nthe media bias problem in Western societies (Graber 2006; Hayes 2008). For our present\npurposes, such ‘‘issue neutrality’’ may come in several forms: the media may simultaneously\npresent the arguments of both sides on an issue, or they may successively alternate between\npros and cons (and thus act neutrally on an aggregate basis), or else they may restrict themselves to presenting ‘‘facts’’ and avoid matters of opinion. Meanwhile, the requirement that\nthere be no outright bias in media coverage must not be taken to mean that the media\nshould display no partisan bias, or that they should avoid expressing opinions altogether.\nActually, some bias is inevitable and probably inconsequential, provided that it is not systematic and identical across all media outlets and issues. In addition, some mix of factual\ninformation and opinion statements is probably preferable to either one alone, for voters\nmost certainly need –– and look for –– both types of information to make up their minds.\nAs one study has shown, a voter’s general need for orientation toward media information is\ncodetermined by her interest in acquiring knowledge about facts and about journalistic evaluations (Matthes 2005).\n4. Source independence. Similar to balance, the ‘‘source independence’’ norm implies\nthat the media are assigned responsibility for addressing issues in an autonomous manner.\nIn this case, the normative expectation is that journalists should not depend too heavily\non government, political parties and special interests for getting and framing information\non campaign issues. Actually, there is a widespread belief in Western societies, including\nSwitzerland, that journalists have ‘‘surrendered to complexity’’ and mainly serve as emissaries or ‘‘postmen’’, as Wuerth (1999: 373) put it. According to the ‘‘determination\nhypothesis’’ and similar accounts of media-politics relationships, most news originates\nfrom oﬃcial sources, including government and various branches of the administration,\nand especially from governmental public relations activities. Such source dependency, so\nthe critics say, would lead to the formation of a misinformed and quiescent public (e.g.,\nBaerns 1979; King and Schudson 1995; Shoemaker and Reese 1995; Bentele 2003). For\ninstance, Grossenbacher et al. (2006) found that the press conferences held by two Swiss\ncantonal governments were indeed covered extensively by the local media, and that the\npress releases issued on these occasions were often published in original or only slightly\nabridged form, reproducing the local authorities’ positive self-assessments and issue priority. Likewise, more than half of the news stories in the U.S. press persistently emanate\nfrom oﬃcial sources (e.g., Sigal 1973; Graber 2006). However, some scholars have cast\ndoubt on the generalizability of such ﬁndings. For instance, it was found that the parties’\npress releases rarely ﬁnd their way into the German print media and ⁄ or that they are frequently altered and reframed by journalists (e.g., Donsbach and Wenzel 2002; Fröhlich\nand Rüdiger 2006). To some extent, journalists and their political sources are interdependent, both from a historical perspective (Schönhagen 2008) and in terms of role relationships (Merritt 1995). Journalists themselves are ambivalent about the autonomy issue. On\nthe one hand, they increasingly value public relations sources and practitioners in the\n4\n\nBiased coverage may occur in relatively subtle ways, such as when the photographs of candidates in newspapers\nare more or less favourable, depending on the ﬁt between the candidate’s and the paper’s political leanings (Barrett\nand Barrington 2005). However, no consensus can be found in the literature as to whether media coverage is structurally biased, for instance conservative-leaning vs. liberal-leaning, or pro- vs. anti-establishment. Interestingly, the\npublic perception that the media are biased toward liberal views may not be due to ‘‘real-world’’ media coverage\nbias, but to media self-coverage about biased media content (Watts et al. 1999).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n132\n\n133\n\ncourse of their professional experience (Sallot and Johnson 2006), not least because by\ncreating long-term relationships with insiders they are granted routine access to valuable\nﬁrst-hand information. On the other hand, ‘‘autonomy’’ is seen as an important journalistic norm (e.g., Gurevitch and Blumler 1977; McDevitt 2003), admittedly with some important diﬀerences between national contexts (Patterson 1998; Statham 2006).5 In the present\nstudy, we will assess to what extent journalistic accounts of the campaign issues are elaborated ‘‘independently’’ or based instead on ‘‘self-serving’’ sources of information such as\ngovernment, parties, and referendum committees.\n5. Source inclusiveness. The norm of inclusion calls for the coverage of the whole diversity of viewpoints, arguments, and groups engaged in a referendum campaign. This norm\nthus concerns the question of how broad the variety of sources to which journalists refer\n(and which they make available to the public) should be. From another perspective, it\nasks how open or restricted the access to the media should be for diﬀerent actors to\nvoice their standpoints toward a referendum issue. Several democratic theorists have\nstressed the importance of an unrestricted and equal access for all individuals and societal groups to democratic processes in general (e.g., Dahl 1989: 119–131) and to the processes of public deliberation and will-formation in particular. The inclusiveness of the\nlatter is especially prominent in theories of deliberative democracy. Cohen (1989: 21–23,\n30; see also Dryzek 1990; Habermas 1992) regards inclusiveness and open access as a\ncrucial aspect of an ‘‘ideal deliberative procedure’’.6 However, various empirical studies\nhave raised doubts about whether the media in reality live up to these expectations of\ndemocratic theorists (e.g., Page 1996; Gerhards 1997; Graber 2003). Pfetsch (2004) and\nBerkowitz (2009) argue that the degree of inclusiveness heavily varies depending on factors such as the cultural context, the journalists’ social characteristics, or the issue at\nstake. Speciﬁcally for Swiss referendums, Marquis and Bergman (2009) report a quite\nmarked decrease in the variety of actors involved in advertisement campaigns in the\n1990s. One reason for a low variety of sources might be the increasing commodiﬁcation\nand commercialization of the media, which presses them to restrict themselves to sources\ncompatible with the mainstream (Meier and Jarren 2002). Second, an increasing professionalization in the PR departments of the more established political actors might raise\nthe hurdles for less prominent and ﬁnancially disadvantaged groups to ﬁnd their way\ninto the media (Gurevitch and Blumler 1990). Third, while there do exist strategies for\npolitical ‘‘outsiders’’ to get included in a mediated political discourse, established political\nactors have also developed counter-strategies to hold outsiders and their arguments oﬀ\nthe media attention (Kriesi 2003: 221–225). In the following analysis, we will assess the\nvariety of reported viewpoints by the number of diﬀerent groups of actors which journalists draw on as information sources.\n6. Substantive coverage. For many observers, it is not enough that media information\nbe balanced and independent of special interests — in addition, it has to address the\nsubstance of political issues. In fact, an essential part of campaign news coverage is\n5\n\nFurther, journalists may feel committed to autonomy as a result of their own audiences’ support for the norm\nof impartial coverage (Hargreaves and Thomas 2002) and as a result of their commitment being challenged by\n‘‘popular commentators’’ such as bloggers (Singer 2007). In fact, public trust in the media may be undermined by\nexcessive governmental control (Connolly and Hargreaves Heap 2007).\n6\nThe inclusion of the whole diversity of opinions and societal groups is also a core request of the so-called ‘‘diﬀerence democrats’’, who emphasize that it enhances not only the legitimacy of the opinion-building process, but also\nthe stock of social knowledge and information available to the participants in the public discourse, thus facilitating\nwell-informed and rational decisions (Young 1990: 119; 2000: 81–120; see also Connolly 1991).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nframed in terms of non-substantive features of elections, such as their ‘‘game’’ or\n‘‘horserace’’ aspects, and ignores their underlying issues (e.g., Strömbäck and Dimitrova\n2006). A strong case has been made against the pervasiveness and deleterious inﬂuence\nof horserace information in a variety of election campaigns (e.g., Gollin 1980; Bartels\n1988; Patterson 1994). We therefore only brieﬂy discuss the relevance of the issue for\nthe Swiss direct democratic environment. As pointed out by Rothmayr and Hardmeier\n(2002) and Longchamp (1998), the practice of direct democracy in Switzerland has\ninhibited rather than stimulated the development and use of opinion polls by both the\nmedia and governmental agencies. This is because frequent and ‘‘real’’ voting results\nare widely considered to provide a better account of public opinion than ‘‘unrealistic’’,\n‘‘out-of-context’’ opinion polls. However, Swiss journalists may ﬁnd such polls attractive\nto report, in light of the news media’s preference for the ‘‘horserace’’ aspects of campaigns and for warfare and sports narratives. Moreover, they may ﬁnd it convenient to\ndraw on such ready-to-use information, without paying too much attention to its technical validity and practical relevance (see Hardmeier 1999). As a way to gauge the\nextent of horserace coverage, we will compare the amounts of ‘‘campaign-oriented’’ and\nof ‘‘issue-oriented’’ information provided by the media.\n7. Spatial homogeneity. In a multicultural society such as Switzerland, the protection\nof minorities is usually a pressing issue. In addition, there is widespread concern that\ndirect democratic decisions might heighten the risk of some ‘‘tyranny of the majority’’\n(e.g., Donovan and Bowler 1998; Hajnal et al. 2002). In Switzerland, diﬀerences between\nlinguistic regions, particularly as concerns voting behaviour in referendums, constitute\none of the most salient political cleavages (e.g., Kriesi 1998; Linder et al. 2008). This\ncleavage is also one that is clearly identiﬁable and frequently reported on in the news\nmedia, probably because it is conﬂict-laden and thus has a high news value (Kriesi et al.\n1996; Hardmeier 2000: 388). The Swiss media system is itself highly segmented along linguistic lines (Kriesi et al. 1996; Wuerth 1999; Blum 2003; Tresch 2008), and even the\npublic service media ﬁnd it increasingly diﬃcult to promote national cohesion, as this\ntask is incompatible with economic imperatives (Meier and Schanne 1994: 37–39). In\nfact, concerns about majority rule are not substantiated by empirical evidence in general\nterms, as referendum voting patterns are much more homogeneous than heterogeneous\nacross cantonal and linguistic units (Diskin et al. 2007). In some cases, however, these\nconcerns may be justiﬁed, as suggested by parliamentary votes or referenda results on welfare state issues, showing support for welfare policies to be signiﬁcantly higher in the\nFrench- than in the German-speaking region (e.g., Leuthold et al. 2007). To be sure, it is\nperfectly legitimate for journalists from diﬀerent places and cultural backgrounds to pursue their own agendas, for example as they index their treatment of job issues to real or\nperceived unemployment rates in their own area. Likewise, journalists may choose diﬀerent speciﬁc information ‘‘formats’’ (e.g., heavily biased ‘‘opinion’’ articles or more balanced ‘‘points of view’’ articles) depending on their cultural environment and on how\nparochial the interests at stake are (e.g., Robinson 1995: 360–362). Accordingly, there is\nno reason to expect equal issue coverage all over the country. However, the inﬂuence of\nthe media on voters can diﬀer between the linguistic areas (e.g., Kriesi 1994; Marquis\n2006: 623–628). Hence, heterogeneity of media content may reinforce existing cleavages\nand (re)produce undesirable tensions between linguistic communities. In the cases where\nthe majority group prevails, it may fuel the argument of a ‘‘tyranny of the majority’’. In\nsum, small between-region variations in media coverage are arguably preferable to great\nvariations.\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n134\n\n135\n\n3. Methods and measurements\nThis study bears on the 24 ballot votes dealing with welfare state issues which were held in\nSwitzerland between 1995 and 2004 (see Table A1 in Appendix). Our empirical data consists of press articles collected in twenty-eight daily or weekly newspapers during an eightweek period preceding each ballot. The papers together account for a daily circulation ﬁgure of about two million copies and they are quite representative of the various Swiss\nregions.7 However, they were selected mainly for availability reasons, as they are consulted\non a daily basis by the collaborators of the Anne´e Politique Suisse at the University\nof Berne, Switzerland, and their content is classiﬁed into ﬁne-grained thematic categories.\nIt was thus easy to ﬁnd out all campaign-related articles and to code the relevant\ninformation.\nTwo levels of analysis: articles and issue statements. Overall 4303 articles were found and\ncoded. From these, a one-quarter sample of 1088 articles was randomly selected for additional analysis of the campaign issue statements.8 A maximum of three issue statements per\narticle were coded, with the selection occurring on the basis of internal importance within\neach article. In total, 2859 issues were coded out of our sample, making for an average of\n2.63 issues per article.\nIntensity and length. The number of articles and their size (in centimetres squared, then\nconverted in number of standard newspaper pages) were used to determine the intensity of\ncampaign coverage.9 Based on the date on which an article was published, the number of\ndays remaining before voting day was used to compute a measure of the ‘‘average campaign\nday’’ (mean of days remaining for separate ballots or newspapers).\nSource independence and inclusiveness. Up to ﬁve sources per article were coded to determine who the ‘‘speakers’’ were, i.e., which categories of individuals or groups were primarily involved in determining the content of an article. Multiple sources were considered; for\nexample, when a journalist interviews a political leader, two separate sources are coded.\nSimilarly, up to two sources were coded for each issue statement within an article. We thus\ncontrol for the fact that the original issue arguments delivered by a given source are often\nembedded in the discourse of a diﬀerent ‘‘speaker’’ through positive or negative references.\nFor example, it can be the case that all issue statements contained in an article where\n7\n\nThe 1998 circulation ﬁgures are taken from the WEMF marketing research institute. The two related outlets\n‘‘Blick’’ and ‘‘Sonntags-Blick’’ are considered here as one and the same paper. In contrast, the French-speaking\ntabloid ‘‘Le Matin’’ was not available in the archive of the Anne´e Politique Suisse, although it is one of the major\nSwiss papers. However, a glimpse at the data for ‘‘Blick’’, its counterpart in the German-speaking region, suggests\nthat tabloids play a relatively minor role in the coverage of referendum campaigns. As a matter of fact, the 28 outlets are edited in 16 diﬀerent Swiss cantons (out of a total of 26 cantons). Further, according to survey data, a\nmajority of people in all but three cantons (SO, TG, ZH) are ‘‘heavy’’ or ‘‘medium users’’ of at least one newspaper\namong those considered here (http://www.remp.ch/fr/glossar/index.php [accessed: 15.02.2010]).\n8\nThe selection was performed by simply picking every fourth article in the database, reinitializing the count for\neach ballot issue. Checks were made to ensure that the obtained sample was not diﬀerent from the whole dataset as\nconcerns provenance, format, and article bias. An issue statement is deﬁned here as an argument or set of arguments related to one speciﬁc matter addressed in the campaign about a ballot measure. It may pertain to a policy\ntheme (e.g., environment, energy), a driving value or principle (e.g., solidarity), distinctive qualities of the proposed\nmeasure (e.g., ﬂexibility), or the larger context of the ballots (e.g., rationale for a tactic vote). Issue statements have\nbeen classiﬁed into thirty-three categories (full list available upon request from the authors). For reasons of space\nlimitation, however, we will not dwell on the question of which speciﬁc issues were emphasized in the various referendum campaigns.\n9\nFor various reasons (e.g., missing part), 24 articles could not be coded as to their size and were assigned the median value of all calculated sizes (266 cm2).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\n‘‘journalists’’ are identiﬁed as the speaker category are in fact attributable to other actors to\nwhich journalists refer (e.g., partisan sources, government, and employees’ associations).\nBoth speakers and issue statements’ sources were coded into fourteen mutually exclusive\ncategories: (1) parties, politicians, and other party-related groups or individuals; (2) committees; (3) journalists and press agencies; (4) employers’ organizations; (5) employees’\norganizations; (6) economic associations; (7) national government; (8) local government; (9)\nscience- and education-related groups; (10) health-related groups; (11) disabled people’s\ngroups; (12) women’s and families’ groups; (13) other non-proﬁt organizations; (14) other\nactors. Together, categories (1) and (2) represent what we call ‘‘partisan actors’’.10\nThe importance of journalists (category 3) will be compared with that of the other actor\ncategories (both as ‘‘speakers’’ and as sources of issue statements) to assess the degree of\nthe press’ ‘‘source independence’’. Note, however, that the total for any two groups of\nactors may exceed 100 percent since, by deﬁnition, several actors may be considered as the\n‘‘sources’’ of an article or issue statement.\nFurther, we used the same source categories to build our measure of inclusiveness. It is\nsimply the number of discrete categories from which at least one source of issue statements\nis drawn. In some of the forthcoming analyses, we will satisfy ourselves with this ﬁrst measure (NBCAT). However, in order to control for the fact that some sources may be only\nmarginally involved in agenda-building (and inclusiveness may thus be overestimated), we\nalso assessed the degree of ‘‘equality’’ in the total references to sources of issue statements.\nThis was achieved through the Index of Qualitative Variation (IQV):\n\n\nk\nP\n2\n2\nk N  fi\nIQV ¼\n\ni¼1\n\nN2 ðk  1Þ\n\n;\n\nwhere k is the total number of source categories, N is the total number of (weighted) issue\nstatements, and fi is the frequency of all issue statements attributable to source i (N and f\nmay be computed either as absolute numbers or as proportions). IQV scores can be integrated with NBCAT into a standardized measure of inclusiveness: INC=(NBCAT ⁄ 14) ·\nIQV. Somewhat surprisingly, NBCAT and IQV scores are totally uncorrelated at the level of\nballot measures or of separate media outlets (r &lt; .06). In fact, restriction of range in IQV\nvalues (M = 0.87, SD = 0.04, N = 24 ballot measures) explains why NBCAT has a much\ngreater impact in determining INC scores.11 It also justiﬁes using NBCAT alone, for simpliﬁcation purposes, when IQV scores barely vary in cross-temporal and spatial comparisons.\nSubstantive coverage. The ‘‘format’’ of each article was coded following a three-fold distinction: (1) ‘‘opinion articles’’ (i.e., editorials, interviews, op-eds, free columns, or letters to\nthe editor); (2) ‘‘factual articles’’ (i.e., mere reporting); and (3) ‘‘horserace information’’\n(i.e., voting cues by parties and groups, opinion polls and other predictions, coverage of\ncampaign events). The percentage of articles of the ‘‘horserace’’ type is used to assess the\namount of ‘‘non-substantive’’ information. Among ‘‘substantive articles’’, the percentage of\n10\n\nUnlike in other policy areas such as foreign policy (see Marquis 2006), virtually all committees on welfare state\nissues are backed by parties and politicians.\n11\nAt the level of ballots and papers, INC is strongly associated with NBCAT (r &gt; 0.96) but not with IQV scores\n(r &lt; 0.19). This raises the question whether the aggregation rule (unweighted multiplication of the two measures)\nis appropriate, since both NBcat and IQV are important on theoretical grounds. At the empirical level, however, it\nmakes sense not to give more weight to the variable with lesser variation.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n136\n\n137\n\n‘‘opinion’’ and ‘‘factual’’ articles is used to shed light on the ‘‘orientation’’ and ‘‘information’’ functions of press coverage, respectively.\nBias in coverage. Five broad categories aimed to assess the overall thrust of each article,\nbased on the general slant of its arguments: (1) predominantly pro (i.e., suggesting a ‘yes’\nvote on the ballot question); (2) predominantly con; (3) neutral; (4) mixed, i.e., controversial\nand including both sides; and (5) no argument. Similarly, the bias of each issue statement\nwas coded on the basis of the same categories (excepting the ‘‘no argument’’ category,\nwhich is irrelevant). The categories were collapsed across ballot measures or other relevant\nunits of analysis (newspapers, language areas, etc.) and combined to produce a summary\nindicator of coverage bias:\n\n\n\npro þ neu þ mix\nB¼\n 0:5  2;\npro þ con þ 2  ðneu þ mixÞ\nwhere pro is the number of positive items, con is the number of negative items, neu is the\nnumber of neutral items, and mix is the number of controversial items.12 Unbiased coverage\nis denoted by a B value of 0, while B values of –1 and +1 indicate the highest possible bias\nagainst and in favour of some proposal, respectively.\nHowever, B scores are not well adapted for comparing bias in coverage across several\nballot measures, since the meaning of pros and cons depends on how the ballot question\nwas framed. One strategy is to rely on absolute values (i.e., |B| scores) to get an estimation\nof the overall extent of bias, regardless of direction. Another strategy is to devise a measure\nthat expresses bias in terms of endorsement or opposition of welfare state policies. This\nrequires that ‘‘pro’’ and ‘‘con’’ categories be inverted for ballots in the ‘‘retrenchment’’ category, i.e., measures that seek to reduce welfare beneﬁts or to limit welfare expansion. Thus\nan original B score of +0.2 remains unchanged for expansion measures but its polarity is\ninverted and shifted to –0.2 for retrenchment measures. We call this new measure B*. Computing B* scores also implies that ballot measures can be clearly identiﬁed as ‘‘expansion’’\nor ‘‘retrenchment’’ measures. In other words, only media contents that can be clearly\nassigned to ‘‘pro-welfare’’ and ‘‘anti-welfare’’ positions should be considered. This leads us\nto remove three ‘‘populist’’ proposals (ballots 724, 732, and 781; see Table A1) from the\nanalysis whenever media bias is analyzed by means of B* scores.13 Except in this case, however, and unless indicated otherwise, all indicators used in this study are based on the total\nnumber of ballots (i.e., 24).\n\n12\nWe take into account ‘‘neutral’’ and ‘‘mixed’’ items because failing to do so leads to serious distortions in the\ncases where coverage is mostly neutral but where only a few biased stories would result in meaninglessly high scores\nof coverage bias. Thus, for example, a number of positive items twice larger than that of negative items but equal\nto the number of non-valenced (i.e., neutral and controversial) items yields a B of ‘‘only’’ about 0.14. By the same\ntoken, B scores are expected to be more polarized when measured at the level of issue statements rather than at the\nlevel of articles, because in the former case the number of non-valenced items is considerably lower. Note also that\nB is very strongly correlated (r &gt; 0.98) with alternative measures of media bias, such as that used by Zaller and\nChiu (1996).\n13\nFor our purposes, we deﬁne populist proposals as emanating from right-wing nationalist parties and groups,\nand being opposed by other parties. They consist of ‘‘radical’’, often ‘‘simplistic’’ solutions to welfare problems,\nusually charging ‘‘big business’’, high-proﬁt sectors, or available public wealth. However, as these proposals do not\nalign with the traditional ideological cleavages on welfare issues, opposition to them does not imply an endorsement of the welfare system. Accordingly, these proposals are hardly comparable with other proposals.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nSpatial homogeneity. Indicators for each of the six above criteria of media fairness can\nbe compared between the two main cultural areas in order to assess the homogeneity\nof media coverage. Simple diﬀerences are calculated between values for the majority\n(German-speaking) cultural area and those of minority areas. The only Italian-speaking\npaper in our database (i.e., Corriere del Ticino) is considered together with the Frenchspeaking outlets.14\nValidity checks. Each of the two independent coders read half the selected articles and\nmeasured all particular aspects listed above. Intercoder disagreement was examined from a\nsample of all coded articles and settled through discussion, resulting in more ﬁne-grained\nand univocal coding procedures. The issue statements of all the 1088 selected articles were\nthen coded again. Finally, a sample of 24 articles (one for each proposal) was drawn to\ncheck for coding consistency. Intercoder reliability was found to be satisfactory (Cohen’s\nkappa=0.704).15\nWeighting procedures. Except for analyses bearing solely on the sheer number of articles,\ntwo weighting procedures were applied. First, in keeping with the literature on public attention and response (e.g., Neuman 1990; Price and Zaller 1993), the size of articles was logged\nand used as a weighting factor to account for the notion that marginal returns of an\nincrease in news volume are generally diminishing. That is, for example, the diﬀerence\nbetween a ﬁve-inch-squared, barely visible, short article and a half-page article is probably\nmore consequential than the diﬀerence between a full-page and a double-page article.\nSecond, the ‘‘internal length’’ of issue statements was used to weigh their importance within\nour sample.16\n\n4. An overall view of press performance\nTable 1 gives an overview of six of the seven criteria of media fairness presented in the theoretical and measurement sections — the ‘‘spatial homogeneity’’ dimension shall be analyzed\nseparately below.\n\nIntensity of coverage\nThere is little reason to expect journalists to devote equal attention to all subject matters;\nsome issues are of greater concern to them (and to their readers) and are thus more likely\nto ﬁnd their way onto the media agenda. In fact, there is a good deal of variation in the\n\n14\n\nJournalists and political actors from the two minority cultural areas usually share the same general orientation\ntoward welfare politics (though not in other important policy ﬁelds) and are probably closer to each other than\nthey are to journalists and political actors from the German-speaking majority. More importantly, diﬀerences\nbetween majority and all minority areas are more commented upon and likely to be more consequential for\nnational cohesion than diﬀerences between minorities.\n15\nThis is actually a more than ‘‘fair’’ performance according to the standard interpretation by Landis and Koch\n(1977: 165). 67 issue statements were coded by the two coders simultaneously, i.e., an average of 2.8 issues per article. Three issues were coded by only one coder and were removed from the analysis, thus very slightly overestimating intercoder reliability by obfuscating disagreement over the sheer number of issue statements present in a press\narticle. However, when the three issues are taken into account, the level of disagreement rises by a very small\namount, and j is still 0.67.\n16\nFive rough categories approximating the ‘‘internal length’’ of issue statements were recoded into ﬁve ratios\nreﬂecting their share in the whole article: 0.20, 0.35, 0.50, 0.65, and 0.80.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n138\n\n 2011 Swiss Political Science Association\n\n22.5\n\n45.1\n\n23.8\n\n60.0\n\n64.5\n\n74.9\n\n71\n\n171\n\n100\n\n186\n\n238\n\n275\n\n21.1\n\n82\n\n48.9\n\n19.8\n\n83\n\n156\n\n64.7\n\n258\n\n48.9\n\n61.5\n\n216\n\n156\n\n95.1\n\n317\n\n91.7\n\n64.3\n\n185\n\n312\n\n96.7\n\nSurfaceb\n\n301\n\nNumbera\n\n0.757\n\n0.628\n\n0.732\n\n0.505\n\n0.587\n\n0.389\n\n0.444\n\n0.444\n\n0.729\n\n0.488\n\n0.434\n\n0.762\n\n0.618\n\n0.858\n\n0.666\n\n0.694\n\nInclusivenessc\n\n25.9\n\n26.2\n\n26.4\n\n20.9\n\n25.5\n\n22.0\n\n26.4\n\n26.4\n\n26.7\n\n23.3\n\n18.6\n\n24.5\n\n19.5\n\n23.0\n\n22.7\n\n22.7\n\nAverage\ncampaign\ndayd\n\n)0.315\n)0.013\n)0.122\n)0.208\n\n)0.071\n)0.046\n)0.064\n)0.086\n\n0.168\n\n)0.489\n\n)0.255\n\n0.075\n\n)0.139\n\n)0.098\n\n)0.210\n\n)0.176\n\n)0.151\n\n)0.071\n\n0.089\n\n)0.098\n\n)0.103\n\n)0.050\n\n0.249\n\n87.3\n\n)0.108\n\n)0.074\n\n0.054\n\n78.6\n\n)0.042\n\n)0.006\n\n89.8\n\n89.9\n\n92.1\n\n83.0\n\n89.1\n\n93.7\n\n85.5\n\n85.5\n\n81.5\n\n78.6\n\n78.8\n\n81.0\n\n81.6\n\n)0.142\n\n)0.062\n\n84.3\n\n% Journalists\n(articles)f\n\n0.144\n\nIssue\nbiase\n\n0.075\n\nArticle\nbiase\n\n21.0\n\n22.2\n\n4.6\n\n20.1\n\n12.1\n\n20.1\n\n19.6\n\n19.6\n\n21.8\n\n21.8\n\n3.2\n\n22.3\n\n15.2\n\n13.0\n\n21.7\n\n18.5\n\n% Parties\n(articles)f\n\n25.5\n\n17.2\n\n22.9\n\n31.1\n\n28.2\n\n44.9\n\n31.0\n\n31.0\n\n31.2\n\n17.1\n\n15.0\n\n20.4\n\n35.2\n\n22.8\n\n39.4\n\n28.7\n\n% Journalists\n(issues)f\n\n47.7\n\n57.7\n\n29.6\n\n57.1\n\n36.6\n\n23.0\n\n47.1\n\n47.0\n\n44.6\n\n47.5\n\n34.7\n\n42.8\n\n40.4\n\n39.6\n\n38.8\n\n43.7\n\n% Parties\n(issues)f\n\n42.0\n\n36.6\n\n61.9\n\n52.0\n\n63.8\n\n46.7\n\n49.2\n\n48.6\n\n53.6\n\n45.6\n\n35.5\n\n50.6\n\n50.8\n\n47.5\n\n49.2\n\n48.4\n\n% Reportingg\n\n31.7\n\n32.8\n\n33.2\n\n38.6\n\n27.8\n\n42.2\n\n39.9\n\n40.5\n\n35.4\n\n41.2\n\n33.6\n\n41.4\n\n42.2\n\n38.6\n\n36.8\n\n33.7\n\n% Opiniong\n\n26.3\n\n30.6\n\n4.9\n\n9.3\n\n8.4\n\n11.2\n\n10.9\n\n10.9\n\n11.0\n\n13.2\n\n30.9\n\n8.0\n\n7.0\n\n13.9\n\n14.0\n\n17.9\n\n% Horseraceg\n\n139\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n571 R ⁄ Reform of pension\nsystem (1995)\n572 I ⁄ ‘‘For extending the\npension system’’ (1995)\n602 R ⁄ Labour (weekend ⁄ night work) (1996)\n622 R ⁄ Unemployment\ninsurance (1997)\n643 I ⁄ Retirement age\n(1998)\n654 R ⁄ Labour (night\nwork, maternity) (1998)\n684 R ⁄ Disability\ninsurance (1999)\n685 R ⁄ Maternity\ninsurance (1999)\n721 I ⁄ Retirement age for\nwomen (2000)\n722 I ⁄ ‘‘Flexible\nretirement age’’ (2000)\n724 I ⁄ ‘‘Reduced hospital\ncosts’’ (2000)\n732 I ⁄ ‘‘Cheaper drugs’’\n(2001)\n752 I ⁄ ‘‘Secure pension\nsystem’’ (2001)\n762 I ⁄ Reduction of work\ntime (2002)\n781 I ⁄ ‘‘Gold to pensions’’\n(2002)\n782 CP ⁄ ‘‘Gold to\npensions’’ (2002)\n\nProject (R=referendum,\nI=initiative,\nCP=counterproposal)\n\nTable 1: Indicators of fairness for media coverage of 24 ballot issues\n\nMedia Coverage of Referendum Campaigns\n\n 2011 Swiss Political Science Association\n\n29.0\n\n48.9\n\n40.3\n\n109\n\n170\n\n131\n\n197.0\n(63.5)\n121.5\n(41.2)\n273.0\n(39.0)\n122.5\n(40.5)\n173.8\n(91.0)\n\nNumbera\n\n57.6\n(19.1)\n34.8\n(12.8)\n76.8\n(14.9)\n33.2\n(12.2)\n51.0\n(29.5)\n\nSurfaceb\n\n52.0\n(R=1248.1)\n22.4\n\n45.4\n\n163\n\n179.3\n(R=4303)\n73.5\n\n49.9\n\n152\n\n61.9\n\n21.8\n\n92\n\n234\n\n47.5\n\nSurfaceb\n\n145\n\nNumbera\n\n0.606\n(0.120)\n0.533\n(0.091)\n0.781\n(0.052)\n0.621\n(0.133)\n0.667\n(0.155)\n\nInclusivenessc\n\n0.131\n\n0.623\n\n0.834\n\n0.475\n\n0.683\n\n0.645\n\n0.754\n\n0.629\n\n0.525\n\n0.674\n\nInclusivenessc\n\n25.0\n(2.1)\n22.9\n(3.5)\n25.6\n(1.1)\n23.9\n(0.6)\n22.8\n(2.8)\n\nAverage\ncampaign\ndayd\n\n2.8\n\n24.1\n\n24.6\n\n27.2\n\n27.4\n\n22.9\n\n24.5\n\n26.5\n\n17.6\n\n26.9\n\nAverage\ncampaign\ndayd\n\n0.079\n(0.021)\n0.138\n(0.076)\n0.073\n(0.019)\n0.121\n(0.054)\n0.051\n(0.030)\n\nArticle\nbiash\n0.135\n(0.070)\n0.300\n(0.179)\n0.353\n(0.103)\n0.308\n(0.098)\n0.061\n(0.042)\n\nIssue\nbiash\n\n0.138\n\n0.182h\n\n0.086h\n0.049\n\n0.456\n\n0.252\n\n0.091\n\n0.114\n\n0.026\n\n0.008\n\n)0.046\n0.081\n\n0.406\n\n)0.008\n\n)0.070\n0.067\n\n0.387\n\n0.156\n\nIssue\nbiase\n\n0.156\n\n0.064\n\nArticle\nbiase\n\n86.3\n(4.5)\n88.3\n(4.2)\n87.6\n(6.1)\n80.5\n(1.9)\n86.4\n(4.0)\n\n% Journalists\n(articles)f\n\n5.2\n\n86.4\n\n93.7\n\n93.1\n\n92.0\n\n85.1\n\n82.4\n\n88.7\n\n81.8\n\n96.0\n\n% Journalists\n(articles)f\n\n20.8\n(1.2)\n17.7\n(3.6)\n17.2\n(4.6)\n19.2\n(2.5)\n8.8\n(4.9)\n\n% Parties\n(articles)f\n\n5.2\n\n17.3\n\n12.6\n\n21.0\n\n21.6\n\n14.3\n\n16.7\n\n17.3\n\n21.3\n\n13.1\n\n% Parties\n(articles)f\n\n25.9\n(7.4)\n28.6\n(10.5)\n28.6\n(2.5)\n17.6\n(0.5)\n23.6\n(6.7)\n\n% Journalists\n(issues)f\n\n7.9\n\n25.8\n\n26.1\n\n21.8\n\n13.1\n\n33.8\n\n18.1\n\n26.0\n\n15.5\n\n22.1\n\n% Journalists\n(issues)f\n\n48.2\n(6.6)\n40.4\n(16.1)\n44.5\n(0.1)\n46.8\n(0.7)\n36.3\n(4.6)\n\n% Parties\n(issues)f\n\n9.5\n\n43.5\n\n44.3\n\n42.5\n\n57.8\n\n41.2\n\n46.0\n\n66.7\n\n35.3\n\n32.5\n\n% Parties\n(issues)f\n\n49.3\n(6.2)\n50.9\n(7.5)\n55.5\n(1.9)\n51.4\n(5.8)\n47.2\n(9.5)\n\n%\nReportingg\n\n7.5\n\n50.6\n\n57.5\n\n58.0\n\n58.3\n\n44.1\n\n57.2\n\n48.0\n\n45.1\n\n64.8\n\n% Reportingg\n\n36.1\n(3.6)\n37.3\n(5.8)\n28.8\n(6.6)\n35.2\n(6.0)\n33.0\n(4.2)\n\n% Opiniong\n\n5.3\n\n35.2\n\n22.2\n\n34.3\n\n31.7\n\n26.6\n\n29.1\n\n37.6\n\n41.8\n\n32.0\n\n% Opiniong\n\n14.6\n(7.6)\n11.8\n(2.2)\n15.7\n(4.7)\n13.4\n(0.2)\n19.7\n(10.8)\n\n% Horseraceg\n\n7.7\n\n14.2\n\n20.3\n\n7.7\n\n10.0\n\n29.3\n\n13.6\n\n14.4\n\n13.1\n\n3.2\n\n% Horseraceg\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nLabour regulation (N = 4)\n\nDisability (N = 2)\n\nMaternity (N = 2)\n\nHealth (N = 4)\n\nPensions (N = 10)\n\nMeans for categories of\nproject (standard\ndeviations in parentheses)\n\nStd. dev.\n\n792 R ⁄ Unemployment\nbeneﬁts (2002)\n802 R ⁄ Financing of\nhospital treatments (2003)\n815 I ⁄ ‘‘Health must\nremain aﬀordable’’ (2003)\n816 I ⁄ ‘‘Equal rights for\ndisabled’’ (2003)\n819 I ⁄ ‘‘Apprenticeship\nplaces’’ (2003)\n831 R ⁄ Increase of\npension age for women\n(2004)\n832 R ⁄ Financing\npensions through VAT\n(2004)\n844 R ⁄ Maternity\ninsurance (2004)\nMean (N = 24)\n\nProject (R=referendum,\nI=initiative,\nCP=counterproposal)\n\nTable 1: (Continued)\n\n140\n\n 2011 Swiss Political Science Association\n\n180.5\n(35.5)\n205.2\n(83.5)\n160.0\n(68.6)\n172.8\n(67.3)\n189.4\n(87.7)\n162.1\n(51.1)\n\nNumbera\n\n54.5\n(7.0)\n61.8\n(26.9)\n44.0\n(17.1)\n49.7\n(20.0)\n55.1\n(27.9)\n47.3\n(14.6)\n\nSurfaceb\n0.646\n(0.028)\n0.669\n(0.110)\n0.535\n(0.104)\n0.622\n(0.134)\n0.638\n(0.137)\n0.599\n(0.122)\n\nInclusivenessc\n23.2\n(3.7)\n23.8\n(2.7)\n24.6\n(1.8)\n24.1\n(2.9)\n23.4\n(3.4)\n24.6\n(1.9)\n\nAverage\ncampaign\ndayd\n0.069\n(0.005)\n0.079\n(0.050)\n0.137\n(0.083)\n0.079\n(0.029)\n0.089\n(0.045)\n0.084\n(0.054)\n\nArticle\nbiash\n0.132\n(0.024)\n0.114\n(0.064)\n0.337\n(0.116)\n0.178\n(0.140)\n0.191\n(0.132)\n0.175\n(0.149)\n\nIssue\nbiash\n87.4\n(8.6)\n85.1\n(6.7)\n90.9\n(2.0)\n86.0\n(4.5)\n86.2\n(6.2)\n86.3\n(4.3)\n\n% Journalists\n(articles)f\n14.2\n(1.1)\n17.2\n(3.7)\n18.1\n(4.4)\n17.1\n(5.9)\n16.7\n(5.6)\n17.5\n(4.9)\n\n% Parties\n(articles)f\n28.7\n(6.6)\n23.2\n(7.3)\n30.1\n(11.4)\n25.9\n(6.8)\n22.6\n(6.8)\n28.7\n(8.0)\n\n% Journalists\n(issues)f\n36.4\n(3.9)\n43.6\n(7.8)\n39.1\n(14.3)\n44.4\n(8.7)\n42.1\n(6.7)\n44.5\n(11.7)\n\n% Parties\n(issues)f\n57.8\n(7.0)\n52.6\n(6.8)\n49.0\n(11.2)\n50.2\n(6.7)\n51.4\n(7.8)\n50.7\n(7.2)\n\n%\nReportingg\n\n37.1\n(5.1)\n36.6\n(4.3)\n34.2\n(6.0)\n34.8\n(5.5)\n35.1\n(5.5)\n35.5\n(5.2)\n\n% Opiniong\n\n5.1\n(1.9)\n10.9\n(4.8)\n16.7\n(9.9)\n15.0\n(7.8)\n13.5\n(7.2)\n13.8\n(7.7)\n\n% Horseraceg\n\n141\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNotes: a: Number of articles. b: Surface in standard newspaper pages (one page=1247 cm2). c: Number of actor categories · IQV (see text for calculation details). d: Mean number of days remaining before voting day. e: B scores comprised between -1 (all articles ⁄ issues against project) and\n+1 (all articles ⁄ issues in favour of project); see text for calculation details. f: Sum of categories ‘‘journalists’’ (including press agencies) and ‘‘parties’’ (including referendum ⁄ initiative committees) may exceed 100%, since several actors may be considered as the ‘‘sources’’ of an article. g: Percentage of articles in each category (see text for deﬁnition). h: Means computed from absolute values for each ballot, i.e. |B|. i: Not considered\nhere: counterproposal to the ‘‘gold’’ initiative (ballot #782; see Appendix).\n\nInitiative (N = 12)i\n\nExpansion proposal\n(N = 15)\nReferendum (N = 11)i\n\nRetrenchment proposal\n(N = 6)\nPopulist proposal (N = 3)\n\nUnemployment (N = 2)\n\nMeans for categories of\nproject (standard\ndeviations in parentheses)\n\nTable 1: (Continued)\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nintensity of media coverage of the various ballot issues (SD is about 22 full newspaper\npages for an overall mean of 52 pages). As shown in Table 1, the intensity of press coverage\nvaries between the speciﬁc policy ﬁelds subsumed under the heading ‘‘welfare state issues’’.\nMaternity seems by far the most important category of issues; in contrast, health and disability are of less importance. Further, it seems that retrenchment proposals lead to more\nintense campaigns than expansion or populist proposals. This is understandable, since cutting back beneﬁts may lead to more mobilization by target groups than the promise of\ndeveloping beneﬁts can possibly achieve. As noted above, though, the two proposals to\nintroduce a maternity insurance are a notable exception in this regard as they elicited substantial press coverage, probably due to the fact that the constitutional mandate to implement a maternity leave program dated back to the end of World War II and thus the issue\nwas a recurring one.17 Likewise, referendums are somewhat more covered by the press than\ninitiatives, probably because they bear more frequently on retrenchment programs, but the\ndiﬀerence is modest.\nIn brief, the intensity of press coverage appears to vary between the diﬀerent policy ﬁelds,\narguably as a result of the journalists’ intrinsic interest in them and due to the varying\nmobilization of political and civil society actors. But, to a large extent, campaign intensity\nis probably also exogenously determined by the uncertainty of the result of the ballot. Both\ncampaigners and voters are more likely to get involved in referendums when the margin of\nvictory is perceived to be small (e.g., Downs 1957; Kirchgässner and Schulz 2005). Likewise,\nin our dataset the overall intensity of press coverage is substantially correlated with the\ncloseness of the voting results.18 The closer the (expected) outcome, the more journalists\nreport on issues.\n\nSource inclusiveness\nOne indicator of the fairness of the coverage of a ballot issue is how many diﬀerent\npolitical actors are involved in the deliberation process. Our standardized measure of\ninclusiveness points to a respectable diversity in the sources of issue statements in press\ncoverage (overall mean=0.62). It is highest for maternity issues, and lowest for public\nhealth issues, as well as for issues comprised in the ‘‘populist’’ category. We thus assume\nthat inclusiveness depends on the nature of issues (see Pfetsch 2004: 87–93), as further\nsuggested by the fact that campaign intensity varies between policy ﬁelds, as we have\nseen. Indeed, intensity was shown to depend strongly on inclusiveness, as far as advertisement campaigns are concerned (Marquis and Bergman 2009). Similarly, in press coverage, the correlation between our indicators of intensity and inclusiveness is fairly high\n(Pearson’s r = 0.76). In other words, the more political actors enter the ﬁeld (and journalists’ accounts presumably reﬂect this increasing diversity), the more likely the issue at\nhand is to receive general attention from the press — whether because inclusiveness\ndetermines intensity or because both coverage features are determined by some higherlevel concept such as ‘‘issue importance’’.\n\n17\n\nPrior to the 1999 and 2004 votes, no less than three proposals to create a maternity insurance had already been\nrejected at the polls (Dec. 8, 1974; Dec. 2, 1984; and Dec. 6, 1987).\n18\nThe correlation coeﬃcient is –.54 for the number of articles and –.48 for total surface. Closeness is measured as\nthe absolute diﬀerence between the actual result and a perfectly balanced result: CLOSENESS = | 50 – RESULT |.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n142\n\n143\n\nLength of coverage\nCampaigns in Swiss direct democracy, whether through paid advertisements or in press\nreporting, usually unfold in two phases: there is ﬁrst an accelerating expansion of coverage\nand then a sharp decline in the last days before the vote (e.g., Marquis 2006: 429–438;\nTresch 2008: 147–149). Based on all articles published during all 24 campaigns, a thirdorder polynomial function modelling this typical development accounts for 67 percent of\nthe variance in the total daily surface of articles.19 Hence, at the aggregate level, the twophase pattern ﬁts the data quite well: referendum campaigns on welfare state issues develop\nin a typical way, similar to what has been observed for other types of issues.20 In addition,\nall policy ﬁelds follow roughly the same pattern — the only notable diﬀerence is that campaigns on health matters (including maternity and disability) reach their peak earlier than\nother types of issues.\nThese ﬁndings may dispel concerns that most media information on ballot issues is\nreleased too fast and too late for citizens to use it eﬃciently in their decision making. But\nactually how long is the press coverage of ballot issues? Drawing on our indicator of the\n‘‘average campaign day’’, the ‘‘average information’’ is published some 24 days before the\nvoting date (i.e, it corresponds to the ‘‘mean average day’’ for all 24 ballots). In the same\nperspective, the average median day is 21.6; this means that, in a typical campaign, half of\nthe total (weighted) sum of all information has been released three weeks before voting day,\nand the other half is to be released in the remaining weeks. In addition, there appears to be\nlittle diﬀerence between the various ballot issues — even though ballot issues that draw\nmore intense coverage (pensions, maternity) also tend to be covered for a slightly longer\ntime. To be sure, actual exposure to the ﬂow of information delivered during referendum\ncampaigns may greatly vary from one citizen to another, depending for example on which\nmedia outlet (if any) they use for their information (see below). But our ﬁndings are hardly\ncompatible with the argument that citizens are too time-pressed to make up their minds\nand are not given a chance to learn what the ballot issues are all about.\n\nSource independence\nThe question of media independence and autonomy is important, both from the perspective\nof media practices and ethics and for the purposes of deliberative processes. For example,\nTresch (2008: 142–149) shows that ‘‘agenda-building’’ by political actors through press conferences, party meetings, and other public relations activities, constitutes a substantial part\nof media content in referendum campaigns. Even though such coverage is certainly not\nwithout merit for citizens’ information and orientation, an overly reliance on external\nagenda-building eﬀorts may lead to media instrumentalization beyond that which stems\nfrom patterns of media ownership (see Hallin and Mancini 2004).\n19\nThe following function was ﬁtted to the data: Surface = 0.0015 time3 – 0.1464 time2 + 3.7937 time + 4.3653,\nwith surface measured as a three-day moving average and time measured as the number of days remaining until\nvoting day. The proportion of explained variance rises to 80 percent when Sunday editions are removed. Because\nof their non-continuous time structure, such editions introduce ‘‘noise’’ into the data. However, only ﬁve outlets\nare weekly papers or are published on Sunday, and only 2 percent of articles were published on that weekday.\n20\nAt the level of each single ballot, the characteristic sigmoid shape can be found for all but four campaigns. With\nthe exception of ballots 572, 622, 781, and 782, all functions have positive values for time3 and time, and negative\nvalues for time2. Article size (rather than number) was used, and time was recoded in eight weekly periods to avoid\nhigh ﬂuctuation in daily values. The average R2 for all 24 campaigns is 0.61 (SD=0.23).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nIf we ﬁrst consider journalists and partisan actors (i.e., parties and committees) in their\nrole of ‘‘speakers’’ at the level of articles, it comes as no surprise that journalists outweigh\npartisan actors (86 percent vs. 17 percent, on average). More remarkably, the diﬀerences\nbetween the various ballot proposals are quite limited. Journalists were identiﬁed as ‘‘speakers’’ in 80 to 88 percent of all articles in each of the six policy ﬁelds, while the corresponding interval is 14 to 21 percent for partisan actors — with the notable exception of labour\nmarket policies, where the parties’ share is only 9 percent.21 As for governmental speakers,\nthey appear in less than 10 percent of articles in all policy ﬁelds. (Note that the percentages\nfor the various categories add up to more than 100 percent, since any article can draw on\nseveral types of speakers.)\nAt the level of issue statements, recall that a total of 2859 issues were coded out of our\nsample of 1088 articles. Parties and committees account for about 44 percent of all coded\nissue statements, journalists and press agencies for 26 percent, governmental actors for 17\npercent, employers’ and employees’ organizations for 14 percent, and other types of actors\nfor 20 percent (similar to articles, percentages do not add to 100 percent because several\ncategories of actors can be involved as sources of one issue).22 Overall, then, journalists\nappear much less important as a source of issue statements than as a source of articles\n(i.e., as ‘‘speakers’’), which makes perfect sense. Conversely, even though partisan actors\nare rarely directly involved as speakers (e.g., through interviews or op-eds), they largely\nsucceed in inﬂuencing campaign news by having their issue statements reported in the press\n(Bonfadelli and Blum 2000; Tresch 2008).\n\nBias in media coverage\nThe extent of bias in press coverage can also be investigated at two levels: at the level of\nwhole articles and at the level of issue statements. The analysis draws in both cases on the\nclassiﬁcation of newspapers’ content into partial (pro or con), neutral, and controversial\ncategories. The resulting B scores theoretically vary between –1 (all content is against ballot\nproposal) and +1 (all content is in favour of proposal). B scores are generally higher for\nissues than for articles, because, for one thing, there are far less ‘‘neutral’’ and ‘‘controversial’’ items (about 27 percent) in issue statements than at the level of whole articles (about\n68 percent).\nA striking feature of our results in Table 1 is the relative neutrality with which Swiss\njournalists report on the issues, at least taken collectively — the question of diﬀerences\nbetween media outlets will be addressed below. The mean absolute B value is 0.09 for\narticles and 0.18 for issue statements. In fact, a good deal of this ‘‘directional thrust’’\nin media reporting is concentrated on ballot issues dealing with health matters (public\nhealth, maternity, disability). For example, the initiatives for ‘‘reduced hospital costs’’\n(2000) and ‘‘equal rights for disabled people’’ (2003), as well as the referendum to\noppose paid maternity leaves (2004), stirred up considerable criticism or enthusiasm\nfrom journalists, leading them to take a clear position on these subjects. On closer\n21\n\nIn this domain, parties are secondary to other representative bodies with which they often have strong ties, in\nparticular employers’ and employees’ associations (15 percent).\n22\nThese shares expectedly vary across policy ﬁelds. Journalists are most involved in unemployment, public health,\nand maternity issues (all 29 percent) and least involved with respect to disability (18 percent). Parties and committees are much quoted sources of statements on pensions and disability (48 and 47 percent) and less so on unemployment and labour regulation (36 percent).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n144\n\n145\n\ninspection, it appears that the general type of ballot proposals combines with their subject matter. As a category, the three populist proposals of the years 2000–2002 (including hospital costs) were treated in a far less even-handed manner than retrenchment or\nexpansion proposals, especially as concerns bias in issue statements.23 We may summarize these ﬁndings by saying that journalists, most of the time, report about ballot\nissues in a quite balanced way.\nInterestingly, bias in press coverage is substantially related to several other features examined here (correlations of 0.4 or higher). To begin with, article bias decreases as coverage\nintensity and inclusiveness increase. In other words, imbalance in coverage looms large\nwhen journalists have little to report and rely on fewer sources. At the level of issue statements, a crucial link seems to be with the importance of partisan actors as sources of statements: the more parties and committees are referred to as a basis for issue analysis, the\nlesser the bias.\nUsing B* values we can also determine how media coverage is basically oriented\ntoward welfare state schemes (i.e., the extent to which campaign news systematically\nsupports welfare state expansion ⁄ protection rather than welfare state limitation ⁄\nretrenchment). In so doing, we obtain a mean B* value of 0.01 for articles and 0.06\nfor issues — the press thus displays a very slight pro-welfare bias. This strongly suggests that there is no overall systematic pro-welfare or anti-welfare bias in press coverage. However, diﬀerences exist between the various policy ﬁelds. While neutral with\nrespect to pensions, labour market and unemployment, Swiss media outlets as a whole\nseem committed to more generous social protection programmes in the area of public\nhealth (B*=0.19 for issue statements), including maternity and invalidity (B*=0.35 and\n0.31, respectively).\nIt should also be noted that editorials and interviews are more critical of the welfare state\nthan other format types. B* scores (issue statements) for editorials and interviews are about\n–0.2 and –0.1, respectively, as compared to +0.1 or higher for reports, letters to the editor,\nand campaign news. Journalists opposed to welfare policies, it would seem, rely heavily on\nwriting editorials and selecting anti-welfare interviewees. But this does not suﬃce to countervail the bulk of pro-welfare coverage that stems from ‘‘factual reporting’’ or coverage of\ncampaign events. Besides, the general thrust of media coverage is highly dependent on\nwhich types of actors get their messages across in the various newspapers, since more often\nthan not journalists are balanced in their own issue statements (B* = –0.02). For instance,\nin the many cases where the parties’ issues ﬁnd their way into the media, center-left parties\nare much more likely to voice pro-welfare issues than are right parties (B* = 0.42 vs.\n–0.26). Similarly, the bias brought about by employees’ organizations counterbalances that\nof employers’ organizations (B* = 0.35 vs. –0.29). Overall, referendum committees are relatively neutral toward the welfare system (B* = 0.04), but the organizations representing\nspeciﬁc population groups (retired people, disabled people, youth, women, families) are\noverwhelmingly pro-welfare. Interestingly, the bias exhibited by governmental sources is\nquite diﬀerent depending on the level of government. Institutions and civil servants at the\nnational level (e.g., federal councillors, senior oﬃcials) are clearly less supportive of the\n\n23\n\nThe 2000 and 2001 initiatives (‘‘reduced hospital costs’’ and ‘‘cheaper drugs’’) were fought by all parties, while\nthe 2002 initiative (‘‘gold reserves to retirement pensions’’) was launched by the Swiss People’s Party and backed\nby other smaller populist right parties. Accordingly, the latter was supported by an important minority of 46% of\nthe popular votes, compared to 18% and 31% for the two earlier initiatives.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nwelfare system (or, at least, of welfare state expansion) than are their counterparts at the\ncantonal or local level (B* = –0.15 vs. 0.48).24\n\nSubstantive coverage\nWe focus here on the three main formats of campaign coverage (i.e., ‘‘opinion articles’’,\n‘‘factual reporting’’, and ‘‘horserace information’’) to determine how ‘‘substantive’’ campaign coverage is. Concerns are often expressed that media news that unduly revolves\naround the horserace and ‘‘game’’ aspects of campaigns has a deleterious inﬂuence on public deliberation and citizens’ decision-making. In fact, horserace information was present in\nall campaigns but it is quite weak (14 percent of the overall amount of news, on average)\ncompared to ‘‘opinion articles’’ (35 percent) and ‘‘factual articles’’ (51 percent). Horserace\ncoverage varies between a minimum of 5 percent for unemployment ballot issues and a\nmaximum of 20 percent for labour regulation ballot issues. In comparison, the share of\nopinion articles varies between 29 and 37 percent depending on policy domains, while the\nshare of factual articles varies between 47 and 58 percent. Thus, unlike in other contexts,\nthe horserace is clearly not the leading theme in Swiss referendum campaigns.25\n\n5. A dynamic view of independence, inclusiveness, bias, and substance\nThe picture thus far supports the notion of rather ‘‘fair’’ journalistic practices, as media\ncoverage appears to be relatively balanced, autonomous and substantive. We now examine\nthe hypothesis that journalists are however not immune to the pressure of the political environment and that they become increasingly dependent on external and ⁄ or biased sources of\ninformation over the course of campaigns. In other words, we ask whether the ‘‘fairness’’ of\ncampaign coverage is aﬀected by agenda-building eﬀorts of political actors. We thus investigate the dynamics of campaign coverage, focusing on four aspects examined above: source\nindependence and inclusiveness, bias in coverage and substantive coverage. We believe that\nthe time dimension can add to our understanding of how much journalistic output is autonomous, inclusive, unbiased, and substantive — and possibly also why it deviates from such\nnorms.\nBeginning with source independence, one interesting result is that journalists are the only\nactor category whose importance as a source of issue statements increases throughout the\n24\n\nThis diﬀerence is consistent across all types of issues, excepting maternity, and it may be explained in two ways.\nOn the one hand, the Swiss federal political system is largely based on the ‘‘principle of subsidiarity’’, which posits\nthat the federal state should assume only those tasks which cannot be performed eﬀectively at a more local level.\nHowever, the federal state assumes the greatest responsibility for managing social beneﬁts and ﬁnancing pension\nand health insurances, while local governments may feel less under pressure. In addition, cantons and municipalities have to draw on their own resources to provide social assistance to needy people who fall through the cracks\nof the social safety net and are no longer eligible for national welfare beneﬁts. Accordingly, local authorities are\nless likely to endorse cutbacks in social beneﬁts and are more inclined to support their constituencies’ demands for\nsocial services. On the other hand, the principle of collegiality implies that federal councillors from left parties are\ncompelled to advocate the view of the government as a collective body even when it contradicts the position of\ntheir party or their own opinion. For example, Federal Councillor Ruth Dreifuss, member of the Social Democratic Party and head of the Federal Department of Home Aﬀairs (1994–2002), often had to oppose initiatives\nfrom left groups aiming at expanding or introducing new welfare programmes.\n25\nThis is all the more signiﬁcant as the deﬁnition of horserace information used in this study is rather broad. As a\nmatter of fact, voting cues by parties and major organizations account for the bulk of ‘‘horserace information’’ as\noperationalized here — rather than opinion surveys or descriptions of campaign events.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n146\n\n147\n\n100\n\n10\n\n90\n\n9\n\n80\n\n8\n\n70\n\n7\n\n60\n\n6\n\n50\n\n5\n\n40\n\n4\n\n30\n\n3\n\n20\n\n2\n\n10\n\n1\n\n0\n\nNumber of source categories\n\nPercent of total sources\n\nFigure 1: Source independence and inclusiveness over time.\n\n% journalists (articles)\n% partisan (articles)\n% journalists (issues)\n% partisan (issues)\nNumber of source\ncategories (issues)\n\n0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\nwhole campaign period, even though their share as ‘‘speakers’’ actually declines (see Figure 1). In contrast, parties and committees become a bit less marginal as speakers (gaining\non average some 10 percent of the total share in the last seven weeks). But, most notably,\npartisan actors remain a major source of issue statements for press journalists during the\nwhole campaign period; their share varies between 33 and 61 percent, but without clear\nupward or downward trend over time.26 Just as signiﬁcant, however, is the fact that the\nsheer number of actor categories used as sources of issue statements grows almost linearly\nduring the campaign period — except in the very last weeks — and actually almost doubles\n(from 3 to 6) in the ﬁrst six weeks (see again Figure 1, right-hand axis). To use our terminology, this shows that press coverage becomes more inclusive as time goes by.27 For example, actors that may be regarded as ‘‘outsiders’’ (science and health professionals,\nassociations defending the rights of women ⁄ families ⁄ disabled people, non-proﬁt organizations, and other similar actors) rise from an average number of 0.7 (8th week before vote) to\nan average of 1.5 (4th week) and manage to keep their share of issue statements at just\nunder 20 percent throughout the campaign.\nTaken together, these results suggest that the dynamics of campaign coverage on welfare\nstate issues is hardly compatible with a radical understanding of the ‘‘determination theory’’. Our analysis reveals that journalists maintain their control over the newsgathering\nprocess and that no single source of campaign issue statements holds sway. As Figure 2\nshows, however, this does not mean that journalists downplay the inﬂuence of political\nactors — or even try to do so in a collective sense. In fact, press coverage increasingly takes\nthe form of ‘‘opinion articles’’ over time, while the share of ‘‘factual reporting’’ sharply\ndeclines. In the eight-week period, opinion articles become at least twice more frequent in\nrelative terms (from 22 to 52 percent), while the share of factual articles considerably\ndecreases (from 69 to 26 percent). With two exceptions, all campaigns exhibit this pattern,\n26\nThe same holds, albeit to a smaller extent, for governmental actors, who account for over one quarter of all\nissue statements in the ﬁrst four campaign weeks, but whose importance then declines to less than 15 percent. Yet,\nas compared to their tiny share of 5 percent of articles as ‘‘speakers’’, governmental actors do succeed in getting\ntheir issues on the campaign agenda, especially at the earlier stage.\n27\nFor the sake of simplicity, Figure 1 displays only the number of issue source categories, because IQV values\nhardly vary (min: 0.85, max: 0.90) and thus the variations over time of the composite index INC boil down to variations in the number of source categories.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nFigure 2: Information format over time (substantive vs. non-substantive content).\n100\nPercent of total sources\n\n90\n80\n70\n% reporting\n\n60\n\n% opinion\n\n50\n40\n\n% horserace\n\n30\n20\n10\n0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\nwhereby opinions gain prominence at the expense of the presentation of facts as voting day\ndraws nearer. This may be related to another ﬁnding stressed above, namely that ‘‘speakers’’, i.e. those actors accountable for the content of an article, comprise less journalists and\nmore partisan actors as time goes by. As for horserace news, its salience ﬂuctuates within a\nnarrow 9–16 percent range –– with the understandable exception of the last campaign week,\ngiven the close proximity of the vote and mobilization eﬀorts by parties and other groups.28\nIn sum, there does not seem to be a strong focus or even focalization on the horserace during referendum campaigns in Switzerland. To a large extent, the overall evolution in the format of information is understandable, and some observers may ﬁnd it comforting from a\nnormative perspective. It can be argued that, as a collective actor, journalists ﬁrst proceed\nto present the facts and main arguments (i.e., information function) and then provide citizens with particular opinions to help them take position on the issues (i.e., orientation function).\nLikewise, the ‘‘tone’’ of media coverage changes over time. To begin with, articles become\nmore ‘‘partial’’, i.e., they increasingly take sides for or against the various ballot proposals\n(see Figure 3). The share of partial articles amounts to slightly more than 20 percent in the\nﬁrst three weeks and approaches 50 percent by the last two weeks.29 In contrast, the share\nof partial issue statements — even though much higher than that of articles in overall level\n— slightly decreases over time. To a large extent this stems from the fact that issue statements get more ‘‘controversial’’ (rather than more ‘‘neutral’’) as voting day draws closer,\nand this is probably reﬂective of the growing recognition by journalists of the complexity of\nballot issues. That the press becomes more committed to its opinion-giving and orientation\nfunction in the later stages of campaigns does not entail, however, that it provides an\nincreasingly biased picture of the ballot issues. As shown in Figure 3 (right-hand axis), it is\nstriking how little deviation there is from perfect neutrality (i.e., B*=0) throughout the\neight campaign weeks, based either on articles or on separate issue statements. In fact, 87\npercent of the weekly bias scores for articles are comprised in a range of ± 20 percent\n28\nWe may also add that most newspapers publish a summary list of all parties’ and important organizations’ voting cues in the last week before voting day (which we also included in the horserace category).\n29\nOne natural hypothesis is that journalists themselves become less impartial over time. There is strong evidence\nsupporting this assumption, as the share of partial items among journalists’ articles rises from a low 16 percent\nseven weeks before voting day to a full 44 percent in the last campaign week.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n148\n\n149\n\n100\n\n1.0\n\n90\n\n0.8\n\n80\n\n0.6\n\n70\n\n0.4\n\n60\n\n0.2\n\n50\n\n0.0\n\n40\n\n–0.2\n\n30\n\n–0.4\n\n20\n\n–0.6\n\n10\n\n–0.8\n\n0\n\nArticle/issue bias (B* score)\n\nPercent of total\n\nFigure 3: Bias in media coverage over time.\n\nArticle partiality\n(pro+con/total)\nIssue partiality\n(pro+con/total)\nArticle bias\n(B* score)\nIssue bias\n(B* score)\n\n–1.0\n8\n\n7\n6\n5\n4\n3\n2\nWeeks remaining until voting day\n\n1\n\naround the neutral value.30 In sum, the fact that campaigns become more partisan over time\ndoes not necessarily imply that one side comes to prevail over the other. More often than\nnot media campaign coverage remains remarkably balanced until the end. As we have\nshown above, ballot campaigns usually heat up in the ﬁnal weeks, as agenda-building\neﬀorts by partisan groups intensify. But even then there is very little to suggest that the\npress gives in to external pressure and leaves the ‘‘undecided’’ citizens or ‘‘late deciders’’\nexposed to the unchecked inﬂuence of partisan or special interests.\n\n6. A particularistic view of media fairness\nBased on a number of formal criteria, the press coverage of ballot issues on welfare state\nissues appears relatively ‘‘fair’’. However, such evidence may be somehow illusory if it stems\nfrom the aggregation of contradictory patterns from diﬀerent types of media outlets. For\nexample, a balanced, unbiased portray of ballot issues at the aggregate level may conceal\nmuch greater variation between individual papers, some of which may be slanted toward\nwelfare state expansion while others may be committed to welfare retrenchment. As most\ncitizens read only one newspaper on a regular basis, this would mean that a majority of\npotential voters are exposed to a one-sided communication ﬂow. In addition, if the papers\non one side of the fence (e.g., the ‘‘pro-welfare camp’’) have a larger overall readership than\nthose on the other side, then the societal balance of information would no longer be guaranteed, despite indications to the contrary such as those provided in the preceding sections.\nTo investigate this question, we ask how the coverage of welfare state issues compares\nacross media outlets. Table 2 displays the whole range of indicators used thus far and shows\nhow they vary between the 28 media outlets included in this analysis.\n30\nThe same result is obtained if one takes absolute B scores (and hence all 24 campaigns are considered). However, when issue statements are considered instead of articles, the proportion of biased weekly values (|B|&gt;0.2) rises\nto 52 percent. To some extent this stems from our sampling procedure, because many weekly values are derived\nfrom a limited number of cases — while the whole data is used for articles’ bias. Accordingly, compared to statistics based on exhaustive data, there is a heightened probability that more extreme values of issue bias are produced\nby chance alone. Moreover, these frequent deviations from neutrality are in general temporary and unlikely to last\nfor longer than one week. In fact, the percent of adjacent weeks that exhibit a similar biased value (e.g., B scores\ngreater than 0.2 for both weeks) is only 19 percent.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n115.2\n\n97.6\n83.1\n80.1\n83.7\n77.7\n73.5\n58.4\n70.9\n68.0\n56.9\n42.6\n\n57.4\n35.2\n33.5\n37.7\n24.9\n26.8\n23.0\n\n19.9\n18.5\n\n18.9\n\n14.2\n8.6\n\n6.3\n\n5.7\n6.0\n\n321\n293\n286\n285\n263\n245\n222\n208\n201\n179\n170\n\n166\n165\n122\n104\n97\n90\n89\n\n70\n60\n\n38\n\n33\n21\n\n18\n\n17\n7\n\nSurfaceb\n\n528\n\nNumbera\n\n 2011 Swiss Political Science Association\n0.202\n0.194\n\n0.206\n\n0.143\n0.277\n\n0.222\n\n0.458\n0.752\n\n0.781\n0.750\n0.484\n0.745\n0.696\n0.409\n0.687\n\n0.873\n0.845\n0.865\n0.816\n0.664\n0.874\n0.866\n0.837\n0.783\n0.818\n0.840\n\n0.891\n\n22.8\n32.0\n\n16.3\n\n26.7\n38.7\n\n30.9\n\n27.4\n17.0\n\n26.1\n16.8\n14.6\n22.1\n22.5\n21.9\n20.6\n\n26.0\n27.2\n24.5\n26.0\n26.2\n28.0\n17.3\n26.4\n24.6\n28.7\n18.0\n\n27.3\n\nAverage\ncampaign\ndayd\n\n0.076\n0.000\n\n)0.200\n\n)0.026\n0.054\n0.106\n\n0.664\n0.051\n\n0.435\n\n0.142\n0.003\n\n0.164\n0.448\n)0.106\n0.206\n)0.007\n)0.124\n0.126\n\n0.675\n0.117\n\n0.425\n\n0.066\n)0.108\n\n0.038\n0.145\n)0.094\n0.012\n)0.026\n0.063\n0.046\n\n0.118\n)0.030\n0.153\n0.133\n0.023\n0.111\n)0.014\n0.057\n0.009\n)0.128\n0.040\n\n)0.279\n\n)0.127\n0.044\n)0.018\n0.011\n0.063\n)0.032\n)0.023\n)0.023\n0.006\n0.004\n)0.027\n)0.038\n\nIssue\nbiase\n\nArticle\nbiase\n\n87.3\n100.0\n\n100.0\n\n82.3\n81.2\n\n82.8\n\n84.9\n86.6\n\n91.0\n54.6\n72.3\n92.2\n90.2\n82.9\n91.9\n\n81.4\n93.6\n85.3\n96.4\n83.0\n98.8\n81.2\n91.4\n91.4\n90.0\n75.4\n\n81.0\n\n% Journalists\n(articles)f\n\n19.0\n34.2\n\n6.8\n\n7.6\n9.4\n\n11.2\n\n26.7\n14.6\n\n17.8\n35.6\n33.0\n11.8\n7.9\n24.1\n8.7\n\n20.9\n14.2\n16.7\n8.8\n25.1\n8.5\n25.7\n18.5\n10.8\n25.2\n20.0\n\n14.7\n\n% Parties\n(articles)f\n\n0.0\n77.6\n\n33.3\n\n57.4\n61.4\n\n67.4\n\n28.3\n24.5\n\n15.9\n10.5\n27.7\n25.7\n10.6\n16.8\n22.8\n\n23.1\n23.8\n26.0\n41.4\n18.2\n29.2\n23.8\n22.5\n16.7\n22.7\n34.7\n\n34.6\n\n% Journalists\n(issues)f\n\n91.3\n47.3\n\n66.7\n\n0.0\n24.5\n\n30.2\n\n36.7\n24.0\n\n56.3\n62.7\n43.9\n44.6\n58.8\n53.2\n58.1\n\n45.2\n38.7\n50.0\n25.5\n55.7\n44.7\n43.4\n45.6\n42.3\n47.1\n42.0\n\n35.3\n\n% Parties\n(issues)f\n\n47.6\n65.8\n\n55.9\n\n22.3\n44.1\n\n37.6\n\n48.1\n48.6\n\n55.0\n37.3\n32.1\n67.2\n65.6\n48.4\n59.7\n\n50.9\n53.7\n49.9\n54.0\n47.6\n64.5\n63.6\n57.1\n61.1\n47.3\n46.1\n\n35.9\n\n% Reportingg\n\n12.7\n34.2\n\n24.0\n\n69.7\n52.0\n\n51.6\n\n33.6\n34.1\n\n32.1\n56.5\n42.2\n21.6\n21.1\n46.5\n27.8\n\n34.6\n27.0\n30.8\n26.5\n39.3\n20.2\n30.9\n31.7\n29.3\n35.0\n51.3\n\n46.2\n\n% Opiniong\n\n39.7\n0.0\n\n20.1\n\n8.0\n3.9\n\n10.7\n\n18.3\n17.2\n\n12.9\n6.2\n25.7\n11.1\n13.2\n5.1\n12.5\n\n14.5\n19.3\n19.4\n19.5\n13.1\n15.2\n5.6\n11.2\n9.6\n17.6\n2.6\n\n17.9\n\n% Horseraceg\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNeue Zürcher Zeitung\n(NZZ)\nBasler Zeitung\nLe Temps (March 1998 –)\nSt. Galler Tagblatt\nTages-Anzeiger\nAargauer Zeitung\nLa Liberté\nCorriere del Ticino\nBund\n24 Heures\nNeue Luzerner Zeitung\nNouvelliste et Feuille\nd’Avis du Valais\nBerner Zeitung\nLe Quotidien Jurassien\nSchaﬀhauser Nachrichten\nTribune de Genève\nL’Express\nSolothurner Zeitung\nSüdostschweiz ⁄ Bündner\nZeitung\nBlick ⁄ Sonntags-Blick\nJournal de Genève\n(1995 – Feb. 1998)\nBerner Tagwacht\n(1995 – 1997)\nWochenzeitung\nSchweizerische\nHandelszeitung\nLe Nouveau Quotidien\n(1995 – Feb.1998)\nSonntags-Zeitung\nDie andere Zeitung (DAZ)\n(1995 – 1997)\n\nNewspaper\n\nInclusivenessc\n\nTable 2: Indicators of fairness for all articles published in 28 daily and weekly newspapers\n\n150\n\n 2011 Swiss Political Science Association\n\n236.6\n(184.9)\n126.4\n(95.7)\n172.3\n(74.6)\n19.0\n(10.0)\n\n61.6\n(41.6)\n37.0\n(27.3)\n51.7\n(22.8)\n8.1\n(4.0)\n\nSurfaceb\n0.641\n(0.271)\n0.666\n(0.238)\n0.702\n(0.190)\n0.203\n(0.048)\n\nInclusivenessc\n\n0.138\n\n0.191\n0.749\n\nInclusivenessc\n\n28.0\n(2.1)\n21.4\n(4.7)\n22.9\n(4.6)\n26.0\n(8.4)\n\nAverage\ncampaign\ndayd\n\n5.5\n\n15.7\n24.0\n\nAverage\ncampaign\ndayd\n\n0.018\n(0.083)\n)0.021\n(0.051)\n0.036\n(0.121)\n0.125\n(0.364)\n\nArticle\nbiase\n\n0.062\n\n-0.347\n).001\n\nArticle\nbiase\n\n% Journalists\n(articles)f\n91.2\n(7.1)\n90.8\n(5.2)\n83.5\n(10.6)\n87.7\n(7.5)\n\n)0.007\n(0.153)\n)0.009\n(0.138)\n0.097\n(0.166)\n0.220\n(0.257)\n\n9.5\n\n100.0\n85.5\n\n% Journalists\n(articles)f\n\nIssue\nbiase\n\n0.146\n\n0.089\n.050\n\nIssue\nbiase\n\n19.7\n(9.3)\n14.4\n(6.5)\n19.4\n(8.5)\n9.0\n(6.8)\n\n% Parties\n(articles)f\n\n7.9\n\n0.0\n18.5\n\n% Parties\n(articles)f\n\n41.1\n(19.2)\n25.9\n(3.9)\n24.5\n(13.6)\n38.6\n(24.3)\n\n% Journalists\n(issues)f\n\n7.5\n\n35.7\n23.8\n\n% Journalists\n(issues)f\n\n36.7\n(7.0)\n49.2\n(14.3)\n47.8\n(8.2)\n29.0\n(37.4)\n\n% Parties\n(issues)f\n\n9.9\n\n0.0\n45.4\n\n% Parties\n(issues)f\n\n51.5\n(9.7)\n52.3\n(4.7)\n52.4\n(11.1)\n48.9\n(21.2)\n\n% Reportingg\n\n9.5\n\n81.5\n52.1\n\n% Reportingg\n\n33.5\n(7.1)\n30.4\n(4.1)\n36.4\n(11.5)\n38.2\n(23.6)\n\n% Opiniong\n\n9.5\n\n18.5\n34.2\n\n% Opiniong\n\n15.0\n(7.5)\n17.4\n(2.7)\n11.2\n(5.5)\n12.9\n(15.7)\n\n% Horseraceg\n\n5.6\n\n0.0\n13.7\n\n% Horseraceg\n\n151\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nNotes: a: Number of articles. b: Surface in standard newspaper pages (one page=1247 cm2). c: Number of actor categories · IQV (see text for calculation details). d: Mean number of days remaining before voting day. e: B* scores comprised between –1 (all articles ⁄ issues against welfare state\npreservation ⁄ extension) and +1 (all articles ⁄ issues in favour of welfare state preservation ⁄ extension); populist ballots removed; see text for calculation details. f: Sum of categories ‘‘journalists’’ (including press agencies) and ‘‘parties’’ (including referendum ⁄ initiative committees) may exceed\n100%, since several actors may be considered as the ‘‘sources’’ of an article. g: Percentage of articles in each category (see text for deﬁnition). h:\nNewspapers with fewer than 50 articles are excluded; all papers retained (N = 28) for number, surface, and average campaign day. i: National\npapers: Blick, Le Temps, NZZ, Tages-Anzeiger, DAZ. Supraregional papers: Journal de Genève, Neue Luzerner Zeitung, Le Nouveau Quotidien,\nSt. Galler Tagblatt, Südostschweiz. Cantonal papers: Aargauer Zeitung, Basler Zeitung, Bund, Berner Zeitung, Corriere del Ticino, L’Express, La\nLiberté, Nouvelliste, Le Quotidien Jurassien, Schaﬀhauser Nachrichten, Solothurner Zeitung, Tribune de Genève, 24 Heures, Berner Tagwacht.\nWeekly papers: Schweizerische Handelszeitung, Sonntags-Zeitung, Wochenzeitung, Weltwoche.\n\nWeeklyi\n\nCantonali\n\nSupraregionali\n\nNationali\n\nMeans for categories of\nnewspapers (standard\ndeviations in parentheses)\n\nb\n\n3.7\n44.6\n(R=1248.1)\n31.3\n\nSurface\n\nNumbera\n\n5\n153.7\n(R=4303)\n121.1\n\nDie Weltwoche\nMean (N = 21)h\n\nStandard deviation\n\nNumber\n\na\n\nNewspaper\n\nTable 2: (Continued)\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nWe will focus here on the three aspects of independence, bias, and substance. An inspection of individual values and standard deviations shows that there is indeed some variation\nbetween newspapers on these three criteria, but that it is rather limited. According to our\nbias measure B* for articles, the economy-oriented newspapers NZZ and Journal de Gene`ve\nmay qualify as ‘‘anti-welfare’’, as they were, on average, predominantly lopsided against\nwelfare state preservation ⁄ extension. In contrast, the left-wing paper Quotidien Jurassien\nappears as ‘‘pro-welfare’’.31 At the level of issue statements, there is greater variation in B*\nscores, but few papers stand outside a ± 20 percent range around the neutral value (antiwelfare: NZZ; pro-welfare: Quotidien Jurassien and Tribune de Gene`ve). In addition, few\nsingle ballots gave way to skewed information even in any separate outlet. Of all instances\nwith a suﬃcient number of cases, 11 percent were rather pro-welfare and 8 percent were\nrather anti-welfare.32 Weekly (mostly Sunday) papers represent an exception to this overall\nmoderation in dealing with welfare issues, as they appear slanted toward pro-welfare positions (but self-evidently not the right-wing Weltwoche). In sum, the concern that our ﬁnding\nof balanced coverage might be an artifact of aggregation is not substantiated by our data.\nOur ﬁndings concerning the criteria of source independence and substantive coverage tell\na similar story. Signiﬁcant variation between media outlets is scarce, even though some\npeculiarities are worth pointing out. For example, journalists outweigh partisan sources in\nthe Tages-Anzeiger, while in other outlets (e.g., Quotidien Jurassien) these two categories are\nalmost equally present — as speakers or sources of issue statements. In general, journalists\nplay a larger role in national papers than in regional and cantonal papers, which may have\nto do with the resources media organizations must invest to have their journalists closely\ncover ballot campaigns. Finally, the ‘‘format’’ of articles shows little diﬀerence between\nnewspapers. Some of them are more preoccupied with opinion formation than with factual\nreporting (NZZ, Nouvelliste, Quotidien Jurassien, Schaﬀhauser Nachrichten), while the\nopposite holds especially for a couple of French-speaking papers (La Liberte´, Tribune de\nGene`ve, L’Express). With one single exception, horserace information account for less than\n20 percent of campaign coverage in all papers. In any account, then, the overall variation in\nsource independence and information format is limited. The existence of such variation cannot be taken to mean that the press coverage of ballot campaigns in Switzerland is a\nmere collection of disjoint ‘‘speciﬁc campaigns’’ with potentially divergent consequences for\ndiﬀerent segments of the electorate.\n\n7. Spatial patterns of media coverage\nWe now turn to the issue of spatial homogeneity. Provided that the Swiss media system is\nhighly fragmented along linguistic lines, is this segmentation reﬂected in region-speciﬁc\n‘‘styles’’ of media coverage? More speciﬁcally, to what extent are the particular dimensions\nof media coverage that we analyzed thus far similar in the two main Swiss regions? As\n\n31\nIn the following, we will not comment on results for newspapers with a small number of published articles\n(N &lt; 50). Note that the indicators in this section are computed on the basis of all articles published in each newspaper, without distinction of the speciﬁc ballot measures.\n32\n292 campaigns in individual papers were analyzed and B* scores for articles were computed for each of them.\nOnly cases where a newspaper published more than 4 articles on a given campaign were considered. When the same\nprocedure is applied to B* scores for issue statements, the proportion of seemingly ‘‘biased campaigns’’ is much\nhigher, but also less reliable (see above note 30).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n152\n\n153\n\nbecomes clear from Table 3, diﬀerences are in general rather limited, and sizable diﬀerences\nare only found for particular types of ballot issues.\nCampaign intensity as reported in Table 3 is a composite measure derived from the surface of articles, from the circulation ﬁgures of the newspapers, and from the number of people eligible to vote.33 The measure thus points out diﬀerences in the overall potential\nexposure of individual citizens and shows that campaigns are clearly more intense in the\nGerman-speaking region. The diﬀerence is particularly noticeable and systematic with\nrespect to pension and maternity issues. As concerns campaign length, the ‘‘average campaign day’’ indicator suggests that overall diﬀerences are slight. Campaigns may last a bit\nlonger in the German-speaking press, but mainly for measures pertaining to unemployment,\nand in any case not for measures on disability. Further, as would be expected from these\ndiﬀerences in intensity and length, media campaigns are also somewhat more ‘‘inclusive’’ in\nthe German-speaking press, where, on average, two additional actor categories are used as\nsources of issue statements.\nTurning to coverage bias, we again note that diﬀerences between the regions are marginal.\nHowever, as already pointed out above, bias is more conspicuous when measured at the level\nof issue statements rather than at the level of whole articles. Although the overall diﬀerence\nis negligible, this stems from the fact that the small diﬀerences that do exist cancel each other\nout across the various policy ﬁelds. Thus coverage in the German-speaking press was more\nskewed on health and disability measures, while it was less skewed on maternity issues (most\nnotably, French- and Italian-speaking papers had been much more enthusiastically endorsing the 1999 maternity leave project than had their German-speaking counterparts).\nNext, we compared the independence of journalists from external sources of information\nin the two regions. On the whole, the diﬀerences are modest. As speakers, German-speaking\njournalists were less prominent than journalists from other regions on maternity and disability issues, but they were more ‘‘autonomous’’ on unemployment. Diﬀerences were somewhat more pronounced as regards the source of issue statements. Journalists were more\nlikely to be the source of reported issues in the German-speaking press than in the Frenchand Italian-speaking press, especially for unemployment and labour regulation (but not for\nmaternity and disability issues). For example, French-speaking journalists sometimes draw\non scientiﬁc or educational sources (8 percent) for addressing labour and unemployment\nissues, while their German-speaking colleagues never do so (at least in our sample). These\nregional patterns may have at least two diﬀerent causes. On the one hand, turning to external sources may occur because journalists are less sure where they stand (or should stand)\non the issues and ⁄ or because they believe that public opinion on the issues is not crystallized\nyet and need orientating information from political sources. On the other hand, the\nobserved regional gaps may simply be reﬂective of more routinized relationships between\njournalists and political actors in some policy domains.\nThe ‘‘format’’ of information was then considered, with a focus on horserace information. Marginal regional gaps were observed, as the share of horserace items rarely exceeded\n20 percent in any region, but the diﬀerences were rather systematic. In general, information\nin German-speaking papers is more often of the ‘‘horserace’’ type than in French- or\nItalian-speaking papers (an overall 4 percent gap), and this diﬀerence holds for 17 of 24\n33\n\nLe Nouveau Quotidien, DAZ, and Berner Tagwacht are not taken into account in this analysis, due to unavailable circulation ﬁgures, but they represent only about 2 percent of articles and surface. More consequential is the\nfact that the French-speaking tabloid Le Matin, which has the largest circulation in the western region, is not\nincluded in our data. The absence of this paper probably explains part of the diﬀerence between the two regions.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n 2011 Swiss Political Science Association\n\n0.5 (10.5)\n4.0 (9.5)\n\n2.0 (9.5)\n\n3.1 (8.8)\n\n9.3 (15.6)\n2.7 (5.5)\n\n2.0 (9.6)\n1.9 (9.7)\n1.3 (7.8)\n2.5 (10.8)\n\n4.2 (9.2)\n4.7 (10.3)\n2.5 (6.4)\n3.2 (8.3)\n\n2.2 (26.4)\n)4.1 (23.9)\n\n8.9 (27.0)\n\n1.6 (24.8)\n1.2 (25.3)\n0.3 (22.8)\n3.0 (23.8)\n\nAverage\ncampaign\nday\n\n)0.236 (0.297)\n0.178* (0.365)\n\n0.002 (0.120)\n\n)0.036 (0.053)\n)0.035 (0.065)\n0.047 (0.131)\n\n0.013 (0.207)\n0.011 (0.145)\n0.125 (0.420)\n)0.045 (0.071)\n\nIssue\nbias\n(|B| scores)\n\n0.009 (0.091)\n)0.010 (0.075)\n0.037 (0.157)\n0.052 (0.080)\n\nArticle\nbias\n(|B| scores)\n\n)4.0 (86.5)\n)11.3 (78.9)\n\n0.5 (28.7)\n)1.6 (16.0)\n\n10.2 (30.9)\n\n6.1** (28.1)\n5.1 (27.7)\n6.0 (33.0)\n13.1* (28.5)\n\n)0.7 (86.3)\n)1.5 (85.9)\n2.2 (89.1)\n1.3 (86.7)\n6.8 (89.2)\n\nSource\nof issues\n= journalists\n\nSource of\narticles\n= journalists\n\n)4.5 (14.2)\n)1.8 (14.0)\n\n3.9 (7.3)\n\n3.9 (15.7)\n5.7 (16.6)\n5.6 (14.2)\n4.6 (21.0)\n\nImportance of\nhorserace\ninformation\n\nLionel Marquis et al.\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n**: p&lt;.05; *: p&lt;.10 (two-tailed tests checking for diﬀerences between paired-sample means).\n\nNotes: The ﬁgures show the diﬀerence between the two main linguistic areas (German-speaking vs. French- or Italian-speaking). A positive (negative) diﬀerence means that a given quantity is higher (lower) in the German-speaking area. In parentheses are the reference quantities, i.e., those\nmeasured in the German-speaking area.\nPk Pn\ncirci surfij\nj¼1\na: Intensity = i¼1 voters\n, with circi=circulation of newspaper i, surfij=surface of article j (in pages) in newspaper i, and voters=people eligible to vote (in thousands).\n\nTotal (N=24)\nPensions (N=10)\nHealth (N=4)\nLabour regulation\n(N=4)\nUnemployment\n(N=2)\nMaternity (N=2)\nDisability (N=2)\n\nIntensity a\n\nInclusiveness\n(# of source\ncategories)\n\nTable 3: Interregional diﬀerences with respect to eight indicators of media fairness and six policy ﬁelds\n\n154\n\n155\n\nballot proposals. The largest between-region diﬀerences in the share of horserace articles\nare found for pension and health issues, but there was actually more horserace coverage in\nthe French ⁄ Italian-speaking area on maternity and disability issues.34\n\n8. Conclusion\nThe aim of this study was to assess the fairness of the press coverage of referendums on\nwelfare state issues in Switzerland. We distinguished seven dimensions of media coverage in\norder to determine how it compares to idealized notions of the media’s role in the democratic process. In this concluding section we summarize our analysis of media coverage\nquality and, whenever possible and sensible, we relate our results to those of other studies.\nFirst, as regards the intensity of press coverage in daily newspapers, we found about eight\narticles per proposal and newspaper, amounting to two or three full pages of coverage.\nWith only modest variation across votes (though variation is more pronounced across\nmedia outlets), such coverage might be considered as a ‘‘fair’’ performance.35\nSecond, turning to the question of campaign duration, our results show that the press coverage peaked two to three weeks before the voting day, and that half of the total information had been released some 22 days before the poll. Although comparable studies of\nEuropean referendums are lacking (see Novik 2009: 13) we interpret this average duration\nas ‘‘appropriate’’, since press coverage was relatively gradual and did not surge in the last\ncampaign days.\nThird, we investigated the bias in media coverage. Overall, we ﬁnd a minimal to nonexistent bias at the level of press articles (i.e., the general thrust of news stories) toward prowelfare state orientation. When looking at particular issue statements, the bias appeared\nlarger but still not overwhelming. In fact, bias was largely restricted to matters of public\nhealth in the larger sense (hospital costs, price of drugs, maternity, disability, etc.) and was\nvirtually absent from campaigns on such themes as pensions, labour regulation, and unemployment. The variation in balance among diﬀerent newspaper outlets is rather limited.\nConcerning articles in daily newspapers, only the Journal de Gene`ve and the NZZ adopted\na rather ‘‘anti-welfare’’ position while the Quotidien Jurassien was lopsided toward the\n‘‘pro-welfare’’ camp. However, compared to news balance in other referendum campaigns,\nsuch as Pilon’s (2009) report on the Ontario Provincial Referendum and Hobolt’s (2009:\n186–189) analysis of the ﬁrst Irish referendum on the Nice Treaty, we conclude that the\nreporting on welfare state issues in the Swiss print media generally provides little ammunition to those who suspect or condemn a systematic bias in media coverage.\n\n34\nIt may be that, due to a more skeptical opinion climate toward the latter issues in their region, German-speaking\njournalists had more incentives to engage in opinion formation rather than stick to hard facts and descriptions of\nthe situation. This is especially true for maternity issues, as welfare state support is 30 percent higher on average\namong French- and Italian-speaking voters than among German-speaking voters (our own calculations from the\nmunicipality-level data available in the ‘‘Political Atlas of Switzerland’’, Swiss Federal Statistical Oﬃce).\n35\nThis rather lenient judgment may be qualiﬁed by comparing our results with those of Hobolt (2009: 207)208),\nwho found more intense press coverage for the 2005 French and the Dutch referendum campaigns on the European\nConstitution, even if we restrict the analysis to the country’s two major broadsheet newspapers (NZZ and\nLe Temps, in the Swiss case) as Hobolt did. However, the ﬁgures might not be fully comparable; the vote on the\nEuropean Constitution might have been of greater salience than single welfare state proposals. Moreover, the lower\nfrequency of popular votes in France and the Netherlands as compared to Switzerland may explain a more intense\ncoverage of those (rare) referendums. We should therefore await further research on news reporting in the Swiss\ncontext in order to compare our ﬁndings.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nFourth, the relative independence of journalists from external (particularly partisan)\nsources was examined. Similar to coverage bias, the dimension of media autonomy was\ninvestigated at two levels: articles and issue statements. At the level of articles, it was found\nthat journalists are by far the most important ‘‘speakers’’. Although they can delegate their\nagenda-setting role to other actors by soliciting their opinions through interviews, op-eds,\nor free columns, they rarely do so — at least not until the last three or four campaign\nweeks. Hence, our analysis suggests that the Swiss newspapers’ progressive loss of attachment to parties and other political groups (Meier and Schanne 1994) may have enhanced\ntheir ‘‘autonomy’’ — a concept not to be confused with that of journalistic ‘‘objectivity’’,\nwhich is outside the scope of this study. However, when evaluated at the level of issue\nstatements, the press coverage of referendum campaigns appears in a somewhat diﬀerent\nlight. Without there being anything ‘‘unfair’’ on a priori grounds, media coverage appears\nto largely reﬂect the issue agenda of the major political forces involved in campaigns (i.e.,\npolitical parties and committees, governmental agencies, professional associations, etc.).\nAltogether, these non-media sources account for about three times the number of journalistic issue items.36 In our view, there is no basic contradiction between the ﬁndings from these\ndistinct levels of analysis; taken together, they are reﬂective of both main functions traditionally assigned to news media — an information and an orientation function.\nThe dominance of journalists as sources of articles suggests that press journalists function\nas gatekeepers, selecting who may intervene directly in the news process, rather than as\nmere providers of a ‘‘free forum’’ to which any group or individual is granted equal and\nunlimited access. On the other hand, the press coverage of ballot issues is of course reﬂective — and possibly ‘‘reﬂexive’’ in the Luhmannian sense (Neidhardt 1994) — of what the\nmain political actors have to say. Therefore, media agenda-setting is not exogenous, but largely driven by the agenda of various political elites. As our measure of source inclusiveness\nsuggests, Swiss press journalists tend to rely on a broad array of diﬀerent actor categories,\nand media coverage may thus be said to be ‘‘inclusive’’. However, this substantial diversity\nin news coverage does not allow us to rule out the gatekeeping hypothesis: it is questionable\nwhether all actors who wanted to participate in the campaign debates ﬁnally found their\nway in news reporting.\nNext, our data provided insight into the substance of media coverage. We found that the\noften-criticized ‘‘horserace’’ nature of election coverage is not prevalent in the context of\nSwiss referendum campaigns. For one thing, horserace information accounts for only about\n13 percent of all news items — a tiny proportion compared, for instance, with U.S. presidential campaigns (Strömbäck and Dimitrova 2006), the 1995 Quebec secession referendum\n(see Pilon 2009), or even with more readily comparable campaigns such as the 2000 Danish\nreferendum on the adoption of the Euro (De Vreese and Semetko 2002). In addition,\nalthough the number of ‘‘factual information’’ items exceeds that of ‘‘opinion’’ items, both\nare important categories of press coverage. This again suggests that information and orientation are important functions performed by the media, and that in assuming these functions the media go well beyond predicting which side is likely to win.\nLastly, spatial homogeneity was deﬁned as an additional norm of media coverage. This\nnorm is rooted in the perception that public opinion on welfare state issues frequently\ndiverges across the main linguistic areas. Accordingly, distinctive media coverage threatens\nto reinforce the pre-existing cleavages and to undermine national cohesion by promoting a\n36\n\nAs compared to Tresch’s (2008: 142–149) ﬁndings on media coverage of European politics, state actors play a\nslightly less prominent role in debates on welfare state issues.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n156\n\n157\n\n‘‘tyranny of the majority’’. It was found that regional gaps in the press coverage of campaigns were minimal and largely restricted to three criteria: intensity of coverage, horserace\nreporting and source independence. In the German-speaking region, campaigns were somewhat more intense, more inclined toward horserace information, and journalists were more\noften the source of issues than was the case in the other linguistic areas. This may reﬂect\neither economic or cultural diﬀerences of media organizations between the regions. But\nagain, the hallmark of this analysis is similarity rather than discrepancy. Even when looking\nat speciﬁc welfare policy areas (pensions, health, etc.), press coverage appears — with few\nexceptions — strikingly similar across both regions, in line with the more detailed analysis\nof Swiss European policy by Tresch (2008).\nIn conclusion, the coverage of referendum campaigns on welfare state issues by the Swiss\npress appears reasonably fair when examined from a broad perspective. However, this\nappraisal of ‘‘satisfactory’’ (though certainly not ‘‘optimal’’) media campaign coverage is\nbased on quantitative indicators that may fail to capture many intrinsic qualities of media\ncoverage. Admittedly, the standards used to assess the fairness of media coverage were not\nexcessively high, and the conclusions we draw from our analysis await conﬁrmation from\nindependent datasets and studies, in particular from more qualitative-oriented research\n‘‘putting qualitative ﬂesh on quantitative bones’’ (Tarrow 2004: 176). Accordingly, we call\nfor further testing of the normative framework developed in the present study and for replications of our analysis in other settings. In addition, there is clearly a need of going beyond\nthe mere ‘‘procedural’’ approach to fairness developed here. Although they can be estimated by quantitative indicators, procedure-independent criteria of media fairness may be\nbest deﬁned through qualitative methods.\n\nReferences\nAlthaus, S. (1998). Information Eﬀects in Collective Preferences. American Political Science Review\n92(3): 545–558.\nBächtiger, A., S. Niemeyer, M. Neblo, M. Steenbergen and J. Steiner (2010). Disentangling Diversity\nin Deliberative Democracy: Competing Theories, Their Blind Spots and Complementarities. Journal of Political Philosophy 18(1): 32–63.\nBaerns, B. (1979). Öﬀentlichkeitsarbeit als Determinante journalistischer Informationsleistungen. Publizistik 24(3): 301–316.\nBarrett, A. and L. Barrington (2005). Bias in Newspaper Photograph Selection. Political Research\nQuarterly 58(4): 609–618.\nBartels, L. (1988). Presidential Primaries and the Dynamics of Public Choice. Princeton: Princeton University Press.\n—— (1996). Uninformed Votes: Information Eﬀects in Presidential Elections. American Journal of\nPolitical Science 40(1): 194–230.\nBennett, L., R. Lawrence and S. Livingston (2007). When the Press Fails. Political Power and the News\nMedia from Iraq to Katrina. Chicago: University of Chicago Press.\nBentele, G. (2003). Kommunikatorforschung: Public Relations. In Bentele, G., H.-B. Brosius and O.\nJarren (eds.), Öﬀentliche Kommunikation. Handbuch Kommunikations- und Medienwissenschaft.\nWiesbaden: Westdeutscher Verlag (54–78).\nBerelson, B. (1952). Democratic Theory and Public Opinion. Public Opinion Quarterly 16(3): 313–330.\nBerelson, B., P. Lazarsfeld and W. McPhee (1954). Voting. A Study of Opinion Formation in a Presidential Campaign. Chicago: The University of Chicago Press.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nBerkowitz, D.A. (2009). Reporters and Their Sources. In Wahl-Jorgensen, K. and T. Hanitzsch (eds.),\nThe Handbook of Journalism Studies. New York: Routledge (102–115).\nBlum, R. (2003). Medienstrukturen der Schweiz. In Bentele, G., H.-B. Brosius and O. Jarren (eds.),\nÖﬀentliche Kommunikation. Handbuch Kommunikations- und Medienwissenschaft. Wiesbaden: Westdeutscher Verlag (366–381).\nBonfadelli, H. and R. Blum (2000). Helvetisches Stiefkind: die Rolle der Massenmedien bei der Vermittlung schweizerischer Aussenpolitik. Bern, NFP 42 Synthesis n 28.\nBornschier, S. (2010). Cleavage Politics and the Populist Right: The New Cultural Conﬂict in Western\nEurope. Philadelphia: Temple University Press.\nBützer, M. and L. Marquis (2002). Public Opinion Formation in Swiss Federal Referendums. In\nFarrell, D. and R. Schmitt-Beck (eds.), Do Political Campaigns Matter? Campaign Eﬀects in Elections and Referendums. London and New York: Routledge (163–182).\nBunton, K. (1998). Social Responsibility in Covering Community: A Narrative Case Analysis. Journal\nof Mass Media Ethics 13(4): 232–246.\nChaﬀee, S. and S.Y. Choe (1980). Time of Decision and Media Use During the Ford-Carter\nCampaign. Public Opinion Quarterly 44(1): 53–69.\nChristians, C. and K. Nordenstreng (2004). Social Responsibility Worldwide. Journal of Mass Media\nEthics 19(1): 3–28.\nCohen, J. (1986). An Epistemic Conception of Democracy. Ethics 97(1): 26–38.\n—— (1989). Deliberation and Democratic Legitimacy. In Hamlin, A. and P. Pettit (eds.), The Good\nPolity. Oxford: Blackwell (17–34).\nConnolly, S. and S. Hargreaves Heap (2007). Cross Country Diﬀerences in Trust in Television and\nthe Governance of Public Broadcasters. Kyklos 60(1): 3–14.\nConnolly, W.E. 1991. Identity, Diﬀerence: Democratic Negotiations of Political Paradox. Ithaca:\nCornell University Press.\nDahl, R.A. 1989. Democracy and Its Critics. New Haven [etc.]: Yale University Press.\nDe Vreese, C. and H. Semetko (2002). Public Perception of Polls and Support for Restrictions on the\nPublication of Polls: Denmark’s 2000 Euro Referendum. International Journal of Public Opinion\nResearch 14(4): 367–390.\nDelli Carpini, M. and S. Keeter 1996. What Americans Know about Politics and Why It Matters. New\nHaven and London: Yale University Press.\nDiskin, A., A. Eschet-Schwarz and D. Felsenthal (2007). Homogeneity, Heterogeneity and Direct\nDemocracy: The Case of Swiss Referenda. Canadian Journal of Political Science 40(2): 317–342.\nDonovan, T. and S. Bowler (1998). An Overview of Direct Democracy in the American States. In\nBowler, S., T. Donovan and C. Tolbert (eds.), Citizens as Legislators. Direct Democracy in the\nUnited States. Columbus: Ohio State University Press (1–21).\nDonsbach, W. and A. Wenzel (2002). Aktivität und Passivität von Journalisten gegenüber parlamentarischer Pressearbeit. Publizistik 47(4): 373–387.\nDowns, A. (1957). An Economic Theory of Democracy. New York: Harper Collins.\nDryzek, J.S. (1990). Discursive Democracy: Politics, Policy, and Political Science. New York:\nCambridge University Press.\nDuVivier, K. (2006). The United States as a Democratic Ideal? International Lessons in Referendum\nDemocracy. Temple Law Review 79: 821–876.\nEntman, R. (2004). Projections of Power. Framing News, Public Opinion, and U.S. Foreign Policy.\nChicago: University of Chicago Press.\nEstlund, D. (1997). Beyond Fairness and Deliberation: The Epistemic Dimension of Democratic\nAuthority. In Bohman, J. and W. Rehg (eds.), Deliberative Democracy: Essays on Reason and\nPolitics. Cambridge: MIT Press (173–204).\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n158\n\n159\n\nFörster, J. and N. Liberman (2007). Knowledge Activation. In Kruglanski, A. and E.T. Higgins\n(eds.), Social Psychology. Handbook of Basic Principles. New York: Guilford Press (201–231).\nFournier, P., R. Nadeau, A. Blais, E. Gidengil and N. Nevitte (2004). Time-of-Voting Decision and\nSusceptibility to Campaign Eﬀects. Electoral Studies 23(4): 661–681.\nFröhlich, R. and B. Rüdiger (2006). Framing Political Public Relations: Measuring Success of Political Communication Strategies in Germany. Public Relations Review 32: 18–25.\nGerhards, J. (1997). Diskursive versus liberale Öﬀentlichkeit. Eine empirische Auseinandersetzung mit\nJürgen Habermas. Kölner Zeitschrift für Soziologie und Sozialpsychologie 49(1): 1–34.\nGilens, M. (2001). Political Ignorance and Collective Policy Preferences. American Political Science\nReview 95(2): 379–396.\nGitlin, T. (1980). The Whole World is Watching. Mass Media in the Making and Unmaking of the New\nLeft. Berkeley: University of California Press.\nGollin, A. (1980). Exploring the Liaison between Polling and the Press. Public Opinion Quarterly\n44(4): 445–461.\nGraber, D. (2003). The Media and Democracy: Beyond Myths and Stereotypes. Annual Review of\nPolitical Science 6: 139–160.\n—— (2006). Mass Media and American Politics. Washington: CQ Press.\nGrossenbacher, R., T. Forsberg, M. Koch and M. Brändli (2006). Politische Öﬀentlichkeitsarbeit in regionalen Medien. Kilchberg: Publicom AG.\nGurevitch, M. and J. Blumler (1977). Linkages between the Mass Media and Politics: A Model for\nthe Analysis of Political Communications Systems. In Curran, J., M. Gurevitch and J. Woollacott\n(eds.), Mass Communication and Society. London: Edward Arnold (270–290).\nGurevitch, M. and J. Blumler (1990). Political Communication Systems and Democratic Values. In\nLichtenberg, J. (ed.), Democracy and the Mass Media. New York: Cambridge University Press\n(269–289).\nHabermas, J. (1992). Faktizität und Geltung. Beiträge zur Diskurstheorie des Rechts und des demokratischen Rechtsstaats. Frankfurt am Main: Suhrkamp.\nHajnal, Z., E. Gerber and H. Louch (2002). Minorities and Direct Legislation: Evidence from\nCalifornia Ballot Proposition Elections. Journal of Politics 64(1): 154–177.\nHallin, D. (1984). The Media, the War in Vietnam, and Political Support: A Critique of the Thesis of\nan Oppositional Media. Journal of Politics 46(1): 2–24.\nHallin, D. and P. Mancini (2004). Comparing Media Systems. Three Models of Media and Politics.\nNew York: Cambridge University Press.\nHardmeier, S. (1999). Political Poll Reporting in Swiss Print Media: Analysis and Suggestions for\nQuality Improvement. International Journal of Public Opinion Research 11(3): 257–74.\n—— (2000). Meinungsumfragen im Journalismus: Nachrichtenwert, Präzision und Publikum. Medien\nund Kommunikationswissenschaft 48(3): 371–395.\nHargreaves, I. and J. Thomas (2002). New News, Old News. An ITC and BSC Research Publication.\nLondon: ITC.\nHayes, A. (2008). Press Critics Are the Fifth Estate: Media Watchdogs in America. New York:\nPraeger.\nHertig, H.P. (1982). Sind Abstimmungserfolge käuﬂich? — Elemente der Meinungsbildung bei\nEidgenössischen Abstimmungen. Annuaire Suisse de Science Politique 22: 35–57.\nHiggins, E. (1996). Knowledge Activation: Accessibility, Applicability, and Salience. In Higgins, E.\nand A. Kruglanski (eds.), Social Psychology. Handbook of Basic Principles. New York: The\nGuilford Press (133–168).\nHofstetter, C. et al. (1999). Information, Misinformation, and Political Talk Radio. Political Research\nQuarterly 52(2): 353–369.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nHobolt Binzer, S. (2009). Europe in Question: Referendums on European Integration. Oxford: Oxford\nUniversity Press.\nJerit, J., J. Barabas and T. Bolsen (2006). Citizens, Knowledge, and the Information Environment.\nAmerican Journal of Political Science 50(2): 266–282.\nKaufmann, B., G. Kreis and A. Gross (2005). Direkte Demokratie und europäische Integration. Die\nHandlungsspielräume der Schweiz. Basel: Europainstitut.\nKelley, S. (1960). Political Campaigning. Problems in Creating an Informed Electorate. Washington:\nThe Brookings Institution.\nKing, E. and M. Schudson (1995). The Press and the Illusion of Public Opinion: The Strange Case of\nRonald Reagan’s ‘Popularity’. In Glasser, T. and C. Salmon (eds.), Public Opinion and the Communication of Consent. New York: The Guilford Press (132–155).\nKirchgässner, G. and T. Schulz (2005). Was treibt die Stimmbürger an die Urne? Eine empirische\nUntersuchung der Abstimmungsbeteiligung in der Schweiz, 1981–1999. Swiss Political Science\nReview 11(1): 1–56.\nKriesi, H. (1994). Le déﬁ à la démocratie directe posé par les transformations de l’espace public. In\nPapadopoulos, Y. (ed.), Pre´sent et avenir de la de´mocratie directe. Geneva: Georg (31–72).\n—— (1998). The Transformation of Cleavage Politics: The 1997 Stein Rokkan Lecture. European\nJournal of Political Research 33(2): 165–185.\n—— (2003). Strategische politische Kommunikation: Bedingungen und Chancen der Mobilisierung\nöﬀentlicher Meinung im internationalen Vergleich. In Esser, F. and B. Pfetsch (eds.), Politische\nKommunikation im internationalen Vergleich. Grundlagen, Anwendungen, Perspektiven. Wiesbaden:\nWestdeutscher Verlag (208–239).\n—— (2005). Direct Democratic Choice. The Swiss Experience. Lanham: Lexington Books.\nKriesi, H., B. Wernli, P. Sciarini and M. Gianni (1996). Le clivage linguistique. Proble`mes de compre´hension entre les communaute´s linguistiques en Suisse. Berne: Oﬃce fédéral de la statistique.\nKrouse, R. and G. Marcus (1984). Electoral Studies and Democratic Theory Reconsidered. Political\nBehavior 6(1): 23–39.\nKuklinski, J. and P. Quirk (2000). Reconsidering the Rational Public: Cognition, Heuristics, and Mass\nOpinion. In Lupia, A., M. McCubbins and S. Popkin (eds.), Elements of Reason. Cambridge:\nCambridge University Press (153–182).\nLandis, J.R. and G. Koch (1977). The Measurement of Observer Agreement for Categorical Data.\nBiometrics 33(1): 159–174.\nLeuthold, H., M. Hermann and S. Fabrikant (2007). Making the Political Landscape Visible:\nMapping and Analyzing Voting Patterns in an Ideological Space. Environment and Planning B:\nPlanning and Design 34: 785–807.\nLinder, W., R. Zürcher and C. Bolliger (2008). Gespaltene Schweiz – geeinte Schweiz. Gesellschaftliche\nSpaltungen und Konkordanz bei den Volksabstimmungen seit 1874. Baden: Hier und Jetzt.\nList, C. and R.E. Goodin (2001). Epistemic Democracy: Generalizing the Condorcet Jury Theorem.\nJournal of Political Philosophy 9(3): 277–306.\nLongchamp, C. (1998). Demoskopie: Seismograph oder Kompass? Ein Überblick über die Ausbreitung\nund Verwendung der politischen Umfrageforschung in der Schweiz. Referat vor der Erdöl-Vereinigung, 23.03.1998. Online: http://www.gfs.ch/publset.html [accessed: 29.04.2010].\nLuskin, R., J. Fishkin and R. Jowell (2002). Considered Opinions: Deliberative Polling in Britain.\nBritish Journal of Political Science 32(3): 455–487.\nMarquis, L. (2006). La formation de l’opinion publique en de´mocratie directe. Les réfe´rendums sur la\npolitique exte´rieure suisse (1981–1995). Zurich: Seismo.\nMarquis, L. and M. Bergman (2009). Development and Consequences of Referendum Campaigns in\nSwitzerland, 1981–1999. Swiss Political Science Review 15(1): 63–97.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n160\n\n161\n\nMatthes, J. (2005). The Need for Orientation Towards News Media: Revising and Validating a Classic\nConcept. International Journal of Public Opinion Research 18(4): 422–444.\nMcDevitt, M. (2003). In Defense of Autonomy: A Critique of the Public Journalism Critique. Journal\nof Communication 53(1): 155–160.\nMcLeod, D., G. Kosicki and J. McLeod (2002). Resurveying the Boundaries of Political Communications Eﬀects. In Bryant, J. and D. Zillmann (eds.), Media Eﬀects. Advances in Theory and Research.\nMahwah: Lawrence Erlbaum (215–267).\nMeier, W. and M. Schanne (1994). Medien-‘‘Landschaft’’ Schweiz. Zurich: Pro Helvetia.\nMeier, W. and O. Jarren (2002). Ökonomisierung und Kommerzialisierung von Medien und Mediensystem. Bemerkungen zu einer (notwendigen) Debatte. In Haas, H. and O. Jarren (eds.), Mediensysteme im Wandel. Struktur, Organisation und Funktion der Massenmedien. Wien: Braumüller\n(201–216).\nMerritt, D. (1995). Public Journalism and Public Life. Why Telling the News Is Not Enough. Mahwah:\nLawrence Erlbaum.\nNeidhardt, F. (1994). Öﬀentlichkeit, öﬀentliche Meinung, soziale Bewegungen. In Neidhardt, F. (ed.),\nÖﬀentlichkeit, öﬀentliche Meinung, soziale Bewegungen. Kölner Zeitschrift für Soziologie und\nSozialpsychologie, Sonderheft 34 (7–41).\nNeidhart, L. (1970). Plebiszit und pluralitäre Demokratie. Eine Analyse der Funktion des schweizerischen Gesetzesreferendums. Berne: Francke.\nNeuman, W.R. (1990). The Threshold of Public Attention. Public Opinion Quarterly 54(2): 159–176.\nNovik, N. (2009). Do Campaigns Matter? The Contribution of European Union Campaigns to Broad\nPolitical Knowledge. Dissertation. Dublin: Trinity College.\nPage, B.I. (1996). Who Deliberates? Mass Media in Modern Democracy. Chicago: University of Chicago Press.\nPapadopoulos, Y. (1998). De´mocratie directe. Paris: Economica.\nPateman, C. (1970). Participation and Democratic Theory. Cambridge: Cambridge University Press.\nPatterson, T. (1994). Out of Order. New York: Vintage.\n—— (1998). Political Roles of the Journalist. In Graber, D., D. McQuail and P. Norris (eds.), The\nPolitics of News. The News of Politics. Washington D.C.: Congressional Quarterly (17–32).\nPfetsch, B. (2004). Geschlossene Gesellschaft? Akteursensembles und Akteursbewertungen in Pressekommentaren. In Eilders, C., F. Neidhardt and B. Pfetsch (eds.), Die Stimme der Medien: Pressekommentare und politische Öﬀentlichkeit in der Bundesrepublik. Wiesbaden: VS Verlag (74–105).\nPilon, D. (2009). Investigating Media as a Deliberative Space: Newspaper Opinions about Voting Systems in the 2007 Ontario Provincial Referendum. Canadian Political Science Review 3(3): 1–23.\nPrice, V. and J. Zaller (1993). Who Gets the News? Alternative Measures of News Reception and their\nImplications for Research. Public Opinion Quarterly 57(2): 133–164.\nRobinson, G. (1995). Making News and Manufacturing Consent: The Journalistic Narrative and Its\nAudience. In Glasser, T. and C. Salmon (eds.), Public Opinion and the Communication of Consent.\nNew York: The Guilford Press (348–369).\nRothmayr, C. and S. Hardmeier (2002). Government and Polling: Use and Impact of Polls in the\nPolicy-Making Process in Switzerland. International Journal of Public Opinion Research 14(2):\n123–140.\nSallot, L. and E. Johnson (2006). Investigating Relationships between Journalists and Public Relations\nPractitioners: Working Together to Set, Frame and Build the Public Agenda, 1991-2004. Public\nRelations Review 32(2): 151–159.\nSchönhagen, P. (2008). Ko-Evolution von Public Relations und Journalismus: Ein erster Beitrag zu\nihrer systematischen Aufarbeitung. Publizistik 53(1): 9–24.\nSchudson, M. (2001). The Objectivity Norm in American Journalism. Journalism 2(2): 149–170.\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\nLionel Marquis et al.\n\nShoemaker, P. and S. Reese (1995). Mediating the Message. Theories of Inﬂuences on Mass Media\nContent. White Plains: Longman.\nSigal, L. (1973). Reporters and Oﬃcials. The Organization and Politics of Newsmaking. Lexington:\nHeath and Company.\nSinger, J. (2007). Contested Autonomy. Professional and Popular Claims on Journalistic Norms. Journalism Studies 8(1): 79–95.\nStatham, P. (2006). Political Journalism and Europeanization: Pressing Europe? European Political\nCommunication Working Paper No. 2006 ⁄ 13.\nStrömbäck, J. and D. Dimitrova (2006). Political and Media Systems Matter: A Comparison of\nElection News Coverage in Sweden and the United States. Harvard International Journal of Press ⁄\nPolitics 11(4): 131–147.\nSturgis, P. (2003). Knowledge and Collective Preferences. A Comparison of Two Approaches to Estimating the Opinions of a Better Informed Public. Sociological Methods and Research 31(4): 453–485.\nTarrow, S. (2004). Bridging the Quantitative-Qualitative Divide. In Brady, H. and D. Collier (eds.),\nRethinking Social Inquiry: Diverse Tools, Shared Standards. Lanham: Rowman &amp; Littleﬁed (171–\n179).\nTrechsel, A. and P. Sciarini (1998). Direct Democracy in Switzerland: Do Elites Matter? European\nJournal of Political Research 33(1): 99–124.\nTresch, A. (2008). Öﬀentlichkeit und Sprachenvielfalt. Medienvermittelte Kommunikation zur Europapolitik in der Deutsch- und Westschweiz. Baden-Baden: Nomos.\nTuchman, G. (1972). Objectivity as Strategic Ritual: An Examination of Newsmen’s Notions of\nObjectivity. American Journal of Sociology 77(4): 660–679.\nVatter, A. (2002). Kantonale Demokratien im Vergleich. Entstehungsgründe, Interaktionen und Wirkungen politischer Institutionen in den Schweizer Kantonen. Opladen: Leske und Budrich.\nWatts, M., D. Domke, D. Shah and D. Fan (1999). Elite Cues and Media Bias in Presidential Campaigns: Explaining Public Perceptions of a Liberal Press. Communication Research 26(2): 144–175.\nWuerth, A. (1999). Mediensystem und politische Kommunikation. In Klöti, U., P. Knoepfel,\nH. Kriesi, W. Linder and Y. Papadopoulos (eds.), Handbuch der Schweizer Politik. Zurich: NZZ\nVerlag (337–384).\nYankelovich, D. (1991). Coming to Public Judgment. Making Democracy Work in a Complex World.\nSyracuse: Syracuse University Press.\nYoung, I.M. (1990). Justice and the Politics of Diﬀerence. Princeton: Princeton University Press.\n—— (2000). Inclusion and Democracy. Oxford: Oxford University Press.\nZaller, J. and D. Chiu (1996). Government’s Little Helper: U.S. Press Coverage of Foreign Policy\nCrises, 1945–1991. Political Communication 13(4): 385–405.\n\nAppendix\nTable A1: List of all ballot measures analyzed in this study\nResult\n(share of yes\nvotes)\n\nBallot title\n571 10th amendment of retirement pension system (25.06.1995)\n572 Initiative on retirement pensions (25.06.1995)\n602 Law on labour: weekend and night work, maternity (01.12.1996)\n622 Financing of unemployment insurance (28.09.1997)\n\n 2011 Swiss Political Science Association\n\n60.7\n27.6\n33.0\n49.2\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\n162\n\n163\n\nTable A1: (Continued).\nResult\n(share of yes\nvotes)\n\nBallot title\n643 10th amendment of pension system without increase of retirement age\n(27.09.1998)\n654 Law on labour: night work, maternity (29.11.1998)\n684 Law on disability insurance (13.06.1999)\n685 Law on maternity insurance (13.06.1999)\n721 Initiative against increase of retirement age for women (26.11.2000)\n722 Initiative for ‘‘ﬂexible retirement age from 62 years’’ (26.11.2000)\n724 Initiative for ‘‘reduced hospital costs’’ (26.11.2000)\n732 Initiative for ‘‘cheaper drugs’’ (04.03.2001)\n752 Initiative to ‘‘secure pension system – tax energy instead of labour’’\n(02.12.2001)\n762 Reduction of work time (03.03.2002)\n781 Initiative about gold reserves to retirement pension (22.09.2002)\n782 Counter-proposal about gold reserves to retirement pension (22.09.2002)\n792 Law on unemployment insurance: unemployment beneﬁts (24.11.2002)\n802 Participation of cantons in ﬁnancing of hospital treatments (09.02.2003)\n815 Initiative ‘‘health must remain aﬀordable’’ (18.05.2003)\n816 Initiative ‘‘equal rights for disabled people’’ (18.05.2003)\n819 Initiative for ‘‘suﬃcient apprenticeship places’’ (18.05.2003)\n831 11th amendment of pension system: increase of pension age for women\n(16.05.2004)\n832 Financing of retirement pension through VAT increase (16.05.2004)\n844 Maternity insurance (26.09.2004)\n\n41.5\n63.4\n30.3\n39.0\n39.5\n46.0\n17.9\n30.9\n22.9\n25.4\n46.4\n46.4\n56.1\n77.4\n27.1\n37.7\n31.6\n32.1\n31.4\n55.5\n\nSource: Swiss Federal Chancellery.\n\nLionel Marquis received his PhD from the University of Geneva in 2002. Since 2008 he has been a lecturer and\nresearcher in political science at the University of Lausanne. His research interests comprise Swiss foreign and\nsocial policy, political behaviour and political psychology. Address for correspondence: Lionel Marquis, University\nof Lausanne, Institut d’Etudes Politiques, et Internationales, UNIL-Dorigny, Anthropole, 1015 Lausanne.\nPhone: +41 (0)21 692 31 56; Email: lionel.marquis@unil.ch\nHans-Peter Schaub is a PhD student at the University of Berne. He is working on the Swiss National Science Foundation project ‘‘The quality of democracy in the Swiss cantons’’ and writing his doctoral thesis on democracy’s\nquality in cantons with a popular assembly (Landsgemeinde) as compared to cantons with a ballot box system.\nAddress for correspondence: Hans-Peter Schaub, University of Berne, Institut für Politikwissenschaft, Lerchenweg\n36, 3000 Bern 9. Phone: +41 (0)31 631 48 49; Email: hans-peter.schaub@ipw.unibe.ch\nMarlène Gerber is a PhD student at the University of Berne. She is working on a project funded by the Swiss\nNational Science foundation that examines the potential for deliberation among EU-citizens. She writes her\ndoctoral thesis on deliberative quality in a European-wide deliberative poll on immigration. Address for correspondence: Marlène Gerber, University of Berne, Institut für Politikwissenschaft, Lerchenweg 36, 3000 Bern 9. Phone:\n+41 (0)31 631 83 37; Email: marlene.gerber@ipw.unibe.ch\n\n 2011 Swiss Political Science Association\n\nSwiss Political Science Review (2011) Vol. 17(2): 128–163\n\n16626370, 2011, 2, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/j.1662-6370.2011.02015.x by Cochrane Israel, Wiley Online Library on [09/12/2022]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n\nMedia Coverage of Referendum Campaigns\n\n</td>
    </tr>
    <tr>
      <th>90</th>
      <td>news</td>
      <td>University of Nebraska - Lincoln\n\nDigitalCommons@University of Nebraska - Lincoln\nFaculty Publications, College of Journalism &amp; Mass\nCommunications\n\nJournalism and Mass Communications, College of\n\n2016\n\nTeaching Fairness in Journalism: A Challenging\nTask\nJoseph Weber\nUniversity of Nebraska–Lincoln, josephweber@unl.edu\n\nFollow this and additional works at: http://digitalcommons.unl.edu/journalismfacpub\nPart of the Journalism Studies Commons\nWeber, Joseph, "Teaching Fairness in Journalism: A Challenging Task" (2016). Faculty Publications, College of Journalism &amp; Mass\nCommunications. 89.\nhttp://digitalcommons.unl.edu/journalismfacpub/89\n\nThis Article is brought to you for free and open access by the Journalism and Mass Communications, College of at DigitalCommons@University of\nNebraska - Lincoln. It has been accepted for inclusion in Faculty Publications, College of Journalism &amp; Mass Communications by an authorized\nadministrator of DigitalCommons@University of Nebraska - Lincoln.\n\nPublished in Journalism &amp; Mass Communication Educator (2015) 12pp.\ndoi: 10.1177/1077695815590014\nCopyright © 2015 AEJMC; published by SAGE Publications.\nUsed by permission.\nPublished online August 19, 2015.\n\ndigitalcommons.unl.edu\ndigitalcommons.unl.edu\n\nTeaching Fairness in Journalism:\nA Challenging Task\nJoseph Weber\nAssociate Professor, College of Journalism and Mass Communications,\nUniversity of Nebraska–Lincoln, 307 Andersen Hall, Lincoln, NE 68588-0474, USA\nemail josephweber@unl.edu\nAbstract\nObjectivity has long been contentious in American journalism. Many practitioners call it essential to a news organization’s credibility. Critics, however, hold objectivity is impossible and\nurge reporters simply to reveal their biases. For educators, teaching objectivity is challenging. Some, seeking a middle ground, instead urge fairness and balance, or counsel “impartiality.” Even such approaches are challenging. This article explores the difficulties, based on\na study where students were lectured on fairness, balance, objectivity, and bias. They wrote\nnews stories before and after the lessons. Evaluators found no substantial improvement in\nfairness and increased bias, however, pointing up the difficulties involved.\nKeywords: bias, fairness, objectivity, balance, media education, teaching fairness, impartiality\n\nIntroduction\nObjectivity has fallen into disfavor in many quarters of journalism in recent years.\nBiased coverage of the news seems to be in ascendance, as viewpoint-based websites such as The Washington Post’s PostEverything site multiply (Kushner, 2014) and\nopinion-driven television enterprises such as Fox News, on the right, and MSNBC,\non the left, compete for attention along ideological lines. Some prominent media\noutlets appear to offer less truly fair and balanced coverage as they cater to splintering audiences, seemingly wagering that audiences prefer to have their biases reinforced rather than challenged by journalism that aspires to impartiality. As the\nPew Research Journalism Project study showed in October, 2014, “When it comes\n1\n\n2    J o s e p h W e b e r i n J o u r n a l i s m &amp; M a s s C o m m u n i c a t i o n E d u c a t o r ( 2 0 1 5 )\n\nto getting news about politics and government, liberals and conservatives inhabit\ndifferent worlds. There is little overlap in the news sources they turn to and trust”\n(Mitchell, Gottfried, Kiley, &amp; Matsa, 2014).\nThe battle over objectivity hit a recent high point in fall 2013. Former New York\nTimes executive editor Bill Keller and former Guardian columnist Glenn Greenwald\nclashed then in Keller’s op-ed column about the desirability of what Keller called\n“aggressive but impartial” journalism. Keller held that journalists who set aside\ntheir opinions “to follow the facts—as a judge in court is supposed to set aside\nprejudices to follow the law and the evidence … can often produce results that are\nmore substantial and more credible” than today’s activist bloggers or earlier opinion-driven pamphleteers and muckrakers. In making his case, Keller gave voice to\nwhat has long been an article of faith for mainstream journalists.\nCountering this, Greenwald acknowledged that some “superb reporting” emerged\nfrom the traditional approach but said it “has also produced a lot of atrocious journalism and some toxic habits that are weakening the profession.” Greenwald, who\nshared a 2014 Pulitzer Prize for reporting the leaks of former National Security\nAgency contractor Edward Snowden, complained that a “journalist who is petrified of appearing to express any opinions will often steer clear of declarative sentences about what is true ….” Furthermore, Greenwald argued, “Human beings are\nnot objectivity-driven machines. We all intrinsically perceive and process the world\nthrough subjective prisms. What is the value in pretending otherwise?” (Keller, 2013)\nAlthough the rise of blogging, websites, and fragmented TV audiences gives\nfresh currency to the debate, the argument predates Greenwald and Keller. “Objectivity is considered doomed to failure and dismissed as an unattainable standard.\nThis discredit has become radical as some scholars have gone so far as to question\nobjectivity as a desirable norm,” Sandrine Boudana (2011), now at Tel Aviv University, wrote in Media, Culture &amp; Society. Earlier, in 2004, journalist Geneva Overholser contended in Nieman Reports that “… ‘objectivity’ as a touchstone has grown\nworse than useless…. To the extent that objectivity still holds sway, it often produces a report bound in rigid orthodoxy, a deplorably narrow product of conventional thinking.” Calling the objective approach an “ineffective and even harmful\nguide,” she held that a “forthright jettisoning of the ‘objectivity’ credo, and a welcoming of the diverse media landscape springing up around us, could have freeing effects.” (Overholser, 2004) A year before, in 2003, Brent Cunningham (2003)\nobserved in Columbia Journalism Review that “few would argue that complete objectivity is possible, yet we bristle when someone suggests we aren’t being objective—\nor fair, or balanced—as if everyone agrees on what they all mean.”\nFaced with such disputes, journalism educators wrestle with how best to teach\ntheir students to practice the craft. Should they hew to the ideal of objectivity or\nshould they yield to the current clamor for viewpoint-oriented and ideologically\ndriven news coverage? Is it possible for students to be taught to set aside their biases and report evenhandedly? If that is desirable, how might one do that? This\nstudy, involving students in a pair of advanced-reporting classes, explored a potential methodology for assessing student biases and examined one avenue for addressing them.\n\nTeaching Fairness in Journalism: A Challenging Task\n\n3\n\nLiterature Review\nFor American journalists, the challenge to report and record the news objectively\nhas a long and tumultuous history. Suggesting he would deliver impartial and thorough reporting, editor James Gordon Bennett in 1835 announced that his then-new\nNew York Herald would “record facts on every public and proper subject, stripped\nof verbiage and coloring” (Mindich, 1998). But his critics thought him incapable of\nfairness, much less objectivity or impartiality. Walt Whitman, a newspaperman as\nwell as a poet, called his competitor\na reptile marking his path with slime wherever he goes, and breathing mildew at\neverything fresh or fragrant; a midnight ghoul, preying on rottenness and repulsive filth; a creature, hated by his nearest intimates, and bearing the consciousness\nthereof upon his distorted features, and upon his despicable soul; one whom good\nmen avoid as a blot to his nature— whom all despise, and whom no one blesses—\nall this is James Gordon Bennett.\n\nSpeaking generally of mid-19th-century journalism, Whitman also said, “Scurrility—the truth may as well be told—is a sin of the American newspaper press.”\n(Reynolds, 1995)\nStill, some journalists strode toward objectivity in the middle and late 1800s, and,\nearly in the 20th century, they enshrined it as a central journalistic value. When a\ngroup of New York editors in 1848 established the Associated Press (AP), they created a news service that by the end of the century was delivering dispatches that sociologist and media historian Michael Schudson said “were markedly more free from\neditorial comment than most reporting for single newspapers.” Schudson speculated\nthat the AP steered a middle course because it served papers with widely varying allegiances. Sensationalism prevailed in many newspapers, nonetheless, at least until\n1896, when the New York Times began rising to prominence because it hewed to an\n“information” model of news delivery rather than the “story” model others used,\nthe sociologist reported (Schudson, 1978). After World War I, devotion to objectivity\ntook hold, such that in 1923, the American Society of Newspaper Editors adopted the\nCanons of Journalism at its first convention, mandating that “news reports should be\nfree from opinion or bias of any kind” (Schudson, 2003). Even as journalists unionized, and fears arose that impartial coverage of business and labor issues would suffer, the American Newspaper Guild, in 1934, adopted a code of ethics that called for\naccurate and unbiased reporting, guided “only by fact and fairness.” By the end of\nWorld War II, Schudson and Tifft (2005) reported that objectivity was “universally\nacknowledged to be the spine of the journalist’s moral code.”\nTo be objective, advocates said, journalists needed to understand their biases\nand, despite them, adopt a scientific fact-based approach, argued press critic Walter Lippmann. In 1920, he and a colleague, Charles Merz, an associate editor for\nthe New York World, lambasted coverage of the Russian Revolution in the rival New\nYork Times for falling short. “In the large, the news about Russia is a case of seeing\nnot what was, but what men wished to see,” they wrote. Lippmann wanted the individual journalist “to remain clear and free of his irrational, his unexamined, his\nunacknowledged prejudgments in observing, understanding and presenting the\n\n4    J o s e p h W e b e r i n J o u r n a l i s m &amp; M a s s C o m m u n i c a t i o n E d u c a t o r ( 2 0 1 5 )\n\nnews.” Journalism, Lippmann railed, was being practiced by “untrained accidental witnesses,” when journalists instead should hew to the “the scientific spirit”\nand should aspire to “a common intellectual method and a common area of valid\nfact.” (Dean, 2015)\nOne can hear echoes of Lippmann’s complaints today, as critics bemoan political polarization in which facts seem to take a backseat to rancorous argument.\nLippmann, cofounder of The New Republic and a propagandist for Washington in\nWorld War I, argued that a more “scientific” approach would have gotten readers\ncloser to the truth about the Bolsheviks whose regime the Times repeatedly misreported as near collapse, as Schudson recounts. In his book, Liberty and the News,\nLippmann complained that\nwhere all news comes at second-hand, where all the testimony is uncertain, men cease\nto respond to truths, and respond simply to opinions. The environment in which they\nact is not the realities themselves, but the pseudo-environment of reports, rumors,\nand guesses. (Schudson, 2007)\n\nHowever, Overholser looked to a more recent conflict, the Iraq War, to argue\nthat the rise of viewpoint-oriented media is healthy, so long as they are transparent and accountable. She bemoaned the “cowardly, credulous and provincial coverage leading up to the Iraq War,” and suggested that “forthrightly partisan media”\ncoverage would have been preferable (Overholser, 2004). Similarly, Cunningham\n(2003) cited examples of flawed pre-war coverage, noting that they\n. . . provide a window into a particular failure of the press: allowing the principle of\nobjectivity to make us passive recipients of news, rather than aggressive analyzers\nand explainers of it. We all learned about objectivity in school or at our first job. Along\nwith its twin sentries “fairness” and “balance,” it defined journalistic standards.\n\nToday, some professionals and educators concede that objectivity may be impossible, but they still insist on fairness and balance. Indeed, Overholser argued\nthat media dedicated to fairness and balance could appeal to those seeking “guidance through an ever more bewildering media forest.” By its nature, journalism involves choices of what to cover and how to cover it, as well as choices in questions\nto pursue. The challenge is to report so thoroughly that all reasonable views are\naired. Subjectivity and bias are impossible to avoid, in this view, but can be minimized. Even journalists at some magazines—where points of view are encouraged and expected by readers— hew to this approach. As the BusinessWeek Code\nof Ethics declared in 2009, “Because we do analytic journalism and commentaries,\nwe do not strive for perfect objectivity. But we must always strive to be fair” (The\nBusinessWeek, 2009).\nEven while acknowledging problems with the ideal of objectivity, many journalism textbooks maintain that it remains central to the journalistic mission. Melvin\nMencher’s News Reporting and Writing, a commonly used text, declares,\nIf readers want to weep or laugh, write angry letters to their senators or send money\nto the Red Cross for tornado victims, that is their business. The reporter is content to\nlay out the facts. Objective journalism is the reporting of the visible and the verifiable.\n\nTeaching Fairness in Journalism: A Challenging Task\n\n5\n\nFurthermore, it reports,\nUnfair and unbalanced journalism might be described as a failure in objectivity. When\njournalists talk about objectivity, they mean that the news story is free of the reporter’s opinion or feelings, that it contains facts and that the account is written by an impartial and independent observer. (Mencher, 2011)\n\nSimilarly, Reporting for the Media, by John R. Bender, Lucinda D. Davenport, Michael W. Drager, and Fred Fedler, urges journalists to remain objective. “Journalists have opinions and biases as do other people,” the authors write.\nBut reporters strive to be as impartial or objective as possible. They are neutral observers, not advocates or participants. They provide the details of the stories they\nreport, not their own opinions about the facts and events. Journalists express their\nopinions only in editorials and commentaries, which are clearly labeled. (Bender,\nDavenport, Drager, &amp; Fedler, 2012)\n\nTo an extent, the textbook authors provide guidance on how students can avoid\ninjecting or revealing bias in their work. “Stories are objective when they can be\nchecked against some kind of record—the text of a speech, the minutes of a meeting, a police report, a purchase voucher, a payroll, or vital statistics,” the Mencher\ntext says, for instance. More to the point, the Bender text says,\nOne way reporters keep their opinions out of stories is by avoiding loaded words,\nsuch as “demagogue,” “extremist,” “radical,” and “zealot.” Such words are often unnecessary and inaccurate. . . . Reporters can eliminate the opinions in some sentences\nsimply by deleting a single adjective or adverb: “alert witness,” “famous author,” “gala\nreception,” “thoughtful reply.”\n\nA third text, Writing and Reporting the News: A Coaching Method, by Carole Rich\n(2013), counsels,\nIf the story involves conflict, you should always get comments from both or all sides\nof an issue. Avoid one-source stories. Also, make sure you attribute your sources; including information you use from websites, other news organizations and quotes or\nstatements from people you interview.\n\nNews Reporting and Writing, by The Missouri Group (Brian S. Brooks, George\nKennedy, Daryl R. Moen, and Don Ranly), offers students a substantial discussion\nabout accuracy, fairness, and bias, as well as objectivity. The text concludes,\nThough there’s debate about just how objective a reporter can possibly be, journalists and scholars all agree about one thing: Reporting the news is not the same as expressing an opinion. The primary goal of a news story is to inform . . . . By contrast,\nthe primary goal of opinion writers and speakers is to persuade.\n\nFurthermore, The Missouri Group text urges accuracy and fairness as “paramount” values. “Fairness requires, above all, that you make every effort to avoid\nfollowing your own biases in your reporting and writing,” the text advises. It gives\n\n6    J o s e p h W e b e r i n J o u r n a l i s m &amp; M a s s C o m m u n i c a t i o n E d u c a t o r ( 2 0 1 5 )\n\nstudents guidance that they can apply to their work to assure accuracy and fairness and to avoid bias. In news stories, for instance, it counsels students to “Work\nto leave personal bias out the story” and to “Use neutral language.” Regarding fairness, it advises that they “Provide context for facts,” “Give all relevant sides of a\nstory,” and “Strive for balance.” Even in commentaries, the text counsels, writers\nmust support their personal bias with facts and reasons, as well as acknowledge\nand rebut other viewpoints, and must use civil language, not “highly charged language” (Brooks, Kennedy, Moen, &amp; Ranly, 2011).\nStill, there is little direct guidance available in the texts or in the academic literature on how an instructor can best teach students to avoid bias and assure fairness in\ntheir work. Neither is there direct guidance on how best to assess bias. This study, in\npart, sought to examine techniques for both teaching fairness and for evaluating bias.\n\nResearch Question and Method\nThe central question in this study was the following:\nResearch Question 1: How can journalism students be taught to avoid bias and\nto build fairness into their work?\nStudents in advanced-reporting classes at the University of Nebraska–Lincoln\nin the spring semester of 2014 read certain materials and then discussed those\nreadings and the topic generally in a lecture session. They also watched a relevant video in class, followed by further discussion. Beforehand, the students reviewed a set of facts and quotes—including fictitious material—about a controversial topic and wrote a news story based on that data. Then, to test whether\nstudents had absorbed the message, they were given a second set of facts and\nquotes after the lecture session and wrote a second story. The hypothesis was\nthat if they took the message in the readings and lecture to heart, they would\nshow less bias and more fairness in their second stories. To assure an impartial\nevaluation, two independent reviewers read the students’ stories and assessed\nthem for fairness and bias.\nThe pedagogical elements included the following:\n• Students read Keller’s op-ed column, “Is Glenn Greenwald the Future of\nNews?” This piece included exchanges between Keller, an advocate of impartial journalism, and Greenwald, an advocate of what Keller called a “more\nactivist, more partisan kind of journalism.” The October 2013 exchange reveals two very different approaches—Keller’s (2013) advocacy of “aggressive\nbut impartial reporting” countered by Greenwald’s view that every journalistic choice is “highly subjective” and all journalism is “a form of activism.”\n• They read the draft of a BusinessWeek feature story about a small town in\nTexas, Waxahachie, in which the writer takes a condescending tone toward\nresidents’ beliefs in creationism and their political and social views in the\n\nTeaching Fairness in Journalism: A Challenging Task\n\n7\n\ncontext of the expected arrival of physicists who would build and operate\na giant “superconducting super collider,” a particle accelerator designed to\nanswer such questions as how the universe came to be.\n• In class, they viewed a video of a July 2013 interview on Fox News with author\nReza Aslan (2013), a religious scholar who wrote Zealot: The Life and Times\nof Jesus of Nazareth. The interview was widely derided as unfair as the questioner repeatedly hammered away on the theme of why a Muslim would\nwrite about Christianity rather than exploring the themes and topics the\nwriter developed in his book. The author repeatedly answered that he was\na scholar who, like many others, had made an academic career in studying\ndifferent religions and whose personal religious views were irrelevant and\nbesides the point of the book.\n• They heard a detailed lecture and took part in a discussion of how impartiality is generally the preferred approach for journalists writing for newspapers. The lecture addressed the issue of how one can use one’s biases in reporting and research (a sense of indignation at injustice, for instance, can be\nhelpful). But the lecture also discussed how one must discard such biases in\nwriting the news. Furthermore, the lecture dealt with fairness, urging that the\nstudents comb their work to make sure they are fair to all parties involved.\nThese lessons were bracketed by the two writing assignments:\n• In the first, the facts and quotes—some fictitious—involved the consequences\nof and reactions to the legalization of marijuana in Colorado. The news developments included plans by a conservative legislator to set a standard\nfor blood tests to determine whether users could be judged guilty of driving under the influence of marijuana. There were comments by marijuana\ncritics and rebuttals by defenders.\n• In the second, the facts and quotes—again including fictitious elements—dealt\nwith abortion. The developments include a US$2 million settlement to be\npaid to the family of a woman who died in a botched abortion. The comments included criticisms by anti-abortion activists and comments by defenders of abortion.\n\nData Collection\nThe instructors collected and graded the 36 resulting papers as they normally\nwould. If explicit opinion statements appeared in the texts, they pointed them out.\nThe grading dealt with all the normal issues of student news accounts, such as completeness, journalistic writing style, proper uses of quotes and anecdotes, and so on.\nTwo faculty members, Associate Professor Bernard R. McCoy and visiting instructor John Baker, then evaluated the student work for fairness and bias. To assure that this was a blinded approach, student names were trimmed from the work\nand the papers did not include grades. The reviewers did not know which assignment preceded the lecture and which followed.\n\n8    J o s e p h W e b e r i n J o u r n a l i s m &amp; M a s s C o m m u n i c a t i o n E d u c a t o r ( 2 0 1 5 )\n\nFigure 1. Reader assessments.\n\nThe reviewers applied two scales to use in evaluating the work, one for bias and\none for fairness. They rated each story on scales of 1 to 5, with 1 indicating low ratings on both bias and fairness (thus, the best rating would be 5 on the fairness scale\nand 1 on the bias scale). They applied separate scales because it is possible (though\nundesirable) for a writer to show bias in a story but still offer a fair account with\nall appropriate viewpoints represented.\n\nAnalysis and Assessment of the Findings\nOne might expect measurable improvement in fairness and the avoidance of bias\nbetween the first story, which dealt with marijuana, and the second, which dealt\nwith abortion. As it turned out, however, there was no substantial improvement\nand, indeed, bias appeared to worsen.\nFigure 1 presents the average and median results. Story 1, with assessments\nreflected in the bar on the left, came before the lecture and discussion (pre-intervention), and Story 2, with assessments reflected in the bar on the left, came after\n(post-intervention).\n\nStatistical Analysis\nThe results suggest that the average degree of fairness rose slightly, but that the\naverage degree of bias also rose slightly. Furthermore, the median amount of fairness declined and the median degree of bias rose. If one looks at the numerical results and renders the changes in percentage terms, one sees that the average degree\nof fairness rose from 2.78 to 2.86, or 2.9%, while the average degree of bias rose from\n2.92 to 3.28, or 12.3%. With the medians, the difference appeared more dramatic:\nfairness declined 16.7%, from 3 to 2.5, while bias rose 33.3%, moving from 3 to 4.\nEven if one allows for overstatement in the medians, the results suggest a rise\nin perceived bias and no appreciable improvement in fairness.\n\nTeaching Fairness in Journalism: A Challenging Task\n\n9\n\nFigure 2. Story 1—Marijuana reader assessments.\n\nDifferences Between Reviewers\nWhen one breaks down the averages between the reviewers, variances emerge.\nOne sees differences between them on each story, and in general one sees differences in their perceptions of bias and fairness. In the marijuana story, the first story,\nReviewer 1 saw substantially more bias, on average, and modestly less fairness,\non average than Reviewer 2. In the second story, about abortion, Reviewer 1 similarly saw substantially more bias than did Reviewer 2. See results below in Figures\n2 and 3, with averages reflected by the bars on the left and medians on the right.\n\nConclusion\nAn unexpected result can be as illuminating as an expected one. In this case, one\nmight expect improvement in the avoidance of bias and in fairness after a lecture\nabout the topics. The results at best were equivocal, however, with no substantial\nimprovement in fairness and an increase in perceived bias. But one can draw conclusions, nonetheless, that can be helpful in teaching:\n• Writing interesting copy in a disinterested manner is a learned skill that takes\ntime, practice, and a teacher’s oversight over time to develop. Journalism\nstudents may need repeated critiques over a full semester or longer to develop a journalist’s mindset and approach to news stories. A single lesson—\neven when it includes substantial reading assignments, a video and a lecture/discussion session—may be inadequate. Sensitizing students to bias\nand fairness may simply take more effort.\n\n10    J o s e p h W e b e r i n J o u r n a l i s m &amp; M a s s C o m m u n i c a t i o n E d u c a t o r ( 2 0 1 5 )\n\nFigure 3. Story 2—Abortion reader assessments.\n\n• It may also be that it is impossible to expunge bias, that nontraditional journalists such as Greenwald are correct. Bias may be inescapable and efforts\nto limit it may be doomed, so the best course may be for journalists to be\ncandid about their attitudes. Veterans in the media business who are familiar with both viewpoint- oriented journalism and “straight news” approaches may not accept this, but must at least understand the argument.\n• The Keller–Greenwald debate document may need to be supplemented by\nothers. One reviewer of this article noted that students tend to find Greenwald more persuasive than Keller. While this article’s author did not find\nthe same skew toward Greenwald, additional material would be helpful,\nnonetheless. One potential additional document for study is “Objectivity\nand Impartiality for Digital News,” by Richard Sambrook of Cardiff University. Sambrook ties “real risks to public understanding” to the growth\nof subjective or advocacy news, linking this further to the significant level\nof distrust in media among the public. His data-based argument goes beyond any mere assertion that the pursuit of objectivity is valuable. (Sambrook, 2015)\n• It may also be that the topics for the stories here yielded poor examples. Abortion may be more inflammatory than marijuana. Furthermore, the facts of\nthe abortion story were especially difficult (involving a woman’s death),\nand thus may give rise to an emotional treatment that could be seen as biased. If the order of the stories had been reversed, the conclusions may\nwell have been different.\n• Perception of bias and fairness may be so subjective that assessments inevitably will be flawed. There was measurable difference between the reviewers\non the issue. To mitigate this, enlisting more reviewers—perhaps as many\nas a halfdozen— could yield more reliable measures, or at least make clear\nwhether one has outliers. So, too, could providing a specific rubric that\n\nTeaching Fairness in Journalism: A Challenging Task\n\n11\n\nreviewers could apply. The tests The Missouri Group suggests, including\nproviding context and all sides of a story, striving for balance, and using\nneutral language, may aid in building such a rubric. These tests, along with\nrequiring students to omit opinion statements, are the kinds of tests that\neditors in news organizations may well already apply, perhaps implicitly,\nas they review material for publication.\n\nFinal Thoughts\nFor journalism educators, dealing with bias and fairness is important. Indeed, it is\na central matter for journalists whose job traditionally has been to deliver news in\nan evenhanded and straightforward manner. Furthermore, students need instruction in how to achieve that approach, in how to develop habits of mind where they\nmay be guided by personal judgments but not impaired by them, and where they\nlearn to listen to and reflect varying viewpoints in their work.\nThis inquiry makes it clear that the task is not simple. Even reviewing student\nwork for bias is challenging, with different reviewers potentially bringing their own\nbiases to bear. Assessing bias and objectivity could easily throw one into a hall of\nmirrors, where bias meets bias and objectivity becomes impossible to measure, no\nmatter how many reviewers one employs. A greater number of reviewers may simply multiply the opportunity for bias.\nNonetheless, more studies on this topic may shed still more light on the questions involved. In future inquiries, those engaged in studies might screen reviewers\nto determine where their biases lay. It is possible that journalism teachers, including those who have worked professionally as editors or journalists, will assess student work through very different prisms. Thus, their views could skew their judgments and those potential skews should be weighed.\nAs for classroom practice, if teachers are to encourage fairness, the results of this\ninquiry suggest that instilling a fair-minded approach in students takes time, effort,\nand substantial criticism. The task appears to take far more than a few weeks and\na single dedicated lesson; indeed, a semester may be inadequate.\nAcknowledgments — The author received no financial support for the research, authorship,\nand publication of this article and declared no potential conflicts of interest with respect to\nits research, authorship, or publication.\n\nReferences\nAslan, R. (2013). Reza Aslan to Fox News anchor: “I wrote ‘Zealot’ because I am an expert.” Retrieved from https://www.youtube.com/watch?v=vsc64Q4KqkE\nBender, J. R., Davenport, L. D., Drager, M. W., &amp; Fedler, F. (2012). Reporting for the media.\nNew York, NY: Oxford University Press.\nBoudana, S. (2011). A definition of journalistic objectivity as a performance. Media, Culture\n&amp; Society, 33, 385-398. doi:10.1177/0163443710394899\n\n12    J o s e p h W e b e r i n J o u r n a l i s m &amp; M a s s C o m m u n i c a t i o n E d u c a t o r ( 2 0 1 5 )\nBrooks, B. S., Kennedy, G., Moen, D. R., &amp; Ranly, D. (2011). News reporting and writing. Boston, MA: Bedford/St. Martin’s.\nThe BusinessWeek code of ethics. (2009). Bloomberg Businessweek. Retrieved from http://www.\nbusinessweek.com/ethics.htm\nCunningham, B. (2003). Re-thinking objectivity. Columbia Journalism Review. Retrieved from\nhttp://www.cjr.org/feature/rethinking_objectivity.php?page=all\nDean, W. (2015). The lost meaning of “objectivity.” American Press Institute. Retrieved\nfrom http://www.americanpressinstitute.org/journalism-essentials/bias-objectivity/\nlost-meaning-objectivity/\nKeller, B. (2013, October 27). Is Glenn Greenwald the future of news? The New York Times.\nRetrieved from http://www.nytimes.com/2013/10/28/opinion/a-conversation-in-lieu-ofa-column.html?_r=0\nKushner, A. B. (Ed.). (2014, May 27). PostEverything. The Washington Post. Retrieved from http://www.washingtonpost.com/posteverything/wp/2014/05/27/\nwelcome-toposteverything/\nMencher, M. (2011). Melvin Mencher’s news reporting and writing (12th edition). New York,\nNY: McGraw-Hill.\nMindich, D. T. Z. (1998). Just the facts: How objectivity came to define American journalism. New\nYork: New York University Press.\nMitchell, A., Gottfried, J., Kiley, J., &amp; Matsa, K. E. (2014). Political polarization &amp; media habits.\nPew Research Journalism Project. Retrieved from http://www.journalism.org/2014/10/21/\npolitical-polarization-media-habits\nOverholser, G. (2004). The inadequacy of objectivity as a touchstone. Nieman Reports. Retrieved\nfrom http://www.nieman.harvard.edu/reports/article/100725/The-Inadequacy-of-Objectivity-as-a-Touchstone.aspx\nReynolds, D. S. (1995). Walt Whitman’s America: A cultural biography. New York, NY: Alfred\nA. Knopf.\nRich, C. (2013). Writing and reporting news: A coaching method. Boston, MA: Wadsworth.\nSambrook, R. (2015). Objectivity and impartiality for digital news (Digital News Report 2014).\nReuters Institute for the Study of Journalism. Retrieved from http://www.digitalnewsreport.org/essays/2014/objectivity-and-impartiality-for-digital-news-consumers/\nSchudson, M. (1978). Discovering the news: A social history of American newspapers. New York,\nNY: Basic Books.\nSchudson, M. (2003). The sociology of news. New York, NY: W.W. Norton.\nSchudson, M. (2007, December 13). Lippmann and the news. The Nation. Retrieved from\nhttp://www.thenation.com/article/lippmann-and-news#\nSchudson, M., &amp; Tifft, S. E. (2005). American journalism in historical perspective. In G. Overholser &amp; K. H. Jamieson (eds.), The press (pp. 27-28). New York, NY: Oxford University\nPress.\n\nThe author\nJoseph Weber is the Jerry and Karla Huse Professor of News-Editorial and an associate\nprofessor of journalism in the College of Journalism &amp; Mass Communications at UNL. He\nworked in magazines and newspapers for 35 years, spending most of that time reporting\nand writing for BusinessWeek and left the magazine in 2009 as its Chief of Correspondents\nand Chicago Bureau Chief.\n\n</td>
    </tr>
  </tbody>
</table>