 Full Terms & Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=hpli20 Psychological Inquiry An International Journal for the Advancement of Psychological Theory ISSN: 1047-840X (Print) 1532-7965 (Online) Journal homepage: https://www.tandfonline.com/loi/hpli20 A Model of Political Bias in Social Science Research Nathan Honeycutt & Lee Jussim To cite this article:  Nathan Honeycutt & Lee Jussim (2020) A Model of Political Bias in Social Science Research, Psychological Inquiry, 31:1, 73-85, DOI: 10.1080/1047840X.2020.1722600 To link to this article:  https://doi.org/10.1080/1047840X.2020.1722600 Published online: 09 Mar 2020. Submit your article to this journal  View related articles  View Crossmark data A Model of Political Bias in Social Science Research Nathan Honeycutt and Lee Jussim Department of Psychology, Rutgers University, New Brunswick, Piscataway, New Jersey In 2019 at the SPSP Political Psychology Pre-Conference, key stakeholders and researchers were invited to debate the question “does ideological diversity impact the quality of our research? ”If Clark and Winegard ’s (this issue) review of ideological epistemology and its significance to social science is mostly on target, it would predict that many at the debate were unconvinced by those arguing that political bias mat- ters. Why? To the extent that social psychologists function as a moral tribal community (as Clark and Winegard argue), motivated to protect their professional and political interests, they will fight tooth and nail to defend their sacred values and professional statuses against charges of political bias. Of course, they might also do so out of a justified belief that they were unfairly accused. How can one tell the difference? In this paper we argue that this can be accomplished by identifying how political biases manifest in social psych- ology. To that end, we expand upon two of Clark and Winegard ’s (this issue) arguments: 1. there are no reasons to believe that social scientists are immune to the biases, errors, and social processes that can lead to distortions that stem from tribal loyalties; 2. these tribal tendencies, combined with extreme ideological homogeneity, work to create sig- nificant problems for the pursuit of scientific truth. Specifically, we present a heuristic model of political bias that identifies ways they manifest, and we review evidence that bears on it. Equalitarianism as a Primary Source of Scientific Bias Clark and Winegard (this issue) reviewed some of the ways in which political biases undermine the validity and credibil- ity of social science research. Their review concludes that political bias manifests as theories the field has advanced that flatter liberals and disparage conservatives, as ideologic- ally motivated skepticism against theories and data that chal- lenge liberal positions, and an overrepresentation of liberals in social psychology. Political bias has also emerged in the review of ideologically charged scientific articles, in exagger- ating the impact of effects favorable to liberal positions, in ignoring plausible alternative hypotheses, in how some find- ings are framed and described, and in how findings are dis- cussed. They argue that these problems are particularly acute when scientific findings (and sometimes, evenquestions) threaten researchers ’sacred values. They further argue that the most sacred value for many social scientists is equalitarianism , by which they refer to a complex of interre- lated ideas: (1) There are no biological differences betweengroups on socially valued traits (and, especially, no geneticdifferences); (2) Prejudice and discrimination are the only sources of group differences (and anyone who says other- wise is a bigot); and (3) Society has a moral obligation toarrange itself so that all groups are equal on socially val- ued outcomes. Although their analysis has merit, we also think it does not go far enough, especially with respect to points one and three. Equalitarianism can, in our view, trigger scientificbiases even when claims do not involve biology. Forexample, arguing that cultural or religious differences between groups produces unequal outcomes can also trigger equalitarian defensiveness, accusations of bigotry, and biasedscience. When Amy Wax argued that differences in the adoption of “bourgeois values ”explains many of the out- come differences between blacks and whites in the U.S.(Wax & Alexander, 2017 ), the outraged response was imme- diate and swift (Haidt, 2017 ). Why? After decades of being inculcated with the evils of “blaming the victim ”(Ryan, 1971 ), any explanation for group differences, whether or not biological, other than discrimination is enough to trigger equalitarian outrage among some scientists. Our point is not that Wax was correct; it is that she made no biological argu-ments at all. This is a real-world case in which somethingother than an attribution to discrimination for group differ- ences on socially valued traits produced the full-blown out- rage predicted by Clark and Winegard ’s perspective. The second author of the present paper also notes that simply presenting evidence of the accuracy of stereotypes (without any presumption or evidence bearing on why groups differ)has also produced similar reactions (Lehmann, 2015 ). We also think their point three is too restrictive. Sacred equalitarianism may even be a bit of a misnomer. In theextreme, this may go beyond a demand for absolute equality among groups and overflow into a motivation to “turn the tables ”(to compensate for past wrongs by placing formerly marginalized groups not on an equal footing, but on a superior one; e.g. Weinstein, 2018 ). For example, samples that skew politically left have recently been found to con-sider companies insufficiently racially diverse unless they CONTACT Nathan Honeycutt nathan.honeycutt@rutgers.edu Department of Psychology, Rutgers University, New Brunswick, 53 Avenue E, Piscataway, NJ 08854 /C2232020 Taylor & Francis Group, LLCPSYCHOLOGICAL INQUIRY 2020, VOL. 31, NO. 1, 73 –85 https://doi.org/10.1080/1047840X.2020.1722600 have at least 25 –32% black representation (Danbold & Unzueta, 2019 ). Because blacks only make up about 13% of the U.S. population (U.S. Census Bureau, 2018 ) this is plaus- ibly viewed as a turn the tables implicit endorsement of dis- crimination against other groups. Similarly, much (we suspect most) of the discourse about sexist bias in education, academia, STEM, and even psych- ology emphasizes the difficulties women face (e.g. Brown & Goh, 2016 ; Greider et al., 2019 ; Handelsman et al., 2005 ; Knobloch-Westerwick, Glynn, & Huge, 2013 ; Ledgerwood, Haines, & Ratliff, 2015 ; Milkman, Akinola, & Chugh, 2012 ; Moss-Racusin, Dovidio, Brescoll, Graham, & Handelsman, 2012 ; National Academies of Sciences, Engineering, and Medicine, 2018 ; Nature, 2015 ; Steele, James, & Barnett, 2016 ; Steinpreis, Anders, & Ritzke, 1999 ; United States National Academy of Sciences, 2007 ; Wenneras & Wold, 1997 ). Nonetheless, women now represent a majority of social psychologists, most of the leadership in at least one of the main social psychology professional organizations (SPSP, 2019 ), a majority of psychologists (American Psychological Association, 2015 ,2018 ), and have been more likely to com- plete high school, college, and graduate degrees than have men for about 40 years (Sharp, 2010 ). If absolute equality was the only driver of motivated bias, one would be witness- ing a dramatic upsurge in claims emphasizing biases against and obstacles to the success and representation of boys and men, given that inequality in these areas now favors women. That so much of the social science effort focuses on biasesagainst women, and so little on those against men, even after women have largely turned the tables in these areas, is plausibly interpretable as indicating that, for some scholars, it is not equality per se that is held sacred. We agree with Clark and Winegard ’s (this issue) articula- tion of where political bias can emerge, and the problems it creates for social science research. Nonetheless, their review was not intended to be comprehensive, and we believe polit-ical biases can also manifest in many additional ways. In the remainder of this article, therefore, we propose and present evidence for a preliminary theoretical model of how political biases manifests in social science. A Preliminary Theoretical Model for Manifestations of Political Bias in Social Science Building upon the evidence offered by Clark and Winegard (this issue), we propose a preliminary heuristic theoretical model identifying key ways in which political biases may manifest in the scientific enterprise: who becomes an aca-demic social scientist, the questions asked, measurement, interpretation of findings, suppression of ideas and findings, citations, and the canonization of research findings (Figure 1 ). Who Becomes an Academic Social Scientist Both informal and formal quantitative investigations indicate that social scientists (including social psychologists) are decidedly left-leaning and that conservatives are the mostunderrepresented group in the social sciences (Al-Gharbi, 2018 ; Haidt, 2011 ; Inbar & Lammers, 2012 ; SPSP Diversity and Climate Committee, 2019 ; Von Hippel & Buss, 2017 ). For example, the Society for Personality and Social Psychology (SPSP; the largest professional organization forsocial and personality psychologists) released a report on diversity and the climate within their organization (SPSP Diversity and Climate Committee, 2019 ). Conservatives con- stituted 4% of the SPSP membership, whereas they consti- tute 35% of the U.S. population (Gallup, 2018). By comparison, African Americans constitute only 4.1% of the membership of SPSP whereas they constitute 13.4% of the U.S. population (U.S. Census Bureau, 2018 ; the membership of SPSP is 84% U.S., so this benchmark seems reasonable). Thus, African Americans are underrepresented by about 70% and conservatives are underrepresented by almost 90%. Further, this general pattern is common throughout the academy more broadly (Langbert, 2018 ; Stolzenberg et al., 2019 ). Role Models In the academy, concerns have frequently been raised about the lack of representation and role models available for stu- dents from underrepresented groups, particularly in terms of race, ethnicity, and gender (e.g. Dasgupta & Stout, 2014 ; Dee, 2004 ; Murphy, Steele, & Gross, 2007 ). The core idea is that mentorship is important (Reinero, 2019 ); if students don’t find successful role models like themselves, they are less likely to pursue a career in that discipline. For example, referring to women in STEM, Dasgupta and Stout ( 2014 , p. 24) argue that “Young adults identify with successful female role models whose presence allows them to think: ‘If she can be successful, so can I ’and‘I want to be like her. ’” Given the support for the gender similarity hypothesis (Hyde, 2005 ), we know of no reason to believe that this sort of social psychological process is unique to women, and there are many to think that they probably apply widely (Honeycutt, Jussim, & Freberg, 2019 ; Reinero, 2019 , includ- ing to political role models in the social sciences (Honeycutt & Freberg, 2017 ). If non-liberal students do not have faculty who share their beliefs and values, this may dissuade some from furthering their studies, and from pursuing academic careers (Redding, 2012 ). It follows, then, that the social sci- ences may be stuck in a self-perpetuating trap whereby pol- itical bias driven by ideological homogeneity has created an obstacle to non-liberal students becoming a part of the field. This process may create further ideological homogeneity in a self-exacerbating cycle. Discrimination Furthermore, when a field becomes politically homogeneous, the norms may shift such that it may even become normal- ized to express hostility toward one ’s ideological opponents (Prentice, 2012 ). These norms can emerge because “everyone ”(in one ’s ideologically homogeneous circles) “knows ”how despicable the other side is (for a report on74 COMMENTARIES asymmetrical mockery of Republicans and conservatives at a conference of the Association for Psychological Science, seeMather, 2018 ). How might this process diminish the pipe- line of non-leftist students in social science? It could do soif these biases manifest in classrooms. Three recent large sample surveys of university students suggest that such biases may indeed manifest in collegeclassrooms. Conservative students reported greater experi-ences of hostility from instructors than did their non-lib-eral peers; furthermore, even liberal students agreed thatconservative and religious students are the disproportionaterecipients of hostility from university faculty (Honeycuttet al., 2019 ; Wills, Brewster, & Nowak, 2019 ). Thus, con- servative students ’perceptions of hostility do not reflect something unique about conservative students; instead,that students across the political spectrum perceive thishostility strongly suggests this reflects an actual class- room dynamic. It should not be surprising, therefore, that conservative students generally try to hide their political beliefs fromtheir professors (Honeycutt et al., 2019 ). Students may view their conservatism as a stigmatized identity requiringconcealment (Crocker, Major, & Steele, 1998 ; Quinn & Chaudoir, 2009 ). The last thing most of these students are likely to do is pursue a career in a field in which theybelieve they are unwelcome (Woessner & Kelly-Woessner,2009 ). Such a process may look like conservative students self-select out of social science research, but some may doso to avoid what they (justifiably) perceive as a hostile environment. Student self-reported experiences and perceptions of pol- itical bias mirror experiences of university faculty (whichwere reviewed by Clark and Winegard). We summarize add-itional studies here that were not included in their review asfurther evidence supporting their perspective. A replicationand extension of Inbar and Lammers ( 2012 ) found that will- ingness to discriminate against one ’s ideological opponents (which they found among social psychologists) extended toacademics across the disciplines (Honeycutt & Freberg, 2017 ). Conservative faculty also reported experiencing more hostility from colleagues because of their political beliefsthan did liberal and moderate faculty (Honeycutt & Freberg,2017 ). These same patterns have also been found among an Figure 1. Preliminary theoretical model for manifestations of political bias in social science.COMMENTARIES 75 international sample of academic philosophers (Peters, Honeycutt, Block, & Jussim, in press ). Additionally, 50% of conservative SPSP members reported that they had experienced an incident of subtle exclusion, compared to 14.2% of liberal members (SPSP Diversity and Climate Committee, 2019 ). For comparison purposes, reported experiences of subtle exclusion for racial/ ethnic minority and white members of SPSP were 24.9 and 12.4%, respectively. For heterosexual and sexual minority members, reported experiences of subtle exclusion were 13.8% and 20.1%, respectively. The SPSP report also con- cluded that conservatives felt “their social identities were less valued than either liberals or participants who reported being neither liberal nor conservative ”(p. 63). Although the sample size for conservatives was small (and, therefore, should be interpreted with caution), the pattern of responses across items all point in the same direction and data from the wide variety of studies reviewed above strongly suggests that conservatives experience more hostility in academia than do liberals. Questions Asked Do political biases manifest as a narrowing of the questionsresearchers can and do ask? According to one recent review, both theory and empirical evidence indicate that cognitive, motivational, and social factors can and do influence the questions researchers ask in ways that are vulnerable to pol- itical biases (Jussim, Stevens, & Honeycutt, 2018 ). For example, political homogeneity may lead to premature scien- tific foreclosure —the erroneous belief that science has settled some question, thereby discouraging further work on the topic that might reveal the error. For example, social psych- ology prematurely foreclosed on conclusions emphasizing the power of self-fulfilling prophecies (Jussim, 2012 ), the greater susceptibility to bias among conservatives than liber- als (Ditto et al., 2018 ), the existence of higher levels of prejudice among conservatives than liberals (Brandt, Reyna, Chambers, Crawford, & Wetherell, 2014 ), and the power and pervasiveness of “unconscious prejudice ”(Jussim, Careem, Goldberg, Honeycutt, & Stevens, in press ). In each case, a “consensus ”in support of the erroneous perspective could be found in the scientific literature that lasted decades. Each of these premature foreclosures involved conclusions flattering to liberals or validating equalitarian narratives. Similarly, motivated reasoning (Kunda, 1990 ) may lead researchers to be more critical and skeptical of findings that challenge their preconceived notions than those that support them (Nickerson, 1998 ). Politics may influence scientists ’ preconceptions, for example, about the rationality of conser- vatives or liberals, or the extent and power of bias and dis- crimination. If so, perhaps, research confirming those notions would be more likely to be published in prestigious journals and highly cited; research disconfirming those notions might have difficulty getting published in prestigious journals, or even getting published at all (as discussed in Clark and Winegard ’s review).Scientists are also heavily influenced by all sorts of social norms (Jussim, Krosnick, Stevens, & Anglin, 2019 ). Norms can influence what is acceptable, popular, or stigmatized tostudy (Jussim et al., 2018 ). When deciding what to study, if one is interested in managing one ’s career as an academic, topics seen as likely to be warmly received may be pursuedfar more aggressively than those seen as likely to be harshlyreceived by one ’s colleagues. If one understands that most of one’s colleagues are politically left, it will be far easier to manage and advance one ’s career if one works on topics appealing to those on the left than on topics that might pro-duce findings that the left opposes (for a brief discussion,see Everett, 2015 ). As Tetlock and Mitchell ( 2015 ) state: It is not the personal political values of researchers that matter, so much as the willingness of researchers to challenge orthodoxideas within a field, but if the costs of dissent outweigh the benefits of dissent then scientific competition can never drive out spurious results produced by political bias rather than bytrue empirical causes and effects (Tetlock & Mitchell, 2015 , p. 32). In addition to what questions get asked, political values can become embedded in how researchers ask questions (see Reyna, 2018 , for a review). This issue was on full display at the 2019 SPSP Political Psychology Pre-Conference. One ofthe sessions addressed the question of ideological symmetryversus asymmetry. Researchers from two camps were invitedto debate whether conservatives and liberals are biased insimilar ways (symmetry), or whether conservatives are morebiased than liberals (asymmetry). The debate certainlyreflected progress, given that for decades the field had pre-maturely foreclosed on the conclusion that conservativeswere more biased than liberals (e.g. Brandt, Reyna,Chambers, Crawford, & Wetherell, 2014 ; Ditto et al., 2018 ). However, and here is an informal test of readers ’own polit- ical biases: Do you see anything missing? (Take a minutebefore reading on …). We do. There was a possibility that was not even considered: Are people on the left more biasedthan those on the right? Given the awful history of leftwingatrocities (Soviet Union, China, Cambodia, Eastern Europeunder Communism, North Korea, et cetera), many of whichwere enabled by all sorts of biases in reasoning and toxicsocial norms (Solzhenitsyn, 1973 ), the failure to even raise this question for consideration was a clear blind spot. Measurement Political skew can manifest in the very measurement of keyconstructs in politicized areas. Although some manifesta-tions of measurement bias might be subtle, others are moreobvious. For example, liberals typically score higher on the“openness to experience ”dimension of the five-factor model of personality. One of the items is “I believe that we should look to our religious authorities for decisions on moralissues ”(Agree: Openness score goes down). Conservatives are more religious than liberals (Hirsh, Walberg, &Peterson, 2013 ; Pew Research Center, 2018 ), and many aca- demics are hostile to religion (Marsden, 2015 ; Yancey,76 COMMENTARIES Reimer, & O ’Connell, 2015 ). Therefore, a failure to recog- nize that an item tapping religion could spuriously inflatethe correlation between the measure of openness and ideol-ogy embeds political bias into the measure (Charney, 2015 ). In the most sweeping review of these issues to date, Reyna ( 2018 ) conducted a systematic march through a myr- iad of ways, with examples, of how political biases under-mine measurement. She reviewed some of the material wejust covered, but through a measurement lens. For example,if we do not measure prejudice held by minority groups toward majority groups, we will develop a skewed view of prejudice as primarily, or even exclusively, the province ofmajority groups. Reyna ( 2018 ) also addressed the problem of “proxy ques- tions, ”which refers to use of questions intended to capture Phenomenon A by measuring Phenomenon B, on thegrounds that B is supposed to be correlated with A. Issues related to social desirability have encouraged the rise of proxy measures in social science research; participants mightnot be willing to admit if they are racist or sexist, so indirectmeasures are needed to get around this. Symbolic racism(Sears, 1988 ), for example, was created to get around social desirability in the assessment of racism. Critics, however,have identified a slew of reasons that this indirect measureof racism was actually, at least in part, a measure of political conservatism and belief in meritocracy (Tetlock & Mitchell, 1993 ). The tangling of conservative and racial concepts in a measure intended to indirectly assess racism makes itimpossible to assess the independent and interactive effectsof either construct (Tetlock, 1994 ). If, in turn, canonical conclusions regarding prejudice become rooted in the use ofindirect measures that are infused with political bias, ourunderstanding of both prejudice and ideology may become deeply flawed (Reyna, 2018 ). Reyna ( 2018 ) reviewed a wide variety of common proxy measures (system justification, symbolic racism, and theimplicit association test [IAT]) and concluded that all impli-citly import potentially unjustified ideological assumptions.Although a full discussion of how ideological assumptions infiltrate these and other measures is beyond the scope of this paper, it is worth noting that measurement issues havebeen addressed in a substantial and growing literature onpolitical biases (Chambers & Schlenker, 2015 ; Duarte et al., 2015 ; Jussim, Crawford, Anglin, & Stevens, 2015 ; Jussim, Crawford, Anglin, Stevens, & Duarte, 2016 ; Martin, 2016 ; Redding, 2001 ; Reyna, 2018 ; Tetlock, 1994 ). It is possible that efforts to raise awareness about biases have begun to bear fruit in the sense of researchers becom-ing more sensitive to their own potential for such biases,and, therefore, being better-positioned to reduce or elimin-ate them. Nearly two decades after introducing items for anactively open-minded thinking scale (AOT), Stanovich andToplak ( 2019 ) discovered they had inadvertently introduced bias against religious individuals into their measure through items asking participants about “beliefs. ”It was assumed by Stanovich and his colleagues that participants all interpreted“belief ”in the same way, but they came to recognize that “…our own political/worldview conceptions leaked intothese items in subtle ways ”(p. 163). Specifically, they pre- sumed “beliefs ”referred to secular, empirically verifiable understandings of the world. For secular academic intellec- tuals, this presumption is understandable. However, when they discovered unexpectedly high negative correlations ofreligiousness with some variations of the AOT scale, theyrevisited the items and reanalyzed some existing data. Thoseanalyses were consistent with a conclusion that religious respondents interpreted “beliefs ”as“spiritual beliefs. ”As a result, this led religious people to appear far less open-minded with respect to secular beliefs (which was the focusof the AOT) than they actually were. “ Are we ideologues masquerading as scientists: Have we rigged the research dice in favor of our political agenda? ” (Tetlock, 1994 , p. 528). For measurement, this is an import- ant question to keep in mind. Being vigilant in the choice and construction of methods used, in addition to ensuringthe validity of measures, would assist in mitigating the effectof political bias on measurement. As summarized by Reyna (2018 ), researchers must ensure their questions are not one- sided, that political assumptions are not embedded to thedetriment of construct and face validity, and reviewers andconsumers must carefully scrutinize measures to ensure thatthey assess what they are purported to assess (see also Flake & Fried, 2019 , for a review of questionable measure- ment practices). Interpretation There are few, if any, strict rules or guidelines governinghow to interpret findings. Therefore, interpretations are sub- ject to a broad array of biases stemming from many sources, including a misunderstanding of statistics, a desire for“wow! effects ”(compelling narratives) to achieve fame and prestige, failure to consider alternative explanations, and more (Jussim, Crawford, Anglin, et al., 2016 ). As such, inter- pretations also constitute fertile ground for the manifestationof political biases (for theoretical reviews of how such biasescan and do manifest in scientific interpretation, see Jussim,Crawford, Anglin, & Stevens, 2015 ; Jussim et al. 2018 ; Jussim, Crawford, Stevens, Anglin, & Duarte, 2016 ; Jussim, Crawford, Stevens, & Anglin, 2016 ). One simplistic way in which politically biased interpreta- tions can manifest is by framing differences between liberalsand conservatives in a manner that stigmatizes conservativeswhen those same differences could just as readily bedescribed neutrally or as stigmatizing liberals. Here we aug- ment the cases reviewed by Clark & Winegard with add- itional evidence. In scientific abstracts for social psychologyresearch, for example, conservatives and conservative ideasare described more negatively than liberals and liberal ideas (Eitan et al., 2018 ). Although such a pattern by itself may or may not reflect bias, other work more clearly identifies howpolitical biases manifest as framing findings in ways thatderogate conservatives. For example, Lilienfeld ( 2015 ) pointed out that the robust finding that conservatives are more sensitive to threat than are liberals has been framed as “negativity bias ”or“motivated closed-mindedness ”(theyCOMMENTARIES 77 could just as readily been framed as liberal “positivity bias ” or“motivated blindness to danger ”). Indeed, even the widespread derogatory characterization of conservatives as “rigid”is primarily based on research that has not actually demonstrated rigidity, if rigiditymeans an inability or unwillingness to change one ’s think- ing. Instead, what has generally been demonstrated is somelevel of mean difference between liberals and conservatives on scales measuring constructs such as dogmatism and cognitive flexibility (Jost, Glasser, Kruglanski, & Sulloway,2003 ). Putting aside the possibility that infiltration of polit- ical biases in the measurement of dogmatism and rigidity(Malka, Lelkes, & Holzer, 2018 ; Reyna, 2018 ) may exagger- ate differences between liberals and conservatives on these measures, how much flexibility is the “right”amount? Should people be entirely “wishy-washy ”(a mirror image pejorative characterization of liberals ’lower “dogmatism ” and greater “flexibility ”), jettisoning their beliefs at the slightest challenge? There currently are no answers to ques- tions like this; value laden characterizations of conserva-tives as “dogmatic ”and liberals as “open-minded ”are scientifically meaningless absent standards for deciding whois dogmatic and open-minded other than “scores on a scale. ” Political bias can also influence the interpretation of findings through the exaggeration of differences between conservatives and liberals in ways that flatter liberals. Suchis the case when researchers commit the high-low fallacy (Reyna, 2018 ). Often, researchers fall victim to interpreting small differences at one end of the scale as if the differencesreflect values at the scale endpoints. For example, eventhough relatively few people score on the authoritarian endof the rightwing authoritarianism scale (RWA), psycholo-gists routinely refer to conservatives as high and liberals as low in authoritarianism (Reyna, 2018 ). Statistically signifi- cant differences do not indicate that groups are at oppositeends of the scale (Reyna, 2018 ). Instead, more valid inter- pretations would be that liberals score low on RWAwhereas conservatives ’scores are more intermediate. Of course, this problem is itself confounded with the measure- ment problem —is anyone shocked that conservatives score higher than liberals on a rightwing authoritarianism scale, whereas liberals score higher than conservatives, on a left- wing authoritarianism scale (Conway, Houck, Gornick, & Repke, 2018 )? Such biases may be particularly powerful when, exactly as argued by Clark and Winegard, they are driven by equalitarian motives. This may help explain why identicaleffect sizes (of about r¼.11) are viewed as socially import- ant if being socially important advances social justice (by revealing that implicit bias causes "important" levels of dis-crimination; Greenwald, Banaji, & Nosek, 2015 ), and trivi- ally small if being trivially small advances social justice(debunking discriminatory stereotypes by revealing thereare few serious differences between men and women Hyde, 2005 ). However, as scientific generalizations, socially important is mutually exclusive with trivially small. How isit possible, then, that both descriptions exist unchallengedin highly-cited articles appearing in prominent peer- reviewed journals, without even acknowledgment of thecontradiction, let alone attempts to resolve it? Clark andWinegard provide a likely answer: both articles advanceequalitarian social justice narratives, and scientists are moti-vated to embrace those narratives. Explicitly acknowledgingthat these two equalitarian narratives conflict with eachother would undercut the ability to advance at least one ofthem. Accordingly, their perspective predicts that few willnotice the contradiction and, even among those that do, even fewer will be motivated to point it out and risk the ire of their colleagues. A similar process may explain unjustified interpretations of the original stereotype threat research (Steele & Aronson,1995 ) as demonstrating that “but for stereotype threat, black and white test scores would be equal. ”This conclusion vali- dates the equalitarian assumptions that there are no realracial differences other than those produced by discrimin-ation. Unfortunately, however, Steele and Aronson ’s(1995 ) findings did not support those conclusions. Specifically, thestudies did not even test the hypothesis that “but for stereo- type threat, black and white test scores would be equal, ” let alone provide data that supported it. Nonetheless, it wasinterpreted in that manner for many years, and, sometimes,still is (see Jussim, Crawford, Stevens, Anglin, Duarte, 2016 , for a review). Space constraints do not permit a full exposition of mis- interpretations that may reflect political bias. Nonetheless,several reviews raise the possibility that, in addition to thecases reviewed here, the problem also characterizes work onenvironmental attitudes, stereotype accuracy and bias, self-fulfilling prophecies, rightwing authoritarianism, microag-gressions, liberal/conservative differences in bias, and more(e.g. Jussim, Crawford, Stevens, & Anglin, 2016 ; Jussim, Crawford, Stevens, Anglin, Duarte, 2016 ; Jussim et al., 2015 , 2018 ; Lilienfeld, 2017 ; Martin, 2015 ; Redding, 2001 ; Reyna, 2018 ). Suppression of Ideas and Findings Political and especially equalitarian biases may operate to suppress certain ideas and findings. One of the definitions of“suppress ”found on dictionary.com is “to withhold from disclosure or publication, ”and that is the meaning used here. Suppression can come in two forms: self-suppression and attempted suppression by others. Self-Suppression Becker ( 1967 ) is plausibly interpreted as implicitly advocat- ing for politically-motivated self-suppression: One can imagine a liberal sociologist who set out to disprove some of the common stereotypes held about a minority group. To his dismay, his investigation reveals that some of the stereotypes are unfortunately true. In the interests of justice and liberalism, he might well be tempted, and might even succumbto the temptation, to suppress those findings (Becker, 1967 , p. 239).78 COMMENTARIES If there is any doubt that Becker ( 1967 ) was advocating for political biases, including suppression, his conclusion(p. 247) leaves no doubt: “We take sides as our personal and political commitments dictate …” Self-suppression is notoriously difficult to demonstrate, of course, because if work has been suppressed, it cannot beeasily found. An absence of evidence cannot, by itself, beinterpreted as suppression. However, we know of at least 17cases of suppression uncovered that are consistent with Clark and Winegard ’s analysis of how the second equalitar- ian assumption (prejudice and discrimination are ubiqui-tous) can bias the scientific literature. Zigerell ( 2018 ) discovered 17 unpublished experiments on racial biasembedded in nationally representative surveys totaling over13,000 respondents. These unpublished experiments failed todetect evidence of anti-black bias among white respondents but did detect pro-black bias among black respondents. Although the role of political biases in producing this situation may never be known with certainty, two points areworth highlighting. First, an alternative explanation is thatresearchers obtained null results, which are notoriously diffi-cult to publish, so they did not bother to try. However, this explanation is, at best, incomplete, inasmuch as statistically significant evidence of anti-white bias among black respond-ents was found and the studies still were not published.Second, regardless of the reasons for suppression, the merefact that these findings were suppressed means that the sci-entific literature was biased in an equalitarian direction(overstating the extent of racial bias by its failure to include these 17 studies finding no bias among whites) until Zigerell ’s(2018 ) forensic work rediscovered these studies. This raises the following unanswerable question: How manyother unpublished studies failing to find evidence of demo-graphic biases are there? Another example of self-suppression can be found in IAT research. In response to criticism of the ability of IAT stud-ies to account for racial discrimination (Blanton et al.,2009 ), a retort emphasized the validity of the IAT and included in its title: “… Executive Summary of Ten Studies that no Manager Should Ignore ”(Jost et al., 2009 ). Putting aside the fact that six of the ten studies did not address racial discrimination, even the four that did found almost no evidence of racial discrimination (see Jussim et al., in press , for a review). This was simply not reported in Jost et al. ’s(2009 ) reply, or in any paper we know of that has cited that reply, until we did a deep dove into the 10 studiesand discovered the almost complete absence of racial biaseffects (Jussim et al, in press ). Of course, it is possible that, rather than suppression, perhaps no one consider it relevant. But how could findings showing little or no bias not be rele-vant to establishing the importance of the IAT to pre-dict bias?Suppression by Others In addition to self-suppression, sometimes, findings are sup- pressed by others . Academia is a social enterprise —our pub- lications, grants, invitations, jobs, and promotions hingeheavily on others ’evaluations of us (Jussim, et al., 2019 ). If some ideas and those who advocate them are sanctionedand punished, suppression is a likely outcome. This state ofaffairs was recently explicitly articulated by social psycholo-gist Michael Inzlicht (WTF is the IDW?, 2018 ): What if I felt that overemphasis on oppression is a terrible idea, hurts alleged victims of oppression, and is bad for everyone.What if I was outspoken about this? I suspect I would face a lot more opposition, even though not much could happen to my job security, but I ’d have a lot of people screaming at me, making my life uncomfortable. And, truly, I wouldn ’t do it, because I ’d be scared. I wouldn ’t do it because I ’m a coward. Our view is that Inzlicht ’s willingness to go public with this sort of statement means, if anything, he is less of a cow-ard than many others —which is plausibly interpretable as suggesting that the problem extends widely. Indeed, thereare more than ample documentable instances where aca-demics have been subject to punishment (investigations, fir-ings, retractions), not because their ideas were refuted ortheir data found to be fraudulent, but because other aca-demics found their ideas offensive. Most of these casesinvolved findings or arguments that challenged (or, perhaps,threatened) academics ’equalitarian sensibilities (race, sex, ethnicity, colonialism, et cetera, Jussim, 2018a ; Quillette, 2019 ). How many early-career researchers are willing to risk their careers by stepping on intellectual hornets nests?Indeed, given the political climate in the academy, and espe-cially in the social sciences, how many even senior scientistsare willing to court the type of hostility feared by Inzlicht? We speculate that Inzlicht ’s comments apply widely. If so, the obvious consequence is that suppression of researchideas and findings out of fear of running afoul of one ’s col- leagues will produce a biased “scientific literature ”that pro- vides more support for equalitarian narratives than isactually justified. Citations Political motivations and blinders may also distort scientificliteratures by influencing which studies researchers empha-size. This can manifest in many ways, one of which is cita- tions. Although papers can be cited for many reasons, some are that researchers consider them relevant, valuable, orimportant. However, it is also possible that many researchersselectively cite and emphasize work that they agree with.Like other biases, this may, but need not, manifest as only Table 1. Citations to two papers finding opposite patterns of gender bias. Number of experiments Total sample size Main findingTotal citations (Google Scholar, 12-9-19)Citations since 2015 (Google Scholar, 12-9-19) Williams & Ceci ( 2015 ) 5 873 Bias favoring women 217 194 Moss-Racusin, et al. ( 2012 ) 1 127 Bias favoring men 1935 1470COMMENTARIES 79 citing work one agrees with; bias would occur when work is cited more frequently based on its political content rather than its scientific quality. Because Clark and Winegard only scratch the surface of citation biases, we present more such evidence here. For example, in 2012 and 2015, papers reporting studies assessing gender biases in STEM hiring were published. Table 1 summarizes their key characteristics and citations and shows the paper finding biases against women has been cited at a vastly higher rate even though by most conventional methodological quality metrics (number of studies, sample size) it was less methodologically sound. This citation pattern shown in Table 1 is not unusual. Jussim ( 2019 ) examined citation patterns of ten papers pub- lished in 2015 or earlier on gender bias in peer review (Table 2 ). Four found biases favoring men; six found either no bias or biases favoring women. The citation patterns ech- oed those shown in Table 1 ; vastly larger-scale studies find- ing no evidence of biases against women are cited at a fraction of the rate of far smaller studies finding biases against women. This pattern is not restricted to gender issues. A famous study that primed age stereotypes and found people walk down the hall more slowly has been cited over 5,000 times (Bargh, Chen, & Burrows, 1996 ); a failed replication (Doyen, Klein, Pichon, & Cleeremans, 2012 ), 580 (all citation counts in the present and next paragraphs were obtained on December 10, 2019 from Google Scholar). Even if we restrict citations to 2013 and later, the counts are 2,340 and 548. The first paper finding stereotype threat effects among women in math (Spencer, Steele, & Quinn, 1999 ) has been cited over 3,800 times; a failed replication with a far larger sample size (Finnigan & Corker, 2016 ), a mere 33. If we restrict citations to 2017 and later, the counts are, respect- ively, 941 and 30. Clark and Winegard described the dramatically higher citation count for Darley and Gross ( 1983 ) than for Baron, Albright, and Malloy ’s(1995 ) failed replication. These pat- terns, however, are not restricted to successful studies versus failed replications. Darley and Gross ( 1983 ) examined whether individuating information reduced stereotype biases (they found it increased bias). However, the first study framed as addressing exactly that issue was published previ- ously, in the same journal, and found that individuating information eliminated stereotype bias (Locksley, Borgida, Brekke, & Hepburn, 1980 ). Locksley et al. ( 1980 ) has been cited 666 times; that is pretty high, but well under half the rate of Darley and Gross ’s(1983 ) over 1,500 citations, and this is despite the fact that Locksley et al. ( 1980 ) reported two studies with a combined total of 325 participants,whereas Darley and Gross ( 1983 ) only reported a single study with 70 participants. Of course, if it is easy to reduceor eliminate stereotype biases in person perception by pro- viding individuating information, this undercuts equalitarian narratives emphasizing the power of such biases. This,according to Clark and Winegard ’s analysis, likely explains some or all of the difference in citations. In this context, it is also interesting to note that Kunda and Thagard ’ s(1996 ) review and meta-analysis finding that individuating information effects were “massive ”(p. 292) is not cited in a single one of the chapters in the 2010Handbook of Social Psychology (Fiske, Gilbert, & Lindzey, 2010 ). The Handbook is one of the most canonical sources in all of social psychology, and Kunda and Thagard ( 1996 ) was itself published in a major outlet ( Psychological Review ). That it was completely uncited, even though several Handbook chapters focused specifically on stereotypes, social justice, and related concepts, is an omission entirely consist-ent with the type of equalitarian biases identified by Clarkand Winegard. Our last example (though there are many more) are com- peting meta-analyses of the psychological characteristics of liberals and conservatives. Jost, et al. ’s(2003 ) meta-analysis showing that conservatives were far higher than liberals ondogmatism and rigidity has been cited almost 4,000 times; ameta-analysis showing small to nonexistent differences in cognitive styles among conservatives and liberals (Van Hiel, Onraet, & De Pauw, 2010 ) has been cited 176 times. If we restrict citations to 2011 and later, the counts are, respect- ively, 3,060 and 173. Admittedly, the Van Hiel et al ( 2010 ) was published in a lower-profile journal, and that may par-tially account for the huge citation difference; however, fromanother perspective, that it was published in a lower profile journal may itself reflect political biases. More importantly, many of the examples used here involve comparisons ofstudies published in the same journal at about the sametime, so that the vast citation differences reviewed here can- not generally be explained by differences in the visibility of the publication outlets. The importance of these citation biases goes well beyond providing evidence consistent with Clark and Winegard ’s account of scientific equalitarian biases. They are importantbecause they go to the heart of the scientific enterprise, which we discuss in the next section on how ideas and find- ings enter the scientific canon. Canonization Canonization ( Table 3 , adapted from Jussim, et al., 2019 ) refers to the process by which research findings and conclu- sions become part of a field ’s accepted and established base of knowledge (Jussim, et al., 2019 ). The social sciences cur- rently have processes, but no consensus or norms, regarding the standards to be used to canonize a finding or conclu- sion. Descriptively, the process seems to involve claims mak-ing it into journals of record (e.g. Psychological Bulletin , Perspectives on Psychological Science , et cetera), Annual Review and Handbook chapters, major textbooks, and theTable 2. Citations to papers based on whether or not they found gender bias favoring men. Found biases favoring men (Four papers)Found unbiased responding or biases favoring women (Six papers) Median sample size 182.5 2311.5 Citations per year 51.5 9.00 Data based on those reported in (Jussim, 2019 )80 COMMENTARIES like. But what determines whether findings make it into those outlets of record? It is currently an unclear combin-ation of popularity, prestige, having the right allies and sup-porters, compellingness of narrative, and validity (Jussim,Crawford, Anglin, et al., 2016 ; Jussim, et al., 2019 ; Merton, 1973 ; Tomkins, Zhang, & Heavlin, 2017 ). Except for validity, none of these factors constitute grounds for claiming a find-ing or conclusion is actually true. Table 3 captures this state of affairs. The ideal situation is when valid findings are canonized. If invalid findings are ignored, the canon is also better off, though, of course, werarely know which findings are valid versus invalid until askeptical scientific community has had years, sometimesdecades, to fully vet the research. The other two cells are even more suboptimal: Canonization of invalid findings can lead to a Reign of Error (and psychology ’s replication crisis strongly suggests that is exactly what we have had in manyareas for the last several decades), and failure to canonizevalid findings harms the field by depriving it of valid knowledge. Canonization is where the biases articulated in the prior sections on questions, measurement, interpretations, andcitations all come together in ways that actually matter. When solid research is blithely ignored because it fails to fit liberal/equalitarian narratives, it impoverishes the social sci-ence canon. Furthermore, to the extent that the largely over-looked work is actually superior in methodological qualityto the cited work (see Tables 1 and 2), it may actually con- tribute to a Reign of Error, whereby flawed studies of lim- ited generalizability are taken to represent the field ’s general knowledge. When certain questions go unasked, the canoncannot possibly have answered them. When we use flawedor biased measures, our interpretations of findings may be distorted at best and wrong at worst. When we reach con- sistently unjustified interpretations, we produce a Reign ofError. And even if all this is corrected in the scientific litera-ture, if those corrections go largely ignored (uncited), theReign of Error can persist. Ellemers ( 2018 ) review of gender stereotypes can be taken as a paradigmatic case. It appeared in Annual Review of Psychology, one of the outlets of record for our field. It also concluded that gender stereotypes were mostly inaccurate — without citing a single one of the 11 papers reporting 16 sep- arate studies that actually assessed the accuracy of genderstereotypes (see Jussim, 2018b , for details). Those 11 papers consistently found that gender stereotypes ranged frommoderately to highly accurate. We note here that it is not the case that the accuracy work could not or did not get published; it clearly did.However, to therefore assume that our science has self-corrected the erroneous claim that gender stereotypes are generally inaccurate would be to commit the fundamental publication error (Jussim, 2017 ). This refers to the mistaken belief that, just because something has been published cor-recting past scientific errors, the scientific record has beencorrected. If the work correcting errors is ignored, no cor-rection has taken place. It is possible, of course, that futureresearch will vindicate the view that gender stereotypes aremostly inaccurate. Furthermore, any scientist is welcome tocriticize any area of research and make the case that it isinvalid. Nonetheless, reviews that claim comprehensivenessand nuance, such as those appearing in Annual Review of Psychology , should not be in the business of simply ignoring work that fails to fit equalitarian narratives. Conclusion Political bias can slip in and distort the research process andscientific pursuit of truth at many stages, influencing whobecomes an academic social scientist, the questions asked,the measures used, how research findings are interpreted, ideas and findings being suppressed, what is cited, and the canonization of research findings. We note here that mostare readily detectable as manifestations in the published lit- erature without requiring attributions to individual researcher motivations. When scale labels condemn conser-vatives, or certain types of studies are systematically ignoredor go unpublished, or certain types of questions go unasked,the scientific literature itself becomes politically biased , regardless of whether individual researchers harbor suchbiases. The existence of political bias in academic researchcan damage the reputation and credibility of individualresearchers, whole fields, and academia itself. It increases skepticism among key consumers such as policymakers, judges, and the public (Cofnas, Carl, & Woodley of Menie,2017 ; Duarte et al., 2015 ; Gauchat, 2012 ; Redding, 2001 ). The patterns of bias described in this review may also atleast partially explain why there has been such a strongdecline in support for science among conservatives, who,with some justification, see science on politicized issues asitself hopelessly politicized (Cofnas et al., 2017 ; Gauchat, 2012 ). We further note that the phenomena reviewed herein likely synergistically combine to undermine the credibility of science with all but the liberal members of the lay public(though possibly with some of them as well). The lack ofconservatives in the social sciences, combined with explicitendorsement of discrimination against conservatives, giveslay conservatives ample reasons to doubt the validity of con-clusions seeming to support liberal, equalitarian, socialTable 3. The importance of canonization. Published research is: Ignored Canonized Invalid IRRELEVANT: No major harm REIGN OF ERROR: Misunderstanding, misrepresentation, bad theory, ineffective and possibly counterproductiveapplications Valid LOSS: Understanding, theory and applications deprived of relevant knowledgeIDEAL: Understanding, theory and applications enhanced by relevant knowledge Adapted from Jussim et al. ( 2019 )COMMENTARIES 81 justice narratives. We urge readers to imagine a counterfac- tual: That the social sciences included a large minority of conservative scientists, that our methods were actually cap- able of providing clear scientific answers tocontroversial and politicized issues, and that most scientists valued truth over politics. In this hypothetical world, high- quality methods could lead both liberal and conservativesocial scientists to converge on answers to some difficult questions. In this case, we speculate that research findings from this hypothetical world would have far higher credibil- ity among the lay public for two reasons: 1. Representation of a broad ideological range of views among scientists sig-nals a commitment to fairness, openness, and honesty; and 2. It guarantees that a large number of scientists (if consen- sus is reached) on everyone ’s“side”confirm the validity of the finding, regardless of whose political narrative it vali- dates. This should make it far more difficult to dismiss sci- entific findings as partisan ax-grinding by other means.Furthermore, by virtue of experts on one ’s own side endors- ing the research, the findings may be rendered far more pal- atable. Although we are not suggesting that vigorousembrace of intellectual and political diversity in the social sciences is some sort of scientific panacea, this hypothetical world —which contrasts sharply with our actual world —cap- tures some of the potential benefits social science might reap by rectifying its political lack of diversity and taking its political bias problems seriously. Clark and Winegard (this issue) close their review and arguments suggesting that social scientists should take a moment to be introspective —to apply their own theories and scholarship to themselves. To aid in this effort, Jussim & Crawford (2018) reviewed research identifying a slew of actions that scientists can take now to limit their vulnerabil-ity to such biases. Although space does not permit a deep exposition here, in brief, those included: increase one ’s own exposure to politically diverse views as espoused by thosewho hold them (rather than [mis]characterizations of those views by their opponents), include political views in diver- sity statements and programs, subject all work (includingequalitarianism-validating work) to intense scientific skepti- cism, use strong inference (design studies to test competing alternative theoretical perspectives), wait to bring research- based interventions into public applications until after the underlying research has undergone a long period of skep-tical scientific vetting, and develop hypotheses and research programs based on theoretical predictions that are so strong they leave little room for political biases. We echo Clark &Winegard ’s hope that social scientists will become more aware of their biases. Through the type of critical introspec- tion they called for, and by acting on some of these recom-mendations described, we also hope this will work toward curtailing its influence on social science research. References Al-Gharbi, M. (2018). Underrepresentation: Race, Gender, Sexuality, Ideology . Retrieved from Heterodox Academy website: https://heter- odoxacademy.org/ideological-underrepresentation-compared-to-race- gender-sexuality/ .American Psychological Association. (2015). Demographic Characteristics of APA Members by Membership Characteristics,2014. Retrieved from https://www.apa.org/workforce/publications/ 14-member/index . American Psychological Association. (2018). Demographics of the U.S. psychology workforce: Findings from the 2007 –16 American Community Survey . Retrieved from https://www.apa.org/workforce/ publications/16-demographics/index . Bargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activationon action. Journal of Personality and Social Psychology ,71(2), 230–244. doi: 10.1037/0022-3514.71.2.230 Baron, R. M., Albright, L., & Malloy, T. E. (1995). Effects of behavioral and social class information on social judgment. Personality and Social Psychology Bulletin ,21(4), 308 –315. doi: 10.1177/ 0146167295214001 Becker, H. S. (1967). Whose side are we on? Social Problems ,14(3), 239–247. doi: 10.1525/sp.1967.14.3.03a00010 Blanton, H., Jaccard, J., Klick, J., Mellers, B., Mitchell, G., & Tetlock, P. E. (2009). Strong claims and weak evidence: Reassessing the pre-dictive validity of the IAT. Journal of Applied Psychology ,94(3), 567–582. doi: 10.1037/a0014665 Brandt, M. J., Reyna, C., Chambers, J. R., Crawford, J. T., & Wetherell, G. (2014). The ideological-conflict hypothesis: Intolerance amongboth liberals and conservatives. Current Directions in Psychological Science ,23(1), 27 –34. doi: 10.1177/0963721413510932 Brown, A. J., & Goh, J. X. (2016). Some evidence for a gender gap in personality and social psychology. Social Psychological and Personality Science ,7(5), 437 –443. doi: 10.1177/1948550616644297 Chambers, J. R., & Schlenker, B. R. (2015). Political homogeneity can nurture threats to research validity. Behavioral and Brain Sciences , 38, e138. doi: 10.1017/S0140525X14001162 Charney, E. (2015). Liberal bias and the five-factor model. Behavioral and Brain Sciences ,38, e139. doi: 10.1017/S0140525X14001174 Cofnas, N., Carl, N., & Woodley of Menie, M. A. (2017). Does activism in social science explain conservatives ’distrust of scientists? The American Sociologist ,49(1), 135 –148. doi: 10.1007/s12108-017-9362-0 Conway, L. G., Houck, S. C., Gornick, L. J., & Repke, M. A. (2018). Finding the Loch Ness Monster: Left-wing authoritarianism in theUnited States. Political Psychology ,39(5), 1049 –1067. doi: 10.1111/ pops.12470 Crocker, J., Major, B., & Steele, C. M. (1998). Social stigma. In D. T. Gilbert, S. T. Fiske, & G. Lindzey (Eds.), Handbook of social psych- ology (Vol. 2, pp. 504 –553). New York, NY: Oxford University Press. Danbold, F., & Unzueta, M. M. (2019). Drawing the diversity line: Numerical thresholds of diversity vary by group status. Journal of Personality and Social Psychology , 118(2):283 –306. doi: 10.1037/ pspi0000182 Darley, J. M., & Gross, P. H. (1983). A hypothesis-confirming bias in labeling effects. Journal of Personality and Social Psychology ,44(1), 20–33. doi: 10.1037/0022-3514.44.1.20 Dasgupta, N., & Stout, J. G. (2014). Girls and women in Science, tech- nology, engineering, and mathematics STEMing the tide and broad-ening participation in STEM careers. Policy Insights from the Behavioral and Brain Sciences ,1(1), 21 –29. doi: 10.1177/ 2372732214549471 Dee, T. S. (2004). Teachers, race, and student achievement in a randomized experiment. Review of Economics and Statistics ,86(1), 195–210. doi: 10.1162/003465304323023750 Ditto, P. H., Liu, B., Clark, C. J., Wojcik, S. P., Chen, E. E., Grady, R. H., …Zinger, J. F. (2018). At least bias is bipartisan: A meta- analytic comparison of partisan bias in liberals and conservatives.Perspectives on Psychological Science , 14(2):273 –291. doi: 10.1177/ 1745691617746796 Doyen, S., Klein, O., Pichon, C.-L., & Cleeremans, A. (2012). Behavioral priming: It ’s all in the mind, but whose mind? PLoS One , 7(1), e29081. doi: 10.1371/journal.pone.0029081 Duarte, J. L., Crawford, J. T., Stern, C., Haidt, J., Jussim, L., & Tetlock, P. E. (2015). Political diversity will improve social psychological82 COMMENTARIES science. Behavioral and Brain Sciences ,38, e130. doi: 10.1017/ S0140525X14000430 Eitan, O., Viganola, D., Inbar, Y., Dreber, A., Johannesson, M., Pfeiffer, T.,…Uhlmann, E. L. (2018). Is research in social psychology polit- ically biased? Systematic empirical tests and a forecasting survey to address the controversy. Journal of Experimental Social Psychology , 79, 188 –199. doi: 10.1016/j.jesp.2018.06.004 Ellemers, N. (2018). Gender stereotypes. Annual Review of Psychology , 69(1), 275 –298. doi: 10.1146/annurev-psych-122216-011719 Everett, J. A. C. (2015). Wait –You’re a conservative? ”Political diver- sity and the dilemma of disclosure. Behavioral and Brain Sciences , 38,e142. doi: 10.1017/S0140525X14001198 Finnigan, K. M., & Corker, K. S. (2016). Do performance avoidance goals moderate the effect of different types of stereotype threat onwomen ’s math performance? Journal of Research in Personality ,63, 36–43. doi: 10.1016/j.jrp.2016.05.009 Fiske, S. T., Gilbert, D. T., & Lindzey, G. (Eds.). (2010). Handbook of social psychology (5th ed.). Hoboken, New Jersey: John Wiley & Sons. Flake, J. K., & Fried, E. I. (2019). Measurement Schmeasurement: Questionable measurement practices and how to avoid them. doi: 10. 31234/osf.io/hs7wm Gauchat, G. (2012). Politicization of science in the public sphere: A study of public trust in the United States, 1974 to 2010. American Sociological Review ,77(2), 167 –187. doi: 10.1177/0003122412438225 Greenwald, A. G., Banaji, M. R., & Nosek, B. A. (2015). Statistically small effects of the Implicit Association Test can have societallylarge effects. Journal of Personality and Social Psychology ,108(4), 553–561. Greider, C. W., Sheltzer, J. M., Cantalupo, N. C., Copeland, W. B., Dasgupta, N., Hopkins, N., …Wong, J. Y. (2019). Increasing gen- der diversity in the STEM research workforce. Science ,366(6466), 692–695. doi: 10.1126/science.aaz0649 Haidt, J. (2011). The bright future of post-partisan social psychology. Presented at the talk given at the annual meeting of the Society forPersonality and Social Psychology, San Antonio, TX. Retrieved from http://people.virginia.edu//C3jdh6n/postpartisan.html . Haidt, J. (2017). In defense of Amy Wax ’s defense of Bourgeois values . Retrieved from Heterodox Academy website: https://heterodoxaca- demy.org/in-defense-of-amy-waxs-defense-of-bourgeois-values/ . Handelsman, J., Cantor, N., Carnes, M., Denton, D., Fine, E., Grosz, B.,…Sheridan, J. (2005). More Women in Science. Science , 309(5738), 1190 –1191. doi: 10.1126/science.1113252 Hirsh, J. B., Walberg, M. D., & Peterson, J. B. (2013). Spiritual liberals and religious conservatives. Social Psychological and Personality Science ,4(1), 14 –20. doi: 10.1177/1948550612444138 Honeycutt, N., & Freberg, L. (2017). The liberal and conservative experience across academic disciplines: An extension of Inbar and Lammers. Social Psychological and Personality Science ,8(2), 115 –123. doi:10.1177/1948550616667617 Honeycutt, N., Jussim, L., & Freberg, L. (2019). University students ’ perceptions of the classroom political climate. Working paper.https://osf.io/7uq6n/ Hyde, J. S. (2005). The gender similarities hypothesis. American Psychologist ,60(6), 581 –592. doi: 10.1037/0003-066X.60.6.581 Inbar, Y., & Lammers, J. (2012). Political diversity in social and per- sonality psychology. Perspectives on Psychological Science ,7(5), 496–503. doi: 10.1177/1745691612448792 Jost, J. T., Glaser, J., Kruglanski, A. W., & Sulloway, F. J. (2003). Political conservatism as motivated social cognition. Psychological Bulletin ,129(3), 339 –375. doi: 10.1037/0033-2909.129.3.339 Jost, J. T., Rudman, L. A., Blair, I. V., Carney, D. R., Dasgupta, N., Glaser, J., & Hardin, C. D. (2009). The existence of implicit bias isbeyond reasonable doubt: A refutation of ideological and methodo-logical objections and executive summary of ten studies that nomanager should ignore. Research in Organizational Behavior ,29, 39–69. doi: 10.1016/j.riob.2009.10.001 Jussim, L. (2012). Social perception and social reality: Why accuracy dominates bias and self-fulfilling prophecy . USA: Oxford University Press.Jussim, L. (2017). Accuracy, bias, self-fulfilling prophecies, and scien- tific self-correction. Behavioral and Brain Sciences , 40, e18. doi: 10. 1017/S0140525X16000339 Jussim, L. (2018a). The reality of the rise of an intolerant and radical left on campus . Retrieved from Areo website: https://areomagazine. com/2018/03/17/the-reality-of-the-rise-of-an-intolerant-and-radical- left-on-campus/ . Jussim, L. (2018b). “Gender stereotypes are inaccurate ”if you ignore the data. Retrieved from Psychology Today website: https://www.psy- chologytoday.com/blog/rabble-rouser/201806/gender-stereotypes-are- inaccurate-if-you-ignore-the-data .1 Jussim, L. (2019, June 23). Scientific Bias in Favor of Studies Finding Gender Bias . Retrieved from Psychology Today website: https:// www.psychologytoday.com/blog/rabble-rouser/201906/scientific-bias- in-favor-studies-finding-gender-bias . Jussim, L., Careem, A., Goldberg, Z., Honeycutt, N., & Stevens, S. (in press). IAT scores, racial gaps, and scientific gaps. In J. A. Krosnick,T. H. Stark, & A. L. Scott (Eds.), The future of research on implicit bias. Jussim, L., & Crawford, J. T. (2018). Possible solutions for a less politi- cized social psychological science. In J. T. Crawford & L. Jussim (Eds.), The politics of social psychology (pp. 126 –146). New York, NY: Psychology Press. Jussim, L., Crawford, J. T., Anglin, S., & Stevens, S. (2015). Ideological bias in social psychological research. In J. Forgas, K. Fiedler, & W. Crano (Eds.), Sydney symposium on social psychology and politics (pp. 91 –109). New York, NY: Taylor & Francis. Jussim, L., Crawford, J. T., Anglin, S. M., Stevens, S. T., & Duarte, J. L. (2016). Interpretations and methods: Towards a more effectively self-correcting social psychology. Journal of Experimental Social Psychology ,66, 116 –133. doi: 10.1016/j.jesp.2015.10.003 Jussim, L., Crawford, J. T., Stevens, S. T., & Anglin, S. (2016). The pol- itics of social psychological science: Distortions in the social psych-ology of intergroup relations. In P. Valdesolo, & J. Graham (Eds.), Claremont Symposium on Social Psychology and Politics . New York, NY: Routledge. Jussim, L., Crawford, J. T., Stevens, S., Anglin, S., & Duarte, J. L. (2016). Do high moral purposes undermine scientific integrity? In J. P. Forgas, Van Lange & L. Jussim (Eds.), The Sydney symposium on the social psychology of morality . New York: Taylor & Francis. Jussim, L., Krosnick, J. A., Stevens, S. T., & Anglin, S. M. (2019). A social psychological model of scientific practices: Explaining researchpractices and outlining the potential for successful reforms. Psychologica Belgica ,59(1), 353 –372. doi: 10.5334/pb.496 Jussim, L., Stevens, S. T., & Honeycutt, N. (2018). Unasked questions about stereotype accuracy. Archives of Scientific Psychology ,6(1), 214–229. http://dx.doi.org/10.1037/arc0000055 . Knobloch-Westerwick, S., Glynn, C. J., & Huge, M. (2013). The Matilda Effect in science communication: An experiment on genderbias in publication quality perceptions and collaboration interest. Science Communication , 35(5), 603 –625. doi: 10.1177/ 1075547012472684 Kunda, Z. (1990). The case for motivated reasoning. Psychological Bulletin ,108(3), 480 –498. doi: 10.1037/0033-2909.108.3.480 Kunda, Z., & Thagard, P. (1996). Forming impressions from stereo- types, traits, and behaviors: A parallel-constraint-satisfaction theory. Psychological Review ,103(2), 284 –308. doi: 10.1037/0033-295X.103.2. 284 Langbert, M. (2018). Homogenous: The political affiliations of Elite Liberal Arts College Faculty. Academic Questions ,31(2), 186 –197. doi:10.1007/s12129-018-9700-x Ledgerwood, A., Haines, E., & Ratliff, K. (2015). Guest post: Not nut- ting up or shutting up . Retrieved from https://sometimesimwrong. typepad.com/wrong/2015/03/guest-post-not-nutting-up-or-shutting- up.html . Lehmann, C. (2015). How a rebellious scientist uncovered the surprising truth about stereotypes . Retrieved from Quillette website: https:// quillette.com/2015/12/04/rebellious-scientist-surprising-truth-about- stereotypes/ .COMMENTARIES 83 Lilienfeld, S. O. (2015). Lack of political diversity and the framing of findings in personality and clinical psychology. Behavioral and Brain Sciences ,38, e149. doi: 10.1017/S0140525X14001253 Lilienfeld, S. O. (2017). Microaggressions: Strong claims, inadequate evidence. Perspectives on Psychological Science ,12(1), 138 –169. doi: 10.1177/1745691616659391 Locksley, A., Borgida, E., Brekke, N., & Hepburn, C. (1980). Sex stereo- types and social judgment. Journal of Personality and Social Psychology ,39(5), 821 –831. doi: 10.1037/0022-3514.39.5.821 Malka, A., Lelkes, Y., & Holzer, N. (2018). Rethinking the rigidity of the right model: Three suboptimal methodological practices andtheir implications. In J. T. Crawford & L. Jussim (Eds.), The Politics of Social Psychology (pp. 126 –146). New York, NY: Psychology Press. Marsden, G. M. (2015). Religious discrimination in academia. Society , 52(1), 19 –22. doi: 10.1007/s12115-014-9853-3 Martin, C. C. (2015). How Ideology Has Hindered Sociological Insight. The American Sociologist ,47(1), 115 –130. doi: 10.1007/s12108-015- 9263-z Martin, C. C. (2016). How ideology has hindered sociological insight. The American Sociologist ,47(1), 115 –130. doi: 10.1007/s12108-015- 9263-z Mather, R. (2018). Continued political bias in social psychology . Retrieved from Psychology Today website: https://www.psychology- today.com/blog/the-conservative-social-psychologist/201805/contin-ued-political-bias-in-social-psychology . Merton, R. K. (1973). The sociology of science: Theoretical and empirical investigations . Chicago, IL: University of Chicago Press. Milkman, K. L., Akinola, M., & Chugh, D. (2012). Temporal distance and discrimination: An audit study in Academia. Psychological Science ,23(7), 710 –717. doi: 10.1177/0956797611434539 Moss-Racusin, C. A., Dovidio, J. F., Brescoll, V. L., Graham, M. J., & Handelsman, J. (2012). Science faculty ’s subtle gender biases favor male students. Proceedings of the National Academy of Sciences , 109(41), 16474 –16479. doi: 10.1073/pnas.1211286109 Murphy, M. C., Steele, C. M., & Gross, J. J. (2007). Signaling threat how situational cues affect women in math. Psychological Science , 18(10), 879 – 885. doi: 10.1111/j.1467-9280.2007.01995.x National Academies of Sciences, Engineering, and Medicine. (2018). Sexual harassment of women: climate, culture, and consequences inacademic sciences, engineering, and medicine . Washington, DC: National Academies Press. Nature, (2015). Sexism has no place in science. Nature ,522(7556), 255–255. doi: 10.1038/522255a Nickerson, R. S. (1998). Confirmation bias: A ubiquitous phenomenon in many guises. Review of General Psychology ,2(2), 175 –220. doi: 10. 1037/1089-2680.2.2.175 Peters, U., Honeycutt, N., Block, A. D., & Jussim, L. (in press). Ideological Diversity, Hostility, and Discrimination in Philosophy.Philosophical Psychology. https://philpapers.org/rec/PETIDH-2 Pew Research Center. (2018). The religious typology . Retrieved from https://www.pewforum.org/2018/08/29/the-religious-typology/ . Prentice, D. A. (2012). Liberal norms and their discontents. Perspectives on Psychological Science ,7(5), 516 –518. doi: 10.1177/ 1745691612454142 Quillette (2019). Noah Carl: An update on the young scholar fired by a Cambridge College for thoughtcrime. Retrieved from Quillette web- site: https://quillette.com/2019/05/28/noah-carl-an-update-on-the- young-scholar-fired-by-a-cambridge-college-for-thoughtcrime/ . Quinn, D. M., & Chaudoir, S. R. (2009). Living with a concealable stig- matized identity: The impact of anticipated stigma, centrality, sali- ence, and cultural stigma on psychological distress and health. Journal of Personality and Social Psychology ,97(4), 634 –651. doi: 10. 1037/a0015815 Redding, R. E. (2001). Sociopolitical diversity in psychology: The case for pluralism. American Psychologist ,56(3), 205 –215. doi: 10.1037/ 0003-066X.56.3.205 Redding, R. E. (2012). Likes attract: The sociopolitical groupthink of (social) psychologists. Perspectives on Psychological Science ,7(5), 512–515. doi: 10.1177/1745691612455206 .Reinero, D. A. (2019). The path to professorship by the numbers and why mentorship matters . Retrieved from Behavioural and Social Sciences at Nature Research website: https://socialsciences.nature. com/users/325112-diego-a-reinero/posts/55118-the-path-to-profes-sorship-by-the-numbers-and-why-mentorship-matters . Reyna, C. (2018). Scale creation, use, and misuse: How politics under- mines measurement. In J. T. Crawford & L. Jussim (Eds.), Politics of social psychology (pp. 81 –98). New York, NY: Psychology Press. Ryan, W. (1971). Blaming the Victim . New York: Vintage Books. Sears, D. O. (1988). Symbolic racism. In P. A. Katz & D. A. Taylor (Eds.), Eliminating racism: Profiles in controversy (pp. 53 –84). Boston, MA: Springer. doi: 10.1007/978-1-4899-0818-6_4 Sharp, G. (2010). Sex, college degrees, and campus equity —sociological images . Retrieved from The Society Pages: Sociological Images web- site: https://thesocietypages.org/socimages/2010/05/22/sex-college- degrees-and-campus-equity/ . Solzhenitsyn, A. (1973). The Gulag Archipelago, 1918 –1956 . New York, NY: Harper & Row. Spencer, S. J., Steele, C. M., & Quinn, D. M. (1999). Stereotype threat and women ’s math performance. Journal of Experimental Social Psychology ,35(1), 4 –28. doi: 10.1006/jesp.1998.1373 SPSP Diversity and Climate Committee. (2019). SPSP diversity and cli- mate survey . Retrieved from http://spsp.org/sites/default/files/SPSP_ Diversity_and_Climate_Survey_Final_Report_January_2019.pdf . SPSP. (2019). Society for personality and social psychology: Leadership. Retrieved from https://my.spsp.org/members/leadership . Stanovich, K. E., & Toplak, M. E. (2019). The need for intellectual diversity in psychological science: Our own studies of actively open-minded thinking as a case study. Cognition ,187, 156 –166. doi: 10. 1016/j.cognition.2019.03.006 Steele, C. M., & Aronson, J. (1995). Stereotype threat and the intellec- tual test performance of African Americans. Journal of Personality and Social Psychology ,69(5), 797 –811. doi: 10.1037/0022-3514.69.5. 797 Steele, J., James, J. B., & Barnett, R. C. (2016). Learning in a man ’s world: Examining the perceptions of undergraduate women in male-dominated academic areas. Psychology of Women Quarterly ,https:// journals.sagepub.com/doi/10.1111/1471-6402.00042 . Steinpreis, R. E., Anders, K. A., & Ritzke, D. (1999). The impact of gender on the review of the curricula vitae of job applicants andtenure candidates: A national empirical study. Sex Roles ,41(7/8), 509–528. doi: 10.1023/A:1018839203698 Stolzenberg, E., Eagan, M., Zimmerman, H., Berdan Lozano, J., Cesar- Davis, N., Aragon, M., & Rios-Aguilar, C. (2019). Undergraduate teaching faculty: The HERI Faculty Survey 2016 –2017 . Los Angeles : Higher Education Research Institute, UCLA. Tetlock, P. E. (1994). Political psychology or politicized psychology: Is the road to scientific hell paved with good moral intentions? Political Psychology ,15 (3), 509 –529. doi: 10.2307/3791569 Tetlock, P. E., & Mitchell, G. (2015). Why so few conservatives and should we care? Society ,52(1), 28 –34. doi: 10.1007/s12115-014-9850- 6 Tetlock, P., & Mitchell, G. (1993). Liberal and conservative approaches to justice: Conflicting psychological portraits. In B. A. Mellers & J.Baron (Eds.), Psychological perspectives on justice: Theory and appli- cations (pp. 234 –255). New York, NY: Cambridge University Press. Tomkins, A., Zhang, M., & Heavlin, W. D. (2017). Reviewer bias in single-versus double-blind peer review. Proceedings of the National Academy of Sciences ,114(48), 12708 –12713. doi: 10.1073/pnas. 1707323114 U.S. Census Bureau. (2018). U.S. Census Bureau QuickFacts: United States . Retrieved from https://www.census.gov/quickfacts/fact/table/ US/PST045218 . United States National Academy of Sciences. (2007). Beyond bias and barriers: Fulfilling the potential of women in academic science andengineering . Washington, DC: National Academies Press. Van Hiel, A., Onraet, E., & De Pauw, S. (2010). The relationship between social-cultural attitudes and behavioral measures of cogni-tive style: A meta-analytic integration of studies. Journal of Personality ,78(6), 1765 –1800. doi: 10.1111/j.1467-6494.2010.00669.x84 COMMENTARIES Von Hippel, W., & Buss, D. M. (2017). Do ideologically driven scien- tific agendas impede the understanding and acceptance of evolution-ary principles in social psychology? In J. T. Crawford & L. Jussim(Eds.), The politics of social psychology (pp. 17 –35). New York: Psychology Press. Wax, A., & Alexander, L. (2017). Paying the price for breakdown of the country ’s bourgeois culture . Retrieved from The Philadelphia Inquirer website: https://www.inquirer.com/philly/opinion/commen- tary/paying-the-price-for-breakdown-of-the-countrys-bourgeois-cul-ture-20170809.html . Weinstein, B. S. (2018). Oppression disguised as equity . Retrieved from https://republicans-oversight.house.gov/wp-content/uploads/2018/05/ TestimonyOfBretWeinstein5-22-18.pdf . Wenneras, C., & Wold, A. (1997). Nepotism and sexism in peer-review. Nature ,387(6631), 341 –343. doi: 10.1038/387341a0 Williams, W. M., & Ceci, S. J. (2015). National hiring experiments reveal 2: 1 faculty preference for women on STEM tenure track.Proceedings of the National Academy of Sciences ,112(17), 5360–5365. doi: 10.1073/pnas.1418878112 Wills, J. B., Brewster, Z. W., & Nowak, G. R. (2019). Students ’religios- ity and perceptions of professor bias: Some empirical lessons for sociologists. The American Sociologist ,50(1), 136 –153. doi: 10.1007/ s12108-018-9388-y . Woessner, M., & Kelly-Woessner, A. (2009). Left pipeline: Why conser- vatives don ’t get doctorates. In R. Maranto, R. E. Redding, & F. Hess (Eds.), The politically correct university: Problems, scope, and reforms (pp. 38 –59). Washington, DC: AEI Press. WTF is the IDW? (2018). Retrieved from https://fourbeers.fireside.fm/3 . Yancey, G., Reimer, S., & O ’Connell, J. (2015). How academics view conservative protestants. Sociology of Religion ,76(3), 315 –336. doi: 10.1093/socrel/srv027 . Zigerell, L. J. (2018). Black and White discrimination in the United States: Evidence from an archive of survey experiment studies. Research and Politics ,5(1), 2053168017753862. doi: 10.1177/ 2053168017753862 .COMMENTARIES 85