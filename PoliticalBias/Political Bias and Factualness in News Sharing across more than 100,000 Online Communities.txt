 Political Bias and Factualness in News Sharing across more than 100,000 Online Communities Galen Weld,1Maria Glenski,2Tim Althoff1 1Paul G. Allen School of Computer Science and Engineering, University of Washington 2National Security Directorate, Paciﬁc Northwest National Laboratory {gweld, althoff}@cs.washington.edu, maria.glenski@pnnl.gov Abstract As civil discourse increasingly takes place online, misinfor- mation and the polarization of news shared in online com-munities have become ever more relevant concerns with realworld harms across our society. Studying online news shar-ing at scale is challenging due to the massive volume of con-tent which is shared by millions of users across thousandsof communities. Therefore, existing research has largely fo-cused on speciﬁc communities or speciﬁc interventions, suchas bans. However, understanding the prevalence and spread ofmisinformation and polarization more broadly, across thou-sands of online communities, is critical for the developmentof governance strategies, interventions, and community de-sign. Here, we conduct the largest study of news sharing onreddit to date, analyzing more than 550 million links spanning4 years. We use non-partisan news source ratings from MediaBias/Fact Check to annotate links to news sources with theirpolitical bias and factualness. We ﬁnd that, compared to left-leaning communities, right-leaning communities have 105%more variance in the political bias of their news sources, andmore links to relatively-more biased sources, on average. Weobserve that reddit users’ voting and re-sharing behaviorsgenerally decrease the visibility of extremely biased and lowfactual content, which receives 20% fewer upvotes and 30%fewer exposures from crossposts than more neutral or morefactual content. This suggests that reddit is more resilient tolow factual content than Twitter. We show that extremely bi-ased and low factual content is very concentrated, with 99%of such content being shared in only 0.5% of communities,giving credence to the recent strategy of community-widebans and quarantines. 1 Introduction Biased and inaccurate news shared online are major con- cerns that have risen to the forefront of public discourse re-garding social media in recent years. Two thirds of Amer-icans get at least some of their news content from socialmedia, but less than half expect this content to be accu-rate (Shearer and Matsa 2018). Globally, only 22% of sur-vey respondents trust the news in social media “most of thetime” (Newman 2020). Internet platforms such as Twitter,Facebook, and reddit account for an ever-increasing share ofthe dissemination and discussion of news (Geiger 2019). Copyright © 2021, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved.Harms caused by biased and false news have substantial impact across our society. Polarized content on Twitter and Facebook has been shown to play a role in the outcome ofelections (Recuero, Soares, and Gruzd 2020; Kharratzadehand¨Ustebay 2017); and misinformation related to COVID- 19 has been found to have a negative impact on public healthresponses to the pandemic (Tasnim, Hossain, and Mazumder2020; Kouzy et al. 2020). Developing methods for reduc-ing these harms requires a broad understanding of the polit-ical bias and factualness of news content shared online, butstudying news sharing is challenging for three reasons: (1)the scale is immense, with billions of news links shared an-nually, (2) it is difﬁcult to automatically quantify bias andfactualness at scales where human labeling is often infeasi-ble (Rajadesingan, Resnick, and Budak 2020), and (3) thedistribution of links is complex, with these links shared bymany millions of users and thousands of communities. While previous research has led to important insights on speciﬁc aspects of news sharing, such as user engagement(Risch and Krestel 2020), fact checking (Vosoughi, Roy,and Aral 2018; Choi et al. 2020), speciﬁc communities (Ra-jadesingan, Resnick, and Budak 2020), and speciﬁc rumors(Vosoughi, Mohsenvand, and Roy 2017; Qazvinian et al.2011), large scale studies of news sharing are critical to un-derstanding polarization and misinformation more broadly,and can inform community design, governance, and moder-ation interventions. In this work, we present the largest study to date of news sharing behavior on reddit, one of the most popular socialmedia websites. We analyze all 559 million links submit-ted to reddit from 2015-2019 1, including 35 million news links submitted by 1.3 million users to 135 thousand com-munities. We rate the bias and factualness of linked-to newssources using Media Bias/Fact Check (MBFC), 2which con- siders how news sources favor different sides of the left-rightpolitical spectrum (bias), and the veracity of claims made inspeciﬁc news stories (factualness) (§3). In our analyses, we examine: the diversity of news within 1August 2019 was the most recent month of data available at the time of this study. 2While bias and factualness may vary from story to story, news source-level ratings maximize the number of links that can be rated, and are commonly used in research (Bozarth, Saraf, and Budak2020). ProceedingsoftheFifteenth InternationalAAAIConferenceonWebandSocial Media(ICWSM2021) 796 communities (§4), and how this diversity is composed of both the differences between community members and in- dividual members’ diversity of submissions; the impact of current curation and ampliﬁcation behaviors on news’ vis- ibility and spread (§5); and the concentration of extremely biased and low factual content (§6), examining the distribu- tion of links from the perspectives of who submitted themand what community they were submitted to. We show that communities on reddit exist across the left-right political spectrum, as measured by MBFC, but74% are ideologically center left. We ﬁnd that the diver-sity of left-leaning communities’ membership is similar tothat of equivalently right-leaning communities, but right-leaning communities have 105% more politically variednews sources, as their members individually post more var-ied links. This variance comes from the presence of linksthat are different from the community average, and in right-leaning communities, 74% of such links are to relatively-more biased news sources, 35% more than in left-leaningcommunities (§4). We demonstrate that, regardless of the political leaning of the community, community members’ voting and crosspost-ing (re-sharing) behavior reduces the impact of extremelybiased and low factual news sources. Links to these newssources receive 20% fewer upvotes (§5.2) and 30% fewerexposures from crossposts compared to more neutral andhigher factual content (§5.3). Furthermore, we ﬁnd that userswho submit such content leave reddit 68% more quicklythan others (§5.1). These ﬁndings suggest that low factualcontent spreads more slowly and is ampliﬁed less on redditthan has been reported for Twitter (Vosoughi, Roy, and Aral2018; Bovet and Makse 2019), although we do not directlycompare behavior across the two platforms. Differences be-tween reddit and Twitter may stem from reddit’s explicit di-vision into communities, or users’ ability to downvote con-tent, both of which help control content exposure. Extremely biased and low factual content can be challeng- ing to manage, as it is spread through many users, newssources, and communities. We ﬁnd that extremely biasedand low factual content is spread by an even broader set ofusers and communities relative to news content as a whole,exacerbating this challenge (§6). However, we ﬁnd that 99%of extremely biased or low factual content is still concen-trated in 0.5% of communities, lending credence to recentinterventions at the community level (Chandrasekharan et al.2017, 2020; Saleem and Ruths 2018; Ribeiro et al. 2020). Our work demonstrates that additional research on news sharing online is especially needed on the topics of whyusers depart platforms and where they go, why false newsappears to spread more quickly on Twitter than on reddit,and how curation and ampliﬁcation practices can manageinﬂuxes of extremely biased and low factual content. Finally, we make all of our data and analyses publicly available 3to encourage future work on this important topic. 3https://behavioral-data.github.io/news labeling reddit/2 Related Work Misinformation and Deceptive News. Social news plat- forms have seen a continued increase in use and a simultane-ous increase in concern regarding biased news and misinfor-mation (Mitchell et al. 2019; Marwick and Lewis 2017). Re-cent studies have used network spread (Vosoughi, Roy, andAral 2018; Ferrara 2017; Bovet and Makse 2019), contentconsumer (Allen et al. 2020), and content producer (Linvilland Warren 2020) approaches to assess the spread of mis-information. In this work, we examine news sharing behav-ior from news sources who publish content with varied de-grees of bias or factualness, building on related work that hasanalyzed social news based on the characteristics of a newsource’s audience (Samory, Abnousi, and Mitra 2020a) orthe type of content posted (Glenski, Weninger, and Volkova2018). Polarization and Political Bias. Many papers have recently been published on detecting political bias of online content either automatically (Baly et al. 2020; Demszky et al. 2019)or manually (Ganguly et al. 2020; Bozarth, Saraf, and Budak2020). Others have examined bias in moderation of content,as opposed to biased content or news sources themselves(Jiang, Robertson, and Wilson 2019, 2020). Echo cham-bers are a major consideration in understanding polariza-tion, with papers focusing on their development (Allison andBussey 2020) and the role of news sources in echo chambers(Horne, Nørregaard, and Adali 2019). Others have examinedwho shares what content with what political bias, but didso using implicit community structure (Samory, Abnousi,and Mitra 2020b). In this work, we examine thousands ofexplicit communities on reddit, characterizing their polar-ization by examining the political diversity of news sourcesshared within, and the diversity of the community memberswho contribute. Moderation and Governance. A large body of work has examined the role of moderation interventions such explana- tions (Jhaver, Bruckman, and Gilbert 2019), content removal(Chandrasekharan et al. 2018), community bans (Chan-drasekharan et al. 2017, 2020; Saleem and Ruths 2018) onoutcomes such as migration (Ribeiro et al. 2020), harass-ment (Matias 2019a) and harmful language use (Waddenet al. 2021). Others have focused on moderators themselves(Matias 2019b; Dosono and Semaan 2019), and technolog-ical tools to assist them (Jhaver et al. 2019; Zhang, Hugh,and Bernstein 2020; Chandrasekharan et al. 2019), as wellas self-moderation through voting (Glenski, Pennycuff, andWeninger 2017; Risch and Krestel 2020) and communitynorms (Fiesler et al. 2018). In contrast, our work informs theviability of different moderation strategies, speciﬁcally byexamining the sharing and visibility of news content acrossthousands of communities. 3 Dataset & Validation We analyze all reddit submissions to extract links, and anno-tate links to news sources with their political bias and factu-alness using ratings from Media Bias/Fact Check. 797 Figure 1: The percentage of links that can be annotated us- ing the MBFC labels is very consistent (± 3.3%) over time, suggesting that comparisons over time are not signiﬁcantlyimpacted by changes in annotation coverage. 3.1 Reddit Content reddit is the sixth most visited website in the world, and iswidely studied due to its size, diversity of communities, andthe public availability of its content (Medvedev, Lambiotte,and Delvenne 2018). Users can submit links or text (knownas “selfposts”) to speciﬁc communities, known as “subred-dits.” Users may view submissions for a single community,or create a “front page” which aggregates submissions fromall communities the user “subscribes” to. Here, we focus onsubmissions over comments, as submissions are the primarymechanism for sharing content on reddit, and users spendmost of their time engaging with submissions (Glenski, Pen-nycuff, and Weninger 2017). To create our dataset, we downloaded all public red- dit submissions from Pushshift (Baumgartner et al. 2020)posted between January 2015 and August 2019 4, inclusive, for a total of 56 months of content (580 million submissions,35 million unique authors, 3.4 million unique subreddits).For each submission, we extract the URLs of each linked-to website, which resulted in 559 million links 5. Additional summary statistics are included in the Appendix. Ethical Considerations. We value and respect the privacy and agency of all people potentially impacted by this work. All reddit content analyzed in this study is publicly accessi-ble, and Pushshift, from which we source our reddit content,permits any user to request removal of their submissions atany time. We take speciﬁc steps to protect the privacy ofpeople included in our study (Fiesler and Proferes 2018):we do not identify speciﬁc users, and we exclusively ana-lyze data and report our results in aggregate. All analysis ofdata in this study was conducted in accordance with the In-stitutional Review Board at the University of Washingtonunder identiﬁcation number STUDY00011457. 3.2 Annotation of Links’ News Sources To identify and annotate links to news sources, we make useof Media Bias/Fact Check (hereafter MBFC), an indepen-dently run news source rating service. Bozarth, Saraf, andBudak (2020) ﬁnd that “the choice of traditional news lists[for fact checking] seems to not matter,” when comparing 5 4August 2019 was the most recent month available at the time of this study. 5While link submissions by deﬁnition contain exactly one link, text submissions (selfposts) can include 0 or more links.different news lists including MBFC. Therefore, we selectedMBFC as it offers the largest set of labels of any news sourcerating service (Bozarth, Saraf, and Budak 2020). MBFC pro-vides ratings of the political bias (left to right) and factual-ness (low to high) of news outlets around the world, alongwith additional details and justiﬁcations for ratings, using arigorous public methodology 6. MBFC is widely used for la- belling bias and factualness of news sources for downstreamanalysis (Heydari et al. 2019; Main 2018; Starbird 2017;Darwish, Magdy, and Zanouda 2017; Nelimarkka, Laakso-nen, and Semaan 2018) and as ground truth for predictiontasks (Dinkov et al. 2019; Stefanov et al. 2020). From MBFC’s public reports on each news source, we extract the name of the news source, its website, and the po-litical bias and factualness ratings. Bias is measured on a7-point scale of ‘extreme left,’ ‘left,’ ‘center left,’ ‘center,’‘center right,’ ‘right,’ and ‘extreme right,’ and is reported for2,440 news sources. Factualness is measured on a 6-pointscale of ‘very low factual,’ ‘low factual,’ ‘mixed factual,’‘mostly factual,’ ‘high factual,’ and ‘very high factual,’ andis reported for 2,676 news sources (as of April 2020). Forbrevity, in the following analyses, we occasionally use theterm ‘left leaning’ to indicate a news source with a biasrating of ‘extreme left,’ ‘left,’ or ‘center left,’ and the term‘right leaning’ to indicate a news source with a bias ratingof ‘center right,’ ‘right,’ or ‘extreme right.’ We then annotate the links extracted from reddit sub- missions with the MBFC ratings using regular expres-sions to match the URL of the link with the domain ofthe corresponding news source. For example, a link towww.rt.com/news/covid/ would be matched with the rt.comdomain of RT, the Russian-funded television network, andannotated with a bias of ‘center right’ and a factualness of‘very low.’ Links to URL shorteners such as bit.ly were ex-cluded from labeling. We ﬁnd that links to center left andhigh factual news sources are most common, accounting for53% and 64% of all news links, respectively. Extreme leftnews source links are much less common, with 22.2 extremeright links for every 1 extreme left link (Fig. 2). Validation of MBFC Annotations. The use of fact check- ing sources such as MBFC is common practice for large scale studies, and MBFC in particular is widelyused (Dinkov et al. 2019; Stefanov et al. 2020; Heydariet al. 2019; Main 2018; Starbird 2017; Darwish, Magdy,and Zanouda 2017; Nelimarkka, Laaksonen, and Semaan2018). Additional conﬁdence in MFBC annotations comesfrom the results of Bozarth, Saraf, and Budak (2020), whoﬁnd that (1) MBFC offers the largest set of biased and lowfactual news sources when compared among 5 fact check-ing datasets, and (2) the selection of a speciﬁc fact checkingsource has little impact on the evaluation of online content.Furthermore, we ﬁnd that the coverage (the percentage oflinks that can be annotated using MBFC, excluding links toobvious non-news sources such as links to elsewhere on red-dit, to shopping sites, etc.) is very consistent ( ±3.3%) over the 4 year span of our dataset (Fig. 1). Additionally, Bozarth,Saraf, and Budak (2020) ﬁnd that it is very rare for a news 6https://mediabiasfactcheck.com/methodology/ 798 Figure 2: Distributions of mean bias and factualness are quite similar for both the user and community units of anal-ysis. Grey bars show the normalized total counts of links ofeach type across all of reddit. source’s bias or factualness to change over time, suggesting that the potential ‘drift’ of ratings over time should not affectour results. Robustness Checks with Different Set of Annotations. Lastly, we use an additional fact checking dataset fromVolkova et al. (2017), consisting of 251 ‘veriﬁed’ newssources and 210 ‘suspicious’ news sources, as an additionalpoint of comparison for validation. While the exact classesin the Volkova et al. dataset are not directly comparable to MBFC, we can create a comparable class by comparinglinks with a MBFC factualness rating of ‘mostly factual’or higher with Volkova et al.’s ‘veriﬁed’ news sources. In this case, when considering links that can be annotated us-ing both datasets, MBFC and Volkova et al. have a Cohen’s kappa coefﬁcient of 0.82, indicating “almost perfect” inter-rater reliability (Landis and Koch 1977). We examined ifthese differences could have an impact of downstream anal-ysis and found this to be unlikely. For example, results com-puted separately using MBFC and Volkova et al. agree with one another with a Pearson’s correlation of 0.98 on the taskof identifying the number of ‘mostly factual’ or higher linksposted to a community. Computing Mean Bias/Factualness. As described above, MBFC labels for bias and factualness are ordinal, yet for many analyses, it is useful to have numeric labels (e.g. com- puting the variance of links in a community). To convertfrom MBFC’s categorical labels to a numeric scale, we usea mapping of (-3, -2, -1, 0, 1, 2, 3) to assign ‘extreme left’links a numeric bias value of -3, ‘left’ links a value of -2,‘center left’ links a value of -1, ‘center’ links a value of 0,and positive values to map to the equivalent categories onthe right. While this choice is somewhat arbitrary, it is con-sistent with the linear spacing between bias levels given byMBFC. Furthermore, we explored different mappings, in-cluding nonlinear ones, and found that our results are robustto different mappings. As such, we use the mapping givenabove as it is easiest to interpret. We use a similar mappingof (0, 1, 2, 3, 4, 5) to assign ‘very low factual’ links a nu-meric value of 0, ‘low factual’ links a value of 1, etc., with ‘very high factualness’ links assigned a value of 5. These numeric values are used to compute users’ and communities’ mean bias andmean factualness, central con- structs in our analyses. To do so, we simply take the averageof the numeric bias and factualness values of the links byeach user or in each community. For many of our analyses,we group users by rounding their mean bias/factualness tothe nearest integer. Thus, when we describe a user as havinga ‘left center bias,’ we are indicating that the mean bias ofthe links they submitted is between -1.5 and -0.5. The distributions of means are very similar for users and communities, with both closely following the overall distri-bution of news links on reddit, shown with grey bars (Fig. 2).74% of communities and 73% of users have a mean bias ofapproximately center left, and 65% of communities and 62%of users have a mean factualness of ‘high factual’ (amongusers/communities with more than 10 links). Similarly, we deﬁne user variance of bias as the variance of the bias values of the links submitted by a user, and sim-ilarly community variance of bias is deﬁned as the variance of of the bias values of links submitted to a community. Aswith mean bias, we ﬁnd that the distributions of user andcommunity variance of bias are very similar to one another.The median user has a variance of 0.85, approximately thevariance of a user with center bias who submits 62% centerlinks, 22% center-left or center-right links, and 16% left orright links. The median community has a variance of 0.91,approximately that of a community where 62% of the con-tent submitted has center bias, 20% of the content has center-left or center-right bias, and 18% of the content has left orright bias. Of course, a substantial amount of a community’svariance comes from the variance of its userbase. We exploresources of this variance in §4. 3.3 Estimating Potential Exposures to Content Links on reddit do not have equal impact; some links areviewed by far more people than others. To understand theimpact of certain types of content, we would like to under-stand how broadly that content is viewed. As view countsare not publicly available, we use the number of subscribersto the community that a link was posted to as an estimatefor the number of potential exposures to community mem- bers that this content may have had. While some users, es-pecially those without accounts, view content from commu-nities they are not subscribed to, subscription counts cap-ture both active contributors and passive consumers withinthe community, which motivated our use of this proxy overother alternatives, such as the number of votes. As communities are constantly growing, we deﬁne the number of potential exposures to a link as the number ofsubscribers to the community the link was posted to at the time it was posted. To estimate historic subscriber counts, wemake use of archived Wayback machine snapshots of sub-reddit about pages, which provide the number of subscribersat the time of the snapshot. These snapshots are availablefor the ⇠3,500 largest subreddits. In addition, we collected the current (as of Dec. 29, 2020) subscriber count for the 799 25,000 largest subreddits, as well as the date the subreddit was created (at which point it had 0 subscribers). We usethe present subscriber count, archived subscriber counts (ifavailable), and the creation date, and linearly interpolate be-tween these data points to create a historical estimate of thesubscriber counts over time for each of the 25,000 largest (bynumber of posts) subreddits in our dataset. The resulting setof subscriber count data, when joined with our set of redditcontent, provides potential exposure estimates for 93.8% ofsubmissions. For the remaining 6.2% of submissions, we in-tentionally, conservatively overestimate the potential expo- sures by using the ﬁrst percentile value (4 subscribers) fromour subscriber count data. The effect of this imputation onour results is very minor as these only occur in communitieswith extremely little activity. 4 Diversity of News within Communities In this section, we examine the factors that contribute toa community’s variance of bias. This variance can comefrom a combination of two sources: (1) community mem-bers who are individually ideologically diverse (user diver-sity), and (2) a diverse group of users with different meanbiases (group diversity). High user diversity corresponds toa community whose members have high user variance (e.g.users who are ideologically diverse individually), and highgroup diversity corresponds to a community with high vari-ance of its members’ mean bias (e.g. a diverse group of users who may be ideologically consistent individually). Ofcourse, these sources of variance are not mutually exclusive;overall community variance is maximized when both user diversity andgroup diversity are large. Method. This intuition can be formalized using the Law of Total Variance, which states that total community varianceis exactly the sum of User Diversity (within-user variance)and Group Diversity (between-user variance): Var(B c) = E[Var( Bc|U)] + Var(E[B c|U]) where Bcis a random variable representing the bias of a link submitted to community c, and Uis a random variable rep- resenting the user who submitted the link. We compute user diversity and group diversity for each community. User diversity is given by taking the mean ofeach user’s variance of bias, weighted by the number of la-beled bias links that user submitted. Group diversity is givenby taking the variance of each community members’ meanuser bias, again weighted by their number of labeled links.We then sum the user and group diversity values to computethe overall community variance of political bias. To understand how communities vary relative to their mean, we compute the balance of links in the adjacent rel-atively more- and less- biased categories. For example, acommunity with ‘left’ mean bias has two adjacent cate-gories: ‘extreme left’ and ‘center left,’ with ‘extreme left’being the relatively-more biased category, and ‘center left’being the relatively-less biased category. Results. Across all of reddit, we ﬁnd most (82%) commu- nities’ group diversity constitutes a majority of their over- all variance of bias. When binned by their mean bias, we Figure 3: While group diversity is similar between left- and right-leaning communities with a similar degree ofbias (right panel), right-leaning communities have higheruser diversity than equivalently biased communities on theleft (left panel). As a result, right-leaning communitieshave higher overall variance around their community mean.Right-leaning communities also favor relatively-more bi-ased links, when compared to left-leaning communities. ﬁnd that communities with extreme bias have, on average, lower total variance than communities closer to the middleof the spectrum (Fig. 3). A community with mean bias of‘extreme left’ would be expected to have a lower total vari-ance as there are no links with bias further left than ‘extremeleft.’ To control for this dynamic, we only compare symmet-ric labels: ‘extreme left’ to ‘extreme right,’ ‘left’ to ‘right,’and ‘center left’ to ‘center right.’ We ﬁnd that right- and left-leaning communities have similar group diversity (Fig. 3, right), but right-leaning com-munities (red) have 341% more user diversity than equiv-alently left-leaning communities, on average (Fig. 3, left).As a result, the average overall variance is 105% greaterfor right-leaning communities than left-leaning communi-ties. Interestingly, we ﬁnd that a larger share of right-leaningcommunities’ variance is in more biased categories, relativeto the community mean. 74% of right-leaning communities’adjacent links are relatively-more biased, compared to 55%for left-leaning communities, in other words, an increase of 35%⇣ 74% 55%⌘ . Implications. These results suggest that members of com- munities on the left and right have comparable group di- versity, indicating the range of users are equally similarto one another. However, right-leaning communities havehigher user diversity, indicating that the individual usersthemselves tend to submit links to news sources with alarger variety of political leaning. This creates higher over-all variance of political bias in right-leaning communities,however these right-leaning communities also contain morelinks with higher bias, relative to the community mean, asopposed to more relatively-neutral news sources. 800 Figure 4: Users with extreme mean bias stay on reddit less than half as long as users with center mean bias. Users withlow and very low mean factualness also leave more quickly,but expected lifespan decreases as users’ mean factualnessincreases past ‘mixed factual’. Across all ﬁgures, error barscorrespond to bootstrapped 95% conﬁdence intervals (andmay be too small to be visible). 5 Impact of Current Curation and Ampliﬁcation Behaviors The impact of content on reddit is affected by users’ behav-ior: how long they stay on the platform, how they vote, andhow they amplify. In this section, we examine user longevityand turnover, community acceptance of biased and low fac-tual content, and ampliﬁcation through crossposting. 5.1 User Lifespan Do users who post extremely biased or low factual contentstay on reddit as long as other users? Method. We compute each user’s lifespan on the platform by measuring how long they stay active on the platform after their ﬁrst submission. We deﬁne “active” as posting at leastonce every 30 days, as in Waller and Anderson (2019). Wegroup users by their mean bias and factualness, and for eachgroup, compute the expected lifespan of the group members. Results. We ﬁnd that expected lifespan is longer for users who typically submit less politically biased content, with users whose mean bias is near center remaining on reddit forapproximately twice as long as users with extreme or mod-erate mean bias, on average (Fig. 4, top). This result holdsregardless of whether users are left- or right-leaning. Userswith a mean factualness close to ‘mixed factual’ or lowerleave reddit 68% faster than users whose mean factualnessis near ‘mostly factual’ (Fig. 4, bottom). However, we alsoﬁnd that users’ expected lifespan decreases dramatically astheir mean factualness increases to ‘high’ or ‘very high’ lev-els of factualness. Implications. These results suggest that users who mostly post links to extremely biased or low factual news sources leave reddit more quickly than other users. We can onlyspeculate as to the causes of this faster turnover, but we notethat users who stay on reddit the longest tend to post links tothe types of news sources that are most prevalent (grey barsin Fig. 2 show overall prevalence of each type of link). The faster turnover suggests that users sharing this type of content leave relatively early, limiting their impact on theircommunities. However, faster turnover also may make user-level interventions such as bans less effective, as these sanc-tions have shorter-lived impact when the users they are madeagainst leave the site more quickly. Future research couldexamine why users leave, whether they rejoin with new ac-counts in violation of reddit policy, and the efﬁcacy of re-strictions of new accounts. 5.2 Acceptance of Biased or Low Factual Content How do communities respond to politically biased or lowfactual content? Method. On reddit, community members curate content in their communities by voting submissions up or down, which affects its position on the community feed (Glenski, Penny-cuff, and Weninger 2017). A submission’s ‘score’ is deﬁnedby reddit as approximately the number of upvotes minus thenumber of downvotes that post receives. The score has beenused in previous work as a proxy for a link’s reception bya community (Waller and Anderson 2019; Datta and Adar2019). Links submitted to larger communities are seen bymore users and therefore receive more votes. Therefore, wenormalize each link’s score by dividing by the mean scoreof all submissions in that community; links with a normal-ized score over 1are more accepted than average, and links with a score under 1are less accepted than average. In ac- cordance with reddit’s ranking algorithm, submissions withhigher normalized score appear higher in the feed viewedby community members, and stay in this position for longer(Medvedev, Lambiotte, and Delvenne 2018). To compute the community acceptance of links of a given bias or factualness, we average the normalized score of alllinks of that type in that community. We then take the me-dian community acceptance across all left-leaning, right-leaning, and neutral communities. Here we use the medianas it is more resilient to outliers than the mean. Results. We ﬁnd that, regardless of the community’s po- litical leaning, median expected community acceptance is 18% lower for extremely biased content than other con-tent (Fig. 5). For left-leaning and neutral communities, com-munity acceptance decreases monotonically as factualnessdrops below ‘high.’ However, we observe that right leaningcommunities are 167% (p =0.0002) more accepting of ex- treme right biased and 85% (p =0.004) more accepting of very low factual content than left-leaning and neutral com-munities (Mann–Whitney Usigniﬁcance tests). Implications. This suggests that across reddit, communities are sensitive to extremely biased and low factual content,and users’ voting behavior is fairly effective at reducing theacceptance of this content. However, curation does not seemto result in better-than-average acceptance for any content—no median acceptance values are signiﬁcantly (p< 0.05) 801 Figure 5: Regardless of the political leaning of the community, extremely biased content is less accepted by communities than content closer to center. Similarly, low and very low factual content is less accepted than higher factual content. Points perturbedon the x-axis to aid readability. above 1, as non-news content tends to receive higher com- munity acceptance than news content. Previous research has found that on Twitter, news that failed fact-checking spread more quickly and was seen morewidely than news that passed a fact-check (Vosoughi, Roy,and Aral 2018). Interestingly, we ﬁnd evidence that behav-ior on reddit is somewhat different, with median left-leaning,right-leaning, and neutral communities all being less accept-ing of low and very low factual content. Importantly, ourmethodology differs from Vosoughi, Roy, and Aral (2018)in that we use bias and factualness evaluations that were ap-plied to entire news sources, as opposed to the fact check-ing of speciﬁc news articles, limiting direct comparisons.Furthermore, we do not analyze the time between an initialpost and its subsequent ampliﬁcation, and so cannot directlycomment on the ‘speed’ of ampliﬁcation. We do ﬁnd evi-dence, however, that highly biased content on reddit is lessupvoted than more neutral content. These difference may in part be explained by differences between reddit’s and Twitter’s mechanisms for impactingthe visibility of content. Whereas Twitter users are only ableto increase visibility by retweeting, liking, replying to, orquoting content, on reddit, users may downvote to decreasevisibility of content they object to. We speculate that thismay partially explain the differences in acceptance that weﬁnd between reddit and Twitter. 5.3 Selective Ampliﬁcation of News Content How does ampliﬁcation of content affect exposure to biasedand low factual content? On reddit, users are not only ableto submit links to external content (such as news sites), but users are also able to submit links to internal content else- where on reddit, effectively re-sharing and therefore ampli- fying content by increasing its visibility on the site. This is commonly known as ‘crossposting,’ and often occurs whena user submits a post from one subreddit to another subred-dit, although such re-sharing of internal content can happenwithin a single community as well. Here, we seek to under-stand the role that ampliﬁcation through crossposts has onreddit user’s exposure to various kinds of content.Method. To identify the political bias and factualness of crossposted content, we identify all crossposted links tonews sources, and propagate the label of the crosspostedlink. Then, we compute the fraction of total potential ex-posures from crossposts for each bias/factualness category. Results. We ﬁnd that ampliﬁcation via crossposting has an overall small effect on the potential exposures of news con- tent. While 10% of all news links are crossposts, only 1% ofpotential exposures to news links are due to crossposts. Thissuggests that the majority of crossposts are content posted inrelatively larger communities re-shared to relatively smallercommunities with relatively fewer subscribers, diminishingthe impact of ampliﬁcation via crossposting. As such, direct links to news sites have a far greater bearing on reddit users’exposure to news content than crossposts. However, the role of crossposts in exposing users to new content is still important, as crossposts account for morethan 750 billion potential exposures. We ﬁnd that extremelybiased and low factual content is ampliﬁed less than othercontent, as shown in Fig. 6, which illustrates the percent-age of total potential exposures that come from crosspostsfor each bias/factualness category. reddit users exposed tocenter left biased, center biased, or center right biased con-tent are 53% more likely to be exposed to this content viaampliﬁcation than reddit users exposed to extremely biasedcontent. Similarly, reddit users exposed to ‘mostly factual’or higher factualness content are 217% more likely to beexposed to such content via ampliﬁcation than reddit usersexposed to very low factual content. Implications. Given that only 1% of potential exposures are from ampliﬁcations, understanding the way that direct links to external content are shared is critical to understanding the sharing of news content on reddit more broadly. The relative lower ampliﬁcation of extremely biased and very low factual content suggests users’ sensitivity to thebias and factualness of the content they are re-sharing. Asin §5.2, this suggests differences between reddit and Twit-ter, where content that failed a fact-check has been found tospread more quickly than fact-checked content (Vosoughi,Roy, and Aral 2018). We speculate that this may be due to 802 Figure 6: Extremely biased and low factual content is ampli- ﬁed by crossposts relatively less than other content. Regard-less of the bias or factualness of the content, while cross-posts are responsible for more than 750 billion potential ex-posures, they make up only 1% of total potential exposures,suggesting that direct links to news sources play an espe-cially important role in content distribution. structural differences between the two platforms. On red- dit, users primarily consume content through subscriptionsto communities, not other users. This may explain the dimin-ished impact of re-sharing on reddit compared to Twitter. 6 Concentrations of Extremely Biased or Low Factual News Content It is critical to understand where different news content isconcentrated in order to best inform strategies for monitor-ing and managing its spread online. In this section, we ex-amine how extremely biased and low factual content is dis-tributed across users, communities, and news sources. Wealso compare the concentration of extremely biased and lowfactual content to all content. Method. We consider three types of content: (1) news con- tent with extreme bias or low factualness, (2) all news con- tent, and (3) all content (including non-news). We groupeach of these types of content by three perspectives: the userwho posted the content, the community it was posted to, andthe news source (or domain, in the case of all content) linkedto. We then take the cumulative sum of potential exposuresacross the users, communities, and news sources, to computethe fraction of potential exposures contributed by the top n% of users, communities, and news sources. We repeat this pro-cess, replacing the number of potential exposures with thetotal number of links, to consider the concentration of linksbeing submitted, regardless of visibility. Results. We ﬁnd that overall, extremely biased and low fac- tual content is highly concentrated across all three perspec- tives, but is especially concentrated in a small number ofcommunities, where 99% of potential exposures stem from amere 109 (0.5%) communities (Gini coefﬁcient=0.997) (Fig. Figure 7: When compared to all content on reddit (dotted line), extremely biased or low factual content (solid line)is more broadly distributed, making it harder to detect, re-gardless of the community, user, or news source perspective.However, 99% of potential exposures to extremely biased orlow factual content are restricted to only 0.5% of communi-ties. Here, a curve closer to the lower-right corner indicatesa more extreme concentration. Note that axis limits do notextend from 0 to 100%. 7a). No matter the perspective, exposures to extremely bi- ased or low factual content (solid line) are less concentratedthan all content (dotted line) (Fig. 7abc). Under the community and news source perspectives, ex- posures (Fig. 7ac) are more concentrated than links (Fig.7df). While links are already concentrated in a small shareof communities, some communities are especially large, andtherefore content from these communities receives a dispro-portionate share of potential exposures. This is not the casefor users, as the distributions of exposures (Fig. 7b) are lessconcentrated than the distributions of links (Fig. 7e). Thisindicates that while some users submit a disproportionateshare of links, these are not the users whose links receive thelargest potential exposure, as potential exposure is primarilya function of submitting links to large communities. Implications. The extreme concentration of extremely bi- ased or low factual content amongst a tiny fraction of com- munities supports reddit’s recent and high proﬁle decision totake sanctions against entire communities, not just speciﬁcusers (Isaac and Conger 2021). These decisions have beenextensively studied (Chandrasekharan et al. 2017, 2020;Thomas et al. 2021; Saleem and Ruths 2018; Ribeiro et al.2020). While this content is relatively less concentratedamongst users, in absolute terms, this content is still fairlyconcentrated, with 10% of users contributing 84% of po-tential exposures. As such, moderation sanctions againstusers can still be effective (Matias 2019b). We note thatthe concentration of extremely biased or low factual contentamongst a small fraction of users is similar to what has been 803 found on Twitter (Grinberg et al. 2019), although method- ological differences preclude a direct comparison. 7 Discussion Summary & Implications. In this work, we analyze all 580 million submissions to reddit from 2015-2019, and annotate35 million links to news sources with their political bias andfactualness using Media Bias/Fact Check. We ﬁnd: • Right-leaning communities’ links to news sources have 105% greater variance in their political bias than left- leaning communities. When right-leaning communitieslink to news sources that are different than the commu-nity average, they link to relatively-more biased sources35% more often than left-leaning communities (§4). • Existing curation and ampliﬁcation behaviors moderately reduce the impact of highly biased and low factual con-tent. This suggests that reddit differs somewhat from Twit-ter, perhaps due to its explicit community structure, or theability for users to downvote content (§5). • Highly biased and low factual content tends to be shared by a broader set of users and in a broader set of commu-nities than news content as a whole. Furthermore, the dis-tribution of this content is more concentrated in a smallnumber of communities than a small number of users, as99% of exposures to extremely biased or low factual con-tent stem from only 0.5% or 109 communities (§6). Thislends credence to recent reddit interventions at the com-munity level, including bans and quarantines. Limitations. One limitation of our analyses is the use of a single news source rating service, MBFC. However, the se-lection of news source rating annotation sets has been foundto have a minimal impact on research results (Bozarth, Saraf,and Budak 2020). MBFC is the largest (that we know of)dataset of news sources’ bias and factualness, and is widelyused (Dinkov et al. 2019; Stefanov et al. 2020; Heydari et al.2019; Starbird 2017; Darwish, Magdy, and Zanouda 2017).More robust approaches could combine annotations frommultiple sources, and we ﬁnd that MBFC annotations agreewith the Volkova et al. (2017) dataset with a Pearson Corre-lation of 0.96 on an example downstream task (§3.2). Our focus is on the bias and factualness of news sources shared online. We do not consider factors such as the contentof links (e.g. shared images, speciﬁc details of news stories), or the context in which links are shared (e.g. sentiment of a submission’s comments). These factors are important areasfor future work, and are outside the scope of this paper. While MBFC (and by extension, our annotations) in- cludes news sources from around the world, our analyses,especially the left-right political spectrum and associatedcolors, takes a US-centric approach. Polarization and misin-formation are challenges across the globe (Newman 2020),and more work is needed on other cultural contexts. Our paper explores the impact of curation and ampliﬁca- tion practices, but not the impact of community moderatorswho are a critical component of reddit’s moderation pipeline(Matias 2019b). Future work could examine news contentremoved by moderators.Bias # of Links # of News Sources Extreme Left 15,157 51 Left 3,023,382 364 Center Left 17,648,711 544 Center 4,494,687 442 Center Right 4,254,705 263 Right 3,226,828 352 Extreme Right 997,703 423 Unlabeled 525,443,378 Table 1: Numbers of links and unique news sources in ourdataset, by the political bias of the link. Finally, we are limited by the unavailability of data on which users view what content. While we use subreddits’subscriber counts to estimate exposures to content, moregranular data would enable us to better understand the im-pact of shared news articles, for example, the percentage ofusers who are exposed to extremely biased or low factualcontent (Grinberg et al. 2019). 8 Conclusion Biased and inaccurate news shared online are signiﬁcantproblems, with real harms across our society. Large-scalestudies of news sharing online are critical for understand-ing the scale and dynamics of these problems. We presentedthe largest study to date of news sharing behavior on red-dit, and found that right-leaning communities have more po-litically varied and relatively-more biased links than left-leaning communities, current voting and re-sharing behav-iors are moderately effective at reducing the impact of ex-tremely biased and low factual content, and that such con-tent is extremely concentrated in a small number of commu-nities. We make our dataset of news sharing on reddit public,in order to support further research 7. Acknowledgements This research was supported by the Laboratory Directed Re-search and Development Program at Paciﬁc Northwest Na-tional Laboratory, a multiprogram national laboratory oper-ated by Battelle for the U.S. Department of Energy. Thisresearch was supported by the Ofﬁce for Naval Research,NSF grant IIS-1901386, the Bill & Melinda Gates Foun-dation (INV-004841), and a Microsoft AI for Accessibilitygrant. Appendix: Dataset Summary Our dataset was created from all public reddit submissionsposted between January 2016 and August 2019, the mostrecent data available at the time of this study. These submis-sions were downloaded using the Pushshift archives (Baum-gartner et al. 2020), and consist of 580 million submissions,35 million unique authors, and 3.4 million unique subred-dits. As each submission may consist of 0 or more links, thedataset includes a total of 559 million links. These links are 7https://behavioral-data.github.io/news labeling reddit/ 804 Factualness # of Links # of News Sources Very Low 609,229 72 Low 749,202 369 Mixed 7,116,130 677 Mostly 2,217,719 110 High 22,055,943 1,313 Very High 2,263,604 134 Unlabeled 524,092,724 Table 2: Numbers of links and unique news sources in our dataset, by the factualness of the link. to 5.1 million unique domains, of which we are able to label 2,801 unique domains with annotations from MBFC. Table 1 shows the number of links in the dataset, as well as the number of unique news sources, for each bias category. Table 2 shows the number of links in the dataset, as well as the number of unique news sources, for each factualnesscategory. The dataset may be downloaded from our website at https://behavioral-data.github.io/news labeling reddit/ References Allen, J.; Howland, B.; Mobius, M.; Rothschild, D.; andWatts, D. J. 2020. Evaluating the fake news problem at thescale of the information ecosystem. Science Advances 6(14). Allison, K.; and Bussey, K. 2020. Communal Quirks andCirclejerks: A Taxonomy of Processes Contributing to Insu-larity in Online Communities. In ICWSM. Baly, R.; Da San Martino, G.; Glass, J.; and Nakov, P. 2020.We Can Detect Your Bias: Predicting the Political Ideologyof News Articles. In EMNLP, 4982–4991. ACL. doi:10. 18653/v1/2020.emnlp-main.404. URL https://www.aclweb.org/anthology/2020.emnlp-main.404. Baumgartner, J.; Zannettou, S.; Keegan, B.; Squire, M.; and Blackburn, J. 2020. The Pushshift Reddit Dataset. InICWSM. Bovet, A.; and Makse, H. 2019. Inﬂuence of fake news in Twitter during the 2016 US presidential election. Nature Communications 10. Bozarth, L.; Saraf, A.; and Budak, C. 2020. Higher Ground?How Groundtruth Labeling Impacts Our Understanding ofFake News about the 2016 U.S. Presidential Nominees. InICWSM. Chandrasekharan, E.; Gandhi, C.; Mustelier, M. W.; and Gilbert, E. 2019. Crossmod: A Cross-Community Learning-based System to Assist Reddit Moderators. CHI 3: 1 – 30. Chandrasekharan, E.; Jhaver, S.; Bruckman, A.; andGilbert, E. 2020. Quarantined! Examining the Effectsof a Community-Wide Moderation Intervention on Reddit.ArXiv abs/2009.11483. Chandrasekharan, E.; Pavalanathan, U.; Srinivasan, A.;Glynn, A.; Eisenstein, J.; and Gilbert, E. 2017. You Can’tStay Here: The Efﬁcacy of Reddit’s 2015 Ban ExaminedThrough Hate Speech. CHI 1: 31:1–31:22.Chandrasekharan, E.; Samory, M.; Jhaver, S.; Charvat, H.;Bruckman, A.; Lampe, C.; Eisenstein, J.; and Gilbert, E.2018. The Internet’s Hidden Rules. CHI 2: 1 – 25. Choi, D.; Chun, S.; Oh, H.; Han, J.; et al. 2020. Rumorpropagation is ampliﬁed by echo chambers in social media.Scientiﬁc Reports 10(1): 1–10. Darwish, K.; Magdy, W.; and Zanouda, T. 2017. Trump vs.Hillary: What Went Viral During the 2016 US PresidentialElection. In SocInfo. Datta, S.; and Adar, E. 2019. Extracting Inter-communityConﬂicts in Reddit. In ICWSM. Demszky, D.; Garg, N.; Voigt, R.; Zou, J.; Gentzkow, M.;Shapiro, J.; and Jurafsky, D. 2019. Analyzing Polarizationin Social Media: Method and Application to Tweets on 21Mass Shootings. In NAACL-HLT. Dinkov, Y.; Ali, A.; Koychev, I.; and Nakov, P. 2019. Pre-dicting the Leading Political Ideology of YouTube ChannelsUsing Acoustic, Textual, and Metadata Information. In IN- TERSPEECH. Dosono, B.; and Semaan, B. C. 2019. Moderation Practices as Emotional Labor in Sustaining Online Communities: TheCase of AAPI Identity Work on Reddit. CHI . Ferrara, E. 2017. Contagion dynamics of extremist propa-ganda in social networks. Information Sciences 418: 1–12. Fiesler, C.; Jiang, J. A.; McCann, J.; Frye, K.; and Brubaker,J. R. 2018. Reddit Rules! Characterizing an Ecosystem ofGovernance. In ICWSM. Fiesler, C.; and Proferes, N. 2018. “Participant” Perceptionsof Twitter Research Ethics. Social Media + Society 4. Ganguly, S.; Kulshrestha, J.; An, J.; and Kwak, H. 2020.Empirical Evaluation of Three Common Assumptions inBuilding Political Media Bias Datasets. In ICWSM. Geiger, A. 2019. Key ﬁndings about the online newslandscape in America. https://www.pewresearch.org/fact-tank/2019/09/11/key-ﬁndings-about-the-online-news-landscape-in-america/. Accessed: 2021-04-09. Glenski, M.; Pennycuff, C.; and Weninger, T. 2017. Con- sumers and Curators: Browsing and Voting Patterns on Red-dit. IEEE TCSS 4(4): 196–206. doi:10.1109/TCSS.2017. 2742242. Glenski, M.; Weninger, T.; and Volkova, S. 2018. Propa- gation from deceptive news sources who shares, how much,how evenly, and how quickly? IEEE TCSS 5(4): 1071–1082. Grinberg, N.; Joseph, K.; Friedland, L.; Swire-Thompson,B.; and Lazer, D. 2019. Fake news on Twitter during the2016 U.S. presidential election. Science 363: 374 – 378. Heydari, A.; Zhang, J.; Appel, S.; Wu, X.; and Ranade, G.2019. YouTube Chatter: Understanding Online CommentsDiscourse on Misinformative and Political YouTube Videos. Horne, B.; Nørregaard, J.; and Adali, S. 2019. Different Spi- rals of Sameness: A Study of Content Sharing in Mainstreamand Alternative Media. In ICWSM. 805 Isaac, M.; and Conger, K. 2021. Reddit bans forum dedicated to supporting Trump. https://www.nytimes.com/2021/01/08/us/politics/reddit-bans-forum-dedicated-to-supporting-trump-and-twitter-permanently-suspends-his-allies-who-spread-conspiracy-theories.html. Accessed:2021-04-09. Jhaver, S.; Birman, I.; Gilbert, E.; and Bruckman, A. 2019. Human-Machine Collaboration for Content Regula-tion. TOCHI 26: 1 – 35. Jhaver, S.; Bruckman, A.; and Gilbert, E. 2019. Does Trans-parency in Moderation Really Matter? CHI 3: 1 – 27. Jiang, S.; Robertson, R. E.; and Wilson, C. 2019. Bias Mis-perceived: The Role of Partisanship and Misinformation inYouTube Comment Moderation. In ICWSM. Jiang, S.; Robertson, R. E.; and Wilson, C. 2020. Reasoningabout Political Bias in Content Moderation. In AAAI. Kharratzadeh, M.; and ¨Ustebay, D. 2017. US Presidential Election: What Engaged People on Facebook. In ICWSM. Kouzy, R.; Jaoude, J. A.; Kraitem, A.; Alam, M. B. E.;Karam, B.; Adib, E.; Zarka, J.; Traboulsi, C.; Akl, E. A.; andBaddour, K. 2020. Coronavirus Goes Viral: Quantifying theCOVID-19 Misinformation Epidemic on Twitter. Cureus 12. Landis, J.; and Koch, G. 1977. The measurement of observeragreement for categorical data. Biometrics 33 1: 159–74. Linvill, D. L.; and Warren, P. L. 2020. Troll factories: Man-ufacturing specialized disinformation on Twitter. Political Communication 1–21. Main, T. J. 2018. The Rise of the Alt-Right. Brookings Insti- tution Press. Marwick, A.; and Lewis, R. 2017. Media manipulation and disinformation online. Data & Society https://datasociety. net/library/media-manipulation-and-disinfo-online/. Matias, J. 2019a. Preventing harassment and increasing group participation through social norms in 2,190 online sci-ence discussions. PNAS 116: 9785 – 9789. Matias, J. N. 2019b. The Civic Labor of Volun-teer Moderators Online. Social Media + Society 5(2): 2056305119836778. doi:10.1177/2056305119836778.URL https://doi.org/10.1177/2056305119836778. Medvedev, A.; Lambiotte, R.; and Delvenne, J. 2018. The anatomy of Reddit: An overview of academic research.ArXiv abs/1810.10881. Mitchell, A.; Gottfried, J.; Srocking, G.; Walker, M.;and Fedeli, S. 2019. Many Americans Say Made-Up News Is a Critical Problem That Needs To BeFixed. Pew Research Center Science and Journalism https://www.journalism.org/2019/06/05/many-americans-say-made-up-news-is-a-critical-problem-that-needs-to-be-ﬁxed/. Nelimarkka, M.; Laaksonen, S.-M.; and Semaan, B. 2018. Social Media Is Polarized, Social Media Is Polarized: To-wards a New Design Agenda for Mitigating Polarization.InACM DIS, 957–970. United States: ACM. doi:10.1145/3196709.3196764. ACM conference on Designing Interac-tive Systems, DIS ; Conference date: 09-06-2018 Through13-06-2018. Newman, N. 2020. Digital News Report. Reuters Institute. Qazvinian, V.; Rosengren, E.; Radev, D.; and Mei, Q. 2011. Rumor has it: Identifying misinformation in microblogs. InEMNLP, 1589–1599. Rajadesingan, A.; Resnick, P.; and Budak, C. 2020. Quick, Community-Speciﬁc Learning: How Distinctive ToxicityNorms Are Maintained in Political Subreddits. In ICWSM. Recuero, R.; Soares, F. B.; and Gruzd, A. A. 2020. Hy-perpartisanship, Disinformation and Political Conversationson Twitter: The Brazilian Presidential Election of 2018. InICWSM. Ribeiro, M. H.; Jhaver, S.; Zannettou, S.; Blackburn, J.; Cristofaro, E. D.; Stringhini, G.; and West, R. 2020.Does Platform Migration Compromise Content Modera-tion? Evidence from r/The Donald and r/Incels. ArXiv abs/2010.10397. Risch, J.; and Krestel, R. 2020. Top Comment or Flop Com- ment? Predicting and Explaining User Engagement in On-line News Discussions. In ICWSM. Saleem, H. M.; and Ruths, D. 2018. The Aftermathof Disbanding an Online Hateful Community. ArXiv abs/1804.07354. Samory, M.; Abnousi, V. K.; and Mitra, T. 2020a. Char- acterizing the Social Media News Sphere through User Co-Sharing Practices. In ICWSM, volume 14, 602–613. Samory, M.; Abnousi, V. K.; and Mitra, T. 2020b. Char-acterizing the Social Media News Sphere through User Co-Sharing Practices. In ICWSM. Shearer, E.; and Matsa, K. E. 2018. News Use Across SocialMedia Platforms 2018. https://www.journalism.org/2018/09/10/news-use-across-social-media-platforms-2018/. Ac-cessed: 2021-04-09. Starbird, K. 2017. Examining the Alternative Media Ecosys- tem Through the Production of Alternative Narratives ofMass Shooting Events on Twitter. In ICWSM. Stefanov, P.; Darwish, K.; Atanasov, A.; and Nakov, P. 2020.Predicting the Topical Stance and Political Leaning of Me-dia using Tweets. In ACL, 527–537. Online: ACL. doi: 10.18653/v1/2020.acl-main.50. URL https://www.aclweb.org/anthology/2020.acl-main.50. Tasnim, S.; Hossain, M.; and Mazumder, H. 2020. Impact of Rumors and Misinformation on COVID-19 in Social Media.Journal of Preventive Medicine and Public Health 53: 171 – 174. Thomas, P. B.; Riehm, D.; Glenski, M.; and Weninger, T. 2021. Behavior Change in Response to Subreddit Bans andExternal Events. IEEE Transactions on Computational So- cial Systems 1–10. doi:10.1109/TCSS.2021.3061957. Volkova, S.; Shaffer, K.; Jang, J. Y.; and Hodas, N. 2017.Separating Facts from Fiction: Linguistic Models to Classify 806 Suspicious and Trusted News Posts on Twitter. In ACL, 647– 653. Vancouver, Canada: ACL. doi:10.18653/v1/P17-2102. URL https://www.aclweb.org/anthology/P17-2102. Vosoughi, S.; Mohsenvand, M. N.; and Roy, D. 2017. Rumor gauge: Predicting the veracity of rumors on Twitter. KDD 11(4): 1–36. Vosoughi, S.; Roy, D.; and Aral, S. 2018. The spread of true and false news online. Science 359(6380): 1146–1151. ISSN 0036-8075. doi:10.1126/science.aap9559. URL https://science.sciencemag.org/content/359/6380/1146. Wadden, D.; August, T.; Li, Q.; and Althoff, T. 2021. The Effect of Moderation on Online Mental Health Conversa-tions. In ICWSM. Waller, I.; and Anderson, A. 2019. Generalists and Special-ists: Using Community Embeddings to Quantify ActivityDiversity in Online Platforms. In The World Wide Web Con- ference, WWW ’19, 1954–1964. New York, NY, USA: As-sociation for Computing Machinery. ISBN 9781450366748.doi:10.1145/3308558.3313729. URL https://doi.org/10.1145/3308558.3313729. Zhang, A. X.; Hugh, G.; and Bernstein, M. S. 2020. Poli- cyKit: Building Governance in Online Communities. UIST URL https://doi.org/10.1145/3379337.3415858. 807