 Univ ersity of Chicago Law School Univ ersity of Chicago Law School  Chicago Unbound Chicago Unbound  Coase-Sandor W orking P aper Series in Law and  Economics Coase-Sandor Institute for Law and E conomics  2014  An Empirical Study of P olitical Bias in Legal Scholarship An Empirical Study of P olitical Bias in Legal Scholarship  Adam S. Chilt on  dangelolawlib+adamchilt on@gmail.com  Eric A. P osner  dangelolawlib+ericposner1@gmail.com  Follow this and additional works at: https:/ /chicagounbound.uchicago.edu/law_and_economics   Part of the Law Commons  Recommended Citation Recommended Citation  Adam S. Chilt on & Eric P osner , "An Empirical Study of P olitical Bias in Legal Scholarship " (Coase-Sandor  Institute for Law & E conomics W orking P aper No. 696, 2014).  This W orking P aper is br ought t o you for fr ee and open access b y the Coase-Sandor Institute for Law and  Economics at Chicago Unbound. It has been accepted for inclusion in Coase-Sandor W orking P aper Series in Law  and E conomics b y an authoriz ed administr ator of Chicago Unbound. F or mor e information, please contact  unbound@law .uchicago.edu .   Electronic  copy available at: http://ssrn.com/abstract=2478908   CHICAGO   COASE -SANDOR INSTITUTE FOR LAW AND  ECONOMICS WORKING PAPER NO. 696  (2D SERIES )                    An Empirical Study of Political Bias in Legal Scholarship     Adam S. Chilton and Eric A. Posner       THE LAW SCHOOL   THE UNIVERSITY OF CHICAGO    August 2014    This paper can be downloaded without charge at:  The University of Chicago, Institute for Law a nd Economics Working Paper Series Index:  http://www.law.uchicago.edu/Lawecon/index.html   and at t he Social Science Research Network Electronic Paper Collection .   Electronic  copy available at: http://ssrn.com/abstract=2478908         AN EMPIRICAL STUDY O F POLITICAL BIAS   IN LEGAL SCHOLARSHIP     Adam S. Chilton* & Eric A. Posner†       Abstract   Law professors routinely accuse each other of making politically  biased arguments in their scholarship. They have also helped  produce a large empirical literature on judicial behavior that has  found that judicial opinions sometimes reflect the ideological biases  of the judges who join them. Yet no one has used statistical methods  to test the parallel hypothesis that legal scholarship reflects the political biases of law professors. This paper provides the results of  such a test. We find that, at a statistic ally significant level, law  professors at elite law schools who make donations to Democratic  political candidates write liberal scholarship, and law professors who  make donations to Republican political candidates write conservative  scholarship. These find ings raise questions about standards of  objectivity in legal scholarship.   * Assistant Professor of Law, University of Chicago Law School.  Email:  adamchilton@uchicago.edu.   † Kirkland & Ellis Distinguished Service Professor, University of Chicago Law  School. Email: eposner@uchicago.edu.   We would like to thank Will Baude, Omri Ben -Shahar, Justin Driver, Lee  Epstein, Tom Ginsburg, Jack Goldsm ith, William Hubbard, Aziz Huq, Daryl  Levinson, Tom Miles, Martha Nussbaum, Richard Posner, Eric Segall, Lior  Strahilevitz, David Strauss, Cass Sunstein, and participants at a workshop at the  University of Chicago Law School, for helpful comments and conversations; and  Adam Bonica and Maya Sen for sharing data. We would also like to thank Katie  Bass, Will Larsen, Michael Lockman, Sang Lee, Paul Rogerson, and Paxton  Williams for research assistance.                                                     Electronic  copy available at: http://ssrn.com/abstract=2478908 2 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  INTRODUCTION     Law professors have frequently accused each other of writing  legal scholarship that claims to be objective but is in fact tainted with  political bias. Conservative law professors argue that liberal  constitutional scholars say that the Constitution protects abortion  rights and same -sex marriage but not gun rights because of their  ideological commitments to abortion, s ame -sex marriage, and gun  control, rather than because of a good -faith analysis of the relevant  legal materials.1 Liberal law professors argue that conservative law  professors have thrown their lot in with originalism because the  original understanding lin es up with the ideological goals of those  professors or can be manipulated to do so.2 Critics of law and  economics argue that this methodology appeals to conservatives who  believe in free markets.3 Defenders of law and economics have not  been shy about accusing their critics of left- wing ideological bias.4 In  countless other debates, charges of ideological bias are common.5 A  full account of the charges and counter -charges of ideological bias in  1 See, e.g. , ROBERT BORK, THE TEMPTING OF AMERICA  199-219 (1997) (accusing  mainstream constitutional law professors of liberal bias).   2 Robert Post & Reva Siegal, Originalism as a Political Practice: The Right’s  Living Constitution , 75 F ORDHAM L. REV. 545 (2006) (arguing that conservatives  prefer originalism for ideological reasons). See generally  Keith E. Whittington, Is  Originalism Too Conservative? , 34 HARV. J.L.  & PUB. POL’Y 29, 30 (2011) (“The  association of conservative politics with originalism is not accidental, however, and  conservatives are generally  more likely than liberals to find originalism a  normatively attractive approach to constitutional interpretation.”).   3 MARK KELMAN , A GUIDE TO CRITICAL LEGAL STUDIES  151 (1987) (law and  economics is “biased … because the people doing this work explicitly and substantively favor certain traditional right -wing positions”).   4 Richard A. Posner, The Economic Approach to Law , 53 T EX. L. REV. 757  (1975) (“The law and economics scholars have been scrupulous —more scrupulous I  would argue than their critics —in resp ecting the line between positive and  normative analysis.”).   5 See, e.g. , Steven Lubet & Cathryn Stewart, A “Public Assets” Theory of  Lawyers' Pro Bono Obligations , 145 U.  PA. L. REV. 1245, 1294 (1997) (claiming  ideological bias motivated professor’s critic isms of pro bono lawyers); Michael L.  Seigel, Corporate America Fights Back: The Battle over Waiver of the Attorney - Client Privilege , 49 B.C.  L. REV. 1, n 163 (2008) (claiming ideological bias  motivated argument that the Justice Department should reduce in vestigations of  corporations); Edith H. Jones & Todd J. Zywicki, It's Time for Means -Testing ,  1999 B.Y.U.  L. REV. 177, 244 (1999) (claiming ideological bias motivated argument  that better health insurance is the solution to the problem of bankruptcy); Lynn e  Marie Kohm & Lynn D. Wardle, The “Echo -Chamber Effect” in Legal Education:  Considering Family Law Casebooks, 6 U.  ST. THOMAS J.L.  & PUB. POL’Y 104 (2011)  (arguing that family law casebooks reflect ideological bias in favor of abortion  rights).                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  3  law reviews could easily fill up the Internet, leaving no room  for cat  videos.   Conservative scholars have also complained that law school  faculties are left -wing. A study by John L. McGinnis, Matthew  Schwartz, and Benjamin Tisdell found that law professors at the top  law schools who made political contributions overw helmingly  contributed to Democratic candidates for political office.6 One  commentator laments that lack of ideological diversity among law professors leads to an “echo chamber” that prevents “an accurate understanding of contemporary reality.” 7 If liberals  predominate on  the faculty, and scholarship reflects ideological biases, then legal research may advance a liberal world view rather than understanding  of the law.   Nor are these accusations restricted to academic work.  Professor David Hyman complains that  the liberal bias of law  professors was reflected in their comments to journalists about the  constitutionality of the individual mandate of the Affordable Care  Act. 8 The law professors argued, in the strongest possible terms, that  the legal argument that the individual mandate violated the  Commerce Clause was not only wrong but “frivolous,” “silly,”  “deserving of sanctions,” “completely bogus,” and “beneath  contempt.”9 Yet that challenge was received favorably by some  district and circuit courts, and prevailed in the Supreme Court in  NFIB v. Sebelius10 by a 5 -4 vote. Hyman believes that their  ideological priors led the law professors astray and thus that the legal  acade my, because of its overwhelming liberal slant, misled  journalists and the public.   The political scientist  Steven Teles places recent developments  in legal scholarship in an ideological framework.11 In his telling, an  alliance of liberal law professors, liberal public -interest groups like  the ACLU, and liberal foundations like the Ford Foundation formed a  6 John L. McGinnis, Matthew Schwartz & Benjamin Tisdell, The Patterns and  Implications of Political Contributions by Elite Law School Faculty , 93 G EO. L.J.  1167, 1169 (2005).   7 George W. Dent, Jr., Toward Improved Intellectual Diversity in Law  Schools , 37 H ARV. J. L. & PUB. POL’Y 165  (2013) . See also  Nicholas Quinn  Rosenkranz, Intellectual Diversity in the Legal Academy , 37 H ARV. J.L.  & PUB.  POL’Y 137 (2013).   8 David A. Hyman, Why Did Law Professors Misunderestimate the Lawsuits  against PPACA ?, 2014 U.  ILL. L. REV. 805.  9 Id. at 809 -10.  10 132 S.Ct. 2566 (2012).   11 STEVEN M. TELES , THE RISE OF THE CONSERVATIVE LEGAL MOVEMENT : THE  BATTLE FOR CONTROL OF THE LAW (2008).                                                    4 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  “liberal legal network”  in the 1970s  that supported liberal legal  scholarship committed  to defending Warren Court decisions:     The near -absence of conservati ve voices in law schools meant  that this interpretation of constitutional law was nearly  hegemonic. This was a “dominance so complete that every casebook, treatise, and handbook used to teach constitutional  law in American law schools is the product of Dem ocrats  writing from Democratic perspectives. 12    The liberal legal network eventually provoked a backlash among  conservatives.  Legal scholars with a conservative or libertarian bent  organized their own institutions to nurture their scholarship —above  all, The  Federalist Society. And they received significant financial  support for their research from right -leaning foundations.13  In this paper, we attempt to test the link between ideology and  research using statistical methods. We have collected data on the  polit ical propensities of a random sample of 156 tenured law  professors from elite law schools, and on the political slant of papers that they have written in the last several years. We do in fact find that  the ideology of a tenured professor at an elite law sc hool —as  measured by his or her contributions to candidates for political  office —is correlated at a statistically significant level with the  ideological valence of the professor’s research.   We are writing on a clean slate. As far as we know, no one has  conducted a statistical study of political bias among law professors.  There is also no comparable research in other fields. However, there  is some related work. In political science, we found one study that  shows that scholars who use different paradigms in in ternational  relations (realist, liberal, etc.) tend to have different ideological views  based on responses to a survey. 14 Economists have produced several  studies of the ideological views of economists. In these studies, authors use surveys to gauge economi sts’ political views and their  views about certain economic parameters, and then investigate the  relationships between them (typically finding a statistically  12 Id. at 45, quoting Martin Shapiro, Interest Groups and Supreme Court  Appointments , 84 NORTHWESTERN U.L.  REV. 935, 955 (1990). For further  discussion, see L AURA KALMAN , THE STRANGE CAREER OF LEGAL LIBERALISM  (1996).   13 Teles, supra  note 11, at 265 -74.  14 Brian Rathbun, Politics and Paradigm Preferences: The Implicit Ideology of  International Relations Scholars , 56 I NT’L STUD. Q. 607 (2012) (finding a  relationship between interna tional relations scholars’ choice of paradigm and  political beliefs).                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  5  significant relationship).15 But they have not tested whether political  views affect published art icles. Psychologists have written extensively  about whether the lack of ideological diversity in their profession has  biased research.16 Historians routinely argue that earlier generations  of historical scholarship reflect the ideological assumptions of the   age.17  The absence of similar research on legal scholarship reflects  15 Jessica Carrick -Hagenbarth & Gerald A. Epstein, Dangerous  interconnectedness: economists’ conflicts of interest, ideology and financial crisis,  36 CAMBRIDGE J. ECON. 43 (2012) (finding that economists proposing financial  reform measures frequently had, but only infrequently and inconsistently disclosed, private financial affiliations); Victor R. Fuchs,  Alan B. Krueger,  & James  M. Poterba,  Why do Economists Disagree Ab out Policy? , NBER Working Paper  No. 6151 (1997) (finding a relationship between economists’ values and their best  estimates of economic parameters as well as their policy preferences); Thomas  Mayer, The Role of Ideology in Disagreements Among Economists: A  Quantitative Analysis , 8 J.  ECON. METH. 253 (2001) (finding a relationship  between economists’ political ideology and their estimates of economic  parameters); Bryan Caplan, Systematically Biased Beliefs About Economics:  Robust Evidence of Judgmental Anoma lies from the Survey of Americans and  Economists on the Economy , 112 T HE ECON. J. 433 (2002) (rejecting the view that  self-serving or ideological biases among economists explain the differences of  opinion between economists and laypeople on economic questi ons); Roger Gordon  & Gordon B. Dahl, Views Among Economists: Professional Consensus or Point - Counterpoint? , 10 A M. ECON. REV: PAPERS & PROCEEDINGS  629 (2013) (finding  consensus among economists on many economic questions and no evidence that  ideological di visions explain disagreement on the others).   16 Yoel Inbar & Jorris Lammers, Political Diversity in Social and Personality  Psychology , 7 P ERSPECTIVES ON PSYCHOLOGICAL SCI. 496 (2012) (finding that social  and personality psychologists overwhelmingly have li beral political beliefs and  some would discriminate against conservatives in professional decisions); Lee  Jussim , Liberal Privilege in Academic Psychology and the Social Sciences:  Commentary on Inbar & Lammers (2012) , 7 P ERSPECTIVES ON PSYCHOLOGICAL  SCIENC E 504 (2012) (arguing that the liberal political beliefs of social psychologists  distort research in the field); Linda J. Skitka, Multifaceted Problems: Liberal Bias  and the Need for Scientific Rigor in Self -Critical Research , 7 P ERSPECTIVES ON  PSYCHOLOGIC AL SCIENCE  508 (2012) (critiquing the methodology of the Inbar &  Lammers study); Richard E. Redding, Likes Attract: The Sociopolitical Groupthink of (Social) Psychologists , 7 P ERSPECTIVES ON PSYCHOLOGICAL SCIENCE  512 (2012)  (arguing that ideological divers ity in the field of psychology is important to  research and teaching); Deborah A. Prentice, Liberal Norms and Their  Discontents , 7 P ERSPECTIVES ON SOCIAL PSYCHOLOGY  516 (2012) (arguing that  liberal norms in the field of social psychology constrain the dire ction of research);  Philip E. Tetlock, Rational Versus Irrational Prejudices: How Problematic Is the  Ideological Lopsidedness of Social Psychology? , 7 P ERSPECTIVES ON SOCIAL  PSYCHOLOGY  519 (2012) (arguing that liberal ideological biases may have  influenced  research).   17 See, e.g ., C. Behan McCullagh, Bias in Historical Description,  Interpretation, and Explanation , 39 H ISTORY & THEORY  39 (2000).                                                    6 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  poorly on our field. And it is surprising in light of the massive  literature on judicial behavior, which uses statistical methods to  predict case outcomes from the ideologies of judges.18 Indeed, we use  a methodology similar to that of the authors in that literature. So,  based on the principle that what is sauce for the goose is sauce for the  gander, we turn now to legal academia.       I. RESEARCH DESIGN      A.  Empirical Strategy     We use a simple empirical strategy modeled on the general  approach used in the judicial behavior literature. That literature tests the hypothesis that case outcomes or votes are affected by the  ideology of judges. Authors have developed an elaborate coding  scheme for clas sifying a case outcome as “liberal” or “conservative.” 19  The ideology of a judge is usually based on the party affiliation of the  president who nominated her.20 Thus, findings that judges  nominated by Democratic presidents vote more frequently for liberal case outcomes than judges nominated by Republican presidents are  consistent with the hypothesis. 21   As explained in greater detail below, we use the same coding  18 See, e.g. , LEE EPSTEIN , ET AL ., THE BEHAVIOR OF FEDERAL JUDGES (2013).   19 See Jeffrey A. Segal &  Harold J. Spaeth, The Supreme Court and the  Attitudinal Model (1993). The “U.S. Supreme Court Database,” initially created by  Harold Spaeth, is widely used in law and social science. Cf . Barry Friedman,  Taking Law Seriously , 4 PERSP . ON POL. 261, 272 n.10  (2006) (noting that the  database was cited 161 times between 2002 to 2006 alone). For a criticism of the coding system developed and used by this widely cited database, see  Carolyn  Shapiro, Coding Complexity: Bringing Law to the Empirical Analysis of the  Supreme Court , 60 H ASTINGS L.J. 477 (2009).   20 See, e.g. , Jonathan P. Kastellec, Hierarchical and Collegial Politics on the  U.S. Court of Appeals , 73 J.  POL. 345 (2011); Cass R. Sunstein & Thomas J. Miles,  Symposium, Depoliticizing Administrative Law , 58 D UKE L.J.  2193,  2197  (2009);   Cass R. Sunstein, David Schkade & Lisa Michelle Ellman, Ideological Voting on  Federal Courts of Appeals: A Preliminary Investigation , 90 V A. L. REV. 301, 303  (2004) .    21 See, e.g. , Frank B. Cross & Emerson H. Tiller, Judicial Partisanship and  Obedience to Legal Doctrine: Whistleblowing on the Federal Court of Appeals,  107 Yale L.J. 2155, 2168 (1998). See also  Kastellec, supra  note 20; Sunstein et al.,  supra  note 20; Richard L. Revesz, Environmental Regulation, Ideology and the  D.C. Circuit , 83 Va. L. Rev.  1717 (1997).                                                       11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  7  system for classifying articles written by professors. Because  professors are not appointed by pol itical officials, we instead rely on  their campaign contributions to infer their ideology. Although it is  possible that an individual’s political donations do  not reflect his or  her true ideological commitments, they do have the advantage of  providing an o bjective and observable measure of preferences.  Moreover, donations are a widely used proxy for ideology in  empirical research.22 Our hypothesis is that professors who  contribute to Democratic politicians are more likely to write liberal  articles than are p rofessors who contribute to Republican politicians.      B.  Data    1. The Sample    Each observation in our dataset is a professor. To choose our  professors, we drew our sample from the top 14 law schools in the  2015 U.S. News & World Report Rankings. 23 We then randoml y  selected ten professors from each law school.24 To ensure that the  22 See generally Adam Bonica, Ideology and Interests in the Political  Marketplace , 57 A M. J. POL. SCIENCE  294 (2013). See infra  note 38 .   23 The 2015 edition of the r ankings were released in the spring of 2014. The top  14 law schools in those rankings are: (1) Yale Law School; (2) Harvard Law School;  (3) Stanford Law School; (4) Columbia Law School; (4) University of Chicago Law School; (6) NYU School of Law; (7) Unive rsity of Pennsylvania Law School; (8)  University of Virginia School of Law; (9) University of California, Berkeley, Boalt  Hall School of Law; (10) Duke University School of Law; (10) University of  Michigan Law School; (12) Northwestern University School of  Law; (13) Cornell  Law School; and (13) Georgetown University Law Center. We focus on elite law schools because other scholarship does as well. See, e.g. , McGinnis et al., supra  note 6. Moreover, we decided to define elite law schools as the Top -14 law schools  in the U.S. News and World Report Rankings because it is the definition common used in both academic scholarship an d discourse more widely. See e.g.,  Maya Sen,  Is Justice Really Blind? Race and Appellate Review in US. Courts , Working Paper  (2013), available at  <http://scholar.harvard.edu/files/msen/files/jpm_v13.pdf>  (last visited August 7, 2014). See also  Wikipedia En try on Law School Rankings,  available at <http://en.wikipedia.org/wiki/Law_school_rankings_in_the_United   _States#Schools_that_rank_in_the_top_14_.28aka_.22T14.22.29> (last visited  August 7, 2014). We of course acknowledge that the decision to focus on elite law  schools does mean that our findings may not be generalizable to the population of all law professors. See infra  Part III.A.   24 We used a five- step process to conduct our random draw of professors. First,  we downloaded a list of the current faculty fr om the website of each of the 14 law  schools in our sample. Second, we counted the number of professors at each  school. Third, we used a random number simulator to create a random list of                                                   8 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  professors included in our sample had sufficient time to develop a  body of scholarship to evaluate, we elected to include only tenured  academic faculty.25 In six cases the professors we initially drew had  written fewer than five journal articles —which we believed to be too  few articles to allow for a confident assessment of the ideological  valence of their research —so we discarded them and replaced them  with an additional professor, chosen at random, from the same  schools. Thus, our initial dataset had 140 observations.    In the initial sample of 140 professors, however, only 8 had  donated more money to Republicans than Democrats (which is our principle measure of ideology). 26 This is perhaps u nsurprising given  prior research that has suggested that academics are skewed far to  the left,27 that lawyers skew to the left as a profession,28 and even  that legal academics skew to the left.29 That said, we still believed  that 8 Republicans was too small a  sample for drawing reliable  inferences, so we proceeded to oversample Republicans. To do so, we  used the Database on Ideology, Money in Politics, and Elections (DIME) developed by the political scientist, Adam Bonica. 30 Using  the DIME database, we searched  for employees of the 14 law schools  in our sample who  were net conservative donors, and who  met our  criteria of being tenured academic scholars. This resulted in the identification of an additional 16 Republican donors who were not  already in our sample. We added these 16 professors to our initial  numbers based on the number of professors each school. For example, Harvard  had 119 professors listed on their website, so we had a computer put the numbers 1  to 119 in random order (i.e. 47, 10, 91, 2, etc.). Fourth, we then took the professor  from our list that was listed in the place determined by the first ten randomly   generated numbers (i.e. if the first number was 47, we’d count down the published  faculty list to the 47th spot, then include that professor in our sample). Fifth, if a  professor was not a tenured doctrinal faculty member, we drew continued down  our rando mly ordered list until we had 10 professors from each school.   25 We excluded Assistant Professors, Associate Professors, Emeritus  Professors, Clinical Professors, Visiting Assistant Professors, and Professors of the Practice.   26 See infra  Part I.B.3.   27 See Adam Bonica, Mapping The Ideological Marketplace , 58 A M. J. POL. SCI.  367 (2014).   28 See Adam Bonica & Maya Sen, Whom Does the Judiciary Represent?   Working Paper (2014) (on file with authors).   29 See McGinnis et al.,  supra  note 6.   30 Adam Bonica, Database on Ideology, Money in Politics, and Elections:  Public version 1.0, available at  ‹http://data.stanford.edu/dime> (last visited July  31, 2014). The DIME database provides data on over 100 million political  donations between 1979 to 2012 based on FEC filings. The reason that we were able to find additional donations using this database is that it includes donations  from earlier years than opensecre ts.com does.                                                                                                                               11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  9  sample of 140 professors, resulting in a sample of 156 total  observations.31    2.  The Dependent Variable    We first selected the five most recent articles published by  those professors, as of July 2014.32 We selected articles published in  law reviews or peer -reviewed journals, and excluded book reviews  and popular writing. With a small number of exceptions where we used our judgment, this process was straightforward.    We hired research assistants —five seco nd-year law students — to classify the articles. We instructed the research assistants to use  the coding system that has been developed by Spaeth et al., 33 and has  been used in numerous judicial behavior articles.34 This coding  system matches case outcomes wit h plausible political indicators. For  example, criminal law cases in which the defendant prevails are  classified as liberal; if the government prevails, they are classified as  conservative. In civil rights cases, when women, gays and lesbians,  and African Americans prevail, the outcome is liberal; otherwise it is  conservative. When workers or consumers prevail over employers  and merchants, the case outcome is liberal; when businesses win, it is  conservative. The coding instructions are reproduced in Appendi x 4.  31 All of the results reported in this paper use the sample of 156 professors. Our  results are robust, however, to only using the initial sample of 140 professors.   32 Although five articles is a small number compared to the body of work of  many  scholars, we do not believe that sampling only a handful of articles  substantively biases our results. It is reasonable to assume that for every legal  academic, the political valiance of the articles she writes falls along some distribution. If enough art icles were sampled from each professor, it would be  possible to know the true distribution.  By only sampling five articles, however, its  possible that we are coding articles that are not representative of that individual’s true distribution. That said, it is likely the case that these errors are randomly  distributed. In other words, for some professors we will have coded five articles  that are more conservative than their overall body of work, and for other professors  we may have coded five articles that ar e more liberal than their overall body of  work. As long as there is not reason to think that there is systematic bias in one direction —which we do not have reason to believe exists —this will not bias our  results.   33 See Harold J. Spaeth, Sara Benesh, Lee E pstein, Andrew D. Martin, Jeffrey  A. Segal, & Theodore J. Ruger . 2013. Supreme Court Database, Version 2013  Release 01. URL: http://supremecourtdatabase.org. Last accessed: July 17,  2014.  For the relevant page of the codebook describing the coding of cases , see  <http://scdb.wustl.edu/documentation.php?var=decisionDirection > (last visited  August 7, 2014).   34 See, e.g. , Joseph Daniel Ura, Backlash and Legitimization: Macro Political  Response to Supreme Court Decisions , 58 A M. J. POL. SCI. 110 (2014).                                                    10 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  We also instructed the research assistants to state whether  they had high confidence or low confidence about any specific coding  decision.35 Although we spot -checked the coders’ judgments,36 and  did not always agree with them, we did not correct any of their  coding decisions. There is a significant risk of unconscious bias on  our part because we, unlike the coders, know the political views of many of the authors. Thus, our dataset no doubt contains many  errors. As long as the errors in the coding are not  correlated with our  treatment variables, the direction of our results will not be affected.  We do not believe that there is such a correlation because the coders  were not provided with data on the political donations of the authors,  and did not know the p olitical views of the authors (perhaps aside  from one or two of the most prominent professors in the sample). Accordingly, coding error will not bias our results but instead only produce noise (that is, reduce the level of statistical significance). 37  Of th e 780 articles in our dataset, 512 are liberal and 237 are  conservative. The research assistants were unable to code 31 articles because they had no political valence. (We call these articles  “neutral.”) We encouraged the coders to classify the articles ev en if  they were unsure; these articles were also coded as low -confidence so  that they are treated as neutral in some of our regressions . Of the 780  articles in the sample, the political valence of 458 articles was coded  with high confidence and the politic al valence of 322 articles was  coded with low confidence.   We constructed our main dependent variable, which we call  “net conservative bias,” by taking the number of conservative articles  and subtracting the number of liberal articles. A professor who wrote   five liberal articles received a score of - 5, while a professor who wrote  five conservative articles received a score of 5. A professor who wrote  3 liberal articles, 1 conservative article, and one unclassifiable article received a score of - 2.   Note that under this measure of bias, a professor who receives  a 0 score might be one who has written two liberal papers, two  35 Although the dependent variable for our primary analysis was calculated as  the net of all conservative articles (whether they were coded with high or low  confidence) minus all liberal articles (whether they were coded with high or low confidence), during robustness checks we also use a measure of the dependent  variable that counts articles as neutral unless they were coded as conservative or  liberal with high confidence. See Part II.B.   36 We also asked some researchers to code the same articles to see if t heir views  matched (which they did to a considerable degree). For more on this test of inter - coder reliability, see infra  Part III.A.   37 For a discussion of possible sources of bias from our coding system, see infra   Part III.A.                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  11  conservative papers, and one neutral paper, or one who has written  five neutral papers. We think it is reasonable to classify both  of these  professors as unbiased. A paper that argues that the individual  mandate violates the Commerce Clause is not necessarily biased —it  may well be right. Thus, a professor who writes such a paper is not  necessarily biased. Our focus is on professors w ho consistently  produce liberal or conservative articles. An unbiased professor may  sometimes produce liberal articles, sometimes conservative articles,  and sometimes neutral articles.     3.  The Independent Variables     Our major independent variable is the political ideology of the  professors in our sample . We gathered information about campaign  contributions made by each of the professors in our dataset from the opensecrets.org website. 38 The variable (“net donations”) is equal to  political contributions to Repu blicans minus political contributions  to Democrats. We also use dummy and logged versions of this variable.    The first of these variables assumes that someone who gives  $10,000 to Republican candidates on net is ten times more  conservative than someone who  gives $1,000 to Republican  candidates. The other variables weaken this assumption.  The dummy  variable assumes that the intensity of ideology does not vary with the size of the donation; the log variable assumes that the intensity of  ideology increases wit h the size of the donation but at a declining  rate.  It is important to recognize a possible ambiguity here. A person  who makes no campaign donations is given a middle score of 0 regardless of whether she is apolitical or an ideologue who cannot  spare money  for campaign contributions or is ideologically opposed  to making campaign contributions. We will address this issue when  we discuss our results.   38 The website is run by the  Center for Responsive Politics, and makes the data  collected by the Federal Elections Commission on all political donations available  to the public. See OpenSecrets.org Donor Lookup, available at   <https://www.opensecrets.org/indivs/> (last visited July 17 , 2014).  Openserets.org has also been widely used as a source for political donation data in  academic research. See, e.g.,  Rachel Brewster & Adam Chilton, Supplying  Compliance: When and Why the United States Complies with WTO Decisions , 39  YALE J. INT’L L. (forthcoming 2014); Michael S. Rocca & Stacy B. Gordon,  Earmarks as a Means and an End: The Link Between Earmarks and Campaign  Contributions in The US House of Representatives , 75 J.  POLITICS  241 (2013);  Nikhar Gaikwad, Presidential prospects, political S upport, and Stock Market  Performance , 8 Q. J. POL. SCI. 451 (2013).                                                    12 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14   Seventy -five of the professors in our dataset were net  Democratic donors. Only 24 professors were net Republi can donors,  while 57 made no donation. The average net donation of a net  Democratic donor was $6,258, while the average net donation of a  net Republican donor was $6,200.    Finally, we use a number of control variables, several of which  are of interest. Fir st, bias in research may reflect generational norms.  As more and more social scientists join the legal academy, academic  standards from other disciplines may increasingly influence legal scholarship. To account for this, we collected the year that each  professor received his or her JD as a measure of age. 39 Second, and  related, it may be the case that scholars with PhDs write less  politically biased articles because their training encourages  objectivity and empiricism. To account for this, we coded whether  each scholar had a PhD and whether that PhD was in the social  sciences. Third, a wide range of research has revealed differences in  the political views of men and women. As a result, we coded the sex  of each professor in our sample.      II.  RESULTS     A.  Main Res ults    Figure 1 provides a graphical depiction of our data.40 The x - axis shows the natural log of net Republican donations (Republican  donations minus Democratic donations), so the negative values are  net Democratic donors. The y -axis shows the net conservat ive  valence of articles —positive numbers are net conservative articles  and the negative numbers are net liberal articles. The regression line  shows a clear slope upward, indicating that professors who make  greater contributions to Republicans also write mo re conservative  articles. Specifically, a net Democratic donor on average writes -2.63  39 For two sets of professors this information was unavailable and we were  forced to use a proxy. First, in a handful of cases, the law professors in our sample  did not have a J.D. or equivalent law degree. All of these professors, however, have a Ph.D. For these professors, we used the year they received their Ph.D. for the JD  Year  variable. Second, for one professor, despite extensive searching we were  unable to find the year that he or s he received his or her JD degree. For this  professor, we used the year the bar was passed as a proxy for the JD Year  variable.   40 Note that the regression line shown in the graph is a fit line that across the  entire data set. The regressions presented in T able 1 instead have coefficients  separately for net Democratic donors and net Republican donors. Also note that we violate the laws of mathematics by treating ln(0) as if it equals zero.                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  13  conservative articles (that is, +2.63 liberal articles), while a net  Republican donor on average writes 0.17 conservative articles. Non - donors write on average 1.44 liberal articles.41      Figure 1: Net Conservative Articles by Political Donations       In addition to analyzing our data graphically, we also analyzed  it formally with multivariate regression. Table 1 provides our primary regression results. For these regressions, the dependent variable is  once again the total number of net conservative articles (from - 5,  which means all liberal articles, to +5, which means all conservative  articles). Recall that a score of - 3 could mean that the author wrote 3  41 This information is also presented in a table in Appendix A.3.                                                     14 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  liberal articles and 2 neutral articles, or 5 liberal articles and 2  conservative articles. Our mai n treatment variables are the natural  log of net Democratic donations ( Net Dem. Donations (ln) ), and the  natural log of net Republican donations ( Net Repub. Donations (ln) ).  The first two models include these treatment variables alone; the last three add v arious controls. All of the regressions presented in Table 1  use a linear probability model. 42     Table 1: Net Conservative Articles as a Function of  Donations     (1) (2) (3) (4) (5)               Net Dem. Donations (ln)  -0.194***    -0.174***    -0.115*    (0.063)    (0.063)    (0.069)   Net Repub. Donations (ln)    0.303***    0.274***  0.204**     (0.088)    (0.090)  (0.099)   JD Year     0.029  0.044*  0.037      (0.024)  (0.024)  (0.024)   PhD     -0.964  -0.662  -0.750      (0.681)  (0.684)  (0.682)   PhD in Social Sciences     0.385  0.425  0.344      (0.884)  (0.878)  (0.874)   Male     1.614***  1.531**  1.467**      (0.601)  (0.601)  (0.599)         Observations  156 156 156 156 156  Standard errors in parentheses       *** p<0.01, ** p<0.05, * p<0.1          The results in Table 1 show that, regardless of the  specification, professors who make net donations to Democrats on average write more liberal articles on net than the remaining non - donor and Republican professors do. Similarly, they show that net Republican donors on average write more conservative articles than non- donor and Democratic professors do. These results are all  42 Although our dependent variable is categorical, for our primary results we  have chosen to analyze the data using a linear model. This is simply because linear  probability models provide a fairly similar estimation to categorical models —like  ordered logit mo dels—but the coefficients are dramatically easier to interpret. All  of the models presented in the body of the paper, however, were also estimated  using an ordered logit model (“o -logit”). These results are presented in Appendix 2.                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  15  statistically significant. They are also substantively large. As noted  above, the average net Democratic donor writes 2.63 liberal art icles  on net, while the average net Republican donor writes 0.17  conservative articles on net. One can also get a sense of magnitudes  by looking at marginal effects.43 Model 5 indicates that the maximal  donor to Democrats writes 1.2 more liberal articles than the least  generous Democratic donor. The maximal donor to Republicans  writes 2.25 more conservative articles than the least generous  Republican donor. The only oth er independent variable that achieves  statistical significance is the sex variable. Male professors write fewer  liberal articles on net. Indeed, 23 of the 24 Republican donors in our  dataset are men.   The findings in Table 1 are robust to a range of additio nal  model specifications. In Table 2, we present regressions that use both an alternative dependent variable and alternative treatment  variables. Model 1 reproduces Model 5 from Table 1 for the purpose  of comparison. But Model 2 uses an alternative dependent variable. For this regression, the dependent variable was calculated based on  the articles for which our coders had “high” confidence in their  coding decisions (and counting all “low” confidence decisions as  neutral). 44 As the results show, changing the dependent variable in  this way had essentially no effect on our results.    As a further robustness check, Models 3 and 4 use an  alternative treatment variable. For these models the treatment  variable is a dummy variable (coded as 0 or 1) for whether a profe ssor was a Net Democratic Donor  or a Net Republican Donor .  For Model 3, the dependent variable was calculated using all of the coded articles in our sample, and for Model 4 was based on the  articles that were coded with high confidence. Once again, our res ults  remained statistically significant and nearly identical to the primary  results presented in Table 1. 45         43 The marginal effects were calculated by moving one variable from its  minimum to maximum value while holding all other covariates at their means.   44 For this dependent variable, all articles that were coded with low confidence  where counted as “neutral.” For example, if our cod ers determined that a professor  wrote 5 liberal articles, but only 2 of these articles were coded with high  confidence, under this coding the professor would have a score of - 2.   45 Appendix B reports the results of all of the regressions reported in Table 2  while using an ordered logit model instead of a linear probability model.                                                    16 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  Table 2: Robustness Checks of Net Conservative Articles  as a Function of Donations     (1)  All  Coded   Articles  (2)  “High”  Confidence  Articles  (3)  All  Coded   Articles  (4)  “High”  Confidence  Articles  (5)  All  Coded   Articles  (6)  “High”  Confidence  Articles                 Net Dem. Donations (ln)  -0.115*  -0.116**          (0.069)  (0.054)        Net Repub. Donations (ln)  0.204**  0.148*          (0.099)  (0.079)        Net Dem. Donor (dummy)    -1.081*  -0.990**        (0.550)  (0.439)     Net Repub. Donor (dummy)    1.395*  0.944        (0.781)  (0.624)     Liberal CF Score      -0.924**  -0.702**        (0.381)  (0.306)   Conservative CF Score      2.265***  1.721***        (0.807)  (0.649)   JD Year  0.037  -0.003  0.039  -0.002  0.043*  0.003    (0.024)  (0.019)  (0.024)  (0.019)  (0.023)  (0.019)   PhD  -0.750  -0.134  -0.725  -0.112  -0.622  -0.025    (0.682)  (0.541)  (0.679)  (0.542)  (0.664)  (0.533)   PhD in Social Sciences  0.344  0.004  0.246  -0.066  0.165  -0.106    (0.874)  (0.694)  (0.876)  (0.699)  (0.871)  (0.700)   Male  1.467**  1.001**  1.496**  1.044**  1.650***  1.167**    (0.599)  (0.476)  (0.598)  (0.477)  (0.587)  (0.472)           Observations  156 156 156 156 156 156  Standard errors in parentheses         *** p<0.01, ** p<0.05, * p<0.1              Finally, as a further robustness check, in Models 5 and 6 we  use yet another treatment variable. For these models, the treatment  variable is whether the professor had a liberal or conservative CF  Score . A CF Score  is a measure of ideology created by Adam Bonica  that uses political donations data to determine the intensity of the  liberal or conservative views of donors based on the voting record of  the candidates they donated to.46 Under Bonica’s system, a  46 See Bonica, supra  note 22; Bonica, supra  note 27: Bonica & Sen, supra  note                                                   11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  17  Democratic donor who donated $1,000 to Dennis Kucinich receives a  more liberal score than a Democratic donor who donated $1,000 to  Hillary Clinton. Using this alternative treatment variable, our results  remain substantively the same. Having a more liberal CF Score  is  associated with writing more liberal articles, and having a more  conservative CF Score  is associated with writing more conservative  articles.     B.  Using Additional Data to Determine Political Affiliation     One shortcoming of using political donations as a pr oxy for  ideology is that not everyone makes campaign contributions. In fact,  37% of the professors in our sample have not made a campaign  contribution (or one that was reported to the Federal Elections Commission). It is likely that most non -donors have po litical  commitments. Moreover, our initial coding revealed only eight Republican net donors, which weakened the statistical significance of our net Republican variables in the previous regressions.   To address this concern, we decided to code the ideology of  the remaining 57 non -donor professors based on information  available on their CVs. We coded professors who had previously held a political appointment as being a member of that political party (i.e., Bush appointees as Republicans, and Clinton or Obama appointees  as Democrats). Additionally, professors who had held an official  position with the Federalist Society were coded as Republicans, and  professors who have held an official position with the American  Constitution Society were coded as Democrats. 47 Finally, we coded  professors who had worked for right leaning think tanks— like CATO  or the American Enterprise Institute— as Republicans, and professors  who had worked for an international organization like the United  Nations as Democrats. Using this approac h, we were able to code an  additional 28 professors as Democrats and an additional 12  professors as Republicans. Seventeen professors remained unclassifiable.    We combined this new coding with our initial coding of  whether a professor was a Net Democratic  Donor or a Net  Republican Donor to produce the new variables Democrat  (Adjusted) and Republican (Adjusted). To graphically depict this  28, Bonica, supra  note 30 .  47 We did not code anyone as a Democrat or Republican based on his or her  affiliation with these organizations if they had merely attended a conference or  spoken at an event.                                                                                                                               18 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  relationship, Figure 2 uses the same approach as Figure 1, and plots  the relationship between these variables and our key dependent  variable: net conservative articles. As Figure 2 shows, there is a  strong relationship between (adjusted) political affiliation and the  political leanings of academic articles. In fact, the effect is only  stronger when using this approach.     Figure 2: Net Conservative Articles by Adjusted Political  Affiliation       Once again, we used multivariate regressions to analyze the  relationship between adjusted political ideology and the bias of each author’s scholarship. To do so, we recreated Table 1 but used these new treatment variables. The results from this analysis —which are  presented in Table 3 —reveal that there is a statistically significant  relationship between ideology and the leanings of each authors’  scholarship. Moreover, the magnitudes of the effects are larger than  the results presented in Table 1. These resul ts are additionally robust  11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  19  to all of the alternative specifications we presented in Table 2.48    Table 3: Net Conservative Articles as a Function of  Adjusted Political Affiliation     (1) (2) (3) (4) (5)               Democrat (Adjusted)  -2.670***    -2.419***    -2.092**    (0.503)    (0.517)    (0.804)   Republican (Adjusted)    2.544***    2.253***  0.476     (0.580)    (0.588)  (0.894)   JD Year     0.026  0.036  0.027      (0.023)  (0.023)  (0.023)   PhD     -0.823  -0.650  -0.777      (0.653)  (0.670)  (0.660)   PhD in Social Sciences     0.193  0.340  0.196      (0.848)  (0.864)  (0.850)   Male     1.207**  1.424**  1.206**      (0.586)  (0.593)  (0.588)         Observations  156 156 156 156 156  Standard errors in parentheses       *** p<0.01, ** p<0.05, * p<0.1            C.  Do Republican Donors Write Less Ideologically Biased  Scholarship Than Democratic Donors Do?      According to our coding system, net Democratic donors write  highly ideological articles, whereas net Republican donors write articles that are distributed widely across the spectrum. The average   net Democratic donor writes 2.63 liberal articles on net, while the  average article of a net Republican donor writes 0.17 conservative  articles on net, which is even closer to 0 than the number of article  written by non -donors, who on average write 1.44 l iberal articles on  net. Figure 3 shows the distribution for Republicans and Democrats.  The modal net Democratic donor writes five out of five liberal  articles. Does this mean that Republican donors write less  ideologically biased scholarship than Democrati c donors do?     48 The results of these robustness  tests are presented in Appendix C.                                                    20 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14      Figure 3: Ideological Valence of Articles Written by  Democratic and Republicans           Professors who are Democrats (adjusted) —shown in the left  panel —have an average article ideology of - 2.67 with a 90%  confidence interval of - 3.13 to - 2.21. Using a t -test, we can say that  this is statistically different from zero (p -value < 0.00). Professors  who are Republicans (adjusted)— shown  in the right panel —have an  average article ideology of 0.17 with a 90% confidence interval of - 0.72 to 1.10. For these professors, we cannot reject the possibility  that the true net ideology of their articles is zero (p -value = 0.72). In  other words, our data suggest that Democrats in our sample do not  write articles that are on balance neutral, but that Republicans in our  sample may write articles that are on balance neutral. 49  These results, however, must be interpreted with caution for  several reasons. F irst, we have many fewer net Republican donors in  our dataset than Democrats and non -donors, and accordingly the  ideological distribution of the articles Republicans write may not  represent the entire population of Republican law professors.  Second, it is possible that the coding scheme encouraged our coders  to interpret articles to be more liberal than they in fact are. That  might explain why non -donors skew liberal. If we take the non -donor  scholarship as the neutral baseline, then the Republicans are alm ost  exactly as ideological as the Democrats are —the two groups are close  49 Forty percent of the articles written by Democrats (adjusted) could not be  classified with high confidence, 51 percent of articles written by Republicans  (adjusted) could not be classified with high confidence. If such articles are  “neutral,” then Republicans wrote substantially more neutral articles.                                                     11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  21  to equidistant from the neutral score . Third, the distributions may  reflect the influence of constitutional law scholarship. Just by chance,  none of the net Republican donors in our d ataset are constitutional  law scholars, and only one of the adjusted Republicans is. If  constitutional law scholarship is more ideological than other forms of  scholarship,50 the different distributions may show that Democrats  are more likely to write constitutional law scholarship but not that  they are otherwise more likely to write ideologically than  Republicans.  Fourth, it is in principle possible that background legal  and political circumstances justify what appears to be an ideological  tilt in scholarshi p. If Hitler were elected, and replaced the judiciary  with Nazi judges, while leaving the law schools alone, we suspect that nearly all professors would write papers criticizing the judges’ right - wing jurisprudence, and rightly so.    With those caveats in m ind, if it is in fact the case that  Republicans write less ideologically biased scholarship than  Democrats do, then one would naturally ask why. The most plausible explanation is that if the dominant ethos in the top law schools is  liberal or left -wing, 51 then Republicans are likely to conceal their  ideological views in their writings. Republican professors might fear that scholarship that appears conservative may be rejected by left - leaning law review editors, and disparaged or ignored by their  colleagues, which will damage their chances for promotions, research  money, and lateral appointments. This would explain why even non-donors tilt left. Republicans could suppress their ideological views by avoiding controversial topics, taking refuge in fields that ha ve little  ideological valence, focusing on empirical or analytical work, or simply writing things that they don’t believe.      D.  Differences Across Fields    Some readers may be interested in whether the research of  faculty at different law schools or working i n different fields displays  different levels of ideological bias. Data limitations prevent us from providing firm conclusions on these issues. Because we select only  ten law professors from each law school, and code the professor  based on only five articles, we are hesitant about drawing  50 A possibility that we explore in Section D, below.   51 As suggested by McGinnis et al., supra  note 6. See also  Adam Bonica & Maya  Sen, Whom Does the Judiciary Represent?, Working Paper (2014), at 16 (on file  with authors) (providing data that show that lawyers skew left and academics skew  left). The Bonica & Sen paper does not isolate legal academics.                                                    22 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  conclusions about whether specific law schools produce more  ideologically biased scholarship than other law schools. Such an  investigation would require more data.    However, we can shed some light on the question of whether   ideological bias differs in different areas of scholarship. The coding  categories in the judicial behavior literature do not track the fields of legal scholarship perfectly, but there is a rough correspondence.  Under the Spaeth et al. coding scheme, legal  opinions are divided  into one of six categories. We asked our coders to determine which of  these six categories was the closest fit for each article. If three of the  five articles a professor wrote were in the same category, we coded  that professor as wri ting in that category.     Table 4: Ideologically Biased Research by Field   Cat. Description  # Dem  Donors  # Rep  Donors  # Non - Donors  Mean  Net Dem  Donation  Mean  Net Rep  Donation  Mean  Conserv.   Articles  by Dem  Donors  Mean  Conserv   Articles  by Rep  Donors   1 Constitutional  Rights  20 1 5 8,095  1,650  -4.00  -1.00   2 Economic Activity  & Unions  8 6 16 8,306  2,500  -2.25  1.00   3 Judicial Power  3 1 0 4,183  4,550  -1.67 -1.00   4 Federalism  1 0 0 2,300  -- -5.00  --  5 Federal Taxation  2 0 0 5,100  -- -1.00  --  6 Miscellaneous  28 13 26 4,942  4,690  -2.18  -0.08       As Table 4 shows, category 1 corresponds roughly to  constitutional law scholarship that focuses on individual rights. Most  private law scholarship falls into category 2, which includes  economic activity, and category 6, which covers miscellaneous fields. The data presented in Table 4 suggest that constitutional rights  scholars are less ideologically diverse than other legal scholars.  Among constitutional rights scholars, 77% are net Democratic  donors, and 4% are net Republican donors. In the rest of the sample,  40% are net Democratic donors, and 20% are net Republican donors.  It also shows that constitutional rights scholars are more likely to  produce biased research (mean of - 3.85 conservative articles) th an  Republican and Democratic scholars in other fields (mean of - 1.35  conservative articles).   11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  23  III.  DISCUSSION     A.  Qualifications     Before discussing the implications of our results, we should  acknowledge some possible statistical limitations of our study. First ,  the generalizability of our results may be limited because our sample  is not representative in several ways. Our sample was drawn entirely  from professors at top -14 law schools, and it might be the case that  professors at other schools write scholarship that is less —or more — biased. Additionally, our sample consists entirely of tenured,  academic faculty. Repeating our analysis on a sample of other types  of legal academics —like assistant professors— might produce  different results. Finally, we coded the five articles that professors  wrote most recently. It is possible that articles coded from different  periods would have different ideological slants.   Second, there are a number of possible problems with our  method of coding the bias of articles. One possible problem is that  the decision s made by our coders might skew liberal or conservative.  For example, a liberal coder might interpret “neutral” articles as  conservative because they are conservative from her perspective; or a  liberal coder might interpret “neutral” articles as liberal, because  they appear reasonable and she assumes that reasonable arguments  are liberal. Moreover, because our coders coded different groups of  articles, there may be inconsistencies in the coding across articles. We are skeptical that this is a problem because coders were given  random samples of the articles, but we nonetheless  took two steps to  address the issue: (a) we  ran regressions that accounted for  differences between coders and found largely the same results ; 52 and  (b) we asked multiple people  to code th e same article and found high  rates of consistency.53  A further concern is that our coders ’ judgments  may have  been biased based on prior knowledge of the authors ’ political  leanings. As previously noted, w e do not believe that this is likely to  52 To do so, we estimated all of the regressions in Table 2 while including  “coder” fixed effects. This allowed for the possibility that there were systematic  differences between coders. This pro duced largely the same results as our baseline  regressions reported in Table 2 that did not include coder fixed effects.   53 We specifically asked a second coder to code a sample of 180 the 780 articles  in our dataset. Doing so revealed a high rate of inter -coder reliability. Our coders  made the same decisions 73% of the time, and when we relied exclusively on  decisions where both coders had high confidence in their decisions, the coders  made the same decision 92% of the time.                                                    24 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  be a signif icant problem because the coders were unlikely to have  previously heard of all but a few of the most prominent professors in  our sample. The exception, however, is that our coders are students  at the University of Chicago Law School and they are likely fam iliar  with a number of professors in the sample from the University of  Chicago. To account for that possibility, we replicated our analysis while dropping Chicago faculty from out sample. After doing so, the  results were substantively the same. 54  Finally, t he Spaeth et al. coding system was not designed with  law review articles in mind and is not a perfect fit.55 Law review  articles are not judicial opinions, after all.  We readily acknowledge  the possibility that coders were misled by the Spaeth et al. system ,  but we do not think this problem is a serious one. Most law review  articles, like most cases, can be easily classified along ideological  lines —as favoring the government or criminal defendants, for  example, or as advocating an expansion of  liability or a  reduction of   it. Many law review articles are technical and hard to code; but that is  true for many cases as well , which can turn on complex questions of  jurisdiction that have no clear ideological valence. Our main effort to address this problem was to a sk our coders to code decisions with  either “low” or high” confidence.” As Models 2, 4, and 6  demonstrated, our results are robust to treating all articles where our  coders had low confidence as neutral. Beyond this empirical test,  however, we would argue that the use of the Spaeth et al. coding  system has an advantage because it was not designed with law review  articles in mind: it reduces the risk that a coding system that we  produced for our purposes might reflect our own unconscious biases.  In sum, these problems are real but their main effect should be to  add noise to our results —to reduce statistical significance —and not to  bias them.   Third, another concern is reverse causation, which in our  context would mean that professors (perhaps with an open mind )  write a number of articles about legal topics and discover pervasive  54 There are 11 professors from  the University of Chicago Law School in our  sample. Of those 11, 10 were from our initial random sample and 1 was from our  attempt to oversample Republicans. See supra  text accompanying notes 27 - 31.  After dropping these professors from our sample we estimated the regressions  reported in Table 2 with the remaining sample o f 145 professors, which produced  results that were substantively similar.   55 It is important to note that it has been argued that the Speath et al. coding  system is not a perfect classification for legal cases. See Shapiro, supra  note 19.  That said, despite these criticisms, the Speath coding system is the dominate  method used to study the ideological leanings of judicial decisions in the United  States.                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  25  error in one ideological direction or another. Suppose, for example, a  professor decides to write about same- sex marriage and discovers  that courts repeatedly err, based on the professo r’s best view of the  legal sources, by recognizing rights to same -sex marriage.  Accordingly, he comes to the view that too many ideologically liberal judges sit on the bench, and starts making donations to Republican political candidates in the hope that t hey will be elected and appoint  less ideologically biased judges.  This story seems implausible. By the  time someone is old enough to receive tenure at a law school, that person will almost certainly have well- defined if not rigid political  views. 56 Casual empiricism on our part indicates that law professors’  political views are established long before they start writing articles.      B.  Interpretation of the Results     With those qualifications in mind, we turn to the  interpretation of our results. To rei terate, we find that law professors  who donate to Democrats write articles that are net liberal, and law professors who donate to Republicans write articles that are net  conservative. Non -donors write articles that fall between these two  extremes. Numerous  robustness checks confirm these results.   This could mean one (or both) of two things. First, a (say)  liberal professor might offer an interpretation of a legal text that  advances liberal values but is not the best interpretation of that text. Let’s call t his phenomenon “substantive bias.” Substantive bias could  be of two types. A professor may deliberately make arguments that she knows to be wrong because she hopes to advance a political  agenda. Probably more common, a professor may sincerely believe  her b iased argument because she has strong ideological priors that  influence how she interprets legal sources. In legal scholarship,  unlike the sciences, there are few, perhaps no, objective ways for  resolving disagreement; thus, there is much  room for priors t o  influence people’s sincere views about legal issues.   Second, the professor might search out research problems  where it happens to be the case that the correct outcome is liberal.  We call this  phenomenon “selection bias.” Imagine, for example, that  56 Yair Ghitza & Andrew Gelman, The Great Society, Reagan’s Revolution, and  Generations of Presidential Voting , Working Paper (2014), available at  <http://www.stat.columbia.edu/~gelman/research/unpublished/cohort_voting_2 0140605.pdf> (last visited July 17, 2 014)  (finding that the presidents that people  vote for is to a significant extent determined by the political events they witness as  teenagers and young adults) .                                                    26 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  court #1 has wrongly interpreted statute A in a liberal direction, and  court #2 has wrongly interpreted unrelated statute B in a  conservative direction. A liberal professor might exercise selection  bias without engaging in substantive bias by writing an article  criticizing court #2 while ignoring court #1.   Another version of the selection bias story is that when  applicants for legal academic positions go on the job market, they select a field in which they believe that they could make the most  important contribu tions, from a moral or ideological standpoint. For  example, a liberal applicant who believes that courts have failed to  provide adequate protection to criminal defendants may select  constitutional law or criminal procedure. This person would then  write lef t-leaning articles over the course of her career.    Our results are consistent with both types of bias— substantive  and selection. There is a parallel ambiguity in the judicial behavior literature. The results in that literature are consistent with both a  substantive bias hypothesis that judges choose outcomes that  advance their ideological preferences (whether consciously or  unconsciously), and a selection bias hypothesis that politicians  appoint judges whose good -faith legal views happen to coincide with  the ideological preferences of the politicians.    The implications of each interpretation are different. As we  discuss in Section C, substantive bias is more troubling than selection  bias, which can be corrected if law schools hire faculty members with  divers e ideological views. It  is less clear how substantive bias can be  corrected.       C.  Implications      The purpose of our study is not to condemn law professors but  to provoke reflection about the role of ideology in legal scholarship. We can imagine a few reactions to our findings.     1.  They don’t matter     Ever since legal realism, we have understood that legal  reasoning is not divorced from politics. It is natural and inevitable that liberals and conservatives interpret legal sources differently. It is a legit imate feature of legal scholarship that moral standpoints affect  legal conclusions. Consider, as a point of comparison, moral philosophy or political theory. Liberals argue in favor of liberal institutions because liberal institutions advance liberal value s.  11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  27  Libertarians extol individual freedom; it is hardly surprising that  they are skeptical of government programs. Social conservatives  criticize abortion, secular education, and gay marriage because they  believe that these practices violate important moral  values and erode  social solidarity. Legal scholarship is itself just a form of moral and  political debate that is focused on law rather than public policy generally.    This may well be true. Ronald Dworkin famously argued that  the right judicial outcome must integrate legal sources and moral principles. 57 But Dworkin never argued that the right legal answer  must conform to the (possibly mistaken) moral views of the judge or academic. Even on Dworkin’s approach, the quality of a legal  argument is independent of the ideological bias of the person who  makes the argument.    Our view is that while some legal scholarship is openly  committed to advancing a specific political or ideological agenda, 58  most is not. Even in the most clearly normative articles, scholars  appeal to common values, constitutional norms, precedents, and  other sources that are “neutral” in the sense that everyone in principle accepts them as sources of authority. If this were not the  case, then the frequent charge of ideological bias that law pro fessors  fling at each other would make no sense.     2.  They cast doubt on the value of legal scholarship     Law professors are paid to do research, not to publish their  political opinions. Most legal research is presented as an objective account of the law. Whe n law professors criticize judicial opinions,  they almost always say or at least imply that the judges committed a legal error. The claim that an error in legal reasoning exists should be  independent of the politics of the person who makes that claim. Just   as we criticize judges who allow their political opinions to influence  their interpretations of legal texts, we should criticize law professors  who allow their political opinions to influence their interpretations of  legal texts. In fact, we do this all t he time. 59 Our findings suggest that  law professors often  fail to satisfy a basic criterion of good  scholarship.    This argument raises difficult questions about what exactly  57 See R ONALD DWORKIN , LAW’S EMPIRE  (1986).   58 See, e.g. , THE CONSTITUTION IN 2020  (JACK M. BALKIN & REVA B. SIEGEL EDS .  2009 ) (discussing ways in advancing progressive values in constitutional law).   59 See supra  notes 1  - 5.                                                   28 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  legal scholarship is supposed to accomplish. One possibility is that it  is supposed  to improve our understanding of the law. If legal  scholarship were purely empirical or analytical, the charge of  ideological bias is troubling. Another possibility is that legal  scholarship is supposed to improve the world. As noted above, it  would not be  surprising if normative scholarship reflects certain  ideological biases, but it is also the case that most normative  scholarship does not present itself as ideological argument but as  based on authoritative legal sources. A more appropriate interpretation  of our findings is that they raise questions about the  value of some  legal scholarship, but certainly not all.     3.  Law faculties need “balance.”     Political bias in scholarship is inevitable; it is human nature.  Indeed, biases of various sorts infect all kinds of scholarship, even the sciences. Consider for example, the ideologically tinged debates about the role of genes in behavior. 60 Interaction and debate among  people with different views ensures that in the long run research results will be objective. The appropriate response to our results is to  ensure that people with different political views are represented in  law schools. The lament that there are too few conservatives in the law schools 61 (or at least too few conservatives who are ideologically  passionate enough to make donations and write conservative  articles) turns out to be a reasonable one, and we should correct this problem by hiring more conservatives even if this means lowering  academic standards . For many people, however, this may be too hi gh  a price to pay.    As noted earlier, a balanced faculty will be particularly helpful  if the selection bias hypothesis is correct. Balance would ensure that  law professors ferret out liberal biases in judicial opinions as well as  conservative biases in jud icial opinions.     4.  Institutional fixes are available.     Most legal scholarship (including nearly all the articles in our  sample) is published in law reviews. It is possible that for many law review editors, who are not experienced academics, the  persuasiven ess of an article depends, at least in part, on its  60 See, e.g. , Richard Dawkins, Sociobiology: The Debate Continues , NEW  SCIENTIST  (Jan. 24, 1985).   61 See Dent, supra note 7                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  29  consistency with their ideological priors. Imagine, for example, an  article that argues that same -sex marriage should receive  constitutional protection and an article that makes the contrary  argument. From a scholarly perspective, the first article should not  be published if it simply repeats arguments that have been made  before, while the second article should be published if it makes novel and interesting arguments. Students with little knowledge of the  underlying literature might accept the first article and reject the  second because they find the ultimate conclusion of the first article more persuasive than that of the second, based on their ideological  priors. Anticipating bias in the selection process , authors might  writes articles with an ideological tilt that they believe that students will be receptive to.    Peer review might help address the problem of political bias in  the selection of articles for publication. Authors might hesitate about making i deological claims if they know that experts in the field rather  than law students will evaluate their work. And while it is true that  many referees may share the author’s political biases, referees who  share authors’ ideological predispositions are likely to reject papers  that reflect a shared ideological bias if those papers are unoriginal,  fail to give credit to previous work, or are analytically flawed. For  these reasons, law reviews that do not already use peer review might consider doing so.       C ONCLUSI ON    Many law professors derive professional pride from their  influence on the development of the law. Law professors, unlike other types of academics, directly influence the law by writing articles that judges read and occasionally cite in judicial opinions.  However, if their articles are seen as “rationalizations of their  authors’ political ideology,” 62 they may well lose whatever influence  they have. Indeed, one court has expressed skepticism about  international law scholarship, noting that the “pra ctice of relying on  international law scholars for summaries and evidence of customary international law —that is, as secondary or ‘subsidiary’ sources of  international law —makes less sense today because much  contemporary international law scholarship is ‘c haracterized by  normative rather than positive argument, and by idealism and  62 See Richard A. Posner, The State of Legal Scholarship Today: A Comment  on Schlag , 97 G EO. L.J. 845, 853 (2009).                                                    30 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  advocacy.’”63 We suspect that other judges take the same line on  constitutional law scholarship, and if such skepticism spreads, law  professors will lose influence on the development of the law.64   It is important not to misinterpret our findings. Our empirical  results do not prove that all of legal scholarship is biased. Our coders  were unable to classify numerous articles with high confidence. Nor do our results prove that law professors self -consciously generate  biased scholarship.  Selection -effect mechanisms and reliance on  priors seem more plausible.  Our findings  raise rather than answer  questions about the relationship between ideology and scholarship,  and whether law faculties should be more ideological ly diverse. But  we believe that our findings are  strong enough results to justify  further research in this area.   We can see several directions in which research may proceed.  Our main concern is that the coding of the law review articles for ideological valence may be inaccurate; there are no doubt other  approaches that could be used, including, for example, coding by scholars rather than by students. Using a larger database, one could  determine whether ideological bias is more co mmon in some areas of  legal scholarship than others— for example, normative versus  empirical scholarship, or public law versus private law. One might  also find (contrary to our results) that different types of training and background lend themselves to diff erent levels of ideological bias.  Other types of bias might be investigated —for example, bias  introduced into the work of law professors who consult and have a financial interest in a specific outcome. Medical researchers have  attempted to determine whether financial interests have influenced  medical research. 65 Researchers should use our methodology— which  relies on coding of research rather than on surveys of academics’  beliefs —to investigate ideological bias in other areas of scholarship,  such as economics , history, and political science.   63 Flores v. Southern Peru Copper Corp., 414 F.3d 233, 251 n.26 (2003)  (quoting Remarks of Jack L. Goldsmith, Panel Discussion, Scholars in the  Construction and Critique of International Law , 94 AM. SOC’Y INT’L L. PROC. 317,  318 (2000)).   64 See, e.g.,  Posner,  supra  62.  65 Justin E. Bekelman, Yan Li, & Cary P. Gross, Scope and Impact of Financial  Conflicts of Interest in Biomedical Research , 289 J. AM. MED. ASSOC . 454 (2 003)  (finding evidence of financial relationships between researchers and industry and  that those relationships can influence research results); Joel Lexchin, Lisa A Bero,  Benjamin Djulbegovic, & Otavio Clark, Pharmaceutical industry sponsorship and  research outcome and quality: systematic review , 326 BMJ 1167 (2003) (finding  that research on drugs sponsored by the drug’s maker was more likely to reach a  favorable result).                                                    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  31  APPENDIX     A.  Summary Statistics       1. Breakdown of the Sample   Democratic   Donors (net)  No   Donations  Republican    Donors (net)   75 57 24          2. Summary Of Independent Variables    Mean  Std. Dev.  Min  Max   Net Dem. Donations (ln)  3.71 4.02  0 10.75   Net Repub. Donations (ln)  1.19 2.84  0 11.02   Net Dem. Donor (dummy)  0.48  0.50  0 1  Net Repub. Donor (dummy  0.15  0.36  0 1  Liberal CF Score  0.45  0.67  0 3.95   Conservative CF Score  0.12  0.32  0 1.16  JD Year  1984  11.52  1960  2007   PhD  0.33  0.47  0 1  PhD in Social Sciences  0.16  0.37  0 1  Male  0.74  0.45  0 1        3. Summary of the Dependent Variable by Donor Type   (All Coded Articles)    Mean  Std. Dev.  Min  Max   Net Dem. Donor  -2.63  2.92  -5 5  No Donations  -1.44  3.36  -5 5  Net Repub. Donor  0.17 2.94  -5 5  Overall  -1.76 3.23  -5 5          32 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14          4. Summary of the Dependent Variable by Donor Type   (“High Confidence” Articles)    Mean  Std. Dev.  Min  Max   Net Dem. Donor  -2.11 2.31 -5 5  No Donations  -1.14 2.68  -5 5  Net Repub. Donor  0.13  2.25  -5 5  Overall  -1.41 2.55  -5 5        5. Coding of Articles    Liberal  Don’t Know  Conservative  Total   All Coding Decisions  512 (66%)  31 (4%)  237 (30%)  780  High -Confidence Decisions  330 (42%)  340 (44%)  110 (14%)  780    11-Aug-14] POLITICAL BIAS IN LEGAL SCHOLARSHIP  33  B.  Robustness Checks Using Ordinal Logit (“O -Logit”) Model       (1)  All  Coded   Articles  (2)  “High”  Confidenc e Articles  (3)  All  Coded   Articles  (4)  “High”  Confidenc e Articles  (5)  All  Coded   Articles  (6)  “High”  Confidenc e Articles                 Net Dem. Donations (ln)  -0.068  -0.088**          (0.042)  (0.042)        Net Repub. Donations (ln)  0.119**  0.110*          (0.057)  (0.059)        Net Dem. Donor (dummy)    -0.616*  -0.737**        (0.333)  (0.332)     Net Repub. Donor  (dummy)    0.823*  0.668        (0.448)  (0.460)     Liberal CF Score      -0.559**  -0.495**        (0.242)  (0.231)   Conservative CF Score      1.247***  1.225***        (0.468)  (0.473)   JD Year  0.024*  0.001  0.025*  0.002  0.026*  0.005    (0.014)  (0.014)  (0.014)  (0.014)  (0.014)  (0.013)   PhD  -0.135  0.058  -0.124  0.075  -0.093  0.149    (0.398)  (0.396)  (0.398)  (0.396)  (0.387)  (0.385)   PhD in Social Sciences  -0.102  -0.150  -0.160  -0.217  -0.091  -0.177    (0.509)  (0.501)  (0.512)  (0.504)  (0.508)  (0.502)   Male  0.916**  0.775**  0.933**  0.814**  0.986***  0.903**    (0.375)  (0.355)  (0.374)  (0.354)  (0.373)  (0.353)           Observations  156 156 156 156 156 156  Model  O-Logit  O-Logit  O-Logit  O-Logit  O-Logit  O-Logit   Standard errors in parentheses         *** p<0.01, ** p<0.05, * p<0.1                 34 POLITICAL BIAS IN LEGAL SCHOLARSHIP  [11-Aug-14  C.  Robustness Checks Using Adjusted Political Affiliation         (1)  All   Coded   Articles  (2)  “High”  Confidenc e Articles  (3)  All   Coded   Articles  (4)  “High”  Confidenc e Articles         Democrat (Adjusted)  -2.092**  -1.500**  -1.172**  -1.200**    (0.804)  (0.631)  (0.484)  (0.496)   Republican (Adjusted)  0.476  0.880  0.335  0.583    (0.894)  (0.701)  (0.530)  (0.546)   JD Year  0.027  -0.009  0.021  -0.002    (0.023)  (0.018)  (0.014)  (0.014)   PhD  -0.777  -0.082  -0.179  0.068    (0.660)  (0.517)  (0.401)  (0.395)   PhD in Social Sciences  0.196  -0.119  -0.199  -0.243    (0.850)  (0.667)  (0.521)  (0.511)   Male  1.206**  0.760  0.766**  0.630*    (0.588)  (0.461)  (0.379)  (0.357)        Observations  156 156 156 156  Model  OLS  OLS  0-Logit  0-Logit   -- Standard errors in parentheses   -- *** p<0.01, ** p<0.05, * p<0.1                                                                                                 Readers with comments should address them to:    Professor  Adam S. Chilton    adamchilton@uchicago.edu      Chicago Working Papers in Law and Economics   (Second Series)     For a listing of papers 1– 600 please go to Working Papers at  http://www.law.uchicago. edu/Lawecon/index.html     601. David A. Weisbach, Should Environmental Taxes Be Precautionary? June 2012   602. Saul Levmore, Harmonization, Preferences, and the Calculus of Consent in Commercial and Other  Law, June 2012  603. David S. Evans, Excessive Litigati on by Business Users of Free Platform Services, June 2012   604. Ariel Porat, Mistake under the Common European Sales Law, June 2012   605. Stephen J. Choi, Mitu Gulati, and Eric A. Posner, The Dynamics of Contrat Evolution, June 2012   606. Eric A. Posner and D avid Weisbach, International Paretianism: A Defense, July 2012   607 Eric A. Posner, The Institutional Structure of Immigration Law, July 2012   608. Lior Jacob Strahilevitz, Absolute Preferences and Relative Preferences in Property Law, July 2012   609. Eric A.  Posner and Alan O. Sykes, International Law and the Limits of Macroeconomic  Cooperation, July 2012  610. M. Todd Henderson and Frederick Tung, Reverse Regulatory Arbitrage: An Auction Approach to Regulatory Assignments, August 2012  611. Joseph Isenbergh, C liff Schmiff, August 2012   612. Tom Ginsburg and James Melton, Does De Jure Judicial Independence Really Matter?  A Reevaluastion of Explanations for Judicial Independence, August 2012   613. M. Todd Henderson, Voice versus Exit in Health Care Policy, October  2012   614. Gary Becker, François Ewald, and Bernard Harcourt, “Becker on Ewald on Foucault on Becker”  American Neoliberalism and Michel Foucault’s 1979 Birth of Biopolitics  Lectures, October 2012   615. William H. J. Hubbard, Another Look at the Eurobaromete r Surveys, October 2012  616. Lee Anne Fennell, Resource Access Costs, October 2012   617. Ariel Porat, Negligence Liability for Non -Negligent Behavior, November 2012   618. William A. Birdthistle and M. Todd Henderson, Becoming the Fifth Branch, November 2012   619. David S. Evans and Elisa V. Mariscal, The Role of Keyword Advertisign in Competition among  Rival Brands, November 2012   620. Rosa M. Abrantes -Metz and David S. Evans, Replacing the LIBOR with a Transparent and  Reliable Index of interbank Borrowing: Com ments on the Wheatley Review of LIBOR Initial  Discussion Paper, November 2012   621. Reid Thompson and David Weisbach, Attributes of Ownership, November 2012   622. Eric A. Posner, Balance- of-Powers Arguments and the Structural Constitution, November 2012   623. David S. Evans and Richard Schmalensee, The Antitrust Analysis of Multi -Sided Platform  Businesses, December 2012   624. James Melton, Zachary Elkins, Tom Ginsburg, and Kalev Leetaru, On the Interpretability of Law:  Lessons from the Decoding of National Cons titutions, December 2012   625. Jonathan S. Masur and Eric A. Posner, Unemployment and Regulatory Policy, December 2012   626. David S. Evans, Economics of Vertical Restraints for Multi -Sided Platforms, January 2013  627. David S. Evans, Attention to Rivalry am ong Online Platforms and Its Implications for Antitrust  Analysis, January 2013   628. Omri Ben -Shahar, Arbitration and Access to Justice: Economic Analysis, January 2013   629. M. Todd Henderson, Can Lawyers Stay in the Driver’s Seat?, January 2013   630. Stephe n J. Choi, Mitu Gulati, and Eric A. Posner, Altruism Exchanges and t he Kidney Shortage,  January 2013  631. Randal C. Picker, Access and the Public Domain, February 2013   632. Adam B. Cox and Thomas J. Miles, Policing Immigration, February 2013  633. Anup Malani and Jonathan S. Masur, Raising the Stakes in Patent Cases, February 2013  634. Arial Porat and Lior Strahilevitz, Personalizing Default Rules and Disclosure with Big Data,  February 2013  635. Douglas G. Baird and Anthony J. Casey, Bankruptcy Step Zero, Fe bruary 2013   636. Oren Bar -Gill and Omri Ben -Shahar, No Contract?   March 2013   637. Lior Jacob Strahilevitz, Toward a Positive Theory of Privacy Law, March 2013   638. M. Todd Henderson, Self -Regulation for the Mortgage Industry, March 2013  639 Lisa Bernstein , Merchant Law in a Modern Economy, April 2013   640. Omri Ben -Shahar, Regulation through Boilerplate: An Apologia, April 2013       641. Anthony J. Casey and Andres Sawicki, Copyright in Teams, May 2013   642. William H. J. Hubbard, An Empirical Study of the Effect of Shady Grove v. Allstate  on Forum  Shopping in the New York Courts, May 2013  643. Eric A. Posner and E. Glen Weyl, Quadratic Vote Buying as Efficient Corporate Governance, May  2013  644. Dhammika Dharmapala, Nuno Garoupa, and Richard H. McAdams, Punitive Polic e? Agency  Costs, Law Enforcement, and Criminal Procedure, June 2013  645. Tom Ginsburg, Jonathan S. Masur, and Richard H. McAdams, Libertarian Paternalism, Path  Dependence, and Temporary Law, June 2013   646.  Stephen M. Bainbridge and M. Todd Henderson,  Boards -R-Us: Reconceptualizing Corporate    Boards, July 2013  647.  Mary Anne Case, Is There a Lingua Franca for the American Legal Academy?  July 2013  648.  Bernard Harcourt, Beccaria’s On Crimes and Punishments:  A Mirror of the History of the   Foundations of Modern Criminal Law , July 2013  649. Christopher Buccafusco  and Jonathan S. Masur , Innovation and Incarceration: An Economic  Analysis of Criminal Intellectual Property Law, July 2013  650.  Rosalind Dixon & Tom Ginsburg, The South African Constitutional C ourt and Socio -economic  Rights as “ Insurance Swaps ”, August 2013   651. Maciej H. Kotowski, David A. Weisbach, and Richard J. Zeckhauser, Audits as Signals, August  2013  652. Elisabeth J. Moyer, Michael D. Woolley, Michael J. Glotter, and David A. Weisbach, C limate  Impacts on Economic Growth as Drivers of Uncertainty in the Social Cost of Carbon, August 2013  653. Eric A. Posner and E. Glen Weyl, A Solution to the Collective Action Problem in Corporate Reorganization, September 2013   654. Gary Becker, François E wald, and Bernard Harcourt, “Becker and Foucault on Crime and  Punishment” —A Conversation with Gary Becker, François Ewald, and Bernard Harcourt: The  Second Session, September 2013   655. Edward R. Morrison, Arpit Gupta, Lenora M. Olson, Lawrence J. Cook, and Heather Keenan,  Health and Financial Fragility: Evidence from Automobile Crashes and Consumer Bankruptcy,  October 2013  656. Evidentiary Privileges in International Arbitration, Richard M. Mosk and Tom Ginsburg, October  2013  657. Voting Squared: Quadratic Voting in Democratic Politics, Eric A. Posner and E. Glen Weyl,  October 2013  658. The Impact of the U.S. Debit Card Interchange Fee Regulation on Consumer Welfare: An Event  Study Analysis, David S. Evans, Howard Chang, and Steven Joyce, October 2013  659. Lee Anne Fennell, Just Enough, October 2013   660. Benefit -Cost Paradigms in Financial Regulation, Eric A. Posner and E. Glen Weyl, April 2014   661. Free at Last? Judicial Discretion and Racial Disparities in Federal Sentencing, Crystal S. Yang, October 2013  662. Have Inter -Judge Sentencing Disparities Increased in an Advisory Guidelines Regime? Evidence  from Booker, Crystal S. Yang, March  2014   663. William H. J. Hubbard, A Theory of Pleading, Litigation, and Settlement, November 2013   664. Tom Ginsburg, Nick Fo ti, and Daniel Rockmore, “We the Peoples”: The Global Origins of  Constitutional Preambles, April 2014   665.  Lee Anne Fennell and Eduardo M. Peñalver, Exactions Creep, December 2013   666.  Lee Anne Fennell, Forcings, December  2013   667. Stephen J. Choi, Mitu Gulati, and Eric A. Posner, A Winner’s Curse?: Promotions from the Lower  Federal Courts, December 2013   668. Jose Antonio Cheibub, Zachary Elkins, and Tom Ginsburg, Beyond Presidentialism and  Parliamentarism, December 2013   669. Lisa Bernstein, Trade Usage i n the Courts: The Flawed Conceptual and Evidentiary Basis of  Article 2’s Incorporation Strategy, November 2013   670. Roger Allan Ford, Patent Invalidity versus Noninfringement, December 2013   671. M. Todd Henderson and William H.J. Hubbard, Do Judges Follow the Law? An Empirical Test of Congressional Control over Judicial Behavior, January 2014   672. Lisa Bernstein, Copying and Context: Tying as a Solution to the Lack of Intellectual Property  Protection of Contract Terms, January 2014       673. Eric A. Posner and A lan O. Sykes, Voting Rules in International Organizations, January 2014  674. Tom Ginsburg and Thomas J. Miles,  The Teaching/Research Tradeoff in Law: Data from the  Right Tail, February 2014  675. Ariel Porat and Eric Posner, Offsetting Benefits, February 20 14  676. Nuno Garoupa and Tom Ginsburg, Judicial Roles in Nonjudicial Functions, February 2014  677. Matthew B. Kugler, The Perceived Intrusiveness of S earching Electronic Devices at the Border:  An Empirical Study, February 2014   678. David S. Evans, Vanessa Yanhua Zhang, and Xinzhu Zhang, Assessing Unfair Pricing under  China's Anti -Monopoly Law for Innovation- Intensive Industries, March 2014   679. Jonathan S. Masur and Lisa Larrimore Ouellette, Deference Mistakes, March 2014   680. Omri Ben -Shahar and Carl E. Sc hneider, The Futility of Cost Benefit Analysis in Financial  Disclosure Regulation, March 2014   681. Yun-chien Chang and Lee Anne Fennell, Partition and Revelation, April 2014  682. Tom Ginsburg and James Melton, Does the Constitutional Amendment Rule Matter at All? Amendment Cultures and the Challenges of Measuring Amendment Difficulty, May 2014  683. Eric A. Posner and E. Glen Weyl, Cost -Benefit Analysis of Financial Regulations: A Response to  Criticisms, May 2014   684. Adam B. Badawi and Anthony J. Casey, The  Fannie and Freddie Bailouts Through the Corporate  Lens, March 2014   685. David S. Evans, Economic Aspects of Bitcoin and Other Decentralized Public- Ledger Currency  Platforms, April 2014  686. Preston M. Torbert, A Study of the Risks of Contract Ambiguity, M ay 2014  687. Adam S. Chilton, The Laws of War and Public Opinion: An Experimental Study, May 2014   688. Robert Cooter and Ariel Porat, Disgorgement for Accidents, May 2014   689. David Weisbach, Distributionally -Weighted Cost Benefit Analysis: Welfare Economi cs Meets  Organizational Design, June 2014   690. Robert Cooter and Ariel Porat, Lapses of Attention in Medical Malpractice and Road Accidents,  June 2014  691. William H. J. Hubbard, Nuisance Suits, June 2014   692. Saul Levmore & Ariel Porat, Credible Threats, July 2014  693. Douglas G. Baird, One -and-a-Half Badges of Fraud, August 2014   694. Adam Chilton and Mila Versteeg, Do Constitutional Rights Make a Difference? August 2014   695. Maria Bigoni, Stefania Bortolotti, Francesco Parisi, and Ariel Porat, Unbundling Efficient Breach, August 2014  696. Adam S. Chilton and Eric A. Posner, An Empirical Study of Political Bias in Legal Scholarship, August 2014   